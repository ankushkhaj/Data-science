{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "start=datetime.now()\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree,model_selection\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "# A convenience for displaying visualizations.\n",
    "from IPython.display import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "import gzip\n",
    "import numpy as np\n",
    "import json\n",
    "# Suppress annoying harmless error.\n",
    "warnings.filterwarnings(\n",
    "    action=\"ignore\",\n",
    "    module=\"scipy\",\n",
    "    message=\"^internal gelsd\"\n",
    ")\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "start=datetime.now()\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import re\n",
    "\n",
    "def parse(path):\n",
    "  g = gzip.open(path, 'rb')\n",
    "  for l in g:\n",
    "    yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "  i = 0\n",
    "  df = {}\n",
    "  for d in parse(path):\n",
    "    df[i] = d\n",
    "    i += 1\n",
    "  return pd.DataFrame.from_dict(df, orient='index')\n",
    "\n",
    "#df = getDF('C:/Users/ankush/Downloads/reviews_Pet_Supplies_5.json.gz')\n",
    "df=data = pd.read_json('C:/Personal/09142640/Downloads/Pet_Supplies_5.json',lines=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>overall</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1223000893</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>I purchased the Trilogy with hoping my two cat...</td>\n",
       "      <td>01 12, 2011</td>\n",
       "      <td>A14CK12J7C7JRK</td>\n",
       "      <td>Consumer in NorCal</td>\n",
       "      <td>Nice Distraction for my cats for about 15 minutes</td>\n",
       "      <td>1294790400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1223000893</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>5</td>\n",
       "      <td>There are usually one or more of my cats watch...</td>\n",
       "      <td>09 14, 2013</td>\n",
       "      <td>A39QHP5WLON5HV</td>\n",
       "      <td>Melodee Placial</td>\n",
       "      <td>Entertaining for my cats</td>\n",
       "      <td>1379116800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1223000893</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>4</td>\n",
       "      <td>I bought the triliogy and have tested out all ...</td>\n",
       "      <td>12 19, 2012</td>\n",
       "      <td>A2CR37UY3VR7BN</td>\n",
       "      <td>Michelle Ashbery</td>\n",
       "      <td>Entertaining</td>\n",
       "      <td>1355875200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1223000893</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>4</td>\n",
       "      <td>My female kitty could care less about these vi...</td>\n",
       "      <td>05 12, 2011</td>\n",
       "      <td>A2A4COGL9VW2HY</td>\n",
       "      <td>Michelle P</td>\n",
       "      <td>Happy to have them</td>\n",
       "      <td>1305158400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1223000893</td>\n",
       "      <td>[6, 7]</td>\n",
       "      <td>3</td>\n",
       "      <td>If I had gotten just volume two, I would have ...</td>\n",
       "      <td>03 5, 2012</td>\n",
       "      <td>A2UBQA85NIGLHA</td>\n",
       "      <td>Tim  Isenhour \"Timbo\"</td>\n",
       "      <td>You really only need vol 2</td>\n",
       "      <td>1330905600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         asin helpful  overall  \\\n",
       "0  1223000893  [0, 0]        3   \n",
       "1  1223000893  [0, 0]        5   \n",
       "2  1223000893  [0, 0]        4   \n",
       "3  1223000893  [2, 2]        4   \n",
       "4  1223000893  [6, 7]        3   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  I purchased the Trilogy with hoping my two cat...  01 12, 2011   \n",
       "1  There are usually one or more of my cats watch...  09 14, 2013   \n",
       "2  I bought the triliogy and have tested out all ...  12 19, 2012   \n",
       "3  My female kitty could care less about these vi...  05 12, 2011   \n",
       "4  If I had gotten just volume two, I would have ...   03 5, 2012   \n",
       "\n",
       "       reviewerID           reviewerName  \\\n",
       "0  A14CK12J7C7JRK     Consumer in NorCal   \n",
       "1  A39QHP5WLON5HV        Melodee Placial   \n",
       "2  A2CR37UY3VR7BN       Michelle Ashbery   \n",
       "3  A2A4COGL9VW2HY             Michelle P   \n",
       "4  A2UBQA85NIGLHA  Tim  Isenhour \"Timbo\"   \n",
       "\n",
       "                                             summary  unixReviewTime  \n",
       "0  Nice Distraction for my cats for about 15 minutes      1294790400  \n",
       "1                           Entertaining for my cats      1379116800  \n",
       "2                                       Entertaining      1355875200  \n",
       "3                                 Happy to have them      1305158400  \n",
       "4                         You really only need vol 2      1330905600  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count   55550.000\n",
       "mean        4.244\n",
       "std         1.182\n",
       "min         1.000\n",
       "25%         4.000\n",
       "50%         5.000\n",
       "75%         5.000\n",
       "max         5.000\n",
       "Name: overall, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['overall'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    purcha trilog hope two cat age 3 5 would inter...\n",
       "1    usual one cat watch tv stay troubl dvd play se...\n",
       "2    bought triliogi test dvd appear volum 2 well r...\n",
       "3    femal kitti could care less videosbut care les...\n",
       "4    gotten volum two would given five star sinc go...\n",
       "5    rotti food allergi poultri beef dairi ive diff...\n",
       "6    puppi love stuff tail start wag soon ask readi...\n",
       "7    toy poodl love stuff let 34sort34 brush teeth ...\n",
       "8    work great dog doesnt hate tast gum health imp...\n",
       "9    ye princess enjoy tast show get besttop result...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "##Stemming is the process of producing morphological variants of a root/base word. Stemming programs are commonly referred to as stemming algorithms or stemmers. A stemming algorithm reduces the words “chocolates”, “chocolatey”, “choco” to the root word, “chocolate” and “retrieval”, “retrieved”, “retrieves” reduce to the stem “retrieve”\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "#cleanup_re = re.compile('[^a-z]+')\n",
    "def cleanText(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    porter = PorterStemmer()\n",
    "    #text=cleanup_re.sub(' ',text)\n",
    "    text = text.lower()\n",
    "    \n",
    "    words = text.split()\n",
    "    words = [w.translate(table) for w in words]\n",
    "    words = [porter.stem(w) for w in words if not w in stop_words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "df['reviewText'] = df['reviewText'].apply(cleanText)\n",
    "df['reviewText'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21924 :  ['zzi', 'realli', 'play', 'much', 'thought', 'would', 'think', 'neat', 'make', 'fun', 'nois', 'bounc', 'floor', 'seem', 'interest', 'though', 'even', 'put', 'kibbl', 'insid', 'teeth', 'month', 'old', 'would', 'think', 'like', 'chew', 'rubber', 'ut', 'far', 'prefer', 'item', 'e', 'keep', 'work', 'though']\n",
      "12644 :  ['zzi', 'love', 'jolli', 'ball', 'blast', 'kick', 'throw', 'around', 'yard', 'run', 'around', 'handl', 'mouth', 'ball', 'strictli', 'outdoor', 'last', 'one', 'season', 'new', 'rlean', 'heat', 'rain', 'upload', 'pictur', 'play', 'super', 'fun', 'outdoor', 'toy', 'reason', 'gave', 'four', 'star', 'handl', 'give', 'dog', 'chew', 'drag', 'reinforc', 'handl', 'would', 'extend', 'longev', 'ball']\n",
      "17631 :  ['zoo', 'med', 'exoterra', 'wire', 'clamp', 'lamp', 'small', 'size', 'eram', 'eat', 'mitter', 'hook', 'thermostat', 'regul', 'temperatur', 'arriv', 'new', 'undamag', 'got', 'zoom', 'one', 'time', 'around', 'slightli', 'less', 'expens', 'exoterra', 'purchas', 'differ', 'terrarium', 'coupl', 'month', 'veral', 'seem', 'much', 'lower', 'qualiti', 'item', 'exoterra', 'one', 'label', 'indic', 'zoom', 'one', 'great', 'difficult', 'tell', 'whether', 'without', 'wait', 'bit', 'feel', 'bulb', 'area', 'clamp', 'attach', 'lamp', 'also', 'seem', 'less', 'secur', 'exoterra', 'fit', 'less', 'secur', 'zoo', 'med', 'version', 'caus', 'wonder', 'whether', 'would', 'stay', 'put', 'simpli', 'fall', 'zoom', 'version', 'also', 'requir', 'attach', 'clamp', 'portion', 'lamp', 'realli', 'big', 'deal', 'bit', 'annoy', 'would', 'recommend', 'spend', 'coupl', 'extra', 'dollar', 'buy', 'nicer', 'exoterra', 'wire', 'cage', 'clamp', 'lamp']\n",
      "52626 :  ['zodyl', 'given', 'us', 'second', 'chanc', 'ur', 'dog', 'late', 'stage', 'kidney', 'diseas', 'multipl', 'enlarg', 'cyst', 'advanc', 'heart', 'failur', 'mani', 'medic', 'imobendan', 'nalapril', 'urosemid', 'zodyl', 'one', 'help', 'dog', 'chang', 'energi', 'level', 'appetit', 'play', 'happi', 'overnight', 'es', 'overnight', 'rior', 'start', 'scari', 'day', 'zotemia', 'rrhythmia', 'well', 'constant', 'vommit', 'diarrhea', 'pup', 'respond', 'well', 'zodyl', 'veryon', 'famili', 'saw', 'happi', 'run', 'around', 'bounci', 'full', 'joy', 'e', 'think', 'zodyl', 'along', 'homemad', 'diet', 'fresh', 'meat', 'veggi', 'potato', 'pepcid', 'twice', 'day', 'given', 'dog', 'true', 'qualiti', 'life', 'feel', 'pup', 'homemad', 'fresh', 'food', 'diet', 'one', 'miss', 'link', 'review', 'onsult', 'pup', 'intern', 'med', 'specialist', 'cardiologist', 'treat', 'manag', 'kidney', 'stage', 'best', 'done', 'specialist', 'ost', 'organ', 'ill', 'treat', 'symptom', 'kidney', 'problem', 'becom', 'late', 'treat', 'pet', 'seed', 'first', 'sign', 'anyth', 'ordinari', 'us', 'start', 'pup', 'want', 'lay', 'cold', 'tile', 'instea', 'dof', 'snuggl', 'us', 'came', 'ind', 'leg', 'weak', 'increas', 'thirst', 'increas', 'urin', 'loss', 'energi', 'vommit', 'diarrhea', 'etc', 'ow', 'happi', 'symptom', 'free', 'pup', 'zodyl', 'oth', 'forev', 'mean', 'qualiti', 'time', 'togeth', 'could', 'ask', 'pet', 'experi', 'diseas', 'differ', 'ont', 'wait', 'late', 'diseas', 'manag', 'year', 'proper', 'diet', 'med', 'leas', 'googl', 'dogawar', 'kidney', 'diseas', 'best', 'pet', 'owner', 'hese', 'capsul', 'probiot', 'must', 'sold', 'reput', 'compani', 'must', 'ship', 'store', 'correctli', 'pet', 'must', 'consum', 'capsul', 'enter', 'coat', 'mean', 'absorb', 'intestin', 'effect', 'hould', 'consum', 'empti', 'stomach', 'small', 'amount', 'food', 'e', 'usual', 'give', 'min', 'meal', 'ood', 'luck', 'ememb', 'said', 'fresh', 'food', 'diet', 'see', 'specialist']\n",
      "53849 :  ['zodyl', 'capsul', 'recommend', 'vet', 'help', 'dog', 'kidney', 'failur', 'inc', 'chang', 'dog', 'food', 'give', 'supplement', 'stop', 'throw', 'feel', 'much', 'better', 'would', 'highli', 'recommend', 'supplement', 'anyon', 'whose', 'dog', 'renal', 'problem']\n",
      "32242 :  ['zipper', 'top', 'great', 'cat', 'skeptic', 'go', 'carrier', 'like', 'e', 'also', 'love', 'fold', 'easi', 'storag']\n",
      "24409 :  ['zip', 'tie', 'still', 'manag', 'fall', 'one', 'stay', 'small', 'one', 'use', 'pug']\n",
      "39130 :  ['zero', 'interest', 'toy', 'tri', 'throw', 'roll', 'spring', 'care']\n",
      "27979 :  ['zebra', 'finch', 'yr', 'old', 'e', 'pice', 'inch', 'cage', 'put', 'perch', 'cage', 'great', 'ebra', 'inch', 'get', 'exercis', 'fli', 'back', 'forth', 'time', 'perch', 'one', 'perch', 'love', 'sit', 'size', 'bird', 'finch', 'lovebird', 'use', 'kind', 'perch']\n",
      "4546 :  ['zebra', 'danio', 'realli', 'love', 'bloodworm', 'ven', 'flake', 'normal', 'give', 'say', 'varieti', 'food', 'sourc', 'rather', 'flake', 'make', 'happi']\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter \n",
    "split_it = df['reviewText'].str.split().to_dict()\n",
    "  \n",
    "# Pass the split_it list to instance of Counter class. \n",
    "Counter = Counter(split_it) \n",
    "  \n",
    "# most_common() produces k frequently encountered \n",
    "# input values and their respective counts. \n",
    "for word, count in Counter.most_common(10):\n",
    "    print(word, \": \", count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55550, 27261)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vect = CountVectorizer()\n",
    "X_counts = count_vect.fit_transform(df.reviewText)\n",
    "X_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(55550, 27261)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_tfidf = tfidf_transformer.fit_transform(X_counts)\n",
    "X_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_state']=[1 if x > 3 else 0 for x in df.overall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x168edf98>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['review_state'].value_counts().plot.bar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Y = [1 if x > 3 else 0 for x in df.overall]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "# Instantiate our model and store it in a new variable.\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=2)\n",
    "X_sampled,y_sampled = sm.fit_sample(X_tfidf,Y)\n",
    "X_train_sample,X_test_sample,y_train_sample,y_test_sample = train_test_split(X_sampled,y_sampled,test_size=.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.random_projection import sparse_random_matrix\n",
    "X_svd = TruncatedSVD(n_components=100, n_iter=7, random_state=42)\n",
    "X_svd.fit(X_train_sample)  \n",
    "X_train_svd = X_svd.transform(X_train_sample)\n",
    "X_test_svd = X_svd.transform(X_test_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6890617666718815\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "bnb = BernoulliNB() \n",
    "bnb = bnb.fit(X_train_svd, y_train_sample)\n",
    "y_pred_bnb = bnb.predict(X_train_svd)\n",
    "print(\"Accuracy:\", bnb.score(X_train_svd, y_train_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Random Forest\n",
    "rfc = ensemble.RandomForestClassifier(max_depth=10,n_estimators= 100)\n",
    "rfc.fit(X_train_svd, y_train_sample)\n",
    "y_pred_rfc = rfc.predict(X_train_svd)\n",
    "#Gridsearchcv to get the best parameters\n",
    "dt_grid={'max_depth':[3,4,5],'max_features': [50]}\n",
    "\n",
    "grid_class_rfc=model_selection.GridSearchCV(rfc,dt_grid,cv=6)\n",
    "grid_class_rfc.fit(X_train_svd, y_train_sample)\n",
    "results = grid_class_rfc.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class_rfc.best_params_)\n",
    "print(grid_class_rfc.best_score_)\n",
    "final_model = grid_class_rfc.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy for RandomForest:  [0.80272882 0.77828312 0.79079022 0.79806598 0.78498294 0.81171786\n",
      " 0.79396699 0.78941377 0.79567445 0.80250427]\n"
     ]
    }
   ],
   "source": [
    "print(\"Testing data accuracy for RandomForest: \",cross_val_score(rfc, X_test_svd, y_test_sample, cv=10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "logreg = linear_model.LogisticRegression(solver='lbfgs' , C=1000)\n",
    "logistic = logreg.fit(X_train_svd, y_train_sample)\n",
    "y_pred_lr = logreg.predict(X_train_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
