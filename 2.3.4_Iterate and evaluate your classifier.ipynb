{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = (\"C:/Personal/09142640/Desktop/Useful docs/Data science/amazon_sentiment.txt\")\n",
    "sms_raw = pd.read_csv(data_path, delimiter= '\\t', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sms_raw.columns=[\"Text\",\"Sentiments\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original features in Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_keywords = ['seamlessly','satisfied', 'happy', 'enjoyed', 'loved', 'prompt', 'great', 'excellent', 'favorite','good','amazing', 'delicious', 'right', 'love','like','recommended']\n",
    "negative_keywords = ['angry', 'slow', 'sucks', 'bad', 'disappointed', 'rude', 'avoid', 'never', 'waste','never', 'mistake', 'not good', 'not like', 'zero', 'dirty', 'bland','disaster','downside', 'joke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in positive_keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    sms_raw[str(key)] = sms_raw.Text.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sms_raw[positive_keywords]\n",
    "target = sms_raw['Sentiments']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unmatched positive statements out of a total 1001 points : 399\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of unmatched positive statements out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity value :  0.25\n",
      "Specificity  value :  0.9520958083832335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "C=confusion_matrix(target, y_pred)\n",
    "print(\"Sensitivity value : \", C[1,1] / (C[1,0]+C[1,1]) )\n",
    "print(\"Specificity  value : \", C[0,0] / (C[0,0]+C[0,1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.6019900497512438\n",
      "Testing on Sample: 0.6013986013986014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6039604, 0.6      , 0.61     , 0.6      , 0.61     , 0.62     ,\n",
       "       0.62     , 0.53     , 0.62     , 0.56     ])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modiying the classifier-Adding capitalised classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_keywords = ['seamlessly','satisfied', 'happy', 'enjoyed', 'loved', 'prompt', 'great', 'excellent', 'favorite','good','amazing', 'delicious', 'right', 'love','like','recommended','Seamlessly','Satisfied', 'Happy', 'Enjoyed', 'Loved', 'Prompt', 'Great', 'Excellent', 'Favorite','Good','Amazing', 'Delicious', 'Right', 'Love','Like','Recommended']\n",
    "negative_keywords = ['angry', 'slow', 'sucks', 'bad', 'disappointed', 'rude', 'avoid', 'never', 'waste','never', 'mistake', 'not good', 'not like', 'zero', 'dirty', 'bland','disaster','downside', 'joke','Angry', 'Slow', 'Sucks', 'Bad', 'Disappointed', 'Rude', 'Avoid', 'Never', 'Waste','Never', 'Mistake', 'Not Good', 'Not Like', 'Zero', 'Dirty', 'Bland','Disaster','Downside', 'Joke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in positive_keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    sms_raw[str(key)] = sms_raw.Text.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sms_raw[positive_keywords]\n",
    "target = sms_raw['Sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unmatched positive statements out of a total 1001 points : 399\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of unmatched positive statements out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity value :  0.25\n",
      "Specificity  value :  0.9520958083832335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "D=confusion_matrix(target, y_pred)\n",
    "print(\"Sensitivity value : \", D[1,1] / (D[1,0]+D[1,1]) )\n",
    "print(\"Specificity  value : \", D[0,0] / (D[0,0]+D[0,1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.6019900497512438\n",
      "Testing on Sample: 0.6013986013986014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6039604, 0.6      , 0.61     , 0.6      , 0.61     , 0.62     ,\n",
       "       0.62     , 0.53     , 0.62     , 0.56     ])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modiying the classifiers again 2nd time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_keywords = ['convenient','friendly','easy','fine','seamlessly','satisfied', 'happy', 'enjoyed', 'loved', 'prompt', 'great', 'excellent', 'favorite','good','amazing', 'delicious', 'right', 'love','like','recommended','Seamlessly','Satisfied', 'Happy', 'Enjoyed', 'Loved', 'Prompt', 'Great', 'Excellent', 'Favorite','Good','Amazing', 'Delicious', 'Right', 'Love','Like','Recommended']\n",
    "negative_keywords = ['angry', 'slow', 'sucks', 'bad', 'disappointed', 'rude', 'avoid', 'never', 'waste','never', 'mistake', 'not good', 'not like', 'zero', 'dirty', 'bland','disaster','downside', 'joke','Angry', 'Slow', 'Sucks', 'Bad', 'Disappointed', 'Rude', 'Avoid', 'Never', 'Waste','Never', 'Mistake', 'Not Good', 'Not Like', 'Zero', 'Dirty', 'Bland','Disaster','Downside', 'Joke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in positive_keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    sms_raw[str(key)] = sms_raw.Text.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sms_raw[positive_keywords]\n",
    "target = sms_raw['Sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unmatched positive statements out of a total 1001 points : 399\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of unmatched positive statements out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity value :  0.282\n",
      "Specificity  value :  0.9461077844311377\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "E=confusion_matrix(target, y_pred)\n",
    "print(\"Sensitivity value : \", E[1,1] / (E[1,0]+E[1,1]) )\n",
    "print(\"Specificity  value : \", E[0,0] / (E[0,0]+E[0,1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.6019900497512438\n",
      "Testing on Sample: 0.6013986013986014\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.6039604, 0.6      , 0.61     , 0.6      , 0.61     , 0.62     ,\n",
       "       0.62     , 0.53     , 0.62     , 0.56     ])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing the capitalised classifiers and adding more classifiers 3rd time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_keywords = ['impressed','cool','convenient','friendly','easy','fine','seamlessly','satisfied', 'happy', 'enjoyed', 'loved', 'prompt', 'great', 'excellent', 'favorite','good','amazing', 'delicious', 'right', 'love','like','recommended']\n",
    "negative_keywords = ['angry', 'slow', 'sucks', 'bad', 'disappointed', 'rude', 'avoid', 'never', 'waste','never', 'mistake', 'not good', 'not like', 'zero', 'dirty', 'bland','disaster','downside', 'joke','Angry', 'Slow', 'Sucks', 'Bad', 'Disappointed', 'Rude', 'Avoid', 'Never', 'Waste','Never', 'Mistake', 'Not Good', 'Not Like', 'Zero', 'Dirty', 'Bland','Disaster','Downside', 'Joke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in positive_keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    sms_raw[str(key)] = sms_raw.Text.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sms_raw[positive_keywords]\n",
    "target = sms_raw['Sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unmatched positive statements out of a total 1001 points : 383\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of unmatched positive statements out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity value :  0.296\n",
      "Specificity  value :  0.93812375249501\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "F=confusion_matrix(target, y_pred)\n",
    "print(\"Sensitivity value : \", F[1,1] / (F[1,0]+F[1,1]) )\n",
    "print(\"Specificity  value : \", F[0,0] / (F[0,0]+F[0,1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.6069651741293532\n",
      "Testing on Sample: 0.6173826173826173\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62376238, 0.6       , 0.61      , 0.6       , 0.61      ,\n",
       "       0.61      , 0.65      , 0.57      , 0.63      , 0.59      ])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding more classifiers 4th time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_keywords = ['fixes','Easy','outperform','AWESOME','high quality','impressed','cool','convenient','friendly','easy','fine','seamlessly','satisfied', 'happy', 'enjoyed', 'loved', 'prompt', 'great', 'excellent', 'favorite','good','amazing', 'delicious', 'right', 'love','like','recommended']\n",
    "negative_keywords = ['angry', 'slow', 'sucks', 'bad', 'disappointed', 'rude', 'avoid', 'never', 'waste','never', 'mistake', 'not good', 'not like', 'zero', 'dirty', 'bland','disaster','downside', 'joke','Angry', 'Slow', 'Sucks', 'Bad', 'Disappointed', 'Rude', 'Avoid', 'Never', 'Waste','Never', 'Mistake', 'Not Good', 'Not Like', 'Zero', 'Dirty', 'Bland','Disaster','Downside', 'Joke']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in positive_keywords:\n",
    "    # Note that we add spaces around the key so that we're getting the word,\n",
    "    # not just pattern matching.\n",
    "    sms_raw[str(key)] = sms_raw.Text.str.contains(\n",
    "        ' ' + str(key) + ' ',\n",
    "        case=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sms_raw[positive_keywords]\n",
    "target = sms_raw['Sentiments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unmatched positive statements out of a total 1001 points : 379\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(data, target)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(data)\n",
    "\n",
    "# Display our results.\n",
    "print(\"Number of unmatched positive statements out of a total {} points : {}\".format(\n",
    "    data.shape[0],\n",
    "    (target != y_pred).sum()\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity value :  0.304\n",
      "Specificity  value :  0.93812375249501\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "G=confusion_matrix(target, y_pred)\n",
    "print(\"Sensitivity value : \", G[1,1] / (G[1,0]+G[1,1]) )\n",
    "print(\"Specificity  value : \", G[0,0] / (G[0,0]+G[0,1]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "With 20% Holdout: 0.6069651741293532\n",
      "Testing on Sample: 0.6213786213786214\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# Use train_test_split to create the necessary training and test groups\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.2, random_state=20)\n",
    "print('With 20% Holdout: ' + str(bnb.fit(X_train, y_train).score(X_test, y_test)))\n",
    "print('Testing on Sample: ' + str(bnb.fit(data, target).score(data, target)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.62376238, 0.6       , 0.61      , 0.6       , 0.61      ,\n",
       "       0.61      , 0.65      , 0.57      , 0.63      , 0.59      ])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(bnb, data, target, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding more features in the last iteration of  classifiers outperformed all the other classifiers\n",
    "Do any of your classifiers seem to overfit?If we use all the data in our training set,overfitting will occur.Since we are training the model with all the data multiple times.There is ovefitting error.\n",
    "Which seem to perform the best? Why?The last iteration seem to perfomed the data interms of accuracy and performance\n",
    "Which features seemed to be most impactful to performance? Adding new features and capitalising existing features impacted the performance to improve in the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
