{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.6.2 Airline Arrival "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this airline arrival  and departure dataset develop an algorithm to predict flight delays. Prioritize correctly finding delayed flights and labelling them as delayed.\n",
    "\n",
    "Data Source: Kaggle Data Set \n",
    "URL-https:http://stat-computing.org/dataexpo/2009/the-data.html\n",
    "\n",
    "Description: The datasets contains flights arrival and departure details.This data set has 29 columns and all the relevant data to get information of delayed flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "start=datetime.now()\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree,model_selection\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "# A convenience for displaying visualizations.\n",
    "from IPython.display import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n",
    "\n",
    "# Suppress annoying harmless error.\n",
    "warnings.filterwarnings(\n",
    "    action=\"ignore\",\n",
    "    module=\"scipy\",\n",
    "    message=\"^internal gelsd\"\n",
    ")\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "start=datetime.now()\n",
    "rfc = ensemble.RandomForestClassifier()\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:/Personal/09142640/Downloads/2008.csv').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>...</th>\n",
       "      <th>TaxiIn</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>CancellationCode</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2003.000</td>\n",
       "      <td>1955</td>\n",
       "      <td>2211.000</td>\n",
       "      <td>2225</td>\n",
       "      <td>WN</td>\n",
       "      <td>335</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>754.000</td>\n",
       "      <td>735</td>\n",
       "      <td>1002.000</td>\n",
       "      <td>1000</td>\n",
       "      <td>WN</td>\n",
       "      <td>3231</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>628.000</td>\n",
       "      <td>620</td>\n",
       "      <td>804.000</td>\n",
       "      <td>750</td>\n",
       "      <td>WN</td>\n",
       "      <td>448</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000</td>\n",
       "      <td>17.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>926.000</td>\n",
       "      <td>930</td>\n",
       "      <td>1054.000</td>\n",
       "      <td>1100</td>\n",
       "      <td>WN</td>\n",
       "      <td>1746</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000</td>\n",
       "      <td>7.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1829.000</td>\n",
       "      <td>1755</td>\n",
       "      <td>1959.000</td>\n",
       "      <td>1925</td>\n",
       "      <td>WN</td>\n",
       "      <td>3920</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>32.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  DayofMonth  DayOfWeek  DepTime  CRSDepTime  ArrTime  \\\n",
       "0  2008      1           3          4 2003.000        1955 2211.000   \n",
       "1  2008      1           3          4  754.000         735 1002.000   \n",
       "2  2008      1           3          4  628.000         620  804.000   \n",
       "3  2008      1           3          4  926.000         930 1054.000   \n",
       "4  2008      1           3          4 1829.000        1755 1959.000   \n",
       "\n",
       "   CRSArrTime UniqueCarrier  FlightNum        ...         TaxiIn  TaxiOut  \\\n",
       "0        2225            WN        335        ...          4.000    8.000   \n",
       "1        1000            WN       3231        ...          5.000   10.000   \n",
       "2         750            WN        448        ...          3.000   17.000   \n",
       "3        1100            WN       1746        ...          3.000    7.000   \n",
       "4        1925            WN       3920        ...          3.000   10.000   \n",
       "\n",
       "   Cancelled  CancellationCode  Diverted  CarrierDelay WeatherDelay NASDelay  \\\n",
       "0          0                 0         0         0.000        0.000    0.000   \n",
       "1          0                 0         0         0.000        0.000    0.000   \n",
       "2          0                 0         0         0.000        0.000    0.000   \n",
       "3          0                 0         0         0.000        0.000    0.000   \n",
       "4          0                 0         0         2.000        0.000    0.000   \n",
       "\n",
       "   SecurityDelay  LateAircraftDelay  \n",
       "0          0.000              0.000  \n",
       "1          0.000              0.000  \n",
       "2          0.000              0.000  \n",
       "3          0.000              0.000  \n",
       "4          0.000             32.000  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>DayofMonth</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>DepTime</th>\n",
       "      <th>CRSDepTime</th>\n",
       "      <th>ArrTime</th>\n",
       "      <th>CRSArrTime</th>\n",
       "      <th>UniqueCarrier</th>\n",
       "      <th>FlightNum</th>\n",
       "      <th>...</th>\n",
       "      <th>TaxiOut</th>\n",
       "      <th>Cancelled</th>\n",
       "      <th>CancellationCode</th>\n",
       "      <th>Diverted</th>\n",
       "      <th>CarrierDelay</th>\n",
       "      <th>WeatherDelay</th>\n",
       "      <th>NASDelay</th>\n",
       "      <th>SecurityDelay</th>\n",
       "      <th>LateAircraftDelay</th>\n",
       "      <th>Delay_30</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2003.000</td>\n",
       "      <td>1955</td>\n",
       "      <td>2211.000</td>\n",
       "      <td>2225</td>\n",
       "      <td>WN</td>\n",
       "      <td>335</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>754.000</td>\n",
       "      <td>735</td>\n",
       "      <td>1002.000</td>\n",
       "      <td>1000</td>\n",
       "      <td>WN</td>\n",
       "      <td>3231</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>628.000</td>\n",
       "      <td>620</td>\n",
       "      <td>804.000</td>\n",
       "      <td>750</td>\n",
       "      <td>WN</td>\n",
       "      <td>448</td>\n",
       "      <td>...</td>\n",
       "      <td>17.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>926.000</td>\n",
       "      <td>930</td>\n",
       "      <td>1054.000</td>\n",
       "      <td>1100</td>\n",
       "      <td>WN</td>\n",
       "      <td>1746</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1829.000</td>\n",
       "      <td>1755</td>\n",
       "      <td>1959.000</td>\n",
       "      <td>1925</td>\n",
       "      <td>WN</td>\n",
       "      <td>3920</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>32.000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  DayofMonth  DayOfWeek  DepTime  CRSDepTime  ArrTime  \\\n",
       "0  2008      1           3          4 2003.000        1955 2211.000   \n",
       "1  2008      1           3          4  754.000         735 1002.000   \n",
       "2  2008      1           3          4  628.000         620  804.000   \n",
       "3  2008      1           3          4  926.000         930 1054.000   \n",
       "4  2008      1           3          4 1829.000        1755 1959.000   \n",
       "\n",
       "   CRSArrTime UniqueCarrier  FlightNum    ...    TaxiOut  Cancelled  \\\n",
       "0        2225            WN        335    ...      8.000          0   \n",
       "1        1000            WN       3231    ...     10.000          0   \n",
       "2         750            WN        448    ...     17.000          0   \n",
       "3        1100            WN       1746    ...      7.000          0   \n",
       "4        1925            WN       3920    ...     10.000          0   \n",
       "\n",
       "   CancellationCode  Diverted  CarrierDelay  WeatherDelay NASDelay  \\\n",
       "0                 0         0         0.000         0.000    0.000   \n",
       "1                 0         0         0.000         0.000    0.000   \n",
       "2                 0         0         0.000         0.000    0.000   \n",
       "3                 0         0         0.000         0.000    0.000   \n",
       "4                 0         0         2.000         0.000    0.000   \n",
       "\n",
       "  SecurityDelay  LateAircraftDelay  Delay_30  \n",
       "0         0.000              0.000         1  \n",
       "1         0.000              0.000         0  \n",
       "2         0.000              0.000         1  \n",
       "3         0.000              0.000         0  \n",
       "4         0.000             32.000         1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Delay_30'] = np.where((data['ArrTime']-data['CRSArrTime'] >= 30)|(data['DepTime']-data['CRSDepTime'] >= 30) , 1, 0)\n",
    "Delay_filter_30=data['Delay_30']==1\n",
    "Delay_filter_nl30=data['Delay_30']!=1\n",
    "data1=data[Delay_filter_30]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total delays per month Month\n",
      "1     145716\n",
      "2     152465\n",
      "3     154913\n",
      "4     120650\n",
      "5     118862\n",
      "6     161321\n",
      "7     141344\n",
      "8     123873\n",
      "9      73994\n",
      "10     77516\n",
      "11     83845\n",
      "12    166461\n",
      "Name: Delay_30, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(\"Total delays per month\",data1.groupby('Month')['Delay_30'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of delayed flights is 21.70%\n"
     ]
    }
   ],
   "source": [
    "data3=data[Delay_filter_30].shape[0]\n",
    "data4=data[Delay_filter_nl30].shape[0]\n",
    "print(\"Percentage of delayed flights is {0:.2f}%\".format(data3/(data3+data4)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Total number of Delays  month wise')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "data1.groupby('Month')['Delay_30'].sum().plot(kind='bar')\n",
    "plt.ylabel('Total number of Delays',fontsize=10)\n",
    "plt.title('Total number of Delays  month wise')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see there are highest delays for more than 30 minutes in the month of December and then followed by other months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=data['Delay_30']\n",
    "X=data[['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime',\n",
    "       'ArrTime', 'CRSArrTime', 'FlightNum',\n",
    "       'ActualElapsedTime', 'CRSElapsedTime','AirTime','ArrDelay','DepDelay','Distance', 'Cancelled', 'Diverted']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using 7 Classification models -Naive Bayes, KNN models ,Decision tree, Random forest,Logistic Regression, SVC,Gradient Boosting to get the accuracy for each model and decide which model will be better suited to the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=datetime.now()\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "# Instantiate our model and store it in a new variable.\n",
    "bnb = BernoulliNB()\n",
    "\n",
    "# Fit our model to the data.\n",
    "bnb.fit(X_train, y_train)\n",
    "\n",
    "# Classify, storing the result in a new variable.\n",
    "y_pred = bnb.predict(X_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have fitted the data to Naive Bayes model so we need to calcuate the accuracy score using Cross verification,grid search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.86070805 0.86144809 0.86061864 0.86079875 0.85992318 0.86135155\n",
      " 0.86099669 0.86123921 0.86096459 0.86084868]\n",
      "Testing data accuracy:  [0.86313349 0.85890367 0.85884661 0.86126467 0.86007347 0.85933165\n",
      " 0.86102928 0.86032312 0.86218285 0.86191893]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(bnb, X_train, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(bnb, X_test, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy score looks to be good.There is no need to use gridearchcv since there are no such hyper-paramters to tune.Now,lets go ahead with Classification report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.86      0.91   4391190\n",
      "          1       0.63      0.85      0.73   1216592\n",
      "\n",
      "avg / total       0.89      0.86      0.87   5607782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8580951603607022\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report and AUC accuracy seems to be good.Its F1-score looks to be good as well.Now, we are going to use PCA to get the optimum number of components to improve the accuracy of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = PCA(n_components=7)\n",
    "X_pca.fit(X_train)\n",
    "X_train_pca = X_pca.transform(X_train)\n",
    "X_test_pca = X_pca.transform(X_test)\n",
    "#Using BNB on reduced PCA dataset \n",
    "bnb.fit(X_train_pca, y_train)\n",
    "y_pred = bnb.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of total variance in the dataset explained by each component from Sklearn PCA.\n",
      " [7.50815418e-01 1.57995634e-01 5.53153343e-02 2.03982247e-02\n",
      " 1.20461842e-02 2.75690231e-03 4.58571404e-04]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'The percentage of total variance in the dataset explained by each',\n",
    "    'component from Sklearn PCA.\\n',\n",
    "    X_pca.explained_variance_ratio_\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.89035788 0.8909196  0.89022216 0.88983519 0.88919858 0.89026139\n",
      " 0.88983698 0.89087304 0.89094972 0.88971393]\n",
      "Testing data accuracy:  [0.89068797 0.89023146 0.88982489 0.88923285 0.88928278 0.88884768\n",
      " 0.89053818 0.88988195 0.89119999 0.89011577]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(bnb, X_train_pca, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(bnb, X_test_pca, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.91      0.93   4391190\n",
      "          1       0.71      0.82      0.76   1216592\n",
      "\n",
      "avg / total       0.90      0.89      0.89   5607782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification matrix is looking good.F-score is on the better side which is a good news.Its looks like using PCA has improved the results.Now,lets use Confusion Matrix to check the accuracy as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3990627  400563]\n",
      " [ 215077 1001515]]\n",
      "Accuracy Score : 0.8902168450913391\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('Accuracy Score :',accuracy_score(y_train, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8659969210220574\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confusion Matrix and AUC accuracy is very good.Now,we are going to use selectkbest to get the best features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year nan\n",
      "Month 9105.920928078025\n",
      "DayofMonth 0.19998160169708612\n",
      "DayOfWeek 729.2934591247921\n",
      "DepTime 295845.0283246868\n",
      "CRSDepTime 115012.21551382955\n",
      "ArrTime 146929.82888242597\n",
      "CRSArrTime 90627.58840487583\n",
      "FlightNum 232.6334491362069\n",
      "ActualElapsedTime 78044.0723908888\n",
      "CRSElapsedTime 16456.00912983227\n",
      "AirTime 30051.566946492214\n",
      "ArrDelay 3484241.265263476\n",
      "DepDelay 2728484.956354014\n",
      "Distance 10972.077758931988\n",
      "Cancelled 30155.756866015516\n",
      "Diverted 2868.9687624607855\n"
     ]
    }
   ],
   "source": [
    "#selectkbest to get the scores of the best parameters\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "names =['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime',\n",
    "       'ArrTime', 'CRSArrTime', 'FlightNum',\n",
    "       'ActualElapsedTime', 'CRSElapsedTime','AirTime','ArrDelay','DepDelay','Distance', 'Cancelled', 'Diverted']\n",
    "#names = X_train.columns[indices[:n_indices]]\n",
    "skb = SelectKBest(score_func=f_classif,k=7)\n",
    "X_train_kbest = skb.fit_transform(X_train, y_train)\n",
    "for n in range(0, len(names)):\n",
    " print(names[n], skb.scores_[n])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#Fitting and transforming data to selectkbest\n",
    "skb.fit(X_train, y_train)\n",
    "X_train_skb = skb.transform(X_train)\n",
    "X_test_skb = skb.transform(X_test)\n",
    "bnb.fit(X_train_skb, y_train)\n",
    "y_pred = bnb.predict(X_train_skb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using cross validation to get the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.86070983 0.86144809 0.86062042 0.86079875 0.85992496 0.86135155\n",
      " 0.86099669 0.86124099 0.86096459 0.86085224]\n",
      "Testing data accuracy:  [0.86313349 0.85890367 0.85884661 0.86126467 0.86007347 0.85933165\n",
      " 0.86102928 0.86032312 0.86218285 0.86191893]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(bnb, X_train_skb, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(bnb, X_test_skb, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.86      0.91   4391190\n",
      "          1       0.63      0.85      0.73   1216592\n",
      "\n",
      "avg / total       0.89      0.86      0.87   5607782\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the classification report is good.We need to play with the value of k to get the optimum accuracy.When k=7, the f1-score  becomes good.One thing we noticed , if you do not play with k values there might be lot of variance in the accuracy using classification report.Now,lets get the accuracy using confusion matrix and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3789736  601454]\n",
      " [ 178640 1037952]]\n",
      "Accuracy Score : 0.860890812089343\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('Accuracy Score :',accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.858097626265459\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we notice above, the accuracy score is good using both Confusion Matrix and AUC.We did notice that accuracy of the model using PCA is better than using selectkbest.Also, there is significant fluctuation in accuracy  when using Selectkbest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:12:56.094500\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN model Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=datetime.now()\n",
    "knn_model = KNeighborsClassifier(n_neighbors=1)\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred = knn_model.predict(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have fitted the data to KNN Classifier model so we need to calcuate the accuracy score using Cross verification,grid search cv,Classification report, AUC and Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets go ahead with Gridsearchcv and find out its accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'leaf_size': 1, 'n_neighbors': 5}, {'leaf_size': 1, 'n_neighbors': 6}, {'leaf_size': 2, 'n_neighbors': 5}, {'leaf_size': 2, 'n_neighbors': 6}]\n",
      "[0.95220537 0.93966931 0.95220537 0.9396717 ]\n",
      "[0.96914503 0.9550664  0.96914503 0.9550664 ]\n",
      "Best Hyper Parameters:\n",
      " {'leaf_size': 1, 'n_neighbors': 5}\n",
      "0.9522053739598979\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "params = {'n_neighbors':[5,6],\n",
    "          'leaf_size':[1,2]\n",
    "                  }\n",
    "#Making models with hyper parameters sets\n",
    "grid_class = model_selection.GridSearchCV(knn_model, param_grid=params)\n",
    "#Learning\n",
    "grid_class.fit(X_train,y_train)\n",
    "#The best hyper parameters set\n",
    "\n",
    "results = grid_class.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class.best_params_)\n",
    "print(grid_class.best_score_)\n",
    "final_model = grid_class.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.97909067 0.97869728 0.97814892 0.97828005 0.97838734 0.97804163\n",
      " 0.97801779 0.97802971 0.97781513 0.97832773]\n",
      "Testing data accuracy:  [0.94406828 0.94683387 0.94573717 0.94559413 0.94464047 0.94726302\n",
      " 0.94607095 0.94454246 0.94487363 0.94606581]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(knn_model, X_train, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(knn_model, X_test, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see above,cross validation accuracy score looks to be very good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    627450\n",
      "          1       1.00      1.00      1.00    211410\n",
      "\n",
      "avg / total       1.00      1.00      1.00    838860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report and AUC seem to be perfect even before using dimension reduction technique PCA.Now,lets use PCA to get the accuracy using Gridsearch,Cross validation,classification report,Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA to get the best features/components\n",
    "X_pca = PCA(n_components=7)\n",
    "X_pca.fit(X_train)\n",
    "X_train_pca = X_pca.transform(X_train)\n",
    "X_test_pca = X_pca.transform(X_test)\n",
    "#Using BNB on reduced PCA dataset \n",
    "knn_model.fit(X_train_pca, y_train)\n",
    "y_pred = knn_model.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of total variance in the dataset explained by each component from Sklearn PCA.\n",
      " [7.53890305e-01 1.57844213e-01 4.97324466e-02 2.08602984e-02\n",
      " 1.40471259e-02 2.88932045e-03 4.98410545e-04]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'The percentage of total variance in the dataset explained by each',\n",
    "    'component from Sklearn PCA.\\n',\n",
    "    X_pca.explained_variance_ratio_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows the variance per component which looks ok.Now,we will use Gridsearch cv to get the best hyper parameters to improve the accuracy and performance of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'leaf_size': 1, 'n_neighbors': 5}, {'leaf_size': 1, 'n_neighbors': 6}, {'leaf_size': 2, 'n_neighbors': 5}, {'leaf_size': 2, 'n_neighbors': 6}]\n",
      "[0.95469089 0.94280214 0.95469089 0.94280214]\n",
      "[0.97077283 0.95758291 0.97077283 0.95758291]\n",
      "Best Hyper Parameters:\n",
      " {'leaf_size': 1, 'n_neighbors': 5}\n",
      "0.9546908900174046\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Using Grid search  for finding the best set of parameters with random Forest model\n",
    "params = {'n_neighbors':[5,6],\n",
    "          'leaf_size':[1,2]\n",
    "                  }\n",
    "#Making models with hyper parameters sets\n",
    "grid_class = model_selection.GridSearchCV(knn_model, param_grid=params)\n",
    "#Learning\n",
    "grid_class.fit(X_train_pca,y_train)\n",
    "#The best hyper parameters set\n",
    "\n",
    "results = grid_class.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class.best_params_)\n",
    "print(grid_class.best_score_)\n",
    "final_model = grid_class.best_estimator_\n",
    "print(final_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.98103378 0.98077152 0.98021124 0.97963903 0.98040197 0.97986553\n",
      " 0.98030661 0.97963903 0.97999666 0.98016356]\n",
      "Testing data accuracy:  [0.94654778 0.94821667 0.94778753 0.94807362 0.94735838 0.94983788\n",
      " 0.94878886 0.94706976 0.94687649 0.94749642]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(knn_model, X_train_pca, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(knn_model, X_test_pca, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    627450\n",
      "          1       1.00      1.00      1.00    211410\n",
      "\n",
      "avg / total       1.00      1.00      1.00    838860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[627450      0]\n",
      " [     0 211410]]\n",
      "Accuracy Score : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('Accuracy Score :',accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed above,Classification report,Confusion matrix ,AUC have very good accuracy scores.Now, we will use another dimension reduction technique -selectkbest to get the  optimum features and will compare the accuracies with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year nan\n",
      "Month 808.9553696705038\n",
      "DayofMonth 403.2220170656302\n",
      "DayOfWeek 79.25829433649136\n",
      "DepTime 48053.52560992163\n",
      "CRSDepTime 14475.04324695549\n",
      "ArrTime 26834.577245858956\n",
      "CRSArrTime 11577.911251133937\n",
      "FlightNum 1547.4690296947113\n",
      "ActualElapsedTime 9970.953035997813\n",
      "CRSElapsedTime 592.5105036295506\n",
      "AirTime 3248.3114961646806\n",
      "ArrDelay 529776.2587817839\n",
      "DepDelay 413990.54075245414\n",
      "Distance 340.9383439359148\n",
      "Cancelled 9575.119516998262\n",
      "Diverted 95.96391089238634\n"
     ]
    }
   ],
   "source": [
    "#selectkbest to get the scores of the best parameters\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "names =['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime',\n",
    "       'ArrTime', 'CRSArrTime', 'FlightNum',\n",
    "       'ActualElapsedTime', 'CRSElapsedTime','AirTime','ArrDelay','DepDelay','Distance', 'Cancelled', 'Diverted']\n",
    "#names = X_train.columns[indices[:n_indices]]\n",
    "skb = SelectKBest(score_func=f_classif,k=7)\n",
    "X_train_kbest = skb.fit_transform(X_train, y_train)\n",
    "for n in range(0, len(names)):\n",
    " print(names[n], skb.scores_[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#Fitting and transforming data to selectkbest\n",
    "skb.fit(X_train, y_train)\n",
    "X_train_skb = skb.transform(X_train)\n",
    "X_test_skb = skb.transform(X_test)\n",
    "knn_model.fit(X_train_skb, y_train)\n",
    "y_pred = knn_model.predict(X_train_skb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use Seleckbest transformed data to get the accuracy using gridsearchcv,cross validation,classification report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'leaf_size': 1, 'n_neighbors': 5}, {'leaf_size': 1, 'n_neighbors': 6}, {'leaf_size': 1, 'n_neighbors': 7}, {'leaf_size': 2, 'n_neighbors': 5}, {'leaf_size': 2, 'n_neighbors': 6}, {'leaf_size': 2, 'n_neighbors': 7}]\n",
      "[0.99216794 0.99072551 0.99153375 0.99216913 0.99072312 0.99153613]\n",
      "[0.99499022 0.99299704 0.99379575 0.99499201 0.99299526 0.99379336]\n",
      "Best Hyper Parameters:\n",
      " {'leaf_size': 2, 'n_neighbors': 5}\n",
      "0.9921691343013137\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=2, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Gridsearch cv to get the best peforming hyper parameters\n",
    "params = {'n_neighbors':[5,6,7],\n",
    "          'leaf_size':[1,2]\n",
    "                  }\n",
    "#Making models with hyper parameters sets\n",
    "grid_class = model_selection.GridSearchCV(knn_model, param_grid=params)\n",
    "#Learning\n",
    "grid_class.fit(X_train_skb,y_train)\n",
    "#The best hyper parameters set\n",
    "\n",
    "results = grid_class.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class.best_params_)\n",
    "print(grid_class.best_score_)\n",
    "final_model = grid_class.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.99395608 0.99403953 0.99387264 0.99359846 0.99407529 0.99325275\n",
      " 0.99350309 0.99378919 0.99365806 0.99378919]\n",
      "Testing data accuracy:  [0.99022506 0.99108335 0.99108335 0.98936677 0.99008201 0.98888995\n",
      " 0.99046348 0.99027228 0.98941345 0.98955651]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(knn_model, X_train_skb, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(knn_model, X_test_skb, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    627450\n",
      "          1       1.00      1.00      1.00    211410\n",
      "\n",
      "avg / total       1.00      1.00      1.00    838860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[627450      0]\n",
      " [     0 211410]]\n",
      "Accuracy Score : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('Accuracy Score :',accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:47:03.925000\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed above, Cross validation, Classification Report, Confusion Matrix ,AUC have very good accuracies.If we compare both PCA and Selectkbest,there doesnt seem to be much difference in terms of accuracies and run time is almost similar as well"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=datetime.now()\n",
    "decision_tree = tree.DecisionTreeClassifier(max_depth=50)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "y_pred = decision_tree.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have fitted the data to Decision Tree model so we need to calcuate the accuracy score using grid search cv,Cross verification,Classification report, AUC and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'leaf_size': 1, 'n_neighbors': 5}, {'leaf_size': 1, 'n_neighbors': 6}, {'leaf_size': 1, 'n_neighbors': 7}, {'leaf_size': 2, 'n_neighbors': 5}, {'leaf_size': 2, 'n_neighbors': 6}, {'leaf_size': 2, 'n_neighbors': 7}]\n",
      "[0.99216794 0.99072551 0.99153375 0.99216913 0.99072312 0.99153613]\n",
      "[0.99499022 0.99299704 0.99379575 0.99499201 0.99299526 0.99379336]\n",
      "Best Hyper Parameters:\n",
      " {'leaf_size': 2, 'n_neighbors': 5}\n",
      "0.9921691343013137\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=2, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "dt_grid={'max_depth':[50],'max_features': [11]}\n",
    "grid_class_dt=model_selection.GridSearchCV(decision_tree,dt_grid,cv=10)\n",
    "grid_class_dt.fit(X_train, y_train)\n",
    "results = grid_class.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class.best_params_)\n",
    "print(grid_class.best_score_)\n",
    "final_model = grid_class.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.93508142 0.92734678 0.92472064 0.93553975 0.93044739 0.93338219\n",
      " 0.94600224 0.93219615 0.91842228 0.94580778]\n",
      "Testing data accuracy:  [0.88627732 0.8606374  0.83601347 0.89722042 0.89166293 0.85862593\n",
      " 0.86537165 0.89297038 0.85236773 0.86037227]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(decision_tree, X_train, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(decision_tree, X_test, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross validation accuracy seems ok..Lets go ahead with Classification report and AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    627450\n",
      "          1       1.00      1.00      1.00    211410\n",
      "\n",
      "avg / total       1.00      1.00      1.00    838860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification report and AUC seem to be perfect even before using dimension reduction technique PCA.Now,lets use PCA to get the accuracy using Gridsearch,Cross validation,classification report,Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA to get the best features/components\n",
    "X_pca = PCA(n_components=7)\n",
    "X_pca.fit(X_train)\n",
    "X_train_pca = X_pca.transform(X_train)\n",
    "X_test_pca = X_pca.transform(X_test)\n",
    "#Using Decision Tree on reduced PCA dataset \n",
    "decision_tree.fit(X_train_pca, y_train)\n",
    "y_pred = decision_tree.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of total variance in the dataset explained by each component from Sklearn PCA.\n",
      " [7.53890305e-01 1.57844213e-01 4.97324466e-02 2.08602984e-02\n",
      " 1.40471259e-02 2.88932045e-03 4.98410545e-04]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'The percentage of total variance in the dataset explained by each',\n",
    "    'component from Sklearn PCA.\\n',\n",
    "    X_pca.explained_variance_ratio_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows the variance per component which looks ok.Now,we will use Gridsearch cv to get the best hyper parameters to improve the accuracy and performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 50, 'max_features': 7}]\n",
      "[0.98286126]\n",
      "[1.]\n",
      "Best Hyper Parameters:\n",
      " {'max_depth': 50, 'max_features': 7}\n",
      "0.982861264096512\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=50,\n",
      "            max_features=7, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Using Grid search  for finding the best set of parameters with random Forest model\n",
    "dt_grid={'max_depth':[50],'max_features': [7]}\n",
    "grid_class=model_selection.GridSearchCV(decision_tree,dt_grid,cv=6)\n",
    "grid_class.fit(X_train_pca, y_train)\n",
    "results = grid_class.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class.best_params_)\n",
    "print(grid_class.best_score_)\n",
    "final_model = grid_class.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.98344181 0.98433588 0.9837756  0.98327492 0.98382328 0.98372792\n",
      " 0.98378752 0.98341797 0.98331068 0.98356102]\n",
      "Testing data accuracy:  [0.97224871 0.96962617 0.97043677 0.97167652 0.97329773 0.97148579\n",
      " 0.97191493 0.97491774 0.97091082 0.97148307]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(decision_tree, X_train_pca, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(decision_tree, X_test_pca, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    627450\n",
      "          1       1.00      1.00      1.00    211410\n",
      "\n",
      "avg / total       1.00      1.00      1.00    838860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[627450      0]\n",
      " [     0 211410]]\n",
      "Accuracy Score : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('Accuracy Score :',accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed above,Classification report,Confusion matrix ,AUC have very good accuracy scores.Now, we will use another dimension reduction technique -selectkbest to get the optimum features and will compare the accuracies with PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SelectKbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year nan\n",
      "Month 808.9553696705038\n",
      "DayofMonth 403.2220170656302\n",
      "DayOfWeek 79.25829433649136\n",
      "DepTime 48053.52560992163\n",
      "CRSDepTime 14475.04324695549\n",
      "ArrTime 26834.577245858956\n",
      "CRSArrTime 11577.911251133937\n",
      "FlightNum 1547.4690296947113\n",
      "ActualElapsedTime 9970.953035997813\n",
      "CRSElapsedTime 592.5105036295506\n",
      "AirTime 3248.3114961646806\n",
      "ArrDelay 529776.2587817839\n",
      "DepDelay 413990.54075245414\n",
      "Distance 340.9383439359148\n",
      "Cancelled 9575.119516998262\n",
      "Diverted 95.96391089238634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#selectkbest to get the scores of the best parameters\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "names =['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime',\n",
    "       'ArrTime', 'CRSArrTime', 'FlightNum',\n",
    "       'ActualElapsedTime', 'CRSElapsedTime','AirTime','ArrDelay','DepDelay','Distance', 'Cancelled', 'Diverted']\n",
    "#names = X_train.columns[indices[:n_indices]]\n",
    "skb = SelectKBest(score_func=f_classif,k=7)\n",
    "X_train_kbest = skb.fit_transform(X_train, y_train)\n",
    "for n in range(0, len(names)):\n",
    " print(names[n], skb.scores_[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#Fitting and transforming data to selectkbest\n",
    "skb.fit(X_train, y_train)\n",
    "X_train_skb = skb.transform(X_train)\n",
    "X_test_skb = skb.transform(X_test)\n",
    "decision_tree.fit(X_train_skb, y_train)\n",
    "y_pred = decision_tree.predict(X_train_skb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use Seleckbest transformed data to get the accuracy using gridsearchcv,cross validation,classification report and Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 50, 'max_features': 7}]\n",
      "[0.9916613]\n",
      "[0.99999881]\n",
      "Best Hyper Parameters:\n",
      " {'max_depth': 50, 'max_features': 7}\n",
      "0.991661302243521\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=50,\n",
      "            max_features=7, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "dt_grid={'max_depth':[50],'max_features': [7]}\n",
    "grid_class_dt=model_selection.GridSearchCV(decision_tree,dt_grid,cv=6)\n",
    "grid_class_dt.fit(X_train_skb, y_train)\n",
    "results = grid_class_dt.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class_dt.best_params_)\n",
    "print(grid_class_dt.best_score_)\n",
    "final_model = grid_class_dt.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.99173879 0.99200105 0.99164342 0.991858   0.99190568 0.99172687\n",
      " 0.99346732 0.99266862 0.99245404 0.99307393]\n",
      "Testing data accuracy:  [0.98564753 0.98383559 0.98374023 0.9854568  0.9865535  0.98197597\n",
      " 0.98512302 0.98588527 0.9817835  0.98240343]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(decision_tree, X_train_skb, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(decision_tree, X_test_skb, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00    627450\n",
      "          1       1.00      1.00      1.00    211410\n",
      "\n",
      "avg / total       1.00      1.00      1.00    838860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.9999976349273922\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[627450      0]\n",
      " [     1 211409]]\n",
      "Accuracy Score : 0.9999988079059676\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('Accuracy Score :',accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:16:51.517000\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As observed above,Classification report,Confusion matrix ,AUC have very good accuracy scores.If we compare the accuracy score between PCA and SelectKbest, they are similar so no real difference between them.Overall,Decision Tree accuaracy is very good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=datetime.now()\n",
    "from sklearn import ensemble\n",
    "rfc = ensemble.RandomForestClassifier(max_depth=10,n_estimators= 100)\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have fitted the data to Random Forest model so we need to calcuate the accuracy score using Cross verification,grid search cv,Classification report, AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 3, 'max_features': 7}, {'max_depth': 4, 'max_features': 7}, {'max_depth': 5, 'max_features': 7}]\n",
      "[0.9228596  0.92570512 0.92768162]\n",
      "[0.92301624 0.92568057 0.92780535]\n",
      "Best Hyper Parameters:\n",
      " {'max_depth': 5, 'max_features': 7}\n",
      "0.9276816155258327\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=7, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Gridsearchcv to get the best parameters\n",
    "dt_grid={'max_depth':[3,4,5],'max_features': [7]}\n",
    "\n",
    "grid_class=model_selection.GridSearchCV(rfc,dt_grid,cv=6)\n",
    "grid_class.fit(X_train, y_train)\n",
    "results = grid_class.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class.best_params_)\n",
    "print(grid_class.best_score_)\n",
    "final_model = grid_class.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.93933433 0.94208807 0.94111055 0.93970388 0.94176621 0.94027609\n",
      " 0.94009727 0.93870252 0.9393701  0.94041914]\n",
      "Testing data accuracy:  [0.93767881 0.94149342 0.93629601 0.93930002 0.9404444  0.93753576\n",
      " 0.93949075 0.9384388  0.93948498 0.94115403]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(rfc, X_train, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(rfc, X_test, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.99      0.96    627450\n",
      "          1       0.98      0.79      0.87    211410\n",
      "\n",
      "avg / total       0.94      0.94      0.94    838860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8925724402289951\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we notice above, the accuracy scores for Cross Validation,Classification report and AUC are good.Now lets use PCA to select optimum features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA to get the best features/components\n",
    "X_pca = PCA(n_components=7)\n",
    "X_pca.fit(X_train)\n",
    "X_train_pca = X_pca.transform(X_train)\n",
    "X_test_pca = X_pca.transform(X_test)\n",
    "#Using Decision Tree on reduced PCA dataset \n",
    "rfc.fit(X_train_pca, y_train)\n",
    "y_pred = rfc.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of total variance in the dataset explained by each component from Sklearn PCA.\n",
      " [7.53890305e-01 1.57844213e-01 4.97324466e-02 2.08602984e-02\n",
      " 1.40471259e-02 2.88932045e-03 4.98410545e-04]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'The percentage of total variance in the dataset explained by each',\n",
    "    'component from Sklearn PCA.\\n',\n",
    "    X_pca.explained_variance_ratio_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows the variance per component which looks ok.Now,we will use Gridsearch cv to get the best hyper parameters to improve the accuracy and performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 3, 'max_features': 7}, {'max_depth': 4, 'max_features': 7}, {'max_depth': 5, 'max_features': 7}]\n",
      "[0.91412631 0.92030136 0.92773526]\n",
      "[0.91425077 0.92051856 0.92802255]\n",
      "Best Hyper Parameters:\n",
      " {'max_depth': 5, 'max_features': 7}\n",
      "0.9277352597572897\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=7, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Using Grid search  for finding the best set of parameters with random Forest model\n",
    "dt_grid={'max_depth':[3,4,5],'max_features': [7]}\n",
    "grid_class=model_selection.GridSearchCV(rfc,dt_grid,cv=6)\n",
    "grid_class.fit(X_train_pca, y_train)\n",
    "results = grid_class.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class.best_params_)\n",
    "print(grid_class.best_score_)\n",
    "final_model = grid_class.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.94926448 0.95133872 0.95082612 0.95009894 0.95139833 0.94982476\n",
      " 0.95290036 0.94889493 0.95079036 0.95191093]\n",
      "Testing data accuracy:  [0.94931337 0.95303261 0.94864581 0.95246042 0.95241274 0.94726302\n",
      " 0.95041007 0.95055076 0.94883166 0.95274201]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(rfc, X_train_pca, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(rfc, X_test_pca, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      1.00      0.98      8521\n",
      "          1       0.99      0.93      0.96      3988\n",
      "\n",
      "avg / total       0.98      0.98      0.98     12509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.9657592069719309\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[619562   7888]\n",
      " [ 32514 178896]]\n",
      "Accuracy Score : 0.9518370169038933\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('Accuracy Score :',accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noticed that the accuracy increased after using PCA.So,using PCA was useful here.Now,we will use Selectkbest and compare it with PCA for the accuracies of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selectkbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Year nan\n",
      "Month 808.9553696705038\n",
      "DayofMonth 403.2220170656302\n",
      "DayOfWeek 79.25829433649136\n",
      "DepTime 48053.52560992163\n",
      "CRSDepTime 14475.04324695549\n",
      "ArrTime 26834.577245858956\n",
      "CRSArrTime 11577.911251133937\n",
      "FlightNum 1547.4690296947113\n",
      "ActualElapsedTime 9970.953035997813\n",
      "CRSElapsedTime 592.5105036295506\n",
      "AirTime 3248.3114961646806\n",
      "ArrDelay 529776.2587817839\n",
      "DepDelay 413990.54075245414\n",
      "Distance 340.9383439359148\n",
      "Cancelled 9575.119516998262\n",
      "Diverted 95.96391089238634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#selectkbest to get the scores of the best parameters\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "names =['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime',\n",
    "       'ArrTime', 'CRSArrTime', 'FlightNum',\n",
    "       'ActualElapsedTime', 'CRSElapsedTime','AirTime','ArrDelay','DepDelay','Distance', 'Cancelled', 'Diverted']\n",
    "#names = X_train.columns[indices[:n_indices]]\n",
    "skb = SelectKBest(score_func=f_classif,k=7)\n",
    "X_train_kbest = skb.fit_transform(X_train, y_train)\n",
    "for n in range(0, len(names)):\n",
    " print(names[n], skb.scores_[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#Fitting and transforming data to selectkbest\n",
    "skb.fit(X_train, y_train)\n",
    "X_train_skb = skb.transform(X_train)\n",
    "X_test_skb = skb.transform(X_test)\n",
    "rfc.fit(X_train_skb, y_train)\n",
    "y_pred = rfc.predict(X_train_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 3, 'max_features': 7}, {'max_depth': 4, 'max_features': 7}, {'max_depth': 5, 'max_features': 7}]\n",
      "[0.92262714 0.92601388 0.92766612]\n",
      "[0.92269962 0.92612522 0.92776625]\n",
      "Best Hyper Parameters:\n",
      " {'max_depth': 5, 'max_features': 7}\n",
      "0.9276661183034117\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=7, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Gridsearchcv to get the best parameters\n",
    "dt_grid={'max_depth':[3,4,5],'max_features': [7]}\n",
    "\n",
    "grid_class=model_selection.GridSearchCV(rfc,dt_grid,cv=6)\n",
    "grid_class.fit(X_train, y_train)\n",
    "results = grid_class.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class.best_params_)\n",
    "print(grid_class.best_score_)\n",
    "final_model = grid_class.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.93928665 0.94133705 0.94137282 0.93941778 0.94027609 0.93879789\n",
      " 0.94133705 0.93903631 0.93858332 0.94173044]\n",
      "Testing data accuracy:  [0.9360576  0.94216098 0.93596224 0.9393477  0.9396338  0.93844173\n",
      " 0.93815564 0.93944018 0.94086791 0.94086791]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(rfc, X_train, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(rfc, X_test, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.94      1.00      0.97    627450\n",
      "          1       0.98      0.81      0.89    211410\n",
      "\n",
      "avg / total       0.95      0.95      0.95    838860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.9026302205981189\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[624334   3116]\n",
      " [ 40120 171290]]\n",
      "Accuracy Score : 0.9484586224161362\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('Accuracy Score :',accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6:20:21.249358\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that accuracy scores of Classification report,AUC and Confusion are very good but if we compare it with PCA, the accuracy using PCA are slightly better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "lr = LogisticRegression(C=1e9)\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now get the accuracies using Gridsearchcv,Cross Validation,Classification Report below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'C': 0.001, 'penalty': 'l1'}, {'C': 0.001, 'penalty': 'l2'}, {'C': 0.01, 'penalty': 'l1'}, {'C': 0.01, 'penalty': 'l2'}, {'C': 0.1, 'penalty': 'l1'}, {'C': 0.1, 'penalty': 'l2'}, {'C': 1.0, 'penalty': 'l1'}, {'C': 1.0, 'penalty': 'l2'}, {'C': 10.0, 'penalty': 'l1'}, {'C': 10.0, 'penalty': 'l2'}, {'C': 100.0, 'penalty': 'l1'}, {'C': 100.0, 'penalty': 'l2'}, {'C': 1000.0, 'penalty': 'l1'}, {'C': 1000.0, 'penalty': 'l2'}]\n",
      "[0.92844694 0.92849939 0.92862933 0.928528   0.92874258 0.92853039\n",
      " 0.92874139 0.92852085 0.92874616 0.928528   0.92874258 0.92853635\n",
      " 0.92874377 0.92851012]\n",
      "[0.92846535 0.92856059 0.92865463 0.92854112 0.9287692  0.92854482\n",
      " 0.92875728 0.92855622 0.92875702 0.92854323 0.92875265 0.92855198\n",
      " 0.92876457 0.9285484 ]\n",
      "Best Hyper Parameters:\n",
      " {'C': 10.0, 'penalty': 'l1'}\n",
      "0.9287461554967456\n",
      "LogisticRegression(C=10.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Gridsearchcv to get the best hyper-parameters\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=model_selection.GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "results = logreg_cv.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",logreg_cv.best_params_)\n",
    "print(logreg_cv.best_score_)\n",
    "final_model = logreg_cv.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.92784255 0.92880814 0.92822402 0.92887967 0.92984527 0.92812865\n",
      " 0.92988103 0.9271869  0.92792599 0.92847436]\n",
      "Testing data accuracy:  [0.92857143 0.93219531 0.92613961 0.93009727 0.92942972 0.92690254\n",
      " 0.92623498 0.93161986 0.92947067 0.93113972]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(lr, X_train, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(lr, X_test, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.97      0.95    627450\n",
      "          1       0.91      0.80      0.85    211410\n",
      "\n",
      "avg / total       0.93      0.93      0.93    838860\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.8849367600617611\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracies for Cross validation,classification report,AUC are very good.Lets see if using PCA and SelectkBest will improve its accuracy further.First lets go with PCA. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA to get the best features/components\n",
    "X_pca = PCA(n_components=7)\n",
    "X_pca.fit(X_train)\n",
    "X_train_pca = X_pca.transform(X_train)\n",
    "X_test_pca = X_pca.transform(X_test)\n",
    "#Using Decision Tree on reduced PCA dataset \n",
    "lr.fit(X_train_pca, y_train)\n",
    "y_pred = lr.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of total variance in the dataset explained by each component from Sklearn PCA.\n",
      " [7.53890305e-01 1.57844213e-01 4.97324466e-02 2.08602984e-02\n",
      " 1.40471259e-02 2.88932045e-03 4.98410545e-04]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'The percentage of total variance in the dataset explained by each',\n",
    "    'component from Sklearn PCA.\\n',\n",
    "    X_pca.explained_variance_ratio_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows the variance per component which looks ok.Now,we will use Gridsearch cv to get the best hyper parameters to improve the accuracy and performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'C': 0.001, 'penalty': 'l1'}, {'C': 0.001, 'penalty': 'l2'}, {'C': 0.01, 'penalty': 'l1'}, {'C': 0.01, 'penalty': 'l2'}, {'C': 0.1, 'penalty': 'l1'}, {'C': 0.1, 'penalty': 'l2'}, {'C': 1.0, 'penalty': 'l1'}, {'C': 1.0, 'penalty': 'l2'}, {'C': 10.0, 'penalty': 'l1'}, {'C': 10.0, 'penalty': 'l2'}, {'C': 100.0, 'penalty': 'l1'}, {'C': 100.0, 'penalty': 'l2'}, {'C': 1000.0, 'penalty': 'l1'}, {'C': 1000.0, 'penalty': 'l2'}]\n",
      "[0.92712968 0.92707007 0.92717855 0.92715352 0.92717259 0.92716305\n",
      " 0.92717617 0.92716305 0.92717736 0.92714756 0.92717498 0.92717736\n",
      " 0.92717378 0.92717378]\n",
      "[0.9271265  0.92706663 0.927191   0.92717259 0.92719418 0.92718491\n",
      " 0.92719365 0.92719219 0.92719339 0.92717736 0.92719299 0.92718875\n",
      " 0.92719219 0.92718928]\n",
      "Best Hyper Parameters:\n",
      " {'C': 0.01, 'penalty': 'l1'}\n",
      "0.9271785518441694\n",
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Gridsearchcv to get the best hyper-parameters\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg_cv=model_selection.GridSearchCV(lr,grid,cv=10)\n",
    "logreg_cv.fit(X_train_pca,y_train)\n",
    "results = logreg_cv.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",logreg_cv.best_params_)\n",
    "print(logreg_cv.best_score_)\n",
    "final_model = logreg_cv.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.97      0.96      8521\n",
      "          1       0.94      0.90      0.92      3988\n",
      "\n",
      "avg / total       0.95      0.95      0.95     12509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.9370656418263121\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8301  220]\n",
      " [ 399 3589]]\n",
      "Accuracy Score : 0.9505156287473019\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('Accuracy Score :',accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noticed above, Classification Report,AUC,Confusion Matrix are very good.Lets use Selectkbest to check its accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selectkbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0 1] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#selectkbest to get the scores of the best parameters\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "names =['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime',\n",
    "       'ArrTime', 'CRSArrTime', 'FlightNum',\n",
    "       'ActualElapsedTime', 'CRSElapsedTime','AirTime','ArrDelay','DepDelay','Distance', 'Cancelled', 'Diverted']\n",
    "#names = X_train.columns[indices[:n_indices]]\n",
    "skb = SelectKBest(score_func=f_classif,k=7)\n",
    "X_train_kbest = skb.fit_transform(X_train, y_train)\n",
    "#for n in range(0, len(names)):\n",
    " #print(names[n], skb.scores_[n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'C': 0.001, 'penalty': 'l1'}, {'C': 0.001, 'penalty': 'l2'}, {'C': 0.01, 'penalty': 'l1'}, {'C': 0.01, 'penalty': 'l2'}, {'C': 0.1, 'penalty': 'l1'}, {'C': 0.1, 'penalty': 'l2'}, {'C': 1.0, 'penalty': 'l1'}, {'C': 1.0, 'penalty': 'l2'}, {'C': 10.0, 'penalty': 'l1'}, {'C': 10.0, 'penalty': 'l2'}, {'C': 100.0, 'penalty': 'l1'}, {'C': 100.0, 'penalty': 'l2'}, {'C': 1000.0, 'penalty': 'l1'}, {'C': 1000.0, 'penalty': 'l2'}]\n",
      "[0.94300104 0.9534735  0.94643856 0.95395315 0.94811736 0.95499241\n",
      " 0.95051563 0.95507235 0.94923655 0.95491246 0.95219442 0.95523223\n",
      " 0.94963626 0.955552  ]\n",
      "[0.94308097 0.95355344 0.94697137 0.95419298 0.94688257 0.95562306\n",
      " 0.94878351 0.95588953 0.94830372 0.95477034 0.95199897 0.95598728\n",
      " 0.94922776 0.9565202 ]\n",
      "Best Hyper Parameters:\n",
      " {'C': 1000.0, 'penalty': 'l2'}\n",
      "0.9555520025581581\n",
      "LogisticRegression(C=1000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Gridsearchcv to get the best hyper-parameters\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg_cv=model_selection.GridSearchCV(lr,grid,cv=10)\n",
    "logreg_cv.fit(X_train_kbest,y_train)\n",
    "results = logreg_cv.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",logreg_cv.best_params_)\n",
    "print(logreg_cv.best_score_)\n",
    "final_model = logreg_cv.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0 1] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#Fitting and transforming data to selectkbest\n",
    "skb.fit(X_train, y_train)\n",
    "X_train_skb = skb.transform(X_train)\n",
    "X_test_skb = skb.transform(X_test)\n",
    "lr.fit(X_train_skb, y_train)\n",
    "y_pred = lr.predict(X_train_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.95047923 0.96322942 0.95523581 0.95603517 0.95443645 0.95523581\n",
      " 0.95923261 0.95043965 0.9584     0.9512    ]\n",
      "Testing data accuracy:  [0.96166134 0.93290735 0.92651757 0.93610224 0.9456869  0.93610224\n",
      " 0.9201278  0.92971246 0.93589744 0.94551282]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(lr, X_train_skb, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(lr, X_test_skb, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.98      0.97      8521\n",
      "          1       0.96      0.91      0.93      3988\n",
      "\n",
      "avg / total       0.96      0.96      0.96     12509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 0.9454093267950783\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8362  159]\n",
      " [ 361 3627]]\n",
      "Accuracy Score : 0.958429930450076\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('Accuracy Score :',accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:53:45.593410\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA and Selectkbest accuracy scores are almost similar.So, it didnot really made any impact."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "svm=SVC()\n",
    "svm.fit(X_train, y_train)\n",
    "y_pred = svm.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use gridsearch cv to get the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridsearch cv to get the best parameters\n",
    "\n",
    "param_grid = {'C':[1,10,100,1000],'gamma':[1,0.1,0.001,0.0001], 'kernel':['linear','rbf']}\n",
    "grid_class_svm=model_selection.GridSearchCV(SVC(),param_grid,refit = True)\n",
    "grid_class_svm.fit(X_train, y_train)\n",
    "results = grid_class_svm.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class_svm.best_params_)\n",
    "print(grid_class_svm.best_score_)\n",
    "final_model = grid_class_svm.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.68168744 0.68105516 0.68201439 0.68153477 0.6818618  0.6828215 ]\n",
      "Testing data accuracy:  [0.67624521 0.67624521 0.67754319 0.67754319 0.67754319 0.67754319]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(SVC(), X_train, y_train, cv=6))\n",
    "print(\"Testing data accuracy: \",cross_val_score(SVC(), X_test, y_test, cv=6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      8521\n",
      "          1       1.00      1.00      1.00      3988\n",
      "\n",
      "avg / total       1.00      1.00      1.00     12509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracies for classification report,AUC are very good.Lets see if using PCA and SelectkBest will improve its accuracy further.First lets go with PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA to get the best features/components\n",
    "X_pca = PCA(n_components=7)\n",
    "X_pca.fit(X_train)\n",
    "X_train_pca = X_pca.transform(X_train)\n",
    "X_test_pca = X_pca.transform(X_test)\n",
    "#Using Decision Tree on reduced PCA dataset \n",
    "svm.fit(X_train_pca, y_train)\n",
    "y_pred = svm.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of total variance in the dataset explained by each component from Sklearn PCA.\n",
      " [0.5351517  0.3262712  0.08247678 0.03437509 0.01697624 0.00382862\n",
      " 0.00066016]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'The percentage of total variance in the dataset explained by each',\n",
    "    'component from Sklearn PCA.\\n',\n",
    "    X_pca.explained_variance_ratio_\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearchcv \n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=model_selection.GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(X_train_pca,y_train)\n",
    "results = logreg_cv.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",logreg_cv.best_params_)\n",
    "print(logreg_cv.best_score_)\n",
    "final_model = logreg_cv.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.68370607 0.68105516 0.68105516 0.68505196 0.68345324 0.68345324\n",
      " 0.68185452 0.68105516 0.6864     0.6832    ]\n",
      "Testing data accuracy:  [0.67731629 0.67731629 0.67731629 0.67731629 0.67731629 0.67731629\n",
      " 0.67731629 0.67731629 0.67628205 0.67628205]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(svm, X_train_pca, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(svm, X_test_pca, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      8521\n",
      "          1       1.00      1.00      1.00      3988\n",
      "\n",
      "avg / total       1.00      1.00      1.00     12509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8521    0]\n",
      " [   0 3988]]\n",
      "Accuracy Score : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('Accuracy Score :',accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noticed above, accuracies are very good.Lets now compare it with selectkbest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0 1] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#Selectkbest\n",
    "#selectkbest to get the scores of the best parameters\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "names =['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime',\n",
    "       'ArrTime', 'CRSArrTime', 'FlightNum',\n",
    "       'ActualElapsedTime', 'CRSElapsedTime','AirTime','ArrDelay','DepDelay','Distance', 'Cancelled', 'Diverted']\n",
    "#names = X_train.columns[indices[:n_indices]]\n",
    "skb = SelectKBest(score_func=f_classif,k=7)\n",
    "X_train_kbest = skb.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0 1] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#Fitting and transforming data to selectkbest\n",
    "skb.fit(X_train, y_train)\n",
    "X_train_skb = skb.transform(X_train)\n",
    "X_test_skb = skb.transform(X_test)\n",
    "svm.fit(X_train_skb, y_train)\n",
    "y_pred = svm.predict(X_train_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearchcv to get the best hyper-parameters\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg_cv=model_selection.GridSearchCV(svm,grid,cv=10)\n",
    "logreg_cv.fit(X_train_skb,y_train)\n",
    "results = logreg_cv.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",logreg_cv.best_params_)\n",
    "print(logreg_cv.best_score_)\n",
    "final_model = logreg_cv.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.68210863 0.68105516 0.68105516 0.68265388 0.68185452 0.68185452\n",
      " 0.68105516 0.68185452 0.6848     0.6816    ]\n",
      "Testing data accuracy:  [0.67731629 0.67731629 0.67731629 0.67731629 0.67731629 0.67731629\n",
      " 0.67731629 0.67731629 0.67628205 0.67628205]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(svm, X_train_skb, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(svm, X_test_skb, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      8521\n",
      "          1       1.00      1.00      1.00      3988\n",
      "\n",
      "avg / total       1.00      1.00      1.00     12509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8521    0]\n",
      " [   0 3988]]\n",
      "Accuracy Score : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('Accuracy Score :',accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracies are very good but it takes lot of time to run.Its very slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "start=datetime.now()\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 7,\n",
    "          'loss': 'deviance'}\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We will now get the accuracies using Gridsearchcv,Cross Validation,Classification Report below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params ={\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"n_estimators\":[1000]\n",
    "    }\n",
    "gb = model_selection.GridSearchCV(clf, params, cv=10)\n",
    "gb.fit(X_train, y_train)\n",
    "results = gb.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",gb.best_params_)\n",
    "print(gb.best_score_)\n",
    "final_model = gb.best_estimator_\n",
    "print(final_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.985623   0.98161471 0.98161471 0.98880895 0.98880895 0.99360512\n",
      " 0.98641087 0.98081535 0.9888     0.9856    ]\n",
      "Testing data accuracy:  [0.94249201 0.92332268 0.93610224 0.93610224 0.93929712 0.95207668\n",
      " 0.94249201 0.95846645 0.93589744 0.92948718]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(clf, X_train, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(clf, X_test, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      8521\n",
      "          1       1.00      1.00      1.00      3988\n",
      "\n",
      "avg / total       1.00      1.00      1.00     12509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracies for Cross validation,classification report,AUC are very good.Lets see if using PCA and SelectkBest will improve its accuracy further.First lets go with PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA to get the best features/components\n",
    "X_pca = PCA(n_components=7)\n",
    "X_pca.fit(X_train)\n",
    "X_train_pca = X_pca.transform(X_train)\n",
    "X_test_pca = X_pca.transform(X_test)\n",
    "#Using Decision Tree on reduced PCA dataset \n",
    "clf.fit(X_train_pca, y_train)\n",
    "y_pred = clf.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch cv to get the best hyper-parameters\n",
    "params ={\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"n_estimators\":[1000]\n",
    "    }\n",
    "gb = model_selection.GridSearchCV(clf, params, cv=10)\n",
    "gb.fit(X_train_pca, y_train)\n",
    "results = gb.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",gb.best_params_)\n",
    "print(gb.best_score_)\n",
    "final_model = gb.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.97603834 0.98241407 0.98081535 0.98721023 0.98960831 0.98161471\n",
      " 0.98401279 0.9736211  0.9808     0.9816    ]\n",
      "Testing data accuracy:  [0.96805112 0.96166134 0.95846645 0.95207668 0.94249201 0.96166134\n",
      " 0.96805112 0.96485623 0.96153846 0.96474359]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(clf, X_train_pca, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(clf, X_test_pca, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      8521\n",
      "          1       1.00      1.00      1.00      3988\n",
      "\n",
      "avg / total       1.00      1.00      1.00     12509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8521    0]\n",
      " [   0 3988]]\n",
      "Accuracy Score : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('Accuracy Score :',accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noticed above, accuracies are very good.Lets now compare it with selectkbest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0 1] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#selectkbest to get the scores of the best parameters\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "names =['Year', 'Month', 'DayofMonth', 'DayOfWeek', 'DepTime', 'CRSDepTime',\n",
    "       'ArrTime', 'CRSArrTime', 'FlightNum',\n",
    "       'ActualElapsedTime', 'CRSElapsedTime','AirTime','ArrDelay','DepDelay','Distance', 'Cancelled', 'Diverted']\n",
    "#names = X_train.columns[indices[:n_indices]]\n",
    "skb = SelectKBest(score_func=f_classif,k=7)\n",
    "X_train_kbest = skb.fit_transform(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:113: UserWarning: Features [0 1] are constant.\n",
      "  UserWarning)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\univariate_selection.py:114: RuntimeWarning: invalid value encountered in true_divide\n",
      "  f = msb / msw\n"
     ]
    }
   ],
   "source": [
    "#Fitting and transforming data to selectkbest\n",
    "skb.fit(X_train, y_train)\n",
    "X_train_skb = skb.transform(X_train)\n",
    "X_test_skb = skb.transform(X_test)\n",
    "clf.fit(X_train_skb, y_train)\n",
    "y_pred = clf.predict(X_train_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearch cv to get the best hyper-parameters\n",
    "params ={\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"n_estimators\":[1000]\n",
    "    }\n",
    "gb = model_selection.GridSearchCV(clf, params, cv=10)\n",
    "gb.fit(X_train_skb, y_train)\n",
    "results = gb.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",gb.best_params_)\n",
    "print(gb.best_score_)\n",
    "final_model = gb.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.99520767 0.99120703 0.98880895 0.9960032  0.99520384 0.99680256\n",
      " 0.99120703 0.99360512 0.996      0.9904    ]\n",
      "Testing data accuracy:  [0.96485623 0.94249201 0.94888179 0.93610224 0.95846645 0.95527157\n",
      " 0.9456869  0.95527157 0.95192308 0.95192308]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(clf, X_train_skb, y_train, cv=10))\n",
    "print(\"Testing data accuracy: \",cross_val_score(clf, X_test_skb, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      1.00      1.00      8521\n",
      "          1       1.00      1.00      1.00      3988\n",
      "\n",
      "avg / total       1.00      1.00      1.00     12509\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "#AUC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score:\" ,roc_auc_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8521    0]\n",
      " [   0 3988]]\n",
      "Accuracy Score : 1.0\n"
     ]
    }
   ],
   "source": [
    "#Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred))\n",
    "print('Accuracy Score :',accuracy_score(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:52:13.071810\n"
     ]
    }
   ],
   "source": [
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice above , accuracies scores in AUC, Classification report and Confusion matrix are very good.If we compare them with PCA, they are almost similar ,so no real difference between them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN models,Decision tree, Random forest,SVC,Logistic Regression,Gradient Boosting seem to peform better than  Naive Bayes.They seem to have better accuracy.The slowest in all of the Classifers was Gradient Boosting and SVC in terms of runtime.Naive Bayes was the fastest interms of runtime.All except Naive Bayes were really slow ,took lot of time to complete.This overall took 15-20 hours to complete.All of these have a very high accuracy score.KNN models,Decision tree, Random forest,SVC,Logistic Regression have consistent high accurate scores for Classification Report,AUC,Confusion Matrix.One thing we have oberserved is that the gridsearchcv is taking bulk of the runtime for each model which is expected since its checking all the paramters ,then selecting the best performing ones.The dataset explains the Airline arrival and departure time.We are checking on the criteria if either arrival or departure time of flight compared to their scheduled time are greater than 30 minutes or not.If yes, then outcome variable will be 1 else 0.Here,almost 21% of the flights were delayed more than 30 minutes which is quite a high number.There needs to be further analysis of why so many flights are getting delayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
