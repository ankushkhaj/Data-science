{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.5.3 Guided example and challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn import datasets\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cntry</th>\n",
       "      <th>idno</th>\n",
       "      <th>year</th>\n",
       "      <th>tvtot</th>\n",
       "      <th>ppltrst</th>\n",
       "      <th>pplfair</th>\n",
       "      <th>pplhlp</th>\n",
       "      <th>happy</th>\n",
       "      <th>sclmeet</th>\n",
       "      <th>sclact</th>\n",
       "      <th>gndr</th>\n",
       "      <th>agea</th>\n",
       "      <th>partner</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CH</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CH</td>\n",
       "      <td>25.0</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CH</td>\n",
       "      <td>26.0</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CH</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CH</td>\n",
       "      <td>29.0</td>\n",
       "      <td>6</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  cntry  idno  year  tvtot  ppltrst  pplfair  pplhlp  happy  sclmeet  sclact  \\\n",
       "0    CH   5.0     6    3.0      3.0     10.0     5.0    8.0      5.0     4.0   \n",
       "1    CH  25.0     6    6.0      5.0      7.0     5.0    9.0      3.0     2.0   \n",
       "2    CH  26.0     6    1.0      8.0      8.0     8.0    7.0      6.0     3.0   \n",
       "3    CH  28.0     6    4.0      6.0      6.0     7.0   10.0      6.0     2.0   \n",
       "4    CH  29.0     6    5.0      6.0      7.0     5.0    8.0      7.0     2.0   \n",
       "\n",
       "   gndr  agea  partner  \n",
       "0   2.0  60.0      1.0  \n",
       "1   2.0  59.0      1.0  \n",
       "2   1.0  24.0      2.0  \n",
       "3   2.0  64.0      1.0  \n",
       "4   2.0  55.0      1.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv((\n",
    "    \"https://raw.githubusercontent.com/Thinkful-Ed/data-201-resources/\"\n",
    "    \"master/ESS_practice_data/ESSdata_Thinkful.csv\")).dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definine outcome and predictors.\n",
    "# Set our outcome to 0 and 1.\n",
    "y = df['partner']-1\n",
    "X = df.loc[:, ~df.columns.isin(['partner', 'cntry', 'idno'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.concat([X, pd.get_dummies(df['cntry'])], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = int(X.shape[0] * 0.9)\n",
    "# Put 90% of the data in the training set.\n",
    "X_train, y_train = X[:offset], y[:offset]\n",
    "\n",
    "# And put 10% in the test set.\n",
    "X_test, y_test = X[offset:], y[offset:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.1276073619631902\n",
      "Percent Type II errors: 0.17300613496932515\n"
     ]
    }
   ],
   "source": [
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.subplot(1, 2, 2)\n",
    "plt.barh(pos,feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(pos, X.columns[sorted_idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this model is already doing alright, we've seen from the Type I and Type II error rates that there is definitely room for improvement. Your task is to see how low you can get the error rates to go in the test set, based on your model in the training set. Strategies you might use include:\n",
    "\n",
    "Creating new features\n",
    "\n",
    "Applying more overfitting-prevention strategies like subsampling\n",
    "\n",
    "More iterations\n",
    "\n",
    "Trying a different loss function\n",
    "\n",
    "Changing the structure of the weak learner: Allowing more leaves in the tree, or other modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try various options as mentioned above.First let us try with adding more iterations by increasing estimators to 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance'}\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.04609929078014184\n",
      "Percent Type II errors: 0.17103109656301146\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.06993865030674846\n",
      "Percent Type II errors: 0.18895705521472392\n"
     ]
    }
   ],
   "source": [
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:The increase of iterations didnt decrease the error score in test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets try to modify max depth to 7 and iterations to 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 7,\n",
    "          'loss': 'deviance'}\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.13006134969325153\n",
      "Percent Type II errors: 0.1705521472392638\n"
     ]
    }
   ],
   "source": [
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Result:The increase of max depth to 7 and iterations to 1000 , shows that the error score decreased significantly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, lets try to use other cost function and play with estimators and max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 1000,\n",
    "          'max_depth': 7,\n",
    "          'loss': 'exponential'}\n",
    "# Initialize and fit the model.\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predict_train = clf.predict(X_train)\n",
    "predict_test = clf.predict(X_test)\n",
    "table_train = pd.crosstab(y_train, predict_train, margins=True)\n",
    "table_test = pd.crosstab(y_test, predict_test, margins=True)\n",
    "train_tI_errors = table_train.loc[0.0,1.0] / table_train.loc['All','All']\n",
    "train_tII_errors = table_train.loc[1.0,0.0] / table_train.loc['All','All']\n",
    "\n",
    "test_tI_errors = table_test.loc[0.0,1.0]/table_test.loc['All','All']\n",
    "test_tII_errors = table_test.loc[1.0,0.0]/table_test.loc['All','All']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set accuracy:\n",
      "Percent Type I errors: 0.0\n",
      "Percent Type II errors: 0.0\n",
      "\n",
      "Test set accuracy:\n",
      "Percent Type I errors: 0.1276073619631902\n",
      "Percent Type II errors: 0.17300613496932515\n"
     ]
    }
   ],
   "source": [
    "print((\n",
    "    'Training set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}\\n\\n'\n",
    "    'Test set accuracy:\\n'\n",
    "    'Percent Type I errors: {}\\n'\n",
    "    'Percent Type II errors: {}'\n",
    ").format(train_tI_errors, train_tII_errors, test_tI_errors, test_tII_errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we noticed above, the change of loss function ,increased estimators to 1000 and increase of depth to 7 improved the error score for test data but loss function as deviance scored better than exponential "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
