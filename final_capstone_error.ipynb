{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#import basic Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import numpy_indexed as npi\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Visualizaiton imports\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#combine sparse matrices\n",
    "import scipy.sparse as sps\n",
    "\n",
    "#Importing Sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.decomposition import MiniBatchDictionaryLearning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error,f1_score \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import tree,model_selection\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from keras.models import Sequential\n",
    "# Import various componenets for model building\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv1D, MaxPooling1D\n",
    "from keras.layers import LSTM, Input, TimeDistributed\n",
    "from keras.models import Model\n",
    "from keras.optimizers import RMSprop\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "# Import the backend\n",
    "from keras import backend as K\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#import of all files from the data folder.\n",
    "aisles = pd.read_csv('C:/Users/ankush/Downloads/aisles.csv')\n",
    "departments = pd.read_csv('C:/Users/ankush/Downloads/departments.csv')\n",
    "order_products__prior = pd.read_csv('C:/Users/ankush/Downloads/order_products__prior.csv')\n",
    "order_products__train = pd.read_csv('C:/Users/ankush/Downloads/order_products__train.csv')\n",
    "orders = pd.read_csv('C:/Users/ankush/Downloads/orders.csv')\n",
    "products = pd.read_csv('C:/Users/ankush/Downloads/products.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "aisle_id    0\n",
       "aisle       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aisles.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "department_id    0\n",
       "department       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "departments.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "product_id       0\n",
       "product_name     0\n",
       "aisle_id         0\n",
       "department_id    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                       0\n",
       "user_id                        0\n",
       "eval_set                       0\n",
       "order_number                   0\n",
       "order_dow                      0\n",
       "order_hour_of_day              0\n",
       "days_since_prior_order    206209\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                  0\n",
       "user_id                   0\n",
       "eval_set                  0\n",
       "order_number              0\n",
       "order_dow                 0\n",
       "order_hour_of_day         0\n",
       "days_since_prior_order    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders=orders.dropna(0)\n",
    "orders.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id             0\n",
       "product_id           0\n",
       "add_to_cart_order    0\n",
       "reordered            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "order_products__train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>add_to_cart_order</th>\n",
       "      <th>reordered</th>\n",
       "      <th>product_name</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>aisle</th>\n",
       "      <th>department</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>49302</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bulgarian Yogurt</td>\n",
       "      <td>120</td>\n",
       "      <td>16</td>\n",
       "      <td>112108</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>yogurt</td>\n",
       "      <td>dairy eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11109</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Organic 4% Milk Fat Whole Milk Cottage Cheese</td>\n",
       "      <td>108</td>\n",
       "      <td>16</td>\n",
       "      <td>112108</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>other creams cheeses</td>\n",
       "      <td>dairy eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>10246</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Organic Celery Hearts</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>112108</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>fresh vegetables</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>49683</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Cucumber Kirby</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>112108</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>fresh vegetables</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>43633</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Lightly Smoked Sardines in Olive Oil</td>\n",
       "      <td>95</td>\n",
       "      <td>15</td>\n",
       "      <td>112108</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>canned meat seafood</td>\n",
       "      <td>canned goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>13176</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Bag of Organic Bananas</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>112108</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>fresh fruits</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>47209</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Organic Hass Avocado</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>112108</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>fresh fruits</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>22035</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Organic Whole String Cheese</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>112108</td>\n",
       "      <td>train</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>9.0</td>\n",
       "      <td>packaged cheese</td>\n",
       "      <td>dairy eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>36</td>\n",
       "      <td>39612</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Grated Pecorino Romano Cheese</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>79431</td>\n",
       "      <td>train</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>30.0</td>\n",
       "      <td>specialty cheeses</td>\n",
       "      <td>dairy eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>36</td>\n",
       "      <td>19660</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Spring Water</td>\n",
       "      <td>115</td>\n",
       "      <td>7</td>\n",
       "      <td>79431</td>\n",
       "      <td>train</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>30.0</td>\n",
       "      <td>water seltzer sparkling water</td>\n",
       "      <td>beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>36</td>\n",
       "      <td>49235</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Organic Half &amp; Half</td>\n",
       "      <td>53</td>\n",
       "      <td>16</td>\n",
       "      <td>79431</td>\n",
       "      <td>train</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>30.0</td>\n",
       "      <td>cream</td>\n",
       "      <td>dairy eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>36</td>\n",
       "      <td>43086</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Super Greens Salad</td>\n",
       "      <td>123</td>\n",
       "      <td>4</td>\n",
       "      <td>79431</td>\n",
       "      <td>train</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>30.0</td>\n",
       "      <td>packaged vegetables fruits</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>36</td>\n",
       "      <td>46620</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Cage Free Extra Large Grade AA Eggs</td>\n",
       "      <td>86</td>\n",
       "      <td>16</td>\n",
       "      <td>79431</td>\n",
       "      <td>train</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>30.0</td>\n",
       "      <td>eggs</td>\n",
       "      <td>dairy eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>36</td>\n",
       "      <td>34497</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Prosciutto, Americano</td>\n",
       "      <td>96</td>\n",
       "      <td>20</td>\n",
       "      <td>79431</td>\n",
       "      <td>train</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>30.0</td>\n",
       "      <td>lunch meat</td>\n",
       "      <td>deli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>36</td>\n",
       "      <td>48679</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Organic Garnet Sweet Potato (Yam)</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>79431</td>\n",
       "      <td>train</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>30.0</td>\n",
       "      <td>fresh vegetables</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>36</td>\n",
       "      <td>46979</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Asparagus</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>79431</td>\n",
       "      <td>train</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>30.0</td>\n",
       "      <td>fresh vegetables</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>38</td>\n",
       "      <td>11913</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Shelled Pistachios</td>\n",
       "      <td>117</td>\n",
       "      <td>19</td>\n",
       "      <td>42756</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>24.0</td>\n",
       "      <td>nuts seeds dried fruit</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>38</td>\n",
       "      <td>18159</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Organic Biologique Limes</td>\n",
       "      <td>123</td>\n",
       "      <td>4</td>\n",
       "      <td>42756</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>24.0</td>\n",
       "      <td>packaged vegetables fruits</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>38</td>\n",
       "      <td>4461</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>Organic Raw Unfiltered Apple Cider Vinegar</td>\n",
       "      <td>19</td>\n",
       "      <td>13</td>\n",
       "      <td>42756</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>24.0</td>\n",
       "      <td>oils vinegars</td>\n",
       "      <td>pantry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>38</td>\n",
       "      <td>21616</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Organic Baby Arugula</td>\n",
       "      <td>123</td>\n",
       "      <td>4</td>\n",
       "      <td>42756</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>24.0</td>\n",
       "      <td>packaged vegetables fruits</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>38</td>\n",
       "      <td>23622</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Organic Hot House Tomato</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>42756</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>24.0</td>\n",
       "      <td>fresh vegetables</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>38</td>\n",
       "      <td>32433</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>Green Peas</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>42756</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>24.0</td>\n",
       "      <td>frozen produce</td>\n",
       "      <td>frozen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>38</td>\n",
       "      <td>28842</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>Bunched Cilantro</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>42756</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>24.0</td>\n",
       "      <td>fresh herbs</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>38</td>\n",
       "      <td>42625</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Flat Parsley, Bunch</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>42756</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>24.0</td>\n",
       "      <td>fresh herbs</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>38</td>\n",
       "      <td>39693</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Fresh Dill</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>42756</td>\n",
       "      <td>train</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>16</td>\n",
       "      <td>24.0</td>\n",
       "      <td>fresh herbs</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>96</td>\n",
       "      <td>20574</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Roasted Turkey</td>\n",
       "      <td>96</td>\n",
       "      <td>20</td>\n",
       "      <td>17227</td>\n",
       "      <td>train</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>30.0</td>\n",
       "      <td>lunch meat</td>\n",
       "      <td>deli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>96</td>\n",
       "      <td>30391</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Organic Cucumber</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>17227</td>\n",
       "      <td>train</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>30.0</td>\n",
       "      <td>fresh vegetables</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>96</td>\n",
       "      <td>40706</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Organic Grape Tomatoes</td>\n",
       "      <td>123</td>\n",
       "      <td>4</td>\n",
       "      <td>17227</td>\n",
       "      <td>train</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>30.0</td>\n",
       "      <td>packaged vegetables fruits</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>96</td>\n",
       "      <td>25610</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Organic Pomegranate Kernels</td>\n",
       "      <td>116</td>\n",
       "      <td>1</td>\n",
       "      <td>17227</td>\n",
       "      <td>train</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>30.0</td>\n",
       "      <td>frozen produce</td>\n",
       "      <td>frozen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>96</td>\n",
       "      <td>27966</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Organic Raspberries</td>\n",
       "      <td>123</td>\n",
       "      <td>4</td>\n",
       "      <td>17227</td>\n",
       "      <td>train</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>30.0</td>\n",
       "      <td>packaged vegetables fruits</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>1591</td>\n",
       "      <td>16900</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>Original Whole Grain Chips</td>\n",
       "      <td>107</td>\n",
       "      <td>19</td>\n",
       "      <td>188528</td>\n",
       "      <td>train</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>chips pretzels</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>1591</td>\n",
       "      <td>18792</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>Goldfish Pretzel Baked Snack Crackers</td>\n",
       "      <td>78</td>\n",
       "      <td>19</td>\n",
       "      <td>188528</td>\n",
       "      <td>train</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>crackers</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>1591</td>\n",
       "      <td>38805</td>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>Twisted Tropical Tango Organic Juice Drink</td>\n",
       "      <td>100</td>\n",
       "      <td>21</td>\n",
       "      <td>188528</td>\n",
       "      <td>train</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>missing</td>\n",
       "      <td>missing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1591</td>\n",
       "      <td>44116</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>Goodness Grapeness Organic Juice Drink</td>\n",
       "      <td>98</td>\n",
       "      <td>7</td>\n",
       "      <td>188528</td>\n",
       "      <td>train</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>juice nectars</td>\n",
       "      <td>beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>1591</td>\n",
       "      <td>25237</td>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>Nutty Bars</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>188528</td>\n",
       "      <td>train</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>1591</td>\n",
       "      <td>9130</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>Honey Graham Snacks</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>188528</td>\n",
       "      <td>train</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>1591</td>\n",
       "      <td>25316</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>Coconut Dreams Cookies</td>\n",
       "      <td>61</td>\n",
       "      <td>19</td>\n",
       "      <td>188528</td>\n",
       "      <td>train</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>6.0</td>\n",
       "      <td>cookies cakes</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>1597</td>\n",
       "      <td>20082</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Organic Whole Milk with DHA Omega-3</td>\n",
       "      <td>84</td>\n",
       "      <td>16</td>\n",
       "      <td>137611</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>milk</td>\n",
       "      <td>dairy eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>1597</td>\n",
       "      <td>25138</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Organic Plain Greek Whole Milk Yogurt</td>\n",
       "      <td>120</td>\n",
       "      <td>16</td>\n",
       "      <td>137611</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>yogurt</td>\n",
       "      <td>dairy eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>1597</td>\n",
       "      <td>47759</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Mandarin Oranges</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>137611</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>fresh fruits</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>1597</td>\n",
       "      <td>38453</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Reduced Fat Chocolate Milk</td>\n",
       "      <td>84</td>\n",
       "      <td>16</td>\n",
       "      <td>137611</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>milk</td>\n",
       "      <td>dairy eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>1597</td>\n",
       "      <td>11352</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Organic Mini Sandwich Crackers Peanut Butter</td>\n",
       "      <td>78</td>\n",
       "      <td>19</td>\n",
       "      <td>137611</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>crackers</td>\n",
       "      <td>snacks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>1597</td>\n",
       "      <td>40009</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Red Seedless Grapes Bunch</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>137611</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>fresh fruits</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>1597</td>\n",
       "      <td>2966</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Pure Coconut Water</td>\n",
       "      <td>98</td>\n",
       "      <td>7</td>\n",
       "      <td>137611</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>juice nectars</td>\n",
       "      <td>beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>1597</td>\n",
       "      <td>37067</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>Organic Banana</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>137611</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>fresh fruits</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>1597</td>\n",
       "      <td>43394</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>Organic Lactose Free Whole Milk</td>\n",
       "      <td>91</td>\n",
       "      <td>16</td>\n",
       "      <td>137611</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>soy lactosefree</td>\n",
       "      <td>dairy eggs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>1597</td>\n",
       "      <td>1376</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Buttermilk Biscuits</td>\n",
       "      <td>105</td>\n",
       "      <td>13</td>\n",
       "      <td>137611</td>\n",
       "      <td>train</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4.0</td>\n",
       "      <td>doughs gelatins bake mixes</td>\n",
       "      <td>pantry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>1620</td>\n",
       "      <td>44626</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ground Allspice</td>\n",
       "      <td>104</td>\n",
       "      <td>13</td>\n",
       "      <td>157320</td>\n",
       "      <td>train</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>spices seasonings</td>\n",
       "      <td>pantry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>1620</td>\n",
       "      <td>15887</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>Rosemary Hand Soap</td>\n",
       "      <td>25</td>\n",
       "      <td>11</td>\n",
       "      <td>157320</td>\n",
       "      <td>train</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>soap</td>\n",
       "      <td>personal care</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>1620</td>\n",
       "      <td>1269</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>of Norwich Original English Mustard Powder Dou...</td>\n",
       "      <td>104</td>\n",
       "      <td>13</td>\n",
       "      <td>157320</td>\n",
       "      <td>train</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>spices seasonings</td>\n",
       "      <td>pantry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>1620</td>\n",
       "      <td>11301</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Free Range Organic Chicken Broth</td>\n",
       "      <td>69</td>\n",
       "      <td>15</td>\n",
       "      <td>157320</td>\n",
       "      <td>train</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>soup broth bouillon</td>\n",
       "      <td>canned goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>1620</td>\n",
       "      <td>25743</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Organic Beef Stock</td>\n",
       "      <td>77</td>\n",
       "      <td>7</td>\n",
       "      <td>157320</td>\n",
       "      <td>train</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>soft drinks</td>\n",
       "      <td>beverages</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>1620</td>\n",
       "      <td>34126</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>Organic Italian Parsley Bunch</td>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>157320</td>\n",
       "      <td>train</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>fresh herbs</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>1620</td>\n",
       "      <td>34969</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Red Vine Tomato</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>157320</td>\n",
       "      <td>train</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>fresh vegetables</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>1620</td>\n",
       "      <td>8670</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>Diced Tomatoes</td>\n",
       "      <td>81</td>\n",
       "      <td>15</td>\n",
       "      <td>157320</td>\n",
       "      <td>train</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>canned jarred vegetables</td>\n",
       "      <td>canned goods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>1620</td>\n",
       "      <td>11250</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Organic Hot Salsa</td>\n",
       "      <td>51</td>\n",
       "      <td>13</td>\n",
       "      <td>157320</td>\n",
       "      <td>train</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>preserved dips spreads</td>\n",
       "      <td>pantry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>1620</td>\n",
       "      <td>41570</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>Active Dry Yeast</td>\n",
       "      <td>17</td>\n",
       "      <td>13</td>\n",
       "      <td>157320</td>\n",
       "      <td>train</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>baking ingredients</td>\n",
       "      <td>pantry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1620</td>\n",
       "      <td>22312</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>Organic Cherry Tomatoes</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>157320</td>\n",
       "      <td>train</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>fresh vegetables</td>\n",
       "      <td>produce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>1620</td>\n",
       "      <td>43909</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>Arrowroot</td>\n",
       "      <td>104</td>\n",
       "      <td>13</td>\n",
       "      <td>157320</td>\n",
       "      <td>train</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>spices seasonings</td>\n",
       "      <td>pantry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>1620</td>\n",
       "      <td>28127</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Flat Fillet Anchovies in Olive Oil with Salt A...</td>\n",
       "      <td>95</td>\n",
       "      <td>15</td>\n",
       "      <td>157320</td>\n",
       "      <td>train</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>8.0</td>\n",
       "      <td>canned meat seafood</td>\n",
       "      <td>canned goods</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     order_id  product_id  add_to_cart_order  reordered  \\\n",
       "0           1       49302                  1          1   \n",
       "1           1       11109                  2          1   \n",
       "2           1       10246                  3          0   \n",
       "3           1       49683                  4          0   \n",
       "4           1       43633                  5          1   \n",
       "5           1       13176                  6          0   \n",
       "6           1       47209                  7          0   \n",
       "7           1       22035                  8          1   \n",
       "8          36       39612                  1          0   \n",
       "9          36       19660                  2          1   \n",
       "10         36       49235                  3          0   \n",
       "11         36       43086                  4          1   \n",
       "12         36       46620                  5          1   \n",
       "13         36       34497                  6          1   \n",
       "14         36       48679                  7          1   \n",
       "15         36       46979                  8          1   \n",
       "16         38       11913                  1          0   \n",
       "17         38       18159                  2          0   \n",
       "18         38        4461                  3          0   \n",
       "19         38       21616                  4          1   \n",
       "20         38       23622                  5          0   \n",
       "21         38       32433                  6          0   \n",
       "22         38       28842                  7          0   \n",
       "23         38       42625                  8          0   \n",
       "24         38       39693                  9          0   \n",
       "25         96       20574                  1          1   \n",
       "26         96       30391                  2          0   \n",
       "27         96       40706                  3          1   \n",
       "28         96       25610                  4          0   \n",
       "29         96       27966                  5          1   \n",
       "..        ...         ...                ...        ...   \n",
       "470      1591       16900                 25          0   \n",
       "471      1591       18792                 26          0   \n",
       "472      1591       38805                 27          0   \n",
       "473      1591       44116                 28          1   \n",
       "474      1591       25237                 29          1   \n",
       "475      1591        9130                 30          1   \n",
       "476      1591       25316                 31          1   \n",
       "477      1597       20082                  1          1   \n",
       "478      1597       25138                  2          1   \n",
       "479      1597       47759                  3          1   \n",
       "480      1597       38453                  4          0   \n",
       "481      1597       11352                  5          1   \n",
       "482      1597       40009                  6          1   \n",
       "483      1597        2966                  7          1   \n",
       "484      1597       37067                  8          1   \n",
       "485      1597       43394                  9          1   \n",
       "486      1597        1376                 10          1   \n",
       "487      1620       44626                  1          0   \n",
       "488      1620       15887                  2          0   \n",
       "489      1620        1269                  3          0   \n",
       "490      1620       11301                  4          1   \n",
       "491      1620       25743                  5          1   \n",
       "492      1620       34126                  6          1   \n",
       "493      1620       34969                  7          1   \n",
       "494      1620        8670                  8          0   \n",
       "495      1620       11250                  9          0   \n",
       "496      1620       41570                 10          0   \n",
       "497      1620       22312                 11          0   \n",
       "498      1620       43909                 12          0   \n",
       "499      1620       28127                 13          0   \n",
       "\n",
       "                                          product_name  aisle_id  \\\n",
       "0                                     Bulgarian Yogurt       120   \n",
       "1        Organic 4% Milk Fat Whole Milk Cottage Cheese       108   \n",
       "2                                Organic Celery Hearts        83   \n",
       "3                                       Cucumber Kirby        83   \n",
       "4                 Lightly Smoked Sardines in Olive Oil        95   \n",
       "5                               Bag of Organic Bananas        24   \n",
       "6                                 Organic Hass Avocado        24   \n",
       "7                          Organic Whole String Cheese        21   \n",
       "8                        Grated Pecorino Romano Cheese         2   \n",
       "9                                         Spring Water       115   \n",
       "10                                 Organic Half & Half        53   \n",
       "11                                  Super Greens Salad       123   \n",
       "12                 Cage Free Extra Large Grade AA Eggs        86   \n",
       "13                               Prosciutto, Americano        96   \n",
       "14                   Organic Garnet Sweet Potato (Yam)        83   \n",
       "15                                           Asparagus        83   \n",
       "16                                  Shelled Pistachios       117   \n",
       "17                            Organic Biologique Limes       123   \n",
       "18          Organic Raw Unfiltered Apple Cider Vinegar        19   \n",
       "19                                Organic Baby Arugula       123   \n",
       "20                            Organic Hot House Tomato        83   \n",
       "21                                          Green Peas       116   \n",
       "22                                    Bunched Cilantro        16   \n",
       "23                                 Flat Parsley, Bunch        16   \n",
       "24                                          Fresh Dill        16   \n",
       "25                                      Roasted Turkey        96   \n",
       "26                                    Organic Cucumber        83   \n",
       "27                              Organic Grape Tomatoes       123   \n",
       "28                         Organic Pomegranate Kernels       116   \n",
       "29                                 Organic Raspberries       123   \n",
       "..                                                 ...       ...   \n",
       "470                         Original Whole Grain Chips       107   \n",
       "471              Goldfish Pretzel Baked Snack Crackers        78   \n",
       "472         Twisted Tropical Tango Organic Juice Drink       100   \n",
       "473             Goodness Grapeness Organic Juice Drink        98   \n",
       "474                                         Nutty Bars        61   \n",
       "475                                Honey Graham Snacks        61   \n",
       "476                             Coconut Dreams Cookies        61   \n",
       "477                Organic Whole Milk with DHA Omega-3        84   \n",
       "478              Organic Plain Greek Whole Milk Yogurt       120   \n",
       "479                                   Mandarin Oranges        24   \n",
       "480                         Reduced Fat Chocolate Milk        84   \n",
       "481       Organic Mini Sandwich Crackers Peanut Butter        78   \n",
       "482                          Red Seedless Grapes Bunch        24   \n",
       "483                                 Pure Coconut Water        98   \n",
       "484                                     Organic Banana        24   \n",
       "485                    Organic Lactose Free Whole Milk        91   \n",
       "486                                Buttermilk Biscuits       105   \n",
       "487                                    Ground Allspice       104   \n",
       "488                                 Rosemary Hand Soap        25   \n",
       "489  of Norwich Original English Mustard Powder Dou...       104   \n",
       "490                   Free Range Organic Chicken Broth        69   \n",
       "491                                 Organic Beef Stock        77   \n",
       "492                      Organic Italian Parsley Bunch        16   \n",
       "493                                    Red Vine Tomato        83   \n",
       "494                                     Diced Tomatoes        81   \n",
       "495                                  Organic Hot Salsa        51   \n",
       "496                                   Active Dry Yeast        17   \n",
       "497                            Organic Cherry Tomatoes        83   \n",
       "498                                          Arrowroot       104   \n",
       "499  Flat Fillet Anchovies in Olive Oil with Salt A...        95   \n",
       "\n",
       "     department_id  user_id eval_set  order_number  order_dow  \\\n",
       "0               16   112108    train             4          4   \n",
       "1               16   112108    train             4          4   \n",
       "2                4   112108    train             4          4   \n",
       "3                4   112108    train             4          4   \n",
       "4               15   112108    train             4          4   \n",
       "5                4   112108    train             4          4   \n",
       "6                4   112108    train             4          4   \n",
       "7               16   112108    train             4          4   \n",
       "8               16    79431    train            23          6   \n",
       "9                7    79431    train            23          6   \n",
       "10              16    79431    train            23          6   \n",
       "11               4    79431    train            23          6   \n",
       "12              16    79431    train            23          6   \n",
       "13              20    79431    train            23          6   \n",
       "14               4    79431    train            23          6   \n",
       "15               4    79431    train            23          6   \n",
       "16              19    42756    train             6          6   \n",
       "17               4    42756    train             6          6   \n",
       "18              13    42756    train             6          6   \n",
       "19               4    42756    train             6          6   \n",
       "20               4    42756    train             6          6   \n",
       "21               1    42756    train             6          6   \n",
       "22               4    42756    train             6          6   \n",
       "23               4    42756    train             6          6   \n",
       "24               4    42756    train             6          6   \n",
       "25              20    17227    train             7          6   \n",
       "26               4    17227    train             7          6   \n",
       "27               4    17227    train             7          6   \n",
       "28               1    17227    train             7          6   \n",
       "29               4    17227    train             7          6   \n",
       "..             ...      ...      ...           ...        ...   \n",
       "470             19   188528    train            31          2   \n",
       "471             19   188528    train            31          2   \n",
       "472             21   188528    train            31          2   \n",
       "473              7   188528    train            31          2   \n",
       "474             19   188528    train            31          2   \n",
       "475             19   188528    train            31          2   \n",
       "476             19   188528    train            31          2   \n",
       "477             16   137611    train             5          1   \n",
       "478             16   137611    train             5          1   \n",
       "479              4   137611    train             5          1   \n",
       "480             16   137611    train             5          1   \n",
       "481             19   137611    train             5          1   \n",
       "482              4   137611    train             5          1   \n",
       "483              7   137611    train             5          1   \n",
       "484              4   137611    train             5          1   \n",
       "485             16   137611    train             5          1   \n",
       "486             13   137611    train             5          1   \n",
       "487             13   157320    train            17          5   \n",
       "488             11   157320    train            17          5   \n",
       "489             13   157320    train            17          5   \n",
       "490             15   157320    train            17          5   \n",
       "491              7   157320    train            17          5   \n",
       "492              4   157320    train            17          5   \n",
       "493              4   157320    train            17          5   \n",
       "494             15   157320    train            17          5   \n",
       "495             13   157320    train            17          5   \n",
       "496             13   157320    train            17          5   \n",
       "497              4   157320    train            17          5   \n",
       "498             13   157320    train            17          5   \n",
       "499             15   157320    train            17          5   \n",
       "\n",
       "     order_hour_of_day  days_since_prior_order                          aisle  \\\n",
       "0                   10                     9.0                         yogurt   \n",
       "1                   10                     9.0           other creams cheeses   \n",
       "2                   10                     9.0               fresh vegetables   \n",
       "3                   10                     9.0               fresh vegetables   \n",
       "4                   10                     9.0            canned meat seafood   \n",
       "5                   10                     9.0                   fresh fruits   \n",
       "6                   10                     9.0                   fresh fruits   \n",
       "7                   10                     9.0                packaged cheese   \n",
       "8                   18                    30.0              specialty cheeses   \n",
       "9                   18                    30.0  water seltzer sparkling water   \n",
       "10                  18                    30.0                          cream   \n",
       "11                  18                    30.0     packaged vegetables fruits   \n",
       "12                  18                    30.0                           eggs   \n",
       "13                  18                    30.0                     lunch meat   \n",
       "14                  18                    30.0               fresh vegetables   \n",
       "15                  18                    30.0               fresh vegetables   \n",
       "16                  16                    24.0         nuts seeds dried fruit   \n",
       "17                  16                    24.0     packaged vegetables fruits   \n",
       "18                  16                    24.0                  oils vinegars   \n",
       "19                  16                    24.0     packaged vegetables fruits   \n",
       "20                  16                    24.0               fresh vegetables   \n",
       "21                  16                    24.0                 frozen produce   \n",
       "22                  16                    24.0                    fresh herbs   \n",
       "23                  16                    24.0                    fresh herbs   \n",
       "24                  16                    24.0                    fresh herbs   \n",
       "25                  20                    30.0                     lunch meat   \n",
       "26                  20                    30.0               fresh vegetables   \n",
       "27                  20                    30.0     packaged vegetables fruits   \n",
       "28                  20                    30.0                 frozen produce   \n",
       "29                  20                    30.0     packaged vegetables fruits   \n",
       "..                 ...                     ...                            ...   \n",
       "470                 17                     6.0                 chips pretzels   \n",
       "471                 17                     6.0                       crackers   \n",
       "472                 17                     6.0                        missing   \n",
       "473                 17                     6.0                  juice nectars   \n",
       "474                 17                     6.0                  cookies cakes   \n",
       "475                 17                     6.0                  cookies cakes   \n",
       "476                 17                     6.0                  cookies cakes   \n",
       "477                  8                     4.0                           milk   \n",
       "478                  8                     4.0                         yogurt   \n",
       "479                  8                     4.0                   fresh fruits   \n",
       "480                  8                     4.0                           milk   \n",
       "481                  8                     4.0                       crackers   \n",
       "482                  8                     4.0                   fresh fruits   \n",
       "483                  8                     4.0                  juice nectars   \n",
       "484                  8                     4.0                   fresh fruits   \n",
       "485                  8                     4.0                soy lactosefree   \n",
       "486                  8                     4.0     doughs gelatins bake mixes   \n",
       "487                 13                     8.0              spices seasonings   \n",
       "488                 13                     8.0                           soap   \n",
       "489                 13                     8.0              spices seasonings   \n",
       "490                 13                     8.0            soup broth bouillon   \n",
       "491                 13                     8.0                    soft drinks   \n",
       "492                 13                     8.0                    fresh herbs   \n",
       "493                 13                     8.0               fresh vegetables   \n",
       "494                 13                     8.0       canned jarred vegetables   \n",
       "495                 13                     8.0         preserved dips spreads   \n",
       "496                 13                     8.0             baking ingredients   \n",
       "497                 13                     8.0               fresh vegetables   \n",
       "498                 13                     8.0              spices seasonings   \n",
       "499                 13                     8.0            canned meat seafood   \n",
       "\n",
       "        department  \n",
       "0       dairy eggs  \n",
       "1       dairy eggs  \n",
       "2          produce  \n",
       "3          produce  \n",
       "4     canned goods  \n",
       "5          produce  \n",
       "6          produce  \n",
       "7       dairy eggs  \n",
       "8       dairy eggs  \n",
       "9        beverages  \n",
       "10      dairy eggs  \n",
       "11         produce  \n",
       "12      dairy eggs  \n",
       "13            deli  \n",
       "14         produce  \n",
       "15         produce  \n",
       "16          snacks  \n",
       "17         produce  \n",
       "18          pantry  \n",
       "19         produce  \n",
       "20         produce  \n",
       "21          frozen  \n",
       "22         produce  \n",
       "23         produce  \n",
       "24         produce  \n",
       "25            deli  \n",
       "26         produce  \n",
       "27         produce  \n",
       "28          frozen  \n",
       "29         produce  \n",
       "..             ...  \n",
       "470         snacks  \n",
       "471         snacks  \n",
       "472        missing  \n",
       "473      beverages  \n",
       "474         snacks  \n",
       "475         snacks  \n",
       "476         snacks  \n",
       "477     dairy eggs  \n",
       "478     dairy eggs  \n",
       "479        produce  \n",
       "480     dairy eggs  \n",
       "481         snacks  \n",
       "482        produce  \n",
       "483      beverages  \n",
       "484        produce  \n",
       "485     dairy eggs  \n",
       "486         pantry  \n",
       "487         pantry  \n",
       "488  personal care  \n",
       "489         pantry  \n",
       "490   canned goods  \n",
       "491      beverages  \n",
       "492        produce  \n",
       "493        produce  \n",
       "494   canned goods  \n",
       "495         pantry  \n",
       "496         pantry  \n",
       "497        produce  \n",
       "498         pantry  \n",
       "499   canned goods  \n",
       "\n",
       "[500 rows x 15 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = order_products__train.merge(products,how='left', on='product_id')\n",
    "opt = opt.merge(orders,how='left', on='order_id')\n",
    "opt = opt.merge(aisles,how='left', on='aisle_id')\n",
    "opt = opt.merge(departments,how='left', on='department_id')\n",
    "opt.head(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "order_id                  0\n",
       "product_id                0\n",
       "add_to_cart_order         0\n",
       "reordered                 0\n",
       "product_name              0\n",
       "aisle_id                  0\n",
       "department_id             0\n",
       "user_id                   0\n",
       "eval_set                  0\n",
       "order_number              0\n",
       "order_dow                 0\n",
       "order_hour_of_day         0\n",
       "days_since_prior_order    0\n",
       "aisle                     0\n",
       "department                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(555793, 15)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt[opt.reordered==0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:617: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "X=opt.drop(['product_name','eval_set','aisle','department','reordered'],axis=1)\n",
    "Y=opt['reordered']\n",
    "X = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969231, 10)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of total variance in the dataset explained by each component from Sklearn PCA.\n",
      " [0.14076004 0.10773474 0.10237999 0.10034129 0.10015277]\n"
     ]
    }
   ],
   "source": [
    "X_pca = PCA(n_components=5)\n",
    "X_pca.fit(X_train)\n",
    "X_train_pca = X_pca.transform(X_train)\n",
    "X_test_pca = X_pca.transform(X_test)\n",
    "print(\n",
    "    'The percentage of total variance in the dataset explained by each',\n",
    "    'component from Sklearn PCA.\\n',\n",
    "    X_pca.explained_variance_ratio_\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(C=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.02, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='warn',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train_pca,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.62909408 0.62596274 0.62846472 0.62941525 0.6278831 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy:  [0.62647151 0.62848923 0.6288022  0.62752627 0.63067997]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(lr, X_train_pca, y_train, cv=5))\n",
    "print(\"Testing data accuracy: \",cross_val_score(lr, X_test_pca, y_test, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_lr = lr.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[112718 276250]\n",
      " [ 81116 499147]]\n",
      "Accuracy Score for Random Forest : 0.6312891354073488\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred_lr))\n",
    "print('Accuracy Score for Random Forest :',accuracy_score(y_train, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Random Forest : 0.5749977753102224\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score for Random Forest :\" ,roc_auc_score(y_train, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Random Forest:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.37      0.45    388968\n",
      "           1       0.66      0.80      0.72    580263\n",
      "\n",
      "   micro avg       0.63      0.63      0.63    969231\n",
      "   macro avg       0.61      0.59      0.58    969231\n",
      "weighted avg       0.62      0.63      0.61    969231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report for Random Forest:\",classification_report(y_train, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = KNeighborsClassifier(n_neighbors=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'leaf_size': 1, 'n_neighbors': 5}, {'leaf_size': 2, 'n_neighbors': 5}, {'leaf_size': 3, 'n_neighbors': 5}, {'leaf_size': 5, 'n_neighbors': 5}]\n",
      "[0.57054717 0.57054717 0.57054717 0.57054717]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.72350967 0.72350967 0.72350967 0.72350967]\n",
      "Best Hyper Parameters:\n",
      " {'leaf_size': 1, 'n_neighbors': 5}\n",
      "0.5705471657427383\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=1, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "params = {'n_neighbors':[5],\n",
    "          'leaf_size':[1,2,3,5]\n",
    "                  }\n",
    "#Making models with hyper parameters sets\n",
    "grid_class_knn = model_selection.GridSearchCV(knn_model, param_grid=params)\n",
    "#Learning\n",
    "grid_class_knn.fit(X_train_pca,y_train)\n",
    "#The best hyper parameters set\n",
    "\n",
    "results = grid_class_knn.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class_knn.best_params_)\n",
    "print(grid_class_knn.best_score_)\n",
    "final_model = grid_class_knn.best_estimator_\n",
    "print(final_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Fitting the model with the parameters and train data\n",
    "knn_model = KNeighborsClassifier(leaf_size=1,n_neighbors=5)\n",
    "knn_model.fit(X_train_pca, y_train)\n",
    "y_pred_knn = knn_model.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969231,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_knn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy for knn:  [0.58909042 0.58860551 0.58934836 0.58908618 0.59056158 0.59064412\n",
      " 0.59096396 0.58943698 0.58689462 0.58962877]\n",
      "Testing data accuracy for knn:  [0.58846895 0.58804978 0.58530538 0.58718313 0.58658129 0.58767875\n",
      " 0.5895084  0.58998989 0.58861765 0.59220473]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy for knn: \",cross_val_score(knn_model, X_train_pca, y_train, cv=10))\n",
    "print(\"Testing data accuracy for knn: \",cross_val_score(knn_model, X_test_pca, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Random Forest : 0.7042915632004009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score for Random Forest :\" ,roc_auc_score(y_train, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[225505 163463]\n",
      " [ 99323 480940]]\n",
      "Accuracy Score for Random Forest : 0.7288716518559559\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred_knn))\n",
    "print('Accuracy Score for Random Forest :',accuracy_score(y_train, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Random Forest:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.58      0.63    388968\n",
      "           1       0.75      0.83      0.79    580263\n",
      "\n",
      "   micro avg       0.73      0.73      0.73    969231\n",
      "   macro avg       0.72      0.70      0.71    969231\n",
      "weighted avg       0.73      0.73      0.72    969231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report for Random Forest:\",classification_report(y_train, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble\n",
    "rfc = ensemble.RandomForestClassifier(max_depth=10,n_estimators= 100)\n",
    "rfc.fit(X_train_pca, y_train)\n",
    "rfc_pred = rfc.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 3, 'max_features': 5}, {'max_depth': 4, 'max_features': 5}, {'max_depth': 5, 'max_features': 5}]\n",
      "[0.62952691 0.63083414 0.63213517]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.62974152 0.63133948 0.63251898]\n",
      "Best Hyper Parameters:\n",
      " {'max_depth': 5, 'max_features': 5}\n",
      "0.6321351669519444\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=5, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "dt_grid={'max_depth':[3,4,5],'max_features': [5]}\n",
    "\n",
    "grid_class_rfc=model_selection.GridSearchCV(rfc,dt_grid,cv=6)\n",
    "grid_class_rfc.fit(X_train_pca, y_train)\n",
    "results = grid_class_rfc.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class_rfc.best_params_)\n",
    "print(grid_class_rfc.best_score_)\n",
    "final_model = grid_class_rfc.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:248: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "rfc = ensemble.RandomForestClassifier(max_depth=5,max_features= 5)\n",
    "rfc.fit(X_train_pca, y_train)\n",
    "rfc_pred = rfc.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.63246787 0.63030122 0.63348414 0.63232995 0.63211329]\n",
      "Testing data accuracy:  [0.66179975 0.66242161 0.66592438 0.66036328 0.66667068]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(rfc, X_train_pca, y_train, cv=5))\n",
    "print(\"Testing data accuracy: \",cross_val_score(rfc, X_test, y_test, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Random Forest : 0.5790349655943385\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score for Random Forest :\" ,roc_auc_score(y_train, rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[120309 268659]\n",
      " [ 87755 492508]]\n",
      "Accuracy Score for Random Forest : 0.6322713573957086\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, rfc_pred))\n",
    "print('Accuracy Score for Random Forest :',accuracy_score(y_train, rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Random Forest:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.31      0.40    388968\n",
      "           1       0.65      0.85      0.73    580263\n",
      "\n",
      "   micro avg       0.63      0.63      0.63    969231\n",
      "   macro avg       0.61      0.58      0.57    969231\n",
      "weighted avg       0.62      0.63      0.60    969231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report for Random Forest:\",classification_report(y_train, rfc_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "decision_tree = tree.DecisionTreeClassifier(max_depth=10)\n",
    "decision_tree.fit(X_train_pca, y_train)\n",
    "y_pred_dt = decision_tree.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 50, 'max_features': 5}]\n",
      "[0.60001383]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99962176]\n",
      "Best Hyper Parameters:\n",
      " {'max_depth': 50, 'max_features': 5}\n",
      "0.6000138253935337\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=50,\n",
      "            max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dt_grid={'max_depth':[50],'max_features': [5]}\n",
    "grid_class_dt=model_selection.GridSearchCV(decision_tree,dt_grid,cv=6)\n",
    "grid_class_dt.fit(X_train_pca, y_train)\n",
    "results = grid_class_dt.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class_dt.best_params_)\n",
    "print(grid_class_dt.best_score_)\n",
    "final_model = grid_class_dt.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Fitting the best parmaters after gridsearchcv to the decision tree\n",
    "decision_tree = tree.DecisionTreeClassifier(max_depth=50,max_features=5)\n",
    "decision_tree.fit(X_train_pca, y_train)\n",
    "y_pred_dt = decision_tree.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy for Decision Tree:  [0.59990302 0.59899509 0.59903636 0.59944492 0.60186953 0.5997854\n",
      " 0.6027981  0.60035286 0.60286622 0.59834712]\n",
      "Testing data accuracy for Decision Tree:  [0.59354839 0.59534413 0.59247936 0.588772   0.59209418 0.59256584\n",
      " 0.5869806  0.59518995 0.59112138 0.58982137]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training data accuracy for Decision Tree: \",cross_val_score(decision_tree, X_train_pca, y_train, cv=10))\n",
    "print(\"Testing data accuracy for Decision Tree: \",cross_val_score(decision_tree, X_test_pca, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Decision Tree : 0.9988297008562766\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score for Decision Tree :\" ,roc_auc_score(y_train, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[388256    712]\n",
      " [   296 579967]]\n",
      "Accuracy Score for Decision Tree : 0.998960000247619\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(confusion_matrix(y_train, y_pred_dt))\n",
    "print('Accuracy Score for Decision Tree :',accuracy_score(y_train, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Decision Tree:               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    388968\n",
      "           1       1.00      1.00      1.00    580263\n",
      "\n",
      "   micro avg       1.00      1.00      1.00    969231\n",
      "   macro avg       1.00      1.00      1.00    969231\n",
      "weighted avg       1.00      1.00      1.00    969231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Decision Tree:\",classification_report(y_train, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm=SVC()\n",
    "svm.fit(X_train_pca, y_train)\n",
    "y_pred_svm = svm.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-76-ab14f6b9c995>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'C'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'gamma'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.0001\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'kernel'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'rbf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgrid_class_svm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msvm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrefit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mgrid_class_svm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_class_svm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'svm' is not defined"
     ]
    }
   ],
   "source": [
    "param_grid = {'C':[1,10,100,1000],'gamma':[1,0.1,0.001,0.0001], 'kernel':['linear','rbf']}\n",
    "grid_class_svm=model_selection.GridSearchCV(svm,param_grid,refit = True)\n",
    "grid_class_svm.fit(X_train_pca, y_train)\n",
    "results = grid_class_svm.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class_svm.best_params_)\n",
    "print(grid_class_svm.best_score_)\n",
    "final_model = grid_class_svm.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm=SVC()\n",
    "svm.fit(X_train_pca, y_train)\n",
    "y_pred_svm = svm.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Training data accuracy for Random Forest: \",cross_val_score(grid_class_rfc, X_train_pca, y_train, cv=10))\n",
    "print(\"Testing data accuracy for Random Forest: \",cross_val_score(grid_class_rfc, X_test_pca, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score for Random Forest :\" ,roc_auc_score(y_train, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(confusion_matrix(y_train_sample, y_pred_bnb))\n",
    "print('Accuracy Score for Random Forest :',accuracy_score(y_train, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Classification Report for Random Forest:\",classification_report(y_train, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GradientBoostingClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 7,\n",
    "          'loss': 'deviance'}\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "y_pred_gbr = clf.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params ={\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"n_estimators\":[1000]\n",
    "    }\n",
    "gb = model_selection.GridSearchCV(clf, params, cv=10)\n",
    "gb.fit(X_train_pca, y_train)\n",
    "results = gb.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",gb.best_params_)\n",
    "print(gb.best_score_)\n",
    "final_model = gb.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "y_pred_gbr = clf.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training data accuracy for GBR: \",cross_val_score(gb, X_train_pca, y_train, cv=10))\n",
    "print(\"Testing data accuracy for GBR: \",cross_val_score(gb, X_test_pca, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score for GBR :\" ,roc_auc_score(y_train, y_pred_gbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(confusion_matrix(y_train_sample, y_pred_gbr))\n",
    "print('Accuracy Score for GBR :',accuracy_score(y_train, y_pred_gbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Classification Report for GBR:\",classification_report(y_train, y_pred_gbr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Using skb to get the best 5 features out of the total\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "skb = SelectKBest(f_classif,k=5)\n",
    "skb.fit(X_train, y_train)\n",
    "#skb.fit(X_train_sample, y_train_sample)\n",
    "X_train_skb = skb.transform(X_train)\n",
    "X_test_skb = skb.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_skb,y_train)\n",
    "y_pred_lr = lr.predict(X_train_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy:  [0.64893447 0.64718567 0.64742813 0.64782687 0.64805386]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data accuracy:  [0.6456583  0.65019199 0.65066143 0.64774847 0.6482781 ]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print(\"Training data accuracy: \",cross_val_score(lr, X_train_skb, y_train, cv=5))\n",
    "print(\"Testing data accuracy: \",cross_val_score(lr, X_test_skb, y_test, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for LR : 0.5972670965121367\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score for LR :\" ,roc_auc_score(y_train, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[132584 256384]\n",
      " [ 84908 495355]]\n",
      "Accuracy Score for LR : 0.647873417172996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred_lr))\n",
    "print('Accuracy Score for LR :',accuracy_score(y_train, y_pred_lr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for LR:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.34      0.44    388968\n",
      "           1       0.66      0.85      0.74    580263\n",
      "\n",
      "   micro avg       0.65      0.65      0.65    969231\n",
      "   macro avg       0.63      0.60      0.59    969231\n",
      "weighted avg       0.64      0.65      0.62    969231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(\"Classification Report for LR:\",classification_report(y_train, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model with the parameters and train data\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train_skb, y_train)\n",
    "y_pred_knn = knn_model.predict(X_train_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'leaf_size': 1, 'n_neighbors': 5}, {'leaf_size': 2, 'n_neighbors': 5}, {'leaf_size': 3, 'n_neighbors': 5}, {'leaf_size': 5, 'n_neighbors': 5}]\n",
      "[0.63439159 0.63460104 0.63437612 0.63429048]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7425397  0.74252423 0.74252474 0.74233078]\n",
      "Best Hyper Parameters:\n",
      " {'leaf_size': 2, 'n_neighbors': 5}\n",
      "0.6346010393807049\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=2, metric='minkowski',\n",
      "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
      "           weights='uniform')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "params = {'n_neighbors':[5],\n",
    "          'leaf_size':[1,2,3,5]\n",
    "                  }\n",
    "#Making models with hyper parameters sets\n",
    "grid_class_knn = model_selection.GridSearchCV(knn_model, param_grid=params)\n",
    "#Learning\n",
    "grid_class_knn.fit(X_train_skb,y_train)\n",
    "#The best hyper parameters set\n",
    "\n",
    "results = grid_class_knn.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class_knn.best_params_)\n",
    "print(grid_class_knn.best_score_)\n",
    "final_model = grid_class_knn.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Fitting the model with the best parameters we got above to improve the performance\n",
    "knn_model = KNeighborsClassifier(leaf_size= 1,n_neighbors=5)\n",
    "knn_model.fit(X_train_skb, y_train)\n",
    "y_pred_knn = knn_model.predict(X_train_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy for KNN:  [0.6357249  0.6370352  0.63624077 0.63537035 0.63627828 0.63483384\n",
      " 0.63819733 0.63732035 0.63763645 0.63613008]\n",
      "Testing data accuracy for KNN:  [0.63088589 0.63241773 0.62890296 0.63020294 0.63410289 0.62855698\n",
      " 0.63329963 0.63026626 0.6317348  0.63380519]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data accuracy for KNN: \",cross_val_score(knn_model, X_train_skb, y_train, cv=10))\n",
    "print(\"Testing data accuracy for KNN: \",cross_val_score(knn_model, X_test_skb, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for KNN : 0.7215467450149926\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score for KNN :\" ,roc_auc_score(y_train, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred_knn))\n",
    "print('Accuracy Score for LR :',accuracy_score(y_train, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for KNN:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.62      0.66    388968\n",
      "           1       0.76      0.83      0.79    580263\n",
      "\n",
      "   micro avg       0.74      0.74      0.74    969231\n",
      "   macro avg       0.73      0.72      0.73    969231\n",
      "weighted avg       0.74      0.74      0.74    969231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Classification Report for KNN:\",classification_report(y_train, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Fitting the model with the parameters and train data\n",
    "rfc = ensemble.RandomForestClassifier(max_depth=10,n_estimators= 100)\n",
    "rfc.fit(X_train_skb, y_train)\n",
    "y_pred_rfc = rfc.predict(X_train_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 3, 'max_features': 5}, {'max_depth': 4, 'max_features': 5}, {'max_depth': 5, 'max_features': 5}]\n",
      "[0.64420659 0.65376675 0.65869953]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64432731 0.65384867 0.6588353 ]\n",
      "Best Hyper Parameters:\n",
      " {'max_depth': 5, 'max_features': 5}\n",
      "0.6586995257064622\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=5, max_features=5, max_leaf_nodes=None,\n",
      "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "            min_samples_leaf=1, min_samples_split=2,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dt_grid={'max_depth':[3,4,5],'max_features': [5]}\n",
    "\n",
    "grid_class_rfc=model_selection.GridSearchCV(rfc,dt_grid,cv=6)\n",
    "grid_class_rfc.fit(X_train_skb, y_train)\n",
    "results = grid_class_rfc.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class_rfc.best_params_)\n",
    "print(grid_class_rfc.best_score_)\n",
    "final_model = grid_class_rfc.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Fitting the model with the best parameters we got above to improve the performance\n",
    "rfc = ensemble.RandomForestClassifier(max_depth=3, max_features= 5,n_estimators= 100)\n",
    "rfc.fit(X_train_skb, y_train)\n",
    "y_pred_rfc = rfc.predict(X_train_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy for Random Forest:  [0.64327721 0.64592877 0.64400974 0.64358305 0.64249972 0.64403702\n",
      " 0.64754496 0.64106559 0.64519923 0.64649925]\n",
      "Testing data accuracy for Random Forest:  [0.64557053 0.64659717 0.64736753 0.64883603 0.64922121 0.64714238\n",
      " 0.64709423 0.64379604 0.6445905  0.64846646]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training data accuracy for Random Forest: \",cross_val_score(rfc, X_train_skb, y_train, cv=10))\n",
    "print(\"Testing data accuracy for Random Forest: \",cross_val_score(rfc, X_test_skb, y_test, cv=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Random Forest : 0.6111819520156541\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print (\"AUC Score for Random Forest :\" ,roc_auc_score(y_train, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[230000 158968]\n",
      " [102308 477955]]\n",
      "Accuracy Score for Random Forest : 0.7304295879929552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score \n",
    "print(confusion_matrix(y_train, y_pred_knn))\n",
    "print('Accuracy Score for Random Forest :',accuracy_score(y_train, y_pred_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report for Random Forest:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.44      0.50    388968\n",
      "           1       0.68      0.78      0.73    580263\n",
      "\n",
      "   micro avg       0.65      0.65      0.65    969231\n",
      "   macro avg       0.63      0.61      0.61    969231\n",
      "weighted avg       0.64      0.65      0.63    969231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification Report for Random Forest:\",classification_report(y_train, y_pred_rfc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model with the parameters and train data\n",
    "decision_tree = tree.DecisionTreeClassifier(max_depth=10)\n",
    "decision_tree.fit(X_train_skb, y_train)\n",
    "y_pred_dt = decision_tree.predict(X_train_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 50, 'max_features': 5}]\n",
      "[0.60235795]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ankush\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:125: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.88816226]\n",
      "Best Hyper Parameters:\n",
      " {'max_depth': 50, 'max_features': 5}\n",
      "0.6023579518195353\n",
      "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=50,\n",
      "            max_features=5, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "            min_impurity_split=None, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            presort=False, random_state=None, splitter='best')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dt_grid={'max_depth':[50],'max_features': [5]}\n",
    "grid_class_dt=model_selection.GridSearchCV(decision_tree,dt_grid,cv=6)\n",
    "grid_class_dt.fit(X_train_skb, y_train)\n",
    "results = grid_class_dt.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class_dt.best_params_)\n",
    "print(grid_class_dt.best_score_)\n",
    "final_model = grid_class_dt.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Fitting the model with the best parameters we got above to improve the performance\n",
    "decision_tree = tree.DecisionTreeClassifier(max_depth=50,max_features=5)\n",
    "decision_tree.fit(X_train_skb, y_train)\n",
    "y_pred_dt = decision_tree.predict(X_train_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy for Decision Tree:  [0.60249578 0.60119579 0.60184063 0.6020016  0.60185715]\n",
      "Testing data accuracy for Decision Tree:  [0.59099882 0.59084945 0.59342538 0.59503834 0.59338927]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Training data accuracy for Decision Tree: \",cross_val_score(decision_tree, X_train_skb, y_train, cv=5))\n",
    "print(\"Testing data accuracy for Decision Tree: \",cross_val_score(decision_tree, X_test_skb, y_test, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score for Decision Tree : 0.8832534428502907\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score for Decision Tree :\" ,roc_auc_score(y_train, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[348463  40505]\n",
      " [ 75062 505201]]\n",
      "Accuracy Score for Decision Tree : 0.8807642347386743\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_train, y_pred_dt))\n",
    "print('Accuracy Score for Decision Tree :',accuracy_score(y_train, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the model with the parameters and train data\n",
    "from sklearn.svm import SVC\n",
    "svm=SVC()\n",
    "svm.fit(X_train_skb, y_train)\n",
    "y_pred_svm = svm.predict(X_train_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {'C':[1,10,100,1000],'gamma':[1,0.1,0.001,0.0001], 'kernel':['linear','rbf']}\n",
    "grid_class_svm=model_selection.GridSearchCV(SVC(),param_grid,refit = True)\n",
    "grid_class_svm.fit(X_train_skb, y_train)\n",
    "results = grid_class_svm.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",grid_class_svm.best_params_)\n",
    "print(grid_class_svm.best_score_)\n",
    "final_model = grid_class_svm.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Training data accuracy for SVC: \",cross_val_score(grid_class_svm, X_train_skb, y_train, cv=5))\n",
    "print(\"Testing data accuracy for SVC: \",cross_val_score(grid_class_svm, X_test_skb, y_test, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score for SVC :\" ,roc_auc_score(y_train, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(confusion_matrix(y_train_sample, y_pred_dt))\n",
    "print('Accuracy Score for SVC :',accuracy_score(y_train_sample, y_pred_dt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Classification Report for SVC:\",classification_report(y_train_sample, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boost Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Fitting the model with the parameters and train data\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 7,\n",
    "          'loss': 'deviance'}\n",
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train_skb, y_train)\n",
    "y_pred_gbr = clf.predict(X_train_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params ={\n",
    "    \"loss\":[\"deviance\"],\n",
    "    \"max_depth\":[3,5,8],\n",
    "    \"n_estimators\":[1000]\n",
    "    \n",
    "    }\n",
    "gb = model_selection.GridSearchCV(clf, params, cv=10)\n",
    "gb.fit(X_train_skb, y_train)\n",
    "results = gb.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(\"Best Hyper Parameters:\\n\",gb.best_params_)\n",
    "print(gb.best_score_)\n",
    "final_model = gb.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = ensemble.GradientBoostingClassifier(**params)\n",
    "clf.fit(X_train_pca, y_train)\n",
    "y_pred_gbr = clf.predict(X_train_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Training data accuracy for GBR: \",cross_val_score(gb, X_train_skb, y_train, cv=5))\n",
    "print(\"Testing data accuracy for GBR: \",cross_val_score(gb, X_test_skb, y_test, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print (\"AUC Score for GBR :\" ,roc_auc_score(y_train y_pred_gbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(confusion_matrix(y_train_sample, y_pred_gbr))\n",
    "print('Accuracy Score for GBR :',accuracy_score(y_train, y_pred_gbr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Classification Report for GBR:\",classification_report(y_train, y_pred_gbr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k means clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3800808255128642\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'KMeans'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-64-6607981ec15f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msilhouette_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'euclidean'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Plot the solution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train_pca\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, data, **kwargs)\u001b[0m\n\u001b[0;32m   2791\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmarker\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmarker\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2792\u001b[0m         \u001b[0mvmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvmax\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvmax\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2793\u001b[1;33m         verts=verts, edgecolors=edgecolors, data=data, **kwargs)\n\u001b[0m\u001b[0;32m   2794\u001b[0m     \u001b[0msci\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m__ret\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2795\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m__ret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\__init__.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(ax, data, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1783\u001b[0m                         \u001b[1;34m\"the Matplotlib list!)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlabel_namer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1784\u001b[0m                         RuntimeWarning, stacklevel=2)\n\u001b[1;32m-> 1785\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1787\u001b[0m         inner.__doc__ = _add_data_doc(inner.__doc__,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\matplotlib\\axes\\_axes.py\u001b[0m in \u001b[0;36mscatter\u001b[1;34m(self, x, y, s, c, marker, cmap, norm, vmin, vmax, alpha, linewidths, verts, edgecolors, **kwargs)\u001b[0m\n\u001b[0;32m   4186\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4187\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# First, does 'c' look suitable for value-mapping?\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4188\u001b[1;33m                 \u001b[0mc_array\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masanyarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4189\u001b[0m                 \u001b[0mn_elem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4190\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mc_array\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxy_shape\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masanyarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m     \"\"\"\n\u001b[1;32m--> 544\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubok\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    545\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'KMeans'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.cluster import KMeans\n",
    "# Normalize the data.\n",
    "X_train_norm = normalize(X_train)\n",
    "\n",
    "# Reduce it to two components.\n",
    "X_train_pca = PCA(2).fit_transform(X_train_norm)\n",
    "\n",
    "# Calculate predicted values.\n",
    "y_pred = KMeans(n_clusters=2, random_state=42).fit(X_train_pca)\n",
    "labels = y_pred.labels_\n",
    "print(metrics.silhouette_score(X_train_pca, labels, metric='euclidean'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing k-means clusters against the data:\n",
      "reordered       0       1\n",
      "row_0                    \n",
      "0          165796  343924\n",
      "1          223172  236339\n"
     ]
    }
   ],
   "source": [
    "y_pred = KMeans(n_clusters=2, random_state=42).fit_predict(X_train_pca)\n",
    "\n",
    "# Plot the solution.\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=y_pred)\n",
    "plt.show()\n",
    "\n",
    "# Check the solution against the data.\n",
    "print('Comparing k-means clusters against the data:')\n",
    "print(pd.crosstab(y_pred, y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjusted Rand Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.029962073447046548"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_pred = KMeans(n_clusters=2, random_state=42).fit_predict(X_train_norm)\n",
    "from sklearn import metrics\n",
    "    \n",
    "metrics.adjusted_rand_score(y_train, full_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try MiniBatch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing k-means and mini batch k-means solutions:\n",
      "col_0       0       1\n",
      "row_0                \n",
      "0      505605    2014\n",
      "1        4115  457497\n"
     ]
    }
   ],
   "source": [
    "# Each batch will be made up of 200 data points.\n",
    "minibatchkmeans = MiniBatchKMeans(\n",
    "    init='random',\n",
    "    n_clusters=2,\n",
    "    batch_size=200)\n",
    "minibatchkmeans.fit(X_train_pca)\n",
    "\n",
    "# Add the new predicted cluster memberships to the data frame.\n",
    "predict_mini = minibatchkmeans.predict(X_train_pca)\n",
    "\n",
    "# Check the MiniBatch model against our earlier one.\n",
    "print('Comparing k-means and mini batch k-means solutions:')\n",
    "print(pd.crosstab(predict_mini, y_pred))        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean-shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimated clusters: 1\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth\n",
    "\n",
    "# Here we set the bandwidth. This function automatically derives a bandwidth\n",
    "# number based on an inspection of the distances among points in the data.\n",
    "bandwidth = estimate_bandwidth(X_train, quantile=0.2, n_samples=500)\n",
    "\n",
    "# Declare and fit the model.\n",
    "ms = MeanShift(bandwidth=bandwidth, bin_seeding=True)\n",
    "ms.fit(X_train_pca)\n",
    "\n",
    "# Extract cluster assignments for each data point.\n",
    "labels = ms.labels_\n",
    "\n",
    "# Coordinates of the cluster centers.\n",
    "cluster_centers = ms.cluster_centers_\n",
    "\n",
    "# Count our clusters.\n",
    "n_clusters_ = len(np.unique(labels))\n",
    "\n",
    "print(\"Number of estimated clusters: {}\".format(n_clusters_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparing the assigned categories to the ones in the data:\n",
      "col_0           0\n",
      "reordered        \n",
      "0          388968\n",
      "1          580263\n"
     ]
    }
   ],
   "source": [
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=labels)\n",
    "plt.show()\n",
    "\n",
    "print('Comparing the assigned categories to the ones in the data:')\n",
    "print(pd.crosstab(y_train,labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-81b88e9b7b7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Declare and fit the model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0msc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSpectralClustering\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0msc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m#Predicted clusters.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\spectral.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    482\u001b[0m             self.affinity_matrix_ = pairwise_kernels(X, metric=self.affinity,\n\u001b[0;32m    483\u001b[0m                                                      \u001b[0mfilter_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 484\u001b[1;33m                                                      **params)\n\u001b[0m\u001b[0;32m    485\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m         \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_random_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_kernels\u001b[1;34m(X, Y, metric, filter_params, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1557\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Unknown kernel %r\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1559\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1067\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1068\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1069\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1071\u001b[0m     \u001b[1;31m# TODO: in some cases, backend='threading' may be appropriate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mrbf_kernel\u001b[1;34m(X, Y, gamma)\u001b[0m\n\u001b[0;32m    821\u001b[0m         \u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 823\u001b[1;33m     \u001b[0mK\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0meuclidean_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    824\u001b[0m     \u001b[0mK\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    825\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m# exponentiate K in-place\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[0mYY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "# We know we're looking for three clusters.\n",
    "n_clusters=3\n",
    "\n",
    "# Declare and fit the model.\n",
    "sc = SpectralClustering(n_clusters=2)\n",
    "sc.fit(X_train_pca)\n",
    "\n",
    "#Predicted clusters.\n",
    "predict=sc.fit_predict(X_train_pca)\n",
    "\n",
    "#Graph results.\n",
    "plt.scatter(X_train_pca[:, 0], X_train_pca[:, 1], c=predict)\n",
    "plt.show()\n",
    "\n",
    "print('Comparing the assigned categories to the ones in the data:')\n",
    "print(pd.crosstab(y_train,predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Affinity Propogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-87f5995796c9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Declare the model and fit it in one statement.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# Note that you can provide arguments to the model, but we didn't.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0maf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAffinityPropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_pca\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Done'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\cluster\\affinity_propagation_.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    369\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maffinity_matrix_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    370\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maffinity\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"euclidean\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 371\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maffinity_matrix_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0meuclidean_distances\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    372\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    373\u001b[0m             raise ValueError(\"Affinity must be 'precomputed' or \"\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[0mYY\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrow_norms\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msquared\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Declare the model and fit it in one statement.\n",
    "# Note that you can provide arguments to the model, but we didn't.\n",
    "af = AffinityPropagation().fit(X_train_pca)\n",
    "print('Done')\n",
    "\n",
    "# Pull the number of clusters and cluster assignments for each data point.\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "n_clusters_ = len(cluster_centers_indices)\n",
    "labels = af.labels_\n",
    "\n",
    "print('Estimated number of clusters: {}'.format(n_clusters_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Output tensors to a Model must be the output of a Keras `Layer` (thus holding past layer metadata). Found: <keras.layers.core.Dense object at 0x0000022CC4815CC0>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-e0defd1ad492>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;31m# Final predictions and model.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'softmax'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m model.compile(loss='binary_crossentropy',\n\u001b[0;32m     28\u001b[0m               \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'rmsprop'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[0;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     91\u001b[0m                 'inputs' in kwargs and 'outputs' in kwargs):\n\u001b[0;32m     92\u001b[0m             \u001b[1;31m# Graph network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_init_graph_network\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m             \u001b[1;31m# Subclassed network\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36m_init_graph_network\u001b[1;34m(self, inputs, outputs, name)\u001b[0m\n\u001b[0;32m    186\u001b[0m                                  \u001b[1;34m'the output of a Keras `Layer` '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m                                  \u001b[1;34m'(thus holding past layer metadata). '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m                                  'Found: ' + str(x))\n\u001b[0m\u001b[0;32m    189\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_base_init\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         self._compute_previous_mask = (\n",
      "\u001b[1;31mValueError\u001b[0m: Output tensors to a Model must be the output of a Keras `Layer` (thus holding past layer metadata). Found: <keras.layers.core.Dense object at 0x0000022CC4815CC0>"
     ]
    }
   ],
   "source": [
    "# Training parameters.\n",
    "batch_size = 64\n",
    "num_classes = 2\n",
    "epochs = 3\n",
    "\n",
    "# Embedding dimensions.\n",
    "row_hidden = 969231\n",
    "col_hidden = 10\n",
    "# Converts class vectors to binary class matrices.\n",
    "y_train = keras.utils.to_categorical(y_train, 2)\n",
    "y_test = keras.utils.to_categorical(y_test, 2)\n",
    "\n",
    "#row, col, pixel = x_train.shape[1:]\n",
    "\n",
    "# 4D input.\n",
    "x = Input(shape=(10, 1))\n",
    "\n",
    "# Encodes a row of pixels using TimeDistributed Wrapper.\n",
    "#encoded_rows = TimeDistributed(LSTM(row_hidden))(x)\n",
    "\n",
    "# Encodes columns of encoded rows.\n",
    "#encoded_columns = LSTM(col_hidden)(encoded_rows)\n",
    "encoded_columns = LSTM(10)\n",
    "# Final predictions and model.\n",
    "prediction = Dense(1, activation='softmax')\n",
    "model = Model(x, prediction)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training.\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=1,\n",
    "          validation_data=(X_train, y_train))\n",
    "\n",
    "# Evaluation.\n",
    "scores = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(300, input_shape=(X_train, X_modified.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(300))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(Y_modified.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# convolutional neural networks(CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 969231 samples, validate on 969231 samples\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 57856/969231 [>.............................] - ETA: 2:55:30 - loss: 5.9784 - acc: 0.62 - ETA: 1:31:11 - loss: 6.2898 - acc: 0.60 - ETA: 26:58 - loss: 6.1385 - acc: 0.6150 - ETA: 19:46 - loss: 6.1777 - acc: 0.61 - ETA: 18:41 - loss: 6.1596 - acc: 0.61 - ETA: 16:35 - loss: 6.2371 - acc: 0.60 - ETA: 12:20 - loss: 6.1375 - acc: 0.61 - ETA: 12:08 - loss: 6.1226 - acc: 0.61 - ETA: 10:47 - loss: 6.1369 - acc: 0.61 - ETA: 9:24 - loss: 6.1844 - acc: 0.6121 - ETA: 9:20 - loss: 6.1906 - acc: 0.611 - ETA: 8:55 - loss: 6.1717 - acc: 0.612 - ETA: 8:08 - loss: 6.2426 - acc: 0.608 - ETA: 7:53 - loss: 6.2311 - acc: 0.609 - ETA: 7:50 - loss: 6.2137 - acc: 0.610 - ETA: 7:48 - loss: 6.2208 - acc: 0.609 - ETA: 7:15 - loss: 6.2366 - acc: 0.608 - ETA: 7:08 - loss: 6.2333 - acc: 0.609 - ETA: 7:03 - loss: 6.2524 - acc: 0.607 - ETA: 6:37 - loss: 6.2936 - acc: 0.605 - ETA: 6:32 - loss: 6.2959 - acc: 0.605 - ETA: 6:18 - loss: 6.3105 - acc: 0.604 - ETA: 5:59 - loss: 6.3134 - acc: 0.604 - ETA: 5:42 - loss: 6.3219 - acc: 0.603 - ETA: 5:28 - loss: 6.3162 - acc: 0.603 - ETA: 5:19 - loss: 6.3340 - acc: 0.602 - ETA: 5:17 - loss: 6.3363 - acc: 0.602 - ETA: 5:10 - loss: 6.3470 - acc: 0.601 - ETA: 5:06 - loss: 6.3375 - acc: 0.602 - ETA: 4:55 - loss: 6.3567 - acc: 0.601 - ETA: 4:50 - loss: 6.3402 - acc: 0.602 - ETA: 4:45 - loss: 6.3549 - acc: 0.601 - ETA: 4:44 - loss: 6.3534 - acc: 0.601 - ETA: 4:36 - loss: 6.3614 - acc: 0.601 - ETA: 4:29 - loss: 6.3931 - acc: 0.599 - ETA: 4:30 - loss: 6.3902 - acc: 0.599 - ETA: 4:28 - loss: 6.3956 - acc: 0.598 - ETA: 4:20 - loss: 6.3864 - acc: 0.599 - ETA: 4:12 - loss: 6.3645 - acc: 0.600 - ETA: 4:11 - loss: 6.3687 - acc: 0.600 - ETA: 4:08 - loss: 6.3780 - acc: 0.599 - ETA: 4:08 - loss: 6.3904 - acc: 0.599 - ETA: 4:05 - loss: 6.3832 - acc: 0.599 - ETA: 4:02 - loss: 6.3976 - acc: 0.598 - ETA: 4:02 - loss: 6.4068 - acc: 0.598 - ETA: 3:59 - loss: 6.4075 - acc: 0.598 - ETA: 3:57 - loss: 6.4081 - acc: 0.598 - ETA: 3:56 - loss: 6.4007 - acc: 0.598 - ETA: 3:54 - loss: 6.3997 - acc: 0.598 - ETA: 3:52 - loss: 6.3933 - acc: 0.599 - ETA: 3:52 - loss: 6.3909 - acc: 0.599 - ETA: 3:52 - loss: 6.3939 - acc: 0.598 - ETA: 3:51 - loss: 6.3881 - acc: 0.599 - ETA: 3:49 - loss: 6.3908 - acc: 0.599 - ETA: 3:48 - loss: 6.3966 - acc: 0.598 - ETA: 3:46 - loss: 6.3868 - acc: 0.599 - ETA: 3:44 - loss: 6.3828 - acc: 0.599 - ETA: 3:44 - loss: 6.3770 - acc: 0.600 - ETA: 3:42 - loss: 6.3734 - acc: 0.600 - ETA: 3:42 - loss: 6.3694 - acc: 0.600 - ETA: 3:43 - loss: 6.3716 - acc: 0.600 - ETA: 3:42 - loss: 6.3749 - acc: 0.600 - ETA: 3:40 - loss: 6.3738 - acc: 0.600 - ETA: 3:40 - loss: 6.3699 - acc: 0.600 - ETA: 3:40 - loss: 6.3676 - acc: 0.600 - ETA: 3:39 - loss: 6.3687 - acc: 0.600 - ETA: 3:36 - loss: 6.3615 - acc: 0.601 - ETA: 3:36 - loss: 6.3668 - acc: 0.600 - ETA: 3:35 - loss: 6.3640 - acc: 0.600 - ETA: 3:35 - loss: 6.3612 - acc: 0.601 - ETA: 3:35 - loss: 6.3507 - acc: 0.601 - ETA: 3:33 - loss: 6.3514 - acc: 0.601 - ETA: 3:31 - loss: 6.3545 - acc: 0.601 - ETA: 3:31 - loss: 6.3527 - acc: 0.601 - ETA: 3:30 - loss: 6.3599 - acc: 0.601 - ETA: 3:30 - loss: 6.3551 - acc: 0.601 - ETA: 3:31 - loss: 6.3503 - acc: 0.601 - ETA: 3:33 - loss: 6.3485 - acc: 0.601 - ETA: 3:34 - loss: 6.3497 - acc: 0.601 - ETA: 3:35 - loss: 6.3556 - acc: 0.601 - ETA: 3:36 - loss: 6.3480 - acc: 0.601 - ETA: 3:36 - loss: 6.3445 - acc: 0.602 - ETA: 3:36 - loss: 6.3412 - acc: 0.602 - ETA: 3:37 - loss: 6.3429 - acc: 0.602 - ETA: 3:37 - loss: 6.3413 - acc: 0.602 - ETA: 3:37 - loss: 6.3453 - acc: 0.602 - ETA: 3:38 - loss: 6.3459 - acc: 0.601 - ETA: 3:39 - loss: 6.3409 - acc: 0.602 - ETA: 3:40 - loss: 6.3360 - acc: 0.602 - ETA: 3:40 - loss: 6.3323 - acc: 0.602 - ETA: 3:42 - loss: 6.3335 - acc: 0.602 - ETA: 3:46 - loss: 6.3357 - acc: 0.602 - ETA: 3:45 - loss: 6.3225 - acc: 0.603 - ETA: 3:45 - loss: 6.3201 - acc: 0.603 - ETA: 3:45 - loss: 6.3237 - acc: 0.603 - ETA: 3:47 - loss: 6.3269 - acc: 0.603 - ETA: 3:48 - loss: 6.3328 - acc: 0.602 - ETA: 3:48 - loss: 6.3298 - acc: 0.603 - ETA: 3:48 - loss: 6.3285 - acc: 0.603 - ETA: 3:48 - loss: 6.3271 - acc: 0.603 - ETA: 3:47 - loss: 6.3200 - acc: 0.603 - ETA: 3:47 - loss: 6.3218 - acc: 0.603 - ETA: 3:46 - loss: 6.3162 - acc: 0.603 - ETA: 3:46 - loss: 6.3151 - acc: 0.603 - ETA: 3:46 - loss: 6.3178 - acc: 0.603 - ETA: 3:45 - loss: 6.3188 - acc: 0.603 - ETA: 3:44 - loss: 6.3252 - acc: 0.603 - ETA: 3:44 - loss: 6.3310 - acc: 0.602 - ETA: 3:43 - loss: 6.3313 - acc: 0.602 - ETA: 3:43 - loss: 6.3296 - acc: 0.603 - ETA: 3:43 - loss: 6.3334 - acc: 0.602 - ETA: 3:43 - loss: 6.3335 - acc: 0.602 - ETA: 3:43 - loss: 6.3320 - acc: 0.602 - ETA: 3:41 - loss: 6.3283 - acc: 0.603 - ETA: 3:42 - loss: 6.3280 - acc: 0.603 - ETA: 3:42 - loss: 6.3321 - acc: 0.602 - ETA: 3:43 - loss: 6.3292 - acc: 0.603 - ETA: 3:43 - loss: 6.3331 - acc: 0.602 - ETA: 3:44 - loss: 6.3307 - acc: 0.602 - ETA: 3:45 - loss: 6.3296 - acc: 0.603 - ETA: 3:45 - loss: 6.3302 - acc: 0.602 - ETA: 3:45 - loss: 6.3299 - acc: 0.603 - ETA: 3:45 - loss: 6.3300 - acc: 0.602 - ETA: 3:44 - loss: 6.3356 - acc: 0.602 - ETA: 3:44 - loss: 6.3402 - acc: 0.602 - ETA: 3:44 - loss: 6.3403 - acc: 0.602 - ETA: 3:44 - loss: 6.3387 - acc: 0.602 - ETA: 3:44 - loss: 6.3432 - acc: 0.602 - ETA: 3:44 - loss: 6.3409 - acc: 0.602 - ETA: 3:45 - loss: 6.3429 - acc: 0.602 - ETA: 3:46 - loss: 6.3442 - acc: 0.602 - ETA: 3:45 - loss: 6.3454 - acc: 0.602 - ETA: 3:46 - loss: 6.3485 - acc: 0.601 - ETA: 3:47 - loss: 6.3532 - acc: 0.601 - ETA: 3:47 - loss: 6.3497 - acc: 0.601 - ETA: 3:47 - loss: 6.3459 - acc: 0.601 - ETA: 3:47 - loss: 6.3467 - acc: 0.601 - ETA: 3:47 - loss: 6.3468 - acc: 0.601 - ETA: 3:47 - loss: 6.3472 - acc: 0.601 - ETA: 3:47 - loss: 6.3476 - acc: 0.601 - ETA: 3:48 - loss: 6.3465 - acc: 0.601 - ETA: 3:48 - loss: 6.3480 - acc: 0.601 - ETA: 3:47 - loss: 6.3484 - acc: 0.601 - ETA: 3:47 - loss: 6.3524 - acc: 0.601 - ETA: 3:46 - loss: 6.3499 - acc: 0.601 - ETA: 3:46 - loss: 6.3517 - acc: 0.601 - ETA: 3:47 - loss: 6.3513 - acc: 0.601 - ETA: 3:47 - loss: 6.3528 - acc: 0.601 - ETA: 3:47 - loss: 6.3535 - acc: 0.601 - ETA: 3:48 - loss: 6.3496 - acc: 0.601 - ETA: 3:50 - loss: 6.3492 - acc: 0.601 - ETA: 3:50 - loss: 6.3493 - acc: 0.601 - ETA: 3:51 - loss: 6.3482 - acc: 0.601 - ETA: 3:51 - loss: 6.3541 - acc: 0.601 - ETA: 3:52 - loss: 6.3534 - acc: 0.601 - ETA: 3:53 - loss: 6.3551 - acc: 0.601 - ETA: 3:53 - loss: 6.3541 - acc: 0.601 - ETA: 3:52 - loss: 6.3520 - acc: 0.601 - ETA: 3:52 - loss: 6.3514 - acc: 0.601 - ETA: 3:52 - loss: 6.3531 - acc: 0.601 - ETA: 3:52 - loss: 6.3480 - acc: 0.601 - ETA: 3:52 - loss: 6.3484 - acc: 0.601 - ETA: 3:52 - loss: 6.3530 - acc: 0.601 - ETA: 3:53 - loss: 6.3534 - acc: 0.601 - ETA: 3:53 - loss: 6.3527 - acc: 0.601 - ETA: 3:53 - loss: 6.3511 - acc: 0.601 - ETA: 3:53 - loss: 6.3488 - acc: 0.601 - ETA: 3:52 - loss: 6.3491 - acc: 0.601 - ETA: 3:52 - loss: 6.3482 - acc: 0.601 - ETA: 3:52 - loss: 6.3505 - acc: 0.601 - ETA: 3:51 - loss: 6.3473 - acc: 0.601 - ETA: 3:51 - loss: 6.3492 - acc: 0.601 - ETA: 3:52 - loss: 6.3495 - acc: 0.601 - ETA: 3:51 - loss: 6.3533 - acc: 0.601 - ETA: 3:51 - loss: 6.3520 - acc: 0.601 - ETA: 3:51 - loss: 6.3511 - acc: 0.601 - ETA: 3:52 - loss: 6.3480 - acc: 0.601 - ETA: 3:52 - loss: 6.3462 - acc: 0.601 - ETA: 3:52 - loss: 6.3453 - acc: 0.602 - ETA: 3:53 - loss: 6.3475 - acc: 0.601 - ETA: 3:54 - loss: 6.3499 - acc: 0.601 - ETA: 3:54 - loss: 6.3508 - acc: 0.601 - ETA: 3:54 - loss: 6.3514 - acc: 0.601 - ETA: 3:53 - loss: 6.3544 - acc: 0.601 - ETA: 3:53 - loss: 6.3571 - acc: 0.601 - ETA: 3:54 - loss: 6.3586 - acc: 0.601 - ETA: 3:54 - loss: 6.3615 - acc: 0.601 - ETA: 3:55 - loss: 6.3636 - acc: 0.600 - ETA: 3:55 - loss: 6.3609 - acc: 0.601 - ETA: 3:55 - loss: 6.3646 - acc: 0.600 - ETA: 3:54 - loss: 6.3611 - acc: 0.601 - ETA: 3:54 - loss: 6.3642 - acc: 0.600 - ETA: 3:53 - loss: 6.3670 - acc: 0.600 - ETA: 3:53 - loss: 6.3669 - acc: 0.600 - ETA: 3:54 - loss: 6.3680 - acc: 0.600 - ETA: 3:54 - loss: 6.3691 - acc: 0.600 - ETA: 3:55 - loss: 6.3682 - acc: 0.600 - ETA: 3:55 - loss: 6.3667 - acc: 0.600 - ETA: 3:54 - loss: 6.3688 - acc: 0.600 - ETA: 3:54 - loss: 6.3688 - acc: 0.600 - ETA: 3:53 - loss: 6.3684 - acc: 0.600 - ETA: 3:53 - loss: 6.3680 - acc: 0.6006\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115840/969231 [==>...........................] - ETA: 3:53 - loss: 6.3693 - acc: 0.600 - ETA: 3:53 - loss: 6.3723 - acc: 0.600 - ETA: 3:52 - loss: 6.3746 - acc: 0.600 - ETA: 3:52 - loss: 6.3745 - acc: 0.600 - ETA: 3:52 - loss: 6.3742 - acc: 0.600 - ETA: 3:53 - loss: 6.3728 - acc: 0.600 - ETA: 3:53 - loss: 6.3724 - acc: 0.600 - ETA: 3:54 - loss: 6.3721 - acc: 0.600 - ETA: 3:53 - loss: 6.3701 - acc: 0.600 - ETA: 3:53 - loss: 6.3750 - acc: 0.600 - ETA: 3:53 - loss: 6.3724 - acc: 0.600 - ETA: 3:54 - loss: 6.3739 - acc: 0.600 - ETA: 3:53 - loss: 6.3719 - acc: 0.600 - ETA: 3:54 - loss: 6.3705 - acc: 0.600 - ETA: 3:54 - loss: 6.3712 - acc: 0.600 - ETA: 3:54 - loss: 6.3712 - acc: 0.600 - ETA: 3:53 - loss: 6.3734 - acc: 0.600 - ETA: 3:52 - loss: 6.3699 - acc: 0.600 - ETA: 3:53 - loss: 6.3729 - acc: 0.600 - ETA: 3:53 - loss: 6.3726 - acc: 0.600 - ETA: 3:54 - loss: 6.3723 - acc: 0.600 - ETA: 3:54 - loss: 6.3685 - acc: 0.600 - ETA: 3:53 - loss: 6.3676 - acc: 0.600 - ETA: 3:54 - loss: 6.3721 - acc: 0.600 - ETA: 3:53 - loss: 6.3700 - acc: 0.600 - ETA: 3:53 - loss: 6.3687 - acc: 0.600 - ETA: 3:53 - loss: 6.3673 - acc: 0.600 - ETA: 3:52 - loss: 6.3668 - acc: 0.600 - ETA: 3:51 - loss: 6.3676 - acc: 0.600 - ETA: 3:51 - loss: 6.3690 - acc: 0.600 - ETA: 3:51 - loss: 6.3676 - acc: 0.600 - ETA: 3:51 - loss: 6.3687 - acc: 0.600 - ETA: 3:50 - loss: 6.3679 - acc: 0.600 - ETA: 3:49 - loss: 6.3675 - acc: 0.600 - ETA: 3:49 - loss: 6.3712 - acc: 0.600 - ETA: 3:49 - loss: 6.3698 - acc: 0.600 - ETA: 3:49 - loss: 6.3709 - acc: 0.600 - ETA: 3:48 - loss: 6.3703 - acc: 0.600 - ETA: 3:48 - loss: 6.3704 - acc: 0.600 - ETA: 3:48 - loss: 6.3723 - acc: 0.600 - ETA: 3:48 - loss: 6.3731 - acc: 0.600 - ETA: 3:47 - loss: 6.3691 - acc: 0.600 - ETA: 3:48 - loss: 6.3679 - acc: 0.600 - ETA: 3:48 - loss: 6.3665 - acc: 0.600 - ETA: 3:48 - loss: 6.3644 - acc: 0.600 - ETA: 3:47 - loss: 6.3623 - acc: 0.600 - ETA: 3:47 - loss: 6.3645 - acc: 0.600 - ETA: 3:47 - loss: 6.3636 - acc: 0.600 - ETA: 3:47 - loss: 6.3680 - acc: 0.600 - ETA: 3:48 - loss: 6.3680 - acc: 0.600 - ETA: 3:47 - loss: 6.3699 - acc: 0.600 - ETA: 3:46 - loss: 6.3689 - acc: 0.600 - ETA: 3:47 - loss: 6.3684 - acc: 0.600 - ETA: 3:47 - loss: 6.3690 - acc: 0.600 - ETA: 3:46 - loss: 6.3661 - acc: 0.600 - ETA: 3:46 - loss: 6.3678 - acc: 0.600 - ETA: 3:46 - loss: 6.3725 - acc: 0.600 - ETA: 3:46 - loss: 6.3707 - acc: 0.600 - ETA: 3:46 - loss: 6.3692 - acc: 0.600 - ETA: 3:46 - loss: 6.3684 - acc: 0.600 - ETA: 3:45 - loss: 6.3705 - acc: 0.600 - ETA: 3:46 - loss: 6.3712 - acc: 0.600 - ETA: 3:46 - loss: 6.3707 - acc: 0.600 - ETA: 3:46 - loss: 6.3691 - acc: 0.600 - ETA: 3:47 - loss: 6.3672 - acc: 0.600 - ETA: 3:47 - loss: 6.3663 - acc: 0.600 - ETA: 3:47 - loss: 6.3682 - acc: 0.600 - ETA: 3:47 - loss: 6.3681 - acc: 0.600 - ETA: 3:47 - loss: 6.3689 - acc: 0.600 - ETA: 3:48 - loss: 6.3697 - acc: 0.600 - ETA: 3:48 - loss: 6.3697 - acc: 0.600 - ETA: 3:47 - loss: 6.3717 - acc: 0.600 - ETA: 3:47 - loss: 6.3691 - acc: 0.600 - ETA: 3:47 - loss: 6.3730 - acc: 0.600 - ETA: 3:46 - loss: 6.3708 - acc: 0.600 - ETA: 3:46 - loss: 6.3683 - acc: 0.600 - ETA: 3:46 - loss: 6.3689 - acc: 0.600 - ETA: 3:46 - loss: 6.3684 - acc: 0.600 - ETA: 3:45 - loss: 6.3704 - acc: 0.600 - ETA: 3:46 - loss: 6.3701 - acc: 0.600 - ETA: 3:46 - loss: 6.3689 - acc: 0.600 - ETA: 3:45 - loss: 6.3718 - acc: 0.600 - ETA: 3:46 - loss: 6.3704 - acc: 0.600 - ETA: 3:46 - loss: 6.3665 - acc: 0.600 - ETA: 3:45 - loss: 6.3674 - acc: 0.600 - ETA: 3:45 - loss: 6.3676 - acc: 0.600 - ETA: 3:45 - loss: 6.3654 - acc: 0.600 - ETA: 3:46 - loss: 6.3647 - acc: 0.600 - ETA: 3:46 - loss: 6.3651 - acc: 0.600 - ETA: 3:46 - loss: 6.3651 - acc: 0.600 - ETA: 3:46 - loss: 6.3631 - acc: 0.600 - ETA: 3:46 - loss: 6.3634 - acc: 0.600 - ETA: 3:46 - loss: 6.3622 - acc: 0.600 - ETA: 3:46 - loss: 6.3618 - acc: 0.601 - ETA: 3:46 - loss: 6.3618 - acc: 0.601 - ETA: 3:47 - loss: 6.3614 - acc: 0.601 - ETA: 3:46 - loss: 6.3625 - acc: 0.600 - ETA: 3:46 - loss: 6.3605 - acc: 0.601 - ETA: 3:46 - loss: 6.3617 - acc: 0.601 - ETA: 3:46 - loss: 6.3626 - acc: 0.600 - ETA: 3:46 - loss: 6.3633 - acc: 0.600 - ETA: 3:46 - loss: 6.3633 - acc: 0.600 - ETA: 3:46 - loss: 6.3623 - acc: 0.600 - ETA: 3:46 - loss: 6.3619 - acc: 0.600 - ETA: 3:46 - loss: 6.3626 - acc: 0.600 - ETA: 3:46 - loss: 6.3590 - acc: 0.601 - ETA: 3:46 - loss: 6.3584 - acc: 0.601 - ETA: 3:46 - loss: 6.3580 - acc: 0.601 - ETA: 3:46 - loss: 6.3597 - acc: 0.601 - ETA: 3:46 - loss: 6.3597 - acc: 0.601 - ETA: 3:46 - loss: 6.3589 - acc: 0.601 - ETA: 3:46 - loss: 6.3635 - acc: 0.600 - ETA: 3:46 - loss: 6.3620 - acc: 0.600 - ETA: 3:46 - loss: 6.3629 - acc: 0.600 - ETA: 3:45 - loss: 6.3627 - acc: 0.600 - ETA: 3:45 - loss: 6.3637 - acc: 0.600 - ETA: 3:45 - loss: 6.3659 - acc: 0.600 - ETA: 3:45 - loss: 6.3651 - acc: 0.600 - ETA: 3:45 - loss: 6.3642 - acc: 0.600 - ETA: 3:45 - loss: 6.3659 - acc: 0.600 - ETA: 3:45 - loss: 6.3664 - acc: 0.600 - ETA: 3:45 - loss: 6.3675 - acc: 0.600 - ETA: 3:44 - loss: 6.3699 - acc: 0.600 - ETA: 3:45 - loss: 6.3695 - acc: 0.600 - ETA: 3:44 - loss: 6.3715 - acc: 0.600 - ETA: 3:45 - loss: 6.3712 - acc: 0.600 - ETA: 3:45 - loss: 6.3704 - acc: 0.600 - ETA: 3:45 - loss: 6.3709 - acc: 0.600 - ETA: 3:46 - loss: 6.3723 - acc: 0.600 - ETA: 3:46 - loss: 6.3699 - acc: 0.600 - ETA: 3:46 - loss: 6.3687 - acc: 0.600 - ETA: 3:45 - loss: 6.3693 - acc: 0.600 - ETA: 3:45 - loss: 6.3703 - acc: 0.600 - ETA: 3:45 - loss: 6.3693 - acc: 0.600 - ETA: 3:45 - loss: 6.3669 - acc: 0.600 - ETA: 3:45 - loss: 6.3666 - acc: 0.600 - ETA: 3:45 - loss: 6.3649 - acc: 0.600 - ETA: 3:45 - loss: 6.3647 - acc: 0.600 - ETA: 3:45 - loss: 6.3636 - acc: 0.600 - ETA: 3:45 - loss: 6.3626 - acc: 0.600 - ETA: 3:45 - loss: 6.3632 - acc: 0.600 - ETA: 3:45 - loss: 6.3639 - acc: 0.600 - ETA: 3:45 - loss: 6.3620 - acc: 0.600 - ETA: 3:44 - loss: 6.3635 - acc: 0.600 - ETA: 3:45 - loss: 6.3636 - acc: 0.600 - ETA: 3:45 - loss: 6.3616 - acc: 0.601 - ETA: 3:45 - loss: 6.3627 - acc: 0.600 - ETA: 3:45 - loss: 6.3629 - acc: 0.600 - ETA: 3:45 - loss: 6.3639 - acc: 0.600 - ETA: 3:45 - loss: 6.3665 - acc: 0.600 - ETA: 3:45 - loss: 6.3656 - acc: 0.600 - ETA: 3:45 - loss: 6.3654 - acc: 0.600 - ETA: 3:44 - loss: 6.3654 - acc: 0.600 - ETA: 3:44 - loss: 6.3650 - acc: 0.600 - ETA: 3:44 - loss: 6.3622 - acc: 0.600 - ETA: 3:44 - loss: 6.3614 - acc: 0.601 - ETA: 3:44 - loss: 6.3620 - acc: 0.600 - ETA: 3:44 - loss: 6.3606 - acc: 0.601 - ETA: 3:44 - loss: 6.3605 - acc: 0.601 - ETA: 3:43 - loss: 6.3614 - acc: 0.601 - ETA: 3:44 - loss: 6.3607 - acc: 0.601 - ETA: 3:45 - loss: 6.3598 - acc: 0.601 - ETA: 3:45 - loss: 6.3601 - acc: 0.601 - ETA: 3:45 - loss: 6.3593 - acc: 0.601 - ETA: 3:45 - loss: 6.3578 - acc: 0.601 - ETA: 3:45 - loss: 6.3581 - acc: 0.601 - ETA: 3:45 - loss: 6.3571 - acc: 0.601 - ETA: 3:45 - loss: 6.3560 - acc: 0.601 - ETA: 3:44 - loss: 6.3563 - acc: 0.601 - ETA: 3:43 - loss: 6.3580 - acc: 0.601 - ETA: 3:42 - loss: 6.3595 - acc: 0.601 - ETA: 3:41 - loss: 6.3589 - acc: 0.601 - ETA: 3:41 - loss: 6.3561 - acc: 0.601 - ETA: 3:41 - loss: 6.3564 - acc: 0.601 - ETA: 3:40 - loss: 6.3588 - acc: 0.601 - ETA: 3:40 - loss: 6.3600 - acc: 0.601 - ETA: 3:39 - loss: 6.3618 - acc: 0.601 - ETA: 3:39 - loss: 6.3602 - acc: 0.601 - ETA: 3:39 - loss: 6.3602 - acc: 0.601 - ETA: 3:38 - loss: 6.3618 - acc: 0.600 - ETA: 3:38 - loss: 6.3618 - acc: 0.600 - ETA: 3:37 - loss: 6.3640 - acc: 0.600 - ETA: 3:37 - loss: 6.3640 - acc: 0.600 - ETA: 3:37 - loss: 6.3656 - acc: 0.600 - ETA: 3:37 - loss: 6.3646 - acc: 0.600 - ETA: 3:36 - loss: 6.3643 - acc: 0.600 - ETA: 3:36 - loss: 6.3638 - acc: 0.600 - ETA: 3:35 - loss: 6.3646 - acc: 0.600 - ETA: 3:35 - loss: 6.3637 - acc: 0.600 - ETA: 3:35 - loss: 6.3656 - acc: 0.600 - ETA: 3:35 - loss: 6.3640 - acc: 0.600 - ETA: 3:34 - loss: 6.3651 - acc: 0.600 - ETA: 3:34 - loss: 6.3659 - acc: 0.600 - ETA: 3:34 - loss: 6.3658 - acc: 0.600 - ETA: 3:33 - loss: 6.3678 - acc: 0.600 - ETA: 3:33 - loss: 6.3686 - acc: 0.600 - ETA: 3:32 - loss: 6.3672 - acc: 0.600 - ETA: 3:31 - loss: 6.3666 - acc: 0.600 - ETA: 3:31 - loss: 6.3663 - acc: 0.600 - ETA: 3:31 - loss: 6.3662 - acc: 0.600 - ETA: 3:30 - loss: 6.3680 - acc: 0.600 - ETA: 3:30 - loss: 6.3678 - acc: 0.600 - ETA: 3:29 - loss: 6.3660 - acc: 0.600 - ETA: 3:28 - loss: 6.3640 - acc: 0.6008"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177536/969231 [====>.........................] - ETA: 3:27 - loss: 6.3661 - acc: 0.600 - ETA: 3:27 - loss: 6.3657 - acc: 0.600 - ETA: 3:26 - loss: 6.3666 - acc: 0.600 - ETA: 3:25 - loss: 6.3660 - acc: 0.600 - ETA: 3:25 - loss: 6.3659 - acc: 0.600 - ETA: 3:25 - loss: 6.3653 - acc: 0.600 - ETA: 3:24 - loss: 6.3654 - acc: 0.600 - ETA: 3:23 - loss: 6.3655 - acc: 0.600 - ETA: 3:23 - loss: 6.3629 - acc: 0.600 - ETA: 3:23 - loss: 6.3629 - acc: 0.600 - ETA: 3:22 - loss: 6.3661 - acc: 0.600 - ETA: 3:22 - loss: 6.3651 - acc: 0.600 - ETA: 3:23 - loss: 6.3653 - acc: 0.600 - ETA: 3:22 - loss: 6.3646 - acc: 0.600 - ETA: 3:22 - loss: 6.3644 - acc: 0.600 - ETA: 3:22 - loss: 6.3644 - acc: 0.600 - ETA: 3:22 - loss: 6.3632 - acc: 0.600 - ETA: 3:22 - loss: 6.3637 - acc: 0.600 - ETA: 3:22 - loss: 6.3628 - acc: 0.600 - ETA: 3:21 - loss: 6.3635 - acc: 0.600 - ETA: 3:21 - loss: 6.3612 - acc: 0.601 - ETA: 3:21 - loss: 6.3597 - acc: 0.601 - ETA: 3:21 - loss: 6.3595 - acc: 0.601 - ETA: 3:20 - loss: 6.3603 - acc: 0.601 - ETA: 3:19 - loss: 6.3600 - acc: 0.601 - ETA: 3:19 - loss: 6.3595 - acc: 0.601 - ETA: 3:19 - loss: 6.3591 - acc: 0.601 - ETA: 3:19 - loss: 6.3588 - acc: 0.601 - ETA: 3:19 - loss: 6.3584 - acc: 0.601 - ETA: 3:18 - loss: 6.3587 - acc: 0.601 - ETA: 3:18 - loss: 6.3583 - acc: 0.601 - ETA: 3:17 - loss: 6.3600 - acc: 0.601 - ETA: 3:17 - loss: 6.3605 - acc: 0.601 - ETA: 3:16 - loss: 6.3608 - acc: 0.601 - ETA: 3:16 - loss: 6.3614 - acc: 0.601 - ETA: 3:16 - loss: 6.3600 - acc: 0.601 - ETA: 3:16 - loss: 6.3613 - acc: 0.601 - ETA: 3:16 - loss: 6.3607 - acc: 0.601 - ETA: 3:16 - loss: 6.3632 - acc: 0.600 - ETA: 3:16 - loss: 6.3637 - acc: 0.600 - ETA: 3:16 - loss: 6.3645 - acc: 0.600 - ETA: 3:16 - loss: 6.3646 - acc: 0.600 - ETA: 3:16 - loss: 6.3654 - acc: 0.600 - ETA: 3:16 - loss: 6.3657 - acc: 0.600 - ETA: 3:15 - loss: 6.3665 - acc: 0.600 - ETA: 3:16 - loss: 6.3673 - acc: 0.600 - ETA: 3:16 - loss: 6.3693 - acc: 0.600 - ETA: 3:15 - loss: 6.3698 - acc: 0.600 - ETA: 3:15 - loss: 6.3693 - acc: 0.600 - ETA: 3:16 - loss: 6.3696 - acc: 0.600 - ETA: 3:16 - loss: 6.3694 - acc: 0.600 - ETA: 3:16 - loss: 6.3696 - acc: 0.600 - ETA: 3:16 - loss: 6.3691 - acc: 0.600 - ETA: 3:16 - loss: 6.3682 - acc: 0.600 - ETA: 3:16 - loss: 6.3691 - acc: 0.600 - ETA: 3:15 - loss: 6.3687 - acc: 0.600 - ETA: 3:16 - loss: 6.3682 - acc: 0.600 - ETA: 3:16 - loss: 6.3681 - acc: 0.600 - ETA: 3:16 - loss: 6.3695 - acc: 0.600 - ETA: 3:16 - loss: 6.3694 - acc: 0.600 - ETA: 3:16 - loss: 6.3705 - acc: 0.600 - ETA: 3:16 - loss: 6.3713 - acc: 0.600 - ETA: 3:16 - loss: 6.3714 - acc: 0.600 - ETA: 3:16 - loss: 6.3704 - acc: 0.600 - ETA: 3:17 - loss: 6.3711 - acc: 0.600 - ETA: 3:17 - loss: 6.3706 - acc: 0.600 - ETA: 3:17 - loss: 6.3706 - acc: 0.600 - ETA: 3:17 - loss: 6.3712 - acc: 0.600 - ETA: 3:17 - loss: 6.3716 - acc: 0.600 - ETA: 3:17 - loss: 6.3706 - acc: 0.600 - ETA: 3:17 - loss: 6.3704 - acc: 0.600 - ETA: 3:18 - loss: 6.3706 - acc: 0.600 - ETA: 3:17 - loss: 6.3701 - acc: 0.600 - ETA: 3:17 - loss: 6.3706 - acc: 0.600 - ETA: 3:17 - loss: 6.3722 - acc: 0.600 - ETA: 3:18 - loss: 6.3709 - acc: 0.600 - ETA: 3:18 - loss: 6.3712 - acc: 0.600 - ETA: 3:18 - loss: 6.3702 - acc: 0.600 - ETA: 3:18 - loss: 6.3692 - acc: 0.600 - ETA: 3:18 - loss: 6.3692 - acc: 0.600 - ETA: 3:18 - loss: 6.3702 - acc: 0.600 - ETA: 3:18 - loss: 6.3695 - acc: 0.600 - ETA: 3:18 - loss: 6.3696 - acc: 0.600 - ETA: 3:18 - loss: 6.3691 - acc: 0.600 - ETA: 3:18 - loss: 6.3677 - acc: 0.600 - ETA: 3:18 - loss: 6.3695 - acc: 0.600 - ETA: 3:18 - loss: 6.3695 - acc: 0.600 - ETA: 3:18 - loss: 6.3699 - acc: 0.600 - ETA: 3:19 - loss: 6.3704 - acc: 0.600 - ETA: 3:19 - loss: 6.3715 - acc: 0.600 - ETA: 3:19 - loss: 6.3703 - acc: 0.600 - ETA: 3:19 - loss: 6.3700 - acc: 0.600 - ETA: 3:19 - loss: 6.3694 - acc: 0.600 - ETA: 3:19 - loss: 6.3701 - acc: 0.600 - ETA: 3:19 - loss: 6.3711 - acc: 0.600 - ETA: 3:19 - loss: 6.3712 - acc: 0.600 - ETA: 3:19 - loss: 6.3727 - acc: 0.600 - ETA: 3:19 - loss: 6.3736 - acc: 0.600 - ETA: 3:19 - loss: 6.3755 - acc: 0.600 - ETA: 3:18 - loss: 6.3760 - acc: 0.600 - ETA: 3:19 - loss: 6.3758 - acc: 0.600 - ETA: 3:18 - loss: 6.3764 - acc: 0.600 - ETA: 3:18 - loss: 6.3746 - acc: 0.600 - ETA: 3:18 - loss: 6.3751 - acc: 0.600 - ETA: 3:18 - loss: 6.3739 - acc: 0.600 - ETA: 3:19 - loss: 6.3739 - acc: 0.600 - ETA: 3:18 - loss: 6.3730 - acc: 0.600 - ETA: 3:18 - loss: 6.3743 - acc: 0.600 - ETA: 3:18 - loss: 6.3743 - acc: 0.600 - ETA: 3:18 - loss: 6.3737 - acc: 0.600 - ETA: 3:18 - loss: 6.3730 - acc: 0.600 - ETA: 3:18 - loss: 6.3718 - acc: 0.600 - ETA: 3:17 - loss: 6.3720 - acc: 0.600 - ETA: 3:17 - loss: 6.3732 - acc: 0.600 - ETA: 3:16 - loss: 6.3716 - acc: 0.600 - ETA: 3:16 - loss: 6.3715 - acc: 0.600 - ETA: 3:16 - loss: 6.3723 - acc: 0.600 - ETA: 3:16 - loss: 6.3728 - acc: 0.600 - ETA: 3:16 - loss: 6.3711 - acc: 0.600 - ETA: 3:16 - loss: 6.3703 - acc: 0.600 - ETA: 3:15 - loss: 6.3704 - acc: 0.600 - ETA: 3:15 - loss: 6.3697 - acc: 0.600 - ETA: 3:15 - loss: 6.3695 - acc: 0.600 - ETA: 3:15 - loss: 6.3701 - acc: 0.600 - ETA: 3:14 - loss: 6.3709 - acc: 0.600 - ETA: 3:13 - loss: 6.3725 - acc: 0.600 - ETA: 3:13 - loss: 6.3711 - acc: 0.600 - ETA: 3:13 - loss: 6.3724 - acc: 0.600 - ETA: 3:12 - loss: 6.3737 - acc: 0.600 - ETA: 3:12 - loss: 6.3725 - acc: 0.600 - ETA: 3:12 - loss: 6.3721 - acc: 0.600 - ETA: 3:12 - loss: 6.3725 - acc: 0.600 - ETA: 3:12 - loss: 6.3730 - acc: 0.600 - ETA: 3:11 - loss: 6.3744 - acc: 0.600 - ETA: 3:10 - loss: 6.3747 - acc: 0.600 - ETA: 3:10 - loss: 6.3758 - acc: 0.600 - ETA: 3:10 - loss: 6.3750 - acc: 0.600 - ETA: 3:10 - loss: 6.3754 - acc: 0.600 - ETA: 3:09 - loss: 6.3739 - acc: 0.600 - ETA: 3:09 - loss: 6.3743 - acc: 0.600 - ETA: 3:09 - loss: 6.3748 - acc: 0.600 - ETA: 3:08 - loss: 6.3746 - acc: 0.600 - ETA: 3:08 - loss: 6.3745 - acc: 0.600 - ETA: 3:08 - loss: 6.3745 - acc: 0.600 - ETA: 3:08 - loss: 6.3729 - acc: 0.600 - ETA: 3:08 - loss: 6.3726 - acc: 0.600 - ETA: 3:07 - loss: 6.3739 - acc: 0.600 - ETA: 3:06 - loss: 6.3726 - acc: 0.600 - ETA: 3:06 - loss: 6.3723 - acc: 0.600 - ETA: 3:06 - loss: 6.3728 - acc: 0.600 - ETA: 3:06 - loss: 6.3734 - acc: 0.600 - ETA: 3:05 - loss: 6.3733 - acc: 0.600 - ETA: 3:05 - loss: 6.3749 - acc: 0.600 - ETA: 3:05 - loss: 6.3749 - acc: 0.600 - ETA: 3:04 - loss: 6.3755 - acc: 0.600 - ETA: 3:04 - loss: 6.3753 - acc: 0.600 - ETA: 3:04 - loss: 6.3747 - acc: 0.600 - ETA: 3:04 - loss: 6.3739 - acc: 0.600 - ETA: 3:03 - loss: 6.3735 - acc: 0.600 - ETA: 3:03 - loss: 6.3738 - acc: 0.600 - ETA: 3:03 - loss: 6.3753 - acc: 0.600 - ETA: 3:03 - loss: 6.3763 - acc: 0.600 - ETA: 3:03 - loss: 6.3768 - acc: 0.600 - ETA: 3:03 - loss: 6.3787 - acc: 0.599 - ETA: 3:02 - loss: 6.3792 - acc: 0.599 - ETA: 3:02 - loss: 6.3806 - acc: 0.599 - ETA: 3:02 - loss: 6.3804 - acc: 0.599 - ETA: 3:02 - loss: 6.3804 - acc: 0.599 - ETA: 3:02 - loss: 6.3810 - acc: 0.599 - ETA: 3:02 - loss: 6.3803 - acc: 0.599 - ETA: 3:02 - loss: 6.3809 - acc: 0.599 - ETA: 3:02 - loss: 6.3816 - acc: 0.599 - ETA: 3:02 - loss: 6.3832 - acc: 0.599 - ETA: 3:02 - loss: 6.3833 - acc: 0.599 - ETA: 3:02 - loss: 6.3840 - acc: 0.599 - ETA: 3:02 - loss: 6.3841 - acc: 0.599 - ETA: 3:03 - loss: 6.3833 - acc: 0.599 - ETA: 3:03 - loss: 6.3824 - acc: 0.599 - ETA: 3:03 - loss: 6.3820 - acc: 0.599 - ETA: 3:03 - loss: 6.3828 - acc: 0.599 - ETA: 3:03 - loss: 6.3825 - acc: 0.599 - ETA: 3:03 - loss: 6.3821 - acc: 0.599 - ETA: 3:02 - loss: 6.3830 - acc: 0.599 - ETA: 3:03 - loss: 6.3827 - acc: 0.599 - ETA: 3:03 - loss: 6.3834 - acc: 0.599 - ETA: 3:03 - loss: 6.3841 - acc: 0.599 - ETA: 3:03 - loss: 6.3846 - acc: 0.599 - ETA: 3:03 - loss: 6.3844 - acc: 0.599 - ETA: 3:03 - loss: 6.3838 - acc: 0.599 - ETA: 3:03 - loss: 6.3833 - acc: 0.599 - ETA: 3:03 - loss: 6.3827 - acc: 0.599 - ETA: 3:03 - loss: 6.3831 - acc: 0.599 - ETA: 3:03 - loss: 6.3830 - acc: 0.599 - ETA: 3:03 - loss: 6.3836 - acc: 0.599 - ETA: 3:03 - loss: 6.3840 - acc: 0.599 - ETA: 3:02 - loss: 6.3838 - acc: 0.599 - ETA: 3:03 - loss: 6.3838 - acc: 0.599 - ETA: 3:03 - loss: 6.3844 - acc: 0.599 - ETA: 3:03 - loss: 6.3844 - acc: 0.599 - ETA: 3:03 - loss: 6.3855 - acc: 0.599 - ETA: 3:03 - loss: 6.3863 - acc: 0.599 - ETA: 3:03 - loss: 6.3861 - acc: 0.599 - ETA: 3:03 - loss: 6.3862 - acc: 0.599 - ETA: 3:03 - loss: 6.3862 - acc: 0.5994"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "222208/969231 [=====>........................] - ETA: 3:03 - loss: 6.3873 - acc: 0.599 - ETA: 3:03 - loss: 6.3876 - acc: 0.599 - ETA: 3:03 - loss: 6.3888 - acc: 0.599 - ETA: 3:03 - loss: 6.3889 - acc: 0.599 - ETA: 3:03 - loss: 6.3895 - acc: 0.599 - ETA: 3:03 - loss: 6.3892 - acc: 0.599 - ETA: 3:03 - loss: 6.3896 - acc: 0.599 - ETA: 3:03 - loss: 6.3898 - acc: 0.599 - ETA: 3:03 - loss: 6.3899 - acc: 0.599 - ETA: 3:03 - loss: 6.3905 - acc: 0.599 - ETA: 3:03 - loss: 6.3905 - acc: 0.599 - ETA: 3:03 - loss: 6.3900 - acc: 0.599 - ETA: 3:03 - loss: 6.3896 - acc: 0.599 - ETA: 3:03 - loss: 6.3900 - acc: 0.599 - ETA: 3:03 - loss: 6.3899 - acc: 0.599 - ETA: 3:03 - loss: 6.3888 - acc: 0.599 - ETA: 3:03 - loss: 6.3885 - acc: 0.599 - ETA: 3:03 - loss: 6.3882 - acc: 0.599 - ETA: 3:04 - loss: 6.3873 - acc: 0.599 - ETA: 3:04 - loss: 6.3869 - acc: 0.599 - ETA: 3:04 - loss: 6.3861 - acc: 0.599 - ETA: 3:04 - loss: 6.3861 - acc: 0.599 - ETA: 3:04 - loss: 6.3859 - acc: 0.599 - ETA: 3:04 - loss: 6.3858 - acc: 0.599 - ETA: 3:04 - loss: 6.3866 - acc: 0.599 - ETA: 3:04 - loss: 6.3859 - acc: 0.599 - ETA: 3:04 - loss: 6.3868 - acc: 0.599 - ETA: 3:04 - loss: 6.3866 - acc: 0.599 - ETA: 3:04 - loss: 6.3871 - acc: 0.599 - ETA: 3:04 - loss: 6.3878 - acc: 0.599 - ETA: 3:04 - loss: 6.3878 - acc: 0.599 - ETA: 3:04 - loss: 6.3872 - acc: 0.599 - ETA: 3:05 - loss: 6.3878 - acc: 0.599 - ETA: 3:04 - loss: 6.3887 - acc: 0.599 - ETA: 3:04 - loss: 6.3879 - acc: 0.599 - ETA: 3:04 - loss: 6.3889 - acc: 0.599 - ETA: 3:05 - loss: 6.3886 - acc: 0.599 - ETA: 3:04 - loss: 6.3888 - acc: 0.599 - ETA: 3:04 - loss: 6.3885 - acc: 0.599 - ETA: 3:04 - loss: 6.3878 - acc: 0.599 - ETA: 3:04 - loss: 6.3882 - acc: 0.599 - ETA: 3:04 - loss: 6.3875 - acc: 0.599 - ETA: 3:04 - loss: 6.3873 - acc: 0.599 - ETA: 3:04 - loss: 6.3873 - acc: 0.599 - ETA: 3:04 - loss: 6.3875 - acc: 0.599 - ETA: 3:04 - loss: 6.3876 - acc: 0.599 - ETA: 3:04 - loss: 6.3873 - acc: 0.599 - ETA: 3:04 - loss: 6.3870 - acc: 0.599 - ETA: 3:04 - loss: 6.3885 - acc: 0.599 - ETA: 3:04 - loss: 6.3878 - acc: 0.599 - ETA: 3:04 - loss: 6.3879 - acc: 0.599 - ETA: 3:04 - loss: 6.3884 - acc: 0.599 - ETA: 3:04 - loss: 6.3874 - acc: 0.599 - ETA: 3:04 - loss: 6.3874 - acc: 0.599 - ETA: 3:05 - loss: 6.3873 - acc: 0.599 - ETA: 3:05 - loss: 6.3877 - acc: 0.599 - ETA: 3:05 - loss: 6.3884 - acc: 0.599 - ETA: 3:05 - loss: 6.3889 - acc: 0.599 - ETA: 3:05 - loss: 6.3886 - acc: 0.599 - ETA: 3:05 - loss: 6.3894 - acc: 0.599 - ETA: 3:05 - loss: 6.3901 - acc: 0.599 - ETA: 3:05 - loss: 6.3897 - acc: 0.599 - ETA: 3:05 - loss: 6.3899 - acc: 0.599 - ETA: 3:05 - loss: 6.3899 - acc: 0.599 - ETA: 3:05 - loss: 6.3891 - acc: 0.599 - ETA: 3:06 - loss: 6.3892 - acc: 0.599 - ETA: 3:06 - loss: 6.3898 - acc: 0.599 - ETA: 3:06 - loss: 6.3898 - acc: 0.599 - ETA: 3:06 - loss: 6.3903 - acc: 0.599 - ETA: 3:06 - loss: 6.3898 - acc: 0.599 - ETA: 3:06 - loss: 6.3892 - acc: 0.599 - ETA: 3:06 - loss: 6.3896 - acc: 0.599 - ETA: 3:06 - loss: 6.3897 - acc: 0.599 - ETA: 3:06 - loss: 6.3905 - acc: 0.599 - ETA: 3:06 - loss: 6.3902 - acc: 0.599 - ETA: 3:06 - loss: 6.3901 - acc: 0.599 - ETA: 3:06 - loss: 6.3894 - acc: 0.599 - ETA: 3:07 - loss: 6.3901 - acc: 0.599 - ETA: 3:07 - loss: 6.3912 - acc: 0.599 - ETA: 3:07 - loss: 6.3911 - acc: 0.599 - ETA: 3:07 - loss: 6.3909 - acc: 0.599 - ETA: 3:07 - loss: 6.3909 - acc: 0.599 - ETA: 3:07 - loss: 6.3908 - acc: 0.599 - ETA: 3:08 - loss: 6.3900 - acc: 0.599 - ETA: 3:08 - loss: 6.3896 - acc: 0.599 - ETA: 3:08 - loss: 6.3894 - acc: 0.599 - ETA: 3:08 - loss: 6.3893 - acc: 0.599 - ETA: 3:08 - loss: 6.3895 - acc: 0.599 - ETA: 3:09 - loss: 6.3898 - acc: 0.599 - ETA: 3:09 - loss: 6.3897 - acc: 0.599 - ETA: 3:09 - loss: 6.3890 - acc: 0.599 - ETA: 3:09 - loss: 6.3896 - acc: 0.599 - ETA: 3:09 - loss: 6.3893 - acc: 0.599 - ETA: 3:09 - loss: 6.3904 - acc: 0.599 - ETA: 3:09 - loss: 6.3911 - acc: 0.599 - ETA: 3:09 - loss: 6.3907 - acc: 0.599 - ETA: 3:09 - loss: 6.3899 - acc: 0.599 - ETA: 3:09 - loss: 6.3897 - acc: 0.599 - ETA: 3:09 - loss: 6.3891 - acc: 0.599 - ETA: 3:09 - loss: 6.3892 - acc: 0.599 - ETA: 3:09 - loss: 6.3899 - acc: 0.599 - ETA: 3:09 - loss: 6.3900 - acc: 0.599 - ETA: 3:09 - loss: 6.3896 - acc: 0.599 - ETA: 3:09 - loss: 6.3903 - acc: 0.599 - ETA: 3:09 - loss: 6.3905 - acc: 0.599 - ETA: 3:09 - loss: 6.3907 - acc: 0.599 - ETA: 3:09 - loss: 6.3905 - acc: 0.599 - ETA: 3:09 - loss: 6.3919 - acc: 0.599 - ETA: 3:10 - loss: 6.3915 - acc: 0.599 - ETA: 3:10 - loss: 6.3907 - acc: 0.599 - ETA: 3:10 - loss: 6.3916 - acc: 0.599 - ETA: 3:11 - loss: 6.3921 - acc: 0.599 - ETA: 3:11 - loss: 6.3919 - acc: 0.599 - ETA: 3:11 - loss: 6.3921 - acc: 0.599 - ETA: 3:11 - loss: 6.3922 - acc: 0.599 - ETA: 3:11 - loss: 6.3923 - acc: 0.599 - ETA: 3:11 - loss: 6.3934 - acc: 0.599 - ETA: 3:11 - loss: 6.3934 - acc: 0.599 - ETA: 3:11 - loss: 6.3935 - acc: 0.599 - ETA: 3:12 - loss: 6.3925 - acc: 0.599 - ETA: 3:12 - loss: 6.3922 - acc: 0.599 - ETA: 3:12 - loss: 6.3928 - acc: 0.599 - ETA: 3:12 - loss: 6.3932 - acc: 0.599 - ETA: 3:12 - loss: 6.3939 - acc: 0.598 - ETA: 3:12 - loss: 6.3944 - acc: 0.598 - ETA: 3:12 - loss: 6.3937 - acc: 0.599 - ETA: 3:12 - loss: 6.3945 - acc: 0.598 - ETA: 3:12 - loss: 6.3957 - acc: 0.598 - ETA: 3:12 - loss: 6.3958 - acc: 0.598 - ETA: 3:12 - loss: 6.3965 - acc: 0.598 - ETA: 3:12 - loss: 6.3968 - acc: 0.598 - ETA: 3:12 - loss: 6.3959 - acc: 0.598 - ETA: 3:12 - loss: 6.3963 - acc: 0.598 - ETA: 3:12 - loss: 6.3955 - acc: 0.598 - ETA: 3:12 - loss: 6.3959 - acc: 0.598 - ETA: 3:12 - loss: 6.3963 - acc: 0.598 - ETA: 3:12 - loss: 6.3964 - acc: 0.598 - ETA: 3:12 - loss: 6.3959 - acc: 0.598 - ETA: 3:12 - loss: 6.3960 - acc: 0.598 - ETA: 3:12 - loss: 6.3962 - acc: 0.598 - ETA: 3:12 - loss: 6.3958 - acc: 0.598 - ETA: 3:12 - loss: 6.3959 - acc: 0.598 - ETA: 3:12 - loss: 6.3969 - acc: 0.598 - ETA: 3:12 - loss: 6.3967 - acc: 0.598 - ETA: 3:12 - loss: 6.3968 - acc: 0.598 - ETA: 3:12 - loss: 6.3966 - acc: 0.598 - ETA: 3:12 - loss: 6.3967 - acc: 0.598 - ETA: 3:12 - loss: 6.3953 - acc: 0.598 - ETA: 3:12 - loss: 6.3956 - acc: 0.598 - ETA: 3:11 - loss: 6.3954 - acc: 0.598 - ETA: 3:11 - loss: 6.3954 - acc: 0.598 - ETA: 3:11 - loss: 6.3962 - acc: 0.598 - ETA: 3:12 - loss: 6.3961 - acc: 0.598 - ETA: 3:12 - loss: 6.3959 - acc: 0.598 - ETA: 3:12 - loss: 6.3960 - acc: 0.598 - ETA: 3:12 - loss: 6.3963 - acc: 0.598 - ETA: 3:11 - loss: 6.3976 - acc: 0.598 - ETA: 3:11 - loss: 6.3967 - acc: 0.598 - ETA: 3:11 - loss: 6.3964 - acc: 0.598 - ETA: 3:11 - loss: 6.3957 - acc: 0.598 - ETA: 3:11 - loss: 6.3955 - acc: 0.598 - ETA: 3:11 - loss: 6.3959 - acc: 0.598 - ETA: 3:11 - loss: 6.3957 - acc: 0.598 - ETA: 3:11 - loss: 6.3949 - acc: 0.598 - ETA: 3:11 - loss: 6.3954 - acc: 0.598 - ETA: 3:11 - loss: 6.3954 - acc: 0.598 - ETA: 3:11 - loss: 6.3956 - acc: 0.598 - ETA: 3:11 - loss: 6.3956 - acc: 0.598 - ETA: 3:11 - loss: 6.3963 - acc: 0.598 - ETA: 3:11 - loss: 6.3955 - acc: 0.598 - ETA: 3:11 - loss: 6.3951 - acc: 0.598 - ETA: 3:11 - loss: 6.3945 - acc: 0.598 - ETA: 3:11 - loss: 6.3946 - acc: 0.598 - ETA: 3:11 - loss: 6.3945 - acc: 0.598 - ETA: 3:11 - loss: 6.3945 - acc: 0.598 - ETA: 3:10 - loss: 6.3952 - acc: 0.598 - ETA: 3:10 - loss: 6.3948 - acc: 0.598 - ETA: 3:10 - loss: 6.3948 - acc: 0.598 - ETA: 3:10 - loss: 6.3954 - acc: 0.598 - ETA: 3:10 - loss: 6.3960 - acc: 0.598 - ETA: 3:10 - loss: 6.3952 - acc: 0.598 - ETA: 3:10 - loss: 6.3936 - acc: 0.599 - ETA: 3:10 - loss: 6.3937 - acc: 0.598 - ETA: 3:10 - loss: 6.3928 - acc: 0.599 - ETA: 3:10 - loss: 6.3913 - acc: 0.599 - ETA: 3:10 - loss: 6.3915 - acc: 0.599 - ETA: 3:10 - loss: 6.3918 - acc: 0.599 - ETA: 3:10 - loss: 6.3915 - acc: 0.599 - ETA: 3:10 - loss: 6.3915 - acc: 0.599 - ETA: 3:10 - loss: 6.3914 - acc: 0.599 - ETA: 3:10 - loss: 6.3909 - acc: 0.599 - ETA: 3:10 - loss: 6.3910 - acc: 0.599 - ETA: 3:10 - loss: 6.3907 - acc: 0.599 - ETA: 3:10 - loss: 6.3908 - acc: 0.599 - ETA: 3:09 - loss: 6.3904 - acc: 0.599 - ETA: 3:09 - loss: 6.3907 - acc: 0.599 - ETA: 3:08 - loss: 6.3890 - acc: 0.599 - ETA: 3:08 - loss: 6.3894 - acc: 0.599 - ETA: 3:08 - loss: 6.3896 - acc: 0.599 - ETA: 3:08 - loss: 6.3894 - acc: 0.599 - ETA: 3:07 - loss: 6.3888 - acc: 0.599 - ETA: 3:07 - loss: 6.3877 - acc: 0.599 - ETA: 3:07 - loss: 6.3881 - acc: 0.599 - ETA: 3:07 - loss: 6.3876 - acc: 0.5993"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285696/969231 [=======>......................] - ETA: 3:06 - loss: 6.3871 - acc: 0.599 - ETA: 3:06 - loss: 6.3870 - acc: 0.599 - ETA: 3:06 - loss: 6.3867 - acc: 0.599 - ETA: 3:06 - loss: 6.3868 - acc: 0.599 - ETA: 3:05 - loss: 6.3877 - acc: 0.599 - ETA: 3:05 - loss: 6.3869 - acc: 0.599 - ETA: 3:05 - loss: 6.3863 - acc: 0.599 - ETA: 3:05 - loss: 6.3867 - acc: 0.599 - ETA: 3:05 - loss: 6.3878 - acc: 0.599 - ETA: 3:04 - loss: 6.3886 - acc: 0.599 - ETA: 3:04 - loss: 6.3898 - acc: 0.599 - ETA: 3:03 - loss: 6.3884 - acc: 0.599 - ETA: 3:03 - loss: 6.3871 - acc: 0.599 - ETA: 3:03 - loss: 6.3879 - acc: 0.599 - ETA: 3:02 - loss: 6.3878 - acc: 0.599 - ETA: 3:02 - loss: 6.3885 - acc: 0.599 - ETA: 3:02 - loss: 6.3885 - acc: 0.599 - ETA: 3:01 - loss: 6.3881 - acc: 0.599 - ETA: 3:01 - loss: 6.3880 - acc: 0.599 - ETA: 3:01 - loss: 6.3873 - acc: 0.599 - ETA: 3:01 - loss: 6.3874 - acc: 0.599 - ETA: 3:01 - loss: 6.3874 - acc: 0.599 - ETA: 3:01 - loss: 6.3874 - acc: 0.599 - ETA: 3:00 - loss: 6.3882 - acc: 0.599 - ETA: 3:00 - loss: 6.3880 - acc: 0.599 - ETA: 3:00 - loss: 6.3888 - acc: 0.599 - ETA: 3:01 - loss: 6.3884 - acc: 0.599 - ETA: 3:01 - loss: 6.3891 - acc: 0.599 - ETA: 3:01 - loss: 6.3895 - acc: 0.599 - ETA: 3:01 - loss: 6.3900 - acc: 0.599 - ETA: 3:01 - loss: 6.3894 - acc: 0.599 - ETA: 3:01 - loss: 6.3890 - acc: 0.599 - ETA: 3:01 - loss: 6.3894 - acc: 0.599 - ETA: 3:01 - loss: 6.3897 - acc: 0.599 - ETA: 3:01 - loss: 6.3897 - acc: 0.599 - ETA: 3:00 - loss: 6.3888 - acc: 0.599 - ETA: 3:01 - loss: 6.3891 - acc: 0.599 - ETA: 3:00 - loss: 6.3895 - acc: 0.599 - ETA: 3:01 - loss: 6.3892 - acc: 0.599 - ETA: 3:01 - loss: 6.3892 - acc: 0.599 - ETA: 3:01 - loss: 6.3898 - acc: 0.599 - ETA: 3:01 - loss: 6.3899 - acc: 0.599 - ETA: 3:01 - loss: 6.3901 - acc: 0.599 - ETA: 3:01 - loss: 6.3898 - acc: 0.599 - ETA: 3:00 - loss: 6.3897 - acc: 0.599 - ETA: 3:00 - loss: 6.3900 - acc: 0.599 - ETA: 3:00 - loss: 6.3898 - acc: 0.599 - ETA: 3:00 - loss: 6.3893 - acc: 0.599 - ETA: 3:00 - loss: 6.3894 - acc: 0.599 - ETA: 3:00 - loss: 6.3910 - acc: 0.599 - ETA: 3:00 - loss: 6.3908 - acc: 0.599 - ETA: 3:00 - loss: 6.3901 - acc: 0.599 - ETA: 3:00 - loss: 6.3896 - acc: 0.599 - ETA: 3:00 - loss: 6.3899 - acc: 0.599 - ETA: 3:00 - loss: 6.3902 - acc: 0.599 - ETA: 2:59 - loss: 6.3899 - acc: 0.599 - ETA: 2:59 - loss: 6.3896 - acc: 0.599 - ETA: 2:59 - loss: 6.3901 - acc: 0.599 - ETA: 2:59 - loss: 6.3892 - acc: 0.599 - ETA: 2:59 - loss: 6.3896 - acc: 0.599 - ETA: 2:59 - loss: 6.3902 - acc: 0.599 - ETA: 2:59 - loss: 6.3904 - acc: 0.599 - ETA: 2:59 - loss: 6.3902 - acc: 0.599 - ETA: 2:59 - loss: 6.3900 - acc: 0.599 - ETA: 2:59 - loss: 6.3901 - acc: 0.599 - ETA: 2:59 - loss: 6.3900 - acc: 0.599 - ETA: 2:59 - loss: 6.3895 - acc: 0.599 - ETA: 2:59 - loss: 6.3892 - acc: 0.599 - ETA: 2:58 - loss: 6.3890 - acc: 0.599 - ETA: 2:58 - loss: 6.3895 - acc: 0.599 - ETA: 2:58 - loss: 6.3889 - acc: 0.599 - ETA: 2:58 - loss: 6.3894 - acc: 0.599 - ETA: 2:58 - loss: 6.3889 - acc: 0.599 - ETA: 2:58 - loss: 6.3889 - acc: 0.599 - ETA: 2:58 - loss: 6.3888 - acc: 0.599 - ETA: 2:58 - loss: 6.3891 - acc: 0.599 - ETA: 2:58 - loss: 6.3891 - acc: 0.599 - ETA: 2:58 - loss: 6.3898 - acc: 0.599 - ETA: 2:58 - loss: 6.3904 - acc: 0.599 - ETA: 2:57 - loss: 6.3901 - acc: 0.599 - ETA: 2:57 - loss: 6.3905 - acc: 0.599 - ETA: 2:57 - loss: 6.3908 - acc: 0.599 - ETA: 2:57 - loss: 6.3909 - acc: 0.599 - ETA: 2:57 - loss: 6.3909 - acc: 0.599 - ETA: 2:57 - loss: 6.3914 - acc: 0.599 - ETA: 2:57 - loss: 6.3912 - acc: 0.599 - ETA: 2:57 - loss: 6.3914 - acc: 0.599 - ETA: 2:57 - loss: 6.3912 - acc: 0.599 - ETA: 2:57 - loss: 6.3913 - acc: 0.599 - ETA: 2:57 - loss: 6.3900 - acc: 0.599 - ETA: 2:57 - loss: 6.3900 - acc: 0.599 - ETA: 2:57 - loss: 6.3903 - acc: 0.599 - ETA: 2:57 - loss: 6.3910 - acc: 0.599 - ETA: 2:57 - loss: 6.3913 - acc: 0.599 - ETA: 2:57 - loss: 6.3919 - acc: 0.599 - ETA: 2:57 - loss: 6.3922 - acc: 0.599 - ETA: 2:57 - loss: 6.3915 - acc: 0.599 - ETA: 2:57 - loss: 6.3918 - acc: 0.599 - ETA: 2:57 - loss: 6.3910 - acc: 0.599 - ETA: 2:57 - loss: 6.3906 - acc: 0.599 - ETA: 2:57 - loss: 6.3914 - acc: 0.599 - ETA: 2:58 - loss: 6.3917 - acc: 0.599 - ETA: 2:58 - loss: 6.3918 - acc: 0.599 - ETA: 2:58 - loss: 6.3915 - acc: 0.599 - ETA: 2:58 - loss: 6.3913 - acc: 0.599 - ETA: 2:58 - loss: 6.3912 - acc: 0.599 - ETA: 2:59 - loss: 6.3911 - acc: 0.599 - ETA: 2:59 - loss: 6.3921 - acc: 0.599 - ETA: 2:59 - loss: 6.3920 - acc: 0.599 - ETA: 2:59 - loss: 6.3920 - acc: 0.599 - ETA: 2:59 - loss: 6.3913 - acc: 0.599 - ETA: 2:59 - loss: 6.3917 - acc: 0.599 - ETA: 2:59 - loss: 6.3920 - acc: 0.599 - ETA: 2:58 - loss: 6.3917 - acc: 0.599 - ETA: 2:58 - loss: 6.3922 - acc: 0.599 - ETA: 2:58 - loss: 6.3923 - acc: 0.599 - ETA: 2:59 - loss: 6.3930 - acc: 0.599 - ETA: 2:58 - loss: 6.3935 - acc: 0.599 - ETA: 2:58 - loss: 6.3929 - acc: 0.599 - ETA: 2:58 - loss: 6.3927 - acc: 0.599 - ETA: 2:58 - loss: 6.3927 - acc: 0.599 - ETA: 2:58 - loss: 6.3926 - acc: 0.599 - ETA: 2:58 - loss: 6.3932 - acc: 0.599 - ETA: 2:58 - loss: 6.3935 - acc: 0.599 - ETA: 2:58 - loss: 6.3926 - acc: 0.599 - ETA: 2:58 - loss: 6.3925 - acc: 0.599 - ETA: 2:58 - loss: 6.3925 - acc: 0.599 - ETA: 2:58 - loss: 6.3934 - acc: 0.599 - ETA: 2:58 - loss: 6.3933 - acc: 0.599 - ETA: 2:58 - loss: 6.3928 - acc: 0.599 - ETA: 2:58 - loss: 6.3936 - acc: 0.599 - ETA: 2:58 - loss: 6.3932 - acc: 0.599 - ETA: 2:58 - loss: 6.3931 - acc: 0.599 - ETA: 2:58 - loss: 6.3934 - acc: 0.599 - ETA: 2:57 - loss: 6.3931 - acc: 0.599 - ETA: 2:57 - loss: 6.3937 - acc: 0.599 - ETA: 2:57 - loss: 6.3935 - acc: 0.599 - ETA: 2:57 - loss: 6.3933 - acc: 0.599 - ETA: 2:57 - loss: 6.3937 - acc: 0.598 - ETA: 2:57 - loss: 6.3936 - acc: 0.599 - ETA: 2:56 - loss: 6.3934 - acc: 0.599 - ETA: 2:56 - loss: 6.3933 - acc: 0.599 - ETA: 2:56 - loss: 6.3928 - acc: 0.599 - ETA: 2:56 - loss: 6.3935 - acc: 0.599 - ETA: 2:56 - loss: 6.3930 - acc: 0.599 - ETA: 2:56 - loss: 6.3928 - acc: 0.599 - ETA: 2:56 - loss: 6.3925 - acc: 0.599 - ETA: 2:56 - loss: 6.3928 - acc: 0.599 - ETA: 2:55 - loss: 6.3929 - acc: 0.599 - ETA: 2:55 - loss: 6.3928 - acc: 0.599 - ETA: 2:55 - loss: 6.3921 - acc: 0.599 - ETA: 2:55 - loss: 6.3925 - acc: 0.599 - ETA: 2:55 - loss: 6.3927 - acc: 0.599 - ETA: 2:55 - loss: 6.3919 - acc: 0.599 - ETA: 2:54 - loss: 6.3910 - acc: 0.599 - ETA: 2:54 - loss: 6.3901 - acc: 0.599 - ETA: 2:54 - loss: 6.3907 - acc: 0.599 - ETA: 2:54 - loss: 6.3908 - acc: 0.599 - ETA: 2:54 - loss: 6.3906 - acc: 0.599 - ETA: 2:54 - loss: 6.3905 - acc: 0.599 - ETA: 2:53 - loss: 6.3911 - acc: 0.599 - ETA: 2:53 - loss: 6.3914 - acc: 0.599 - ETA: 2:53 - loss: 6.3913 - acc: 0.599 - ETA: 2:53 - loss: 6.3913 - acc: 0.599 - ETA: 2:53 - loss: 6.3912 - acc: 0.599 - ETA: 2:52 - loss: 6.3914 - acc: 0.599 - ETA: 2:52 - loss: 6.3909 - acc: 0.599 - ETA: 2:52 - loss: 6.3912 - acc: 0.599 - ETA: 2:52 - loss: 6.3912 - acc: 0.599 - ETA: 2:52 - loss: 6.3913 - acc: 0.599 - ETA: 2:52 - loss: 6.3914 - acc: 0.599 - ETA: 2:52 - loss: 6.3918 - acc: 0.599 - ETA: 2:52 - loss: 6.3922 - acc: 0.599 - ETA: 2:52 - loss: 6.3923 - acc: 0.599 - ETA: 2:51 - loss: 6.3916 - acc: 0.599 - ETA: 2:51 - loss: 6.3913 - acc: 0.599 - ETA: 2:50 - loss: 6.3926 - acc: 0.599 - ETA: 2:50 - loss: 6.3935 - acc: 0.599 - ETA: 2:50 - loss: 6.3936 - acc: 0.599 - ETA: 2:50 - loss: 6.3924 - acc: 0.599 - ETA: 2:49 - loss: 6.3915 - acc: 0.599 - ETA: 2:49 - loss: 6.3919 - acc: 0.599 - ETA: 2:49 - loss: 6.3925 - acc: 0.599 - ETA: 2:48 - loss: 6.3915 - acc: 0.599 - ETA: 2:48 - loss: 6.3920 - acc: 0.599 - ETA: 2:47 - loss: 6.3913 - acc: 0.599 - ETA: 2:47 - loss: 6.3918 - acc: 0.599 - ETA: 2:47 - loss: 6.3911 - acc: 0.599 - ETA: 2:47 - loss: 6.3916 - acc: 0.599 - ETA: 2:47 - loss: 6.3916 - acc: 0.599 - ETA: 2:47 - loss: 6.3913 - acc: 0.599 - ETA: 2:47 - loss: 6.3916 - acc: 0.599 - ETA: 2:47 - loss: 6.3907 - acc: 0.599 - ETA: 2:46 - loss: 6.3918 - acc: 0.599 - ETA: 2:46 - loss: 6.3926 - acc: 0.599 - ETA: 2:46 - loss: 6.3931 - acc: 0.599 - ETA: 2:46 - loss: 6.3929 - acc: 0.599 - ETA: 2:45 - loss: 6.3921 - acc: 0.599 - ETA: 2:45 - loss: 6.3927 - acc: 0.599 - ETA: 2:45 - loss: 6.3925 - acc: 0.599 - ETA: 2:45 - loss: 6.3911 - acc: 0.599 - ETA: 2:44 - loss: 6.3895 - acc: 0.599 - ETA: 2:44 - loss: 6.3893 - acc: 0.599 - ETA: 2:43 - loss: 6.3899 - acc: 0.5992"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392960/969231 [===========>..................] - ETA: 2:43 - loss: 6.3896 - acc: 0.599 - ETA: 2:43 - loss: 6.3911 - acc: 0.599 - ETA: 2:42 - loss: 6.3919 - acc: 0.599 - ETA: 2:42 - loss: 6.3910 - acc: 0.599 - ETA: 2:42 - loss: 6.3919 - acc: 0.599 - ETA: 2:42 - loss: 6.3922 - acc: 0.599 - ETA: 2:41 - loss: 6.3935 - acc: 0.599 - ETA: 2:41 - loss: 6.3936 - acc: 0.599 - ETA: 2:41 - loss: 6.3949 - acc: 0.598 - ETA: 2:40 - loss: 6.3944 - acc: 0.598 - ETA: 2:40 - loss: 6.3941 - acc: 0.598 - ETA: 2:40 - loss: 6.3943 - acc: 0.598 - ETA: 2:40 - loss: 6.3942 - acc: 0.598 - ETA: 2:40 - loss: 6.3940 - acc: 0.598 - ETA: 2:39 - loss: 6.3937 - acc: 0.599 - ETA: 2:39 - loss: 6.3937 - acc: 0.598 - ETA: 2:39 - loss: 6.3942 - acc: 0.598 - ETA: 2:39 - loss: 6.3936 - acc: 0.599 - ETA: 2:39 - loss: 6.3939 - acc: 0.598 - ETA: 2:39 - loss: 6.3946 - acc: 0.598 - ETA: 2:38 - loss: 6.3942 - acc: 0.598 - ETA: 2:38 - loss: 6.3945 - acc: 0.598 - ETA: 2:38 - loss: 6.3940 - acc: 0.598 - ETA: 2:38 - loss: 6.3941 - acc: 0.598 - ETA: 2:38 - loss: 6.3943 - acc: 0.598 - ETA: 2:38 - loss: 6.3939 - acc: 0.598 - ETA: 2:38 - loss: 6.3938 - acc: 0.598 - ETA: 2:38 - loss: 6.3935 - acc: 0.599 - ETA: 2:38 - loss: 6.3942 - acc: 0.598 - ETA: 2:37 - loss: 6.3931 - acc: 0.599 - ETA: 2:37 - loss: 6.3925 - acc: 0.599 - ETA: 2:37 - loss: 6.3928 - acc: 0.599 - ETA: 2:37 - loss: 6.3930 - acc: 0.599 - ETA: 2:37 - loss: 6.3931 - acc: 0.599 - ETA: 2:37 - loss: 6.3931 - acc: 0.599 - ETA: 2:37 - loss: 6.3925 - acc: 0.599 - ETA: 2:36 - loss: 6.3921 - acc: 0.599 - ETA: 2:36 - loss: 6.3924 - acc: 0.599 - ETA: 2:36 - loss: 6.3924 - acc: 0.599 - ETA: 2:36 - loss: 6.3933 - acc: 0.599 - ETA: 2:36 - loss: 6.3931 - acc: 0.599 - ETA: 2:36 - loss: 6.3932 - acc: 0.599 - ETA: 2:36 - loss: 6.3937 - acc: 0.599 - ETA: 2:36 - loss: 6.3938 - acc: 0.598 - ETA: 2:35 - loss: 6.3937 - acc: 0.599 - ETA: 2:35 - loss: 6.3930 - acc: 0.599 - ETA: 2:35 - loss: 6.3923 - acc: 0.599 - ETA: 2:35 - loss: 6.3917 - acc: 0.599 - ETA: 2:34 - loss: 6.3922 - acc: 0.599 - ETA: 2:34 - loss: 6.3929 - acc: 0.599 - ETA: 2:34 - loss: 6.3926 - acc: 0.599 - ETA: 2:34 - loss: 6.3937 - acc: 0.599 - ETA: 2:33 - loss: 6.3943 - acc: 0.598 - ETA: 2:33 - loss: 6.3936 - acc: 0.599 - ETA: 2:32 - loss: 6.3930 - acc: 0.599 - ETA: 2:32 - loss: 6.3933 - acc: 0.599 - ETA: 2:32 - loss: 6.3932 - acc: 0.599 - ETA: 2:31 - loss: 6.3934 - acc: 0.599 - ETA: 2:31 - loss: 6.3938 - acc: 0.598 - ETA: 2:31 - loss: 6.3930 - acc: 0.599 - ETA: 2:30 - loss: 6.3925 - acc: 0.599 - ETA: 2:30 - loss: 6.3928 - acc: 0.599 - ETA: 2:30 - loss: 6.3937 - acc: 0.599 - ETA: 2:30 - loss: 6.3941 - acc: 0.598 - ETA: 2:29 - loss: 6.3943 - acc: 0.598 - ETA: 2:29 - loss: 6.3946 - acc: 0.598 - ETA: 2:29 - loss: 6.3944 - acc: 0.598 - ETA: 2:29 - loss: 6.3937 - acc: 0.599 - ETA: 2:29 - loss: 6.3935 - acc: 0.599 - ETA: 2:29 - loss: 6.3941 - acc: 0.598 - ETA: 2:28 - loss: 6.3941 - acc: 0.598 - ETA: 2:28 - loss: 6.3945 - acc: 0.598 - ETA: 2:28 - loss: 6.3946 - acc: 0.598 - ETA: 2:28 - loss: 6.3945 - acc: 0.598 - ETA: 2:27 - loss: 6.3939 - acc: 0.598 - ETA: 2:27 - loss: 6.3922 - acc: 0.599 - ETA: 2:27 - loss: 6.3928 - acc: 0.599 - ETA: 2:27 - loss: 6.3926 - acc: 0.599 - ETA: 2:26 - loss: 6.3929 - acc: 0.599 - ETA: 2:26 - loss: 6.3924 - acc: 0.599 - ETA: 2:26 - loss: 6.3919 - acc: 0.599 - ETA: 2:26 - loss: 6.3924 - acc: 0.599 - ETA: 2:25 - loss: 6.3930 - acc: 0.599 - ETA: 2:25 - loss: 6.3932 - acc: 0.599 - ETA: 2:26 - loss: 6.3934 - acc: 0.599 - ETA: 2:25 - loss: 6.3937 - acc: 0.598 - ETA: 2:25 - loss: 6.3937 - acc: 0.599 - ETA: 2:25 - loss: 6.3937 - acc: 0.599 - ETA: 2:25 - loss: 6.3937 - acc: 0.599 - ETA: 2:25 - loss: 6.3931 - acc: 0.599 - ETA: 2:25 - loss: 6.3940 - acc: 0.598 - ETA: 2:25 - loss: 6.3939 - acc: 0.598 - ETA: 2:25 - loss: 6.3942 - acc: 0.598 - ETA: 2:24 - loss: 6.3938 - acc: 0.598 - ETA: 2:24 - loss: 6.3939 - acc: 0.598 - ETA: 2:24 - loss: 6.3937 - acc: 0.598 - ETA: 2:24 - loss: 6.3941 - acc: 0.598 - ETA: 2:24 - loss: 6.3934 - acc: 0.599 - ETA: 2:24 - loss: 6.3937 - acc: 0.599 - ETA: 2:24 - loss: 6.3938 - acc: 0.598 - ETA: 2:24 - loss: 6.3935 - acc: 0.599 - ETA: 2:24 - loss: 6.3928 - acc: 0.599 - ETA: 2:24 - loss: 6.3927 - acc: 0.599 - ETA: 2:24 - loss: 6.3928 - acc: 0.599 - ETA: 2:24 - loss: 6.3928 - acc: 0.599 - ETA: 2:24 - loss: 6.3930 - acc: 0.599 - ETA: 2:24 - loss: 6.3934 - acc: 0.599 - ETA: 2:24 - loss: 6.3936 - acc: 0.599 - ETA: 2:24 - loss: 6.3935 - acc: 0.599 - ETA: 2:24 - loss: 6.3933 - acc: 0.599 - ETA: 2:24 - loss: 6.3942 - acc: 0.598 - ETA: 2:23 - loss: 6.3944 - acc: 0.598 - ETA: 2:23 - loss: 6.3945 - acc: 0.598 - ETA: 2:23 - loss: 6.3949 - acc: 0.598 - ETA: 2:23 - loss: 6.3950 - acc: 0.598 - ETA: 2:22 - loss: 6.3958 - acc: 0.598 - ETA: 2:22 - loss: 6.3960 - acc: 0.598 - ETA: 2:22 - loss: 6.3957 - acc: 0.598 - ETA: 2:22 - loss: 6.3952 - acc: 0.598 - ETA: 2:22 - loss: 6.3963 - acc: 0.598 - ETA: 2:21 - loss: 6.3962 - acc: 0.598 - ETA: 2:21 - loss: 6.3959 - acc: 0.598 - ETA: 2:21 - loss: 6.3947 - acc: 0.598 - ETA: 2:20 - loss: 6.3951 - acc: 0.598 - ETA: 2:20 - loss: 6.3947 - acc: 0.598 - ETA: 2:20 - loss: 6.3958 - acc: 0.598 - ETA: 2:20 - loss: 6.3962 - acc: 0.598 - ETA: 2:20 - loss: 6.3961 - acc: 0.598 - ETA: 2:19 - loss: 6.3964 - acc: 0.598 - ETA: 2:19 - loss: 6.3971 - acc: 0.598 - ETA: 2:19 - loss: 6.3965 - acc: 0.598 - ETA: 2:19 - loss: 6.3960 - acc: 0.598 - ETA: 2:19 - loss: 6.3960 - acc: 0.598 - ETA: 2:19 - loss: 6.3959 - acc: 0.598 - ETA: 2:18 - loss: 6.3956 - acc: 0.598 - ETA: 2:18 - loss: 6.3951 - acc: 0.598 - ETA: 2:18 - loss: 6.3956 - acc: 0.598 - ETA: 2:18 - loss: 6.3947 - acc: 0.598 - ETA: 2:18 - loss: 6.3948 - acc: 0.598 - ETA: 2:17 - loss: 6.3947 - acc: 0.598 - ETA: 2:17 - loss: 6.3948 - acc: 0.598 - ETA: 2:17 - loss: 6.3949 - acc: 0.598 - ETA: 2:16 - loss: 6.3956 - acc: 0.598 - ETA: 2:16 - loss: 6.3960 - acc: 0.598 - ETA: 2:16 - loss: 6.3959 - acc: 0.598 - ETA: 2:15 - loss: 6.3954 - acc: 0.598 - ETA: 2:15 - loss: 6.3951 - acc: 0.598 - ETA: 2:15 - loss: 6.3949 - acc: 0.598 - ETA: 2:14 - loss: 6.3946 - acc: 0.598 - ETA: 2:14 - loss: 6.3940 - acc: 0.598 - ETA: 2:14 - loss: 6.3935 - acc: 0.599 - ETA: 2:13 - loss: 6.3931 - acc: 0.599 - ETA: 2:13 - loss: 6.3940 - acc: 0.598 - ETA: 2:13 - loss: 6.3943 - acc: 0.598 - ETA: 2:13 - loss: 6.3937 - acc: 0.599 - ETA: 2:12 - loss: 6.3939 - acc: 0.598 - ETA: 2:12 - loss: 6.3950 - acc: 0.598 - ETA: 2:12 - loss: 6.3950 - acc: 0.598 - ETA: 2:11 - loss: 6.3952 - acc: 0.598 - ETA: 2:11 - loss: 6.3946 - acc: 0.598 - ETA: 2:11 - loss: 6.3943 - acc: 0.598 - ETA: 2:10 - loss: 6.3949 - acc: 0.598 - ETA: 2:10 - loss: 6.3954 - acc: 0.598 - ETA: 2:10 - loss: 6.3952 - acc: 0.598 - ETA: 2:09 - loss: 6.3949 - acc: 0.598 - ETA: 2:09 - loss: 6.3949 - acc: 0.598 - ETA: 2:09 - loss: 6.3953 - acc: 0.598 - ETA: 2:08 - loss: 6.3951 - acc: 0.598 - ETA: 2:08 - loss: 6.3956 - acc: 0.598 - ETA: 2:08 - loss: 6.3952 - acc: 0.598 - ETA: 2:07 - loss: 6.3965 - acc: 0.598 - ETA: 2:07 - loss: 6.3973 - acc: 0.598 - ETA: 2:06 - loss: 6.3976 - acc: 0.598 - ETA: 2:06 - loss: 6.3971 - acc: 0.598 - ETA: 2:06 - loss: 6.3960 - acc: 0.598 - ETA: 2:05 - loss: 6.3965 - acc: 0.598 - ETA: 2:05 - loss: 6.3971 - acc: 0.598 - ETA: 2:05 - loss: 6.3969 - acc: 0.598 - ETA: 2:05 - loss: 6.3968 - acc: 0.598 - ETA: 2:05 - loss: 6.3973 - acc: 0.598 - ETA: 2:04 - loss: 6.3965 - acc: 0.598 - ETA: 2:04 - loss: 6.3966 - acc: 0.598 - ETA: 2:04 - loss: 6.3964 - acc: 0.598 - ETA: 2:04 - loss: 6.3967 - acc: 0.598 - ETA: 2:03 - loss: 6.3969 - acc: 0.598 - ETA: 2:03 - loss: 6.3961 - acc: 0.598 - ETA: 2:03 - loss: 6.3955 - acc: 0.598 - ETA: 2:02 - loss: 6.3953 - acc: 0.598 - ETA: 2:02 - loss: 6.3951 - acc: 0.598 - ETA: 2:02 - loss: 6.3957 - acc: 0.598 - ETA: 2:01 - loss: 6.3948 - acc: 0.598 - ETA: 2:01 - loss: 6.3955 - acc: 0.598 - ETA: 2:01 - loss: 6.3962 - acc: 0.598 - ETA: 2:00 - loss: 6.3966 - acc: 0.598 - ETA: 2:00 - loss: 6.3963 - acc: 0.598 - ETA: 2:00 - loss: 6.3963 - acc: 0.598 - ETA: 2:00 - loss: 6.3966 - acc: 0.598 - ETA: 2:00 - loss: 6.3967 - acc: 0.598 - ETA: 1:59 - loss: 6.3960 - acc: 0.598 - ETA: 1:59 - loss: 6.3958 - acc: 0.598 - ETA: 1:59 - loss: 6.3954 - acc: 0.598 - ETA: 1:59 - loss: 6.3943 - acc: 0.598 - ETA: 1:58 - loss: 6.3948 - acc: 0.598 - ETA: 1:58 - loss: 6.3940 - acc: 0.5989"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "490368/969231 [==============>...............] - ETA: 1:58 - loss: 6.3945 - acc: 0.598 - ETA: 1:58 - loss: 6.3950 - acc: 0.598 - ETA: 1:57 - loss: 6.3943 - acc: 0.598 - ETA: 1:57 - loss: 6.3937 - acc: 0.598 - ETA: 1:57 - loss: 6.3927 - acc: 0.599 - ETA: 1:56 - loss: 6.3926 - acc: 0.599 - ETA: 1:56 - loss: 6.3916 - acc: 0.599 - ETA: 1:56 - loss: 6.3914 - acc: 0.599 - ETA: 1:55 - loss: 6.3918 - acc: 0.599 - ETA: 1:55 - loss: 6.3916 - acc: 0.599 - ETA: 1:55 - loss: 6.3911 - acc: 0.599 - ETA: 1:55 - loss: 6.3910 - acc: 0.599 - ETA: 1:54 - loss: 6.3908 - acc: 0.599 - ETA: 1:54 - loss: 6.3897 - acc: 0.599 - ETA: 1:54 - loss: 6.3893 - acc: 0.599 - ETA: 1:53 - loss: 6.3895 - acc: 0.599 - ETA: 1:53 - loss: 6.3901 - acc: 0.599 - ETA: 1:53 - loss: 6.3906 - acc: 0.599 - ETA: 1:52 - loss: 6.3913 - acc: 0.599 - ETA: 1:52 - loss: 6.3910 - acc: 0.599 - ETA: 1:52 - loss: 6.3902 - acc: 0.599 - ETA: 1:52 - loss: 6.3900 - acc: 0.599 - ETA: 1:51 - loss: 6.3905 - acc: 0.599 - ETA: 1:51 - loss: 6.3907 - acc: 0.599 - ETA: 1:51 - loss: 6.3903 - acc: 0.599 - ETA: 1:51 - loss: 6.3903 - acc: 0.599 - ETA: 1:50 - loss: 6.3897 - acc: 0.599 - ETA: 1:50 - loss: 6.3903 - acc: 0.599 - ETA: 1:50 - loss: 6.3907 - acc: 0.599 - ETA: 1:49 - loss: 6.3904 - acc: 0.599 - ETA: 1:49 - loss: 6.3910 - acc: 0.599 - ETA: 1:49 - loss: 6.3906 - acc: 0.599 - ETA: 1:49 - loss: 6.3901 - acc: 0.599 - ETA: 1:49 - loss: 6.3901 - acc: 0.599 - ETA: 1:49 - loss: 6.3906 - acc: 0.599 - ETA: 1:49 - loss: 6.3913 - acc: 0.599 - ETA: 1:48 - loss: 6.3915 - acc: 0.599 - ETA: 1:48 - loss: 6.3914 - acc: 0.599 - ETA: 1:48 - loss: 6.3915 - acc: 0.599 - ETA: 1:48 - loss: 6.3914 - acc: 0.599 - ETA: 1:48 - loss: 6.3912 - acc: 0.599 - ETA: 1:48 - loss: 6.3913 - acc: 0.599 - ETA: 1:48 - loss: 6.3916 - acc: 0.599 - ETA: 1:48 - loss: 6.3918 - acc: 0.599 - ETA: 1:47 - loss: 6.3921 - acc: 0.599 - ETA: 1:47 - loss: 6.3919 - acc: 0.599 - ETA: 1:47 - loss: 6.3925 - acc: 0.599 - ETA: 1:47 - loss: 6.3929 - acc: 0.599 - ETA: 1:46 - loss: 6.3928 - acc: 0.599 - ETA: 1:46 - loss: 6.3926 - acc: 0.599 - ETA: 1:46 - loss: 6.3925 - acc: 0.599 - ETA: 1:46 - loss: 6.3915 - acc: 0.599 - ETA: 1:46 - loss: 6.3920 - acc: 0.599 - ETA: 1:45 - loss: 6.3920 - acc: 0.599 - ETA: 1:45 - loss: 6.3927 - acc: 0.599 - ETA: 1:45 - loss: 6.3930 - acc: 0.599 - ETA: 1:45 - loss: 6.3927 - acc: 0.599 - ETA: 1:44 - loss: 6.3928 - acc: 0.599 - ETA: 1:44 - loss: 6.3925 - acc: 0.599 - ETA: 1:44 - loss: 6.3928 - acc: 0.599 - ETA: 1:44 - loss: 6.3927 - acc: 0.599 - ETA: 1:43 - loss: 6.3923 - acc: 0.599 - ETA: 1:43 - loss: 6.3925 - acc: 0.599 - ETA: 1:43 - loss: 6.3924 - acc: 0.599 - ETA: 1:43 - loss: 6.3929 - acc: 0.599 - ETA: 1:43 - loss: 6.3929 - acc: 0.599 - ETA: 1:43 - loss: 6.3929 - acc: 0.599 - ETA: 1:43 - loss: 6.3934 - acc: 0.599 - ETA: 1:43 - loss: 6.3936 - acc: 0.599 - ETA: 1:43 - loss: 6.3933 - acc: 0.599 - ETA: 1:42 - loss: 6.3933 - acc: 0.599 - ETA: 1:42 - loss: 6.3932 - acc: 0.599 - ETA: 1:42 - loss: 6.3927 - acc: 0.599 - ETA: 1:42 - loss: 6.3927 - acc: 0.599 - ETA: 1:42 - loss: 6.3927 - acc: 0.599 - ETA: 1:42 - loss: 6.3926 - acc: 0.599 - ETA: 1:42 - loss: 6.3929 - acc: 0.599 - ETA: 1:42 - loss: 6.3930 - acc: 0.599 - ETA: 1:42 - loss: 6.3931 - acc: 0.599 - ETA: 1:42 - loss: 6.3931 - acc: 0.599 - ETA: 1:42 - loss: 6.3930 - acc: 0.599 - ETA: 1:42 - loss: 6.3924 - acc: 0.599 - ETA: 1:41 - loss: 6.3923 - acc: 0.599 - ETA: 1:41 - loss: 6.3926 - acc: 0.599 - ETA: 1:41 - loss: 6.3933 - acc: 0.599 - ETA: 1:41 - loss: 6.3935 - acc: 0.599 - ETA: 1:41 - loss: 6.3936 - acc: 0.599 - ETA: 1:41 - loss: 6.3933 - acc: 0.599 - ETA: 1:41 - loss: 6.3930 - acc: 0.599 - ETA: 1:41 - loss: 6.3928 - acc: 0.599 - ETA: 1:40 - loss: 6.3932 - acc: 0.599 - ETA: 1:40 - loss: 6.3929 - acc: 0.599 - ETA: 1:40 - loss: 6.3927 - acc: 0.599 - ETA: 1:40 - loss: 6.3928 - acc: 0.599 - ETA: 1:40 - loss: 6.3927 - acc: 0.599 - ETA: 1:40 - loss: 6.3927 - acc: 0.599 - ETA: 1:40 - loss: 6.3924 - acc: 0.599 - ETA: 1:40 - loss: 6.3925 - acc: 0.599 - ETA: 1:40 - loss: 6.3927 - acc: 0.599 - ETA: 1:40 - loss: 6.3930 - acc: 0.599 - ETA: 1:40 - loss: 6.3929 - acc: 0.599 - ETA: 1:39 - loss: 6.3927 - acc: 0.599 - ETA: 1:39 - loss: 6.3931 - acc: 0.599 - ETA: 1:39 - loss: 6.3938 - acc: 0.598 - ETA: 1:39 - loss: 6.3942 - acc: 0.598 - ETA: 1:39 - loss: 6.3937 - acc: 0.598 - ETA: 1:39 - loss: 6.3932 - acc: 0.599 - ETA: 1:39 - loss: 6.3939 - acc: 0.598 - ETA: 1:39 - loss: 6.3935 - acc: 0.599 - ETA: 1:39 - loss: 6.3938 - acc: 0.598 - ETA: 1:39 - loss: 6.3938 - acc: 0.598 - ETA: 1:39 - loss: 6.3933 - acc: 0.599 - ETA: 1:38 - loss: 6.3936 - acc: 0.599 - ETA: 1:38 - loss: 6.3935 - acc: 0.599 - ETA: 1:38 - loss: 6.3935 - acc: 0.599 - ETA: 1:38 - loss: 6.3933 - acc: 0.599 - ETA: 1:38 - loss: 6.3930 - acc: 0.599 - ETA: 1:38 - loss: 6.3929 - acc: 0.599 - ETA: 1:38 - loss: 6.3926 - acc: 0.599 - ETA: 1:38 - loss: 6.3925 - acc: 0.599 - ETA: 1:38 - loss: 6.3926 - acc: 0.599 - ETA: 1:38 - loss: 6.3926 - acc: 0.599 - ETA: 1:38 - loss: 6.3929 - acc: 0.599 - ETA: 1:38 - loss: 6.3931 - acc: 0.599 - ETA: 1:38 - loss: 6.3935 - acc: 0.599 - ETA: 1:38 - loss: 6.3930 - acc: 0.599 - ETA: 1:37 - loss: 6.3935 - acc: 0.599 - ETA: 1:37 - loss: 6.3943 - acc: 0.598 - ETA: 1:37 - loss: 6.3941 - acc: 0.598 - ETA: 1:37 - loss: 6.3944 - acc: 0.598 - ETA: 1:37 - loss: 6.3945 - acc: 0.598 - ETA: 1:37 - loss: 6.3947 - acc: 0.598 - ETA: 1:37 - loss: 6.3946 - acc: 0.598 - ETA: 1:37 - loss: 6.3945 - acc: 0.598 - ETA: 1:37 - loss: 6.3941 - acc: 0.598 - ETA: 1:37 - loss: 6.3942 - acc: 0.598 - ETA: 1:37 - loss: 6.3938 - acc: 0.598 - ETA: 1:36 - loss: 6.3936 - acc: 0.599 - ETA: 1:36 - loss: 6.3932 - acc: 0.599 - ETA: 1:36 - loss: 6.3930 - acc: 0.599 - ETA: 1:36 - loss: 6.3931 - acc: 0.599 - ETA: 1:36 - loss: 6.3928 - acc: 0.599 - ETA: 1:36 - loss: 6.3930 - acc: 0.599 - ETA: 1:36 - loss: 6.3926 - acc: 0.599 - ETA: 1:36 - loss: 6.3923 - acc: 0.599 - ETA: 1:36 - loss: 6.3924 - acc: 0.599 - ETA: 1:36 - loss: 6.3922 - acc: 0.599 - ETA: 1:35 - loss: 6.3917 - acc: 0.599 - ETA: 1:35 - loss: 6.3924 - acc: 0.599 - ETA: 1:35 - loss: 6.3924 - acc: 0.599 - ETA: 1:35 - loss: 6.3926 - acc: 0.599 - ETA: 1:35 - loss: 6.3927 - acc: 0.599 - ETA: 1:35 - loss: 6.3927 - acc: 0.599 - ETA: 1:35 - loss: 6.3923 - acc: 0.599 - ETA: 1:35 - loss: 6.3921 - acc: 0.599 - ETA: 1:35 - loss: 6.3926 - acc: 0.599 - ETA: 1:34 - loss: 6.3925 - acc: 0.599 - ETA: 1:34 - loss: 6.3928 - acc: 0.599 - ETA: 1:34 - loss: 6.3922 - acc: 0.599 - ETA: 1:34 - loss: 6.3919 - acc: 0.599 - ETA: 1:34 - loss: 6.3911 - acc: 0.599 - ETA: 1:34 - loss: 6.3914 - acc: 0.599 - ETA: 1:34 - loss: 6.3910 - acc: 0.599 - ETA: 1:34 - loss: 6.3917 - acc: 0.599 - ETA: 1:33 - loss: 6.3914 - acc: 0.599 - ETA: 1:33 - loss: 6.3908 - acc: 0.599 - ETA: 1:33 - loss: 6.3903 - acc: 0.599 - ETA: 1:33 - loss: 6.3904 - acc: 0.599 - ETA: 1:33 - loss: 6.3909 - acc: 0.599 - ETA: 1:33 - loss: 6.3898 - acc: 0.599 - ETA: 1:33 - loss: 6.3896 - acc: 0.599 - ETA: 1:33 - loss: 6.3896 - acc: 0.599 - ETA: 1:33 - loss: 6.3899 - acc: 0.599 - ETA: 1:32 - loss: 6.3895 - acc: 0.599 - ETA: 1:32 - loss: 6.3892 - acc: 0.599 - ETA: 1:32 - loss: 6.3903 - acc: 0.599 - ETA: 1:32 - loss: 6.3904 - acc: 0.599 - ETA: 1:32 - loss: 6.3901 - acc: 0.599 - ETA: 1:32 - loss: 6.3899 - acc: 0.599 - ETA: 1:32 - loss: 6.3899 - acc: 0.599 - ETA: 1:32 - loss: 6.3898 - acc: 0.599 - ETA: 1:32 - loss: 6.3897 - acc: 0.599 - ETA: 1:32 - loss: 6.3899 - acc: 0.599 - ETA: 1:32 - loss: 6.3900 - acc: 0.599 - ETA: 1:32 - loss: 6.3904 - acc: 0.599 - ETA: 1:32 - loss: 6.3905 - acc: 0.599 - ETA: 1:32 - loss: 6.3908 - acc: 0.599 - ETA: 1:32 - loss: 6.3909 - acc: 0.599 - ETA: 1:32 - loss: 6.3912 - acc: 0.599 - ETA: 1:32 - loss: 6.3913 - acc: 0.599 - ETA: 1:32 - loss: 6.3912 - acc: 0.599 - ETA: 1:32 - loss: 6.3916 - acc: 0.599 - ETA: 1:32 - loss: 6.3913 - acc: 0.599 - ETA: 1:32 - loss: 6.3918 - acc: 0.599 - ETA: 1:32 - loss: 6.3920 - acc: 0.599 - ETA: 1:31 - loss: 6.3926 - acc: 0.599 - ETA: 1:31 - loss: 6.3930 - acc: 0.599 - ETA: 1:31 - loss: 6.3932 - acc: 0.599 - ETA: 1:31 - loss: 6.3937 - acc: 0.599 - ETA: 1:31 - loss: 6.3942 - acc: 0.598 - ETA: 1:31 - loss: 6.3941 - acc: 0.598 - ETA: 1:31 - loss: 6.3943 - acc: 0.598 - ETA: 1:31 - loss: 6.3945 - acc: 0.598 - ETA: 1:30 - loss: 6.3946 - acc: 0.5989"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "554624/969231 [================>.............] - ETA: 1:30 - loss: 6.3944 - acc: 0.598 - ETA: 1:30 - loss: 6.3946 - acc: 0.598 - ETA: 1:30 - loss: 6.3949 - acc: 0.598 - ETA: 1:30 - loss: 6.3948 - acc: 0.598 - ETA: 1:30 - loss: 6.3945 - acc: 0.598 - ETA: 1:30 - loss: 6.3945 - acc: 0.598 - ETA: 1:30 - loss: 6.3944 - acc: 0.598 - ETA: 1:30 - loss: 6.3934 - acc: 0.599 - ETA: 1:30 - loss: 6.3935 - acc: 0.599 - ETA: 1:30 - loss: 6.3935 - acc: 0.599 - ETA: 1:30 - loss: 6.3941 - acc: 0.598 - ETA: 1:30 - loss: 6.3945 - acc: 0.598 - ETA: 1:30 - loss: 6.3947 - acc: 0.598 - ETA: 1:30 - loss: 6.3951 - acc: 0.598 - ETA: 1:30 - loss: 6.3949 - acc: 0.598 - ETA: 1:30 - loss: 6.3953 - acc: 0.598 - ETA: 1:29 - loss: 6.3958 - acc: 0.598 - ETA: 1:29 - loss: 6.3958 - acc: 0.598 - ETA: 1:29 - loss: 6.3959 - acc: 0.598 - ETA: 1:30 - loss: 6.3959 - acc: 0.598 - ETA: 1:29 - loss: 6.3954 - acc: 0.598 - ETA: 1:29 - loss: 6.3956 - acc: 0.598 - ETA: 1:30 - loss: 6.3956 - acc: 0.598 - ETA: 1:30 - loss: 6.3958 - acc: 0.598 - ETA: 1:30 - loss: 6.3956 - acc: 0.598 - ETA: 1:30 - loss: 6.3953 - acc: 0.598 - ETA: 1:29 - loss: 6.3954 - acc: 0.598 - ETA: 1:29 - loss: 6.3954 - acc: 0.598 - ETA: 1:29 - loss: 6.3956 - acc: 0.598 - ETA: 1:29 - loss: 6.3959 - acc: 0.598 - ETA: 1:29 - loss: 6.3961 - acc: 0.598 - ETA: 1:29 - loss: 6.3959 - acc: 0.598 - ETA: 1:29 - loss: 6.3959 - acc: 0.598 - ETA: 1:29 - loss: 6.3961 - acc: 0.598 - ETA: 1:29 - loss: 6.3956 - acc: 0.598 - ETA: 1:29 - loss: 6.3956 - acc: 0.598 - ETA: 1:29 - loss: 6.3960 - acc: 0.598 - ETA: 1:29 - loss: 6.3962 - acc: 0.598 - ETA: 1:29 - loss: 6.3959 - acc: 0.598 - ETA: 1:29 - loss: 6.3964 - acc: 0.598 - ETA: 1:29 - loss: 6.3964 - acc: 0.598 - ETA: 1:29 - loss: 6.3962 - acc: 0.598 - ETA: 1:29 - loss: 6.3966 - acc: 0.598 - ETA: 1:29 - loss: 6.3966 - acc: 0.598 - ETA: 1:29 - loss: 6.3967 - acc: 0.598 - ETA: 1:29 - loss: 6.3966 - acc: 0.598 - ETA: 1:29 - loss: 6.3964 - acc: 0.598 - ETA: 1:29 - loss: 6.3966 - acc: 0.598 - ETA: 1:29 - loss: 6.3965 - acc: 0.598 - ETA: 1:29 - loss: 6.3971 - acc: 0.598 - ETA: 1:29 - loss: 6.3969 - acc: 0.598 - ETA: 1:29 - loss: 6.3970 - acc: 0.598 - ETA: 1:29 - loss: 6.3973 - acc: 0.598 - ETA: 1:29 - loss: 6.3974 - acc: 0.598 - ETA: 1:28 - loss: 6.3972 - acc: 0.598 - ETA: 1:28 - loss: 6.3976 - acc: 0.598 - ETA: 1:28 - loss: 6.3978 - acc: 0.598 - ETA: 1:28 - loss: 6.3977 - acc: 0.598 - ETA: 1:28 - loss: 6.3974 - acc: 0.598 - ETA: 1:28 - loss: 6.3976 - acc: 0.598 - ETA: 1:28 - loss: 6.3973 - acc: 0.598 - ETA: 1:28 - loss: 6.3975 - acc: 0.598 - ETA: 1:28 - loss: 6.3978 - acc: 0.598 - ETA: 1:28 - loss: 6.3978 - acc: 0.598 - ETA: 1:28 - loss: 6.3978 - acc: 0.598 - ETA: 1:28 - loss: 6.3978 - acc: 0.598 - ETA: 1:28 - loss: 6.3977 - acc: 0.598 - ETA: 1:28 - loss: 6.3977 - acc: 0.598 - ETA: 1:28 - loss: 6.3978 - acc: 0.598 - ETA: 1:28 - loss: 6.3981 - acc: 0.598 - ETA: 1:28 - loss: 6.3980 - acc: 0.598 - ETA: 1:28 - loss: 6.3981 - acc: 0.598 - ETA: 1:28 - loss: 6.3980 - acc: 0.598 - ETA: 1:28 - loss: 6.3987 - acc: 0.598 - ETA: 1:28 - loss: 6.3989 - acc: 0.598 - ETA: 1:28 - loss: 6.3985 - acc: 0.598 - ETA: 1:28 - loss: 6.3985 - acc: 0.598 - ETA: 1:28 - loss: 6.3984 - acc: 0.598 - ETA: 1:28 - loss: 6.3985 - acc: 0.598 - ETA: 1:28 - loss: 6.3987 - acc: 0.598 - ETA: 1:28 - loss: 6.3983 - acc: 0.598 - ETA: 1:28 - loss: 6.3982 - acc: 0.598 - ETA: 1:28 - loss: 6.3982 - acc: 0.598 - ETA: 1:28 - loss: 6.3982 - acc: 0.598 - ETA: 1:28 - loss: 6.3983 - acc: 0.598 - ETA: 1:27 - loss: 6.3981 - acc: 0.598 - ETA: 1:27 - loss: 6.3984 - acc: 0.598 - ETA: 1:27 - loss: 6.3981 - acc: 0.598 - ETA: 1:27 - loss: 6.3982 - acc: 0.598 - ETA: 1:27 - loss: 6.3981 - acc: 0.598 - ETA: 1:27 - loss: 6.3978 - acc: 0.598 - ETA: 1:27 - loss: 6.3978 - acc: 0.598 - ETA: 1:27 - loss: 6.3977 - acc: 0.598 - ETA: 1:27 - loss: 6.3974 - acc: 0.598 - ETA: 1:27 - loss: 6.3971 - acc: 0.598 - ETA: 1:27 - loss: 6.3970 - acc: 0.598 - ETA: 1:27 - loss: 6.3969 - acc: 0.598 - ETA: 1:27 - loss: 6.3971 - acc: 0.598 - ETA: 1:27 - loss: 6.3973 - acc: 0.598 - ETA: 1:27 - loss: 6.3974 - acc: 0.598 - ETA: 1:27 - loss: 6.3973 - acc: 0.598 - ETA: 1:27 - loss: 6.3974 - acc: 0.598 - ETA: 1:27 - loss: 6.3970 - acc: 0.598 - ETA: 1:27 - loss: 6.3972 - acc: 0.598 - ETA: 1:27 - loss: 6.3971 - acc: 0.598 - ETA: 1:26 - loss: 6.3974 - acc: 0.598 - ETA: 1:26 - loss: 6.3973 - acc: 0.598 - ETA: 1:26 - loss: 6.3972 - acc: 0.598 - ETA: 1:26 - loss: 6.3972 - acc: 0.598 - ETA: 1:26 - loss: 6.3973 - acc: 0.598 - ETA: 1:26 - loss: 6.3971 - acc: 0.598 - ETA: 1:26 - loss: 6.3965 - acc: 0.598 - ETA: 1:26 - loss: 6.3965 - acc: 0.598 - ETA: 1:26 - loss: 6.3962 - acc: 0.598 - ETA: 1:26 - loss: 6.3960 - acc: 0.598 - ETA: 1:26 - loss: 6.3959 - acc: 0.598 - ETA: 1:26 - loss: 6.3956 - acc: 0.598 - ETA: 1:26 - loss: 6.3956 - acc: 0.598 - ETA: 1:26 - loss: 6.3956 - acc: 0.598 - ETA: 1:26 - loss: 6.3961 - acc: 0.598 - ETA: 1:26 - loss: 6.3959 - acc: 0.598 - ETA: 1:26 - loss: 6.3954 - acc: 0.598 - ETA: 1:25 - loss: 6.3948 - acc: 0.598 - ETA: 1:25 - loss: 6.3946 - acc: 0.598 - ETA: 1:25 - loss: 6.3946 - acc: 0.598 - ETA: 1:25 - loss: 6.3948 - acc: 0.598 - ETA: 1:25 - loss: 6.3946 - acc: 0.598 - ETA: 1:25 - loss: 6.3941 - acc: 0.598 - ETA: 1:25 - loss: 6.3941 - acc: 0.598 - ETA: 1:25 - loss: 6.3939 - acc: 0.598 - ETA: 1:25 - loss: 6.3936 - acc: 0.599 - ETA: 1:25 - loss: 6.3937 - acc: 0.599 - ETA: 1:25 - loss: 6.3936 - acc: 0.599 - ETA: 1:25 - loss: 6.3939 - acc: 0.598 - ETA: 1:25 - loss: 6.3939 - acc: 0.598 - ETA: 1:25 - loss: 6.3938 - acc: 0.598 - ETA: 1:25 - loss: 6.3937 - acc: 0.599 - ETA: 1:24 - loss: 6.3933 - acc: 0.599 - ETA: 1:24 - loss: 6.3934 - acc: 0.599 - ETA: 1:24 - loss: 6.3935 - acc: 0.599 - ETA: 1:24 - loss: 6.3936 - acc: 0.599 - ETA: 1:24 - loss: 6.3935 - acc: 0.599 - ETA: 1:24 - loss: 6.3937 - acc: 0.598 - ETA: 1:24 - loss: 6.3937 - acc: 0.599 - ETA: 1:24 - loss: 6.3939 - acc: 0.598 - ETA: 1:24 - loss: 6.3939 - acc: 0.598 - ETA: 1:24 - loss: 6.3937 - acc: 0.598 - ETA: 1:24 - loss: 6.3934 - acc: 0.599 - ETA: 1:24 - loss: 6.3938 - acc: 0.598 - ETA: 1:24 - loss: 6.3938 - acc: 0.598 - ETA: 1:23 - loss: 6.3937 - acc: 0.598 - ETA: 1:23 - loss: 6.3941 - acc: 0.598 - ETA: 1:23 - loss: 6.3939 - acc: 0.598 - ETA: 1:23 - loss: 6.3938 - acc: 0.598 - ETA: 1:23 - loss: 6.3935 - acc: 0.599 - ETA: 1:23 - loss: 6.3932 - acc: 0.599 - ETA: 1:23 - loss: 6.3932 - acc: 0.599 - ETA: 1:23 - loss: 6.3932 - acc: 0.599 - ETA: 1:23 - loss: 6.3938 - acc: 0.598 - ETA: 1:23 - loss: 6.3941 - acc: 0.598 - ETA: 1:22 - loss: 6.3942 - acc: 0.598 - ETA: 1:22 - loss: 6.3941 - acc: 0.598 - ETA: 1:22 - loss: 6.3936 - acc: 0.599 - ETA: 1:22 - loss: 6.3937 - acc: 0.598 - ETA: 1:22 - loss: 6.3934 - acc: 0.599 - ETA: 1:22 - loss: 6.3933 - acc: 0.599 - ETA: 1:22 - loss: 6.3935 - acc: 0.599 - ETA: 1:22 - loss: 6.3934 - acc: 0.599 - ETA: 1:22 - loss: 6.3932 - acc: 0.599 - ETA: 1:22 - loss: 6.3934 - acc: 0.599 - ETA: 1:22 - loss: 6.3939 - acc: 0.598 - ETA: 1:21 - loss: 6.3934 - acc: 0.599 - ETA: 1:21 - loss: 6.3935 - acc: 0.599 - ETA: 1:21 - loss: 6.3936 - acc: 0.599 - ETA: 1:21 - loss: 6.3937 - acc: 0.598 - ETA: 1:21 - loss: 6.3940 - acc: 0.598 - ETA: 1:21 - loss: 6.3938 - acc: 0.598 - ETA: 1:21 - loss: 6.3936 - acc: 0.599 - ETA: 1:21 - loss: 6.3936 - acc: 0.599 - ETA: 1:21 - loss: 6.3940 - acc: 0.598 - ETA: 1:21 - loss: 6.3939 - acc: 0.598 - ETA: 1:20 - loss: 6.3939 - acc: 0.598 - ETA: 1:20 - loss: 6.3939 - acc: 0.598 - ETA: 1:20 - loss: 6.3938 - acc: 0.598 - ETA: 1:20 - loss: 6.3943 - acc: 0.598 - ETA: 1:20 - loss: 6.3942 - acc: 0.598 - ETA: 1:20 - loss: 6.3941 - acc: 0.598 - ETA: 1:20 - loss: 6.3939 - acc: 0.598 - ETA: 1:20 - loss: 6.3938 - acc: 0.598 - ETA: 1:20 - loss: 6.3942 - acc: 0.598 - ETA: 1:20 - loss: 6.3944 - acc: 0.598 - ETA: 1:20 - loss: 6.3944 - acc: 0.598 - ETA: 1:19 - loss: 6.3942 - acc: 0.598 - ETA: 1:19 - loss: 6.3944 - acc: 0.598 - ETA: 1:19 - loss: 6.3945 - acc: 0.598 - ETA: 1:19 - loss: 6.3942 - acc: 0.598 - ETA: 1:19 - loss: 6.3943 - acc: 0.598 - ETA: 1:19 - loss: 6.3942 - acc: 0.598 - ETA: 1:19 - loss: 6.3940 - acc: 0.598 - ETA: 1:19 - loss: 6.3943 - acc: 0.598 - ETA: 1:19 - loss: 6.3942 - acc: 0.598 - ETA: 1:19 - loss: 6.3944 - acc: 0.598 - ETA: 1:19 - loss: 6.3943 - acc: 0.598 - ETA: 1:19 - loss: 6.3946 - acc: 0.5989"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627840/969231 [==================>...........] - ETA: 1:19 - loss: 6.3947 - acc: 0.598 - ETA: 1:18 - loss: 6.3946 - acc: 0.598 - ETA: 1:18 - loss: 6.3951 - acc: 0.598 - ETA: 1:18 - loss: 6.3954 - acc: 0.598 - ETA: 1:18 - loss: 6.3956 - acc: 0.598 - ETA: 1:18 - loss: 6.3956 - acc: 0.598 - ETA: 1:18 - loss: 6.3956 - acc: 0.598 - ETA: 1:18 - loss: 6.3954 - acc: 0.598 - ETA: 1:18 - loss: 6.3954 - acc: 0.598 - ETA: 1:18 - loss: 6.3952 - acc: 0.598 - ETA: 1:18 - loss: 6.3951 - acc: 0.598 - ETA: 1:18 - loss: 6.3951 - acc: 0.598 - ETA: 1:18 - loss: 6.3951 - acc: 0.598 - ETA: 1:18 - loss: 6.3946 - acc: 0.598 - ETA: 1:17 - loss: 6.3943 - acc: 0.598 - ETA: 1:17 - loss: 6.3942 - acc: 0.598 - ETA: 1:17 - loss: 6.3938 - acc: 0.598 - ETA: 1:17 - loss: 6.3940 - acc: 0.598 - ETA: 1:17 - loss: 6.3936 - acc: 0.599 - ETA: 1:17 - loss: 6.3932 - acc: 0.599 - ETA: 1:17 - loss: 6.3930 - acc: 0.599 - ETA: 1:17 - loss: 6.3931 - acc: 0.599 - ETA: 1:17 - loss: 6.3935 - acc: 0.599 - ETA: 1:17 - loss: 6.3939 - acc: 0.598 - ETA: 1:16 - loss: 6.3937 - acc: 0.599 - ETA: 1:16 - loss: 6.3937 - acc: 0.598 - ETA: 1:16 - loss: 6.3934 - acc: 0.599 - ETA: 1:16 - loss: 6.3939 - acc: 0.598 - ETA: 1:16 - loss: 6.3940 - acc: 0.598 - ETA: 1:16 - loss: 6.3938 - acc: 0.598 - ETA: 1:16 - loss: 6.3941 - acc: 0.598 - ETA: 1:16 - loss: 6.3942 - acc: 0.598 - ETA: 1:16 - loss: 6.3949 - acc: 0.598 - ETA: 1:16 - loss: 6.3949 - acc: 0.598 - ETA: 1:16 - loss: 6.3949 - acc: 0.598 - ETA: 1:16 - loss: 6.3951 - acc: 0.598 - ETA: 1:16 - loss: 6.3951 - acc: 0.598 - ETA: 1:16 - loss: 6.3950 - acc: 0.598 - ETA: 1:16 - loss: 6.3950 - acc: 0.598 - ETA: 1:16 - loss: 6.3952 - acc: 0.598 - ETA: 1:15 - loss: 6.3950 - acc: 0.598 - ETA: 1:15 - loss: 6.3952 - acc: 0.598 - ETA: 1:15 - loss: 6.3955 - acc: 0.598 - ETA: 1:15 - loss: 6.3959 - acc: 0.598 - ETA: 1:15 - loss: 6.3956 - acc: 0.598 - ETA: 1:15 - loss: 6.3955 - acc: 0.598 - ETA: 1:15 - loss: 6.3957 - acc: 0.598 - ETA: 1:14 - loss: 6.3958 - acc: 0.598 - ETA: 1:14 - loss: 6.3953 - acc: 0.598 - ETA: 1:14 - loss: 6.3960 - acc: 0.598 - ETA: 1:14 - loss: 6.3957 - acc: 0.598 - ETA: 1:14 - loss: 6.3954 - acc: 0.598 - ETA: 1:14 - loss: 6.3956 - acc: 0.598 - ETA: 1:14 - loss: 6.3957 - acc: 0.598 - ETA: 1:14 - loss: 6.3953 - acc: 0.598 - ETA: 1:14 - loss: 6.3952 - acc: 0.598 - ETA: 1:13 - loss: 6.3953 - acc: 0.598 - ETA: 1:13 - loss: 6.3952 - acc: 0.598 - ETA: 1:13 - loss: 6.3954 - acc: 0.598 - ETA: 1:13 - loss: 6.3957 - acc: 0.598 - ETA: 1:13 - loss: 6.3955 - acc: 0.598 - ETA: 1:13 - loss: 6.3959 - acc: 0.598 - ETA: 1:13 - loss: 6.3957 - acc: 0.598 - ETA: 1:13 - loss: 6.3956 - acc: 0.598 - ETA: 1:13 - loss: 6.3956 - acc: 0.598 - ETA: 1:13 - loss: 6.3959 - acc: 0.598 - ETA: 1:13 - loss: 6.3960 - acc: 0.598 - ETA: 1:13 - loss: 6.3965 - acc: 0.598 - ETA: 1:13 - loss: 6.3967 - acc: 0.598 - ETA: 1:13 - loss: 6.3969 - acc: 0.598 - ETA: 1:12 - loss: 6.3966 - acc: 0.598 - ETA: 1:12 - loss: 6.3969 - acc: 0.598 - ETA: 1:12 - loss: 6.3969 - acc: 0.598 - ETA: 1:12 - loss: 6.3972 - acc: 0.598 - ETA: 1:12 - loss: 6.3972 - acc: 0.598 - ETA: 1:12 - loss: 6.3972 - acc: 0.598 - ETA: 1:12 - loss: 6.3975 - acc: 0.598 - ETA: 1:12 - loss: 6.3976 - acc: 0.598 - ETA: 1:12 - loss: 6.3977 - acc: 0.598 - ETA: 1:12 - loss: 6.3978 - acc: 0.598 - ETA: 1:12 - loss: 6.3977 - acc: 0.598 - ETA: 1:12 - loss: 6.3981 - acc: 0.598 - ETA: 1:12 - loss: 6.3976 - acc: 0.598 - ETA: 1:11 - loss: 6.3975 - acc: 0.598 - ETA: 1:11 - loss: 6.3971 - acc: 0.598 - ETA: 1:11 - loss: 6.3968 - acc: 0.598 - ETA: 1:11 - loss: 6.3967 - acc: 0.598 - ETA: 1:11 - loss: 6.3968 - acc: 0.598 - ETA: 1:11 - loss: 6.3966 - acc: 0.598 - ETA: 1:11 - loss: 6.3964 - acc: 0.598 - ETA: 1:11 - loss: 6.3963 - acc: 0.598 - ETA: 1:11 - loss: 6.3964 - acc: 0.598 - ETA: 1:11 - loss: 6.3964 - acc: 0.598 - ETA: 1:11 - loss: 6.3965 - acc: 0.598 - ETA: 1:11 - loss: 6.3963 - acc: 0.598 - ETA: 1:11 - loss: 6.3962 - acc: 0.598 - ETA: 1:11 - loss: 6.3961 - acc: 0.598 - ETA: 1:11 - loss: 6.3962 - acc: 0.598 - ETA: 1:10 - loss: 6.3962 - acc: 0.598 - ETA: 1:11 - loss: 6.3963 - acc: 0.598 - ETA: 1:10 - loss: 6.3968 - acc: 0.598 - ETA: 1:10 - loss: 6.3970 - acc: 0.598 - ETA: 1:10 - loss: 6.3972 - acc: 0.598 - ETA: 1:10 - loss: 6.3971 - acc: 0.598 - ETA: 1:10 - loss: 6.3972 - acc: 0.598 - ETA: 1:10 - loss: 6.3972 - acc: 0.598 - ETA: 1:10 - loss: 6.3972 - acc: 0.598 - ETA: 1:10 - loss: 6.3971 - acc: 0.598 - ETA: 1:10 - loss: 6.3969 - acc: 0.598 - ETA: 1:10 - loss: 6.3970 - acc: 0.598 - ETA: 1:10 - loss: 6.3970 - acc: 0.598 - ETA: 1:10 - loss: 6.3976 - acc: 0.598 - ETA: 1:10 - loss: 6.3977 - acc: 0.598 - ETA: 1:10 - loss: 6.3975 - acc: 0.598 - ETA: 1:10 - loss: 6.3976 - acc: 0.598 - ETA: 1:10 - loss: 6.3972 - acc: 0.598 - ETA: 1:10 - loss: 6.3967 - acc: 0.598 - ETA: 1:10 - loss: 6.3973 - acc: 0.598 - ETA: 1:10 - loss: 6.3970 - acc: 0.598 - ETA: 1:10 - loss: 6.3970 - acc: 0.598 - ETA: 1:09 - loss: 6.3969 - acc: 0.598 - ETA: 1:09 - loss: 6.3972 - acc: 0.598 - ETA: 1:09 - loss: 6.3975 - acc: 0.598 - ETA: 1:09 - loss: 6.3972 - acc: 0.598 - ETA: 1:09 - loss: 6.3980 - acc: 0.598 - ETA: 1:09 - loss: 6.3984 - acc: 0.598 - ETA: 1:09 - loss: 6.3986 - acc: 0.598 - ETA: 1:09 - loss: 6.3989 - acc: 0.598 - ETA: 1:09 - loss: 6.3986 - acc: 0.598 - ETA: 1:09 - loss: 6.3986 - acc: 0.598 - ETA: 1:09 - loss: 6.3986 - acc: 0.598 - ETA: 1:09 - loss: 6.3982 - acc: 0.598 - ETA: 1:09 - loss: 6.3984 - acc: 0.598 - ETA: 1:09 - loss: 6.3989 - acc: 0.598 - ETA: 1:09 - loss: 6.3989 - acc: 0.598 - ETA: 1:09 - loss: 6.3988 - acc: 0.598 - ETA: 1:09 - loss: 6.3985 - acc: 0.598 - ETA: 1:08 - loss: 6.3984 - acc: 0.598 - ETA: 1:08 - loss: 6.3986 - acc: 0.598 - ETA: 1:08 - loss: 6.3988 - acc: 0.598 - ETA: 1:08 - loss: 6.3987 - acc: 0.598 - ETA: 1:08 - loss: 6.3987 - acc: 0.598 - ETA: 1:08 - loss: 6.3989 - acc: 0.598 - ETA: 1:08 - loss: 6.3991 - acc: 0.598 - ETA: 1:08 - loss: 6.3993 - acc: 0.598 - ETA: 1:08 - loss: 6.3996 - acc: 0.598 - ETA: 1:08 - loss: 6.3996 - acc: 0.598 - ETA: 1:08 - loss: 6.3996 - acc: 0.598 - ETA: 1:08 - loss: 6.3995 - acc: 0.598 - ETA: 1:08 - loss: 6.3994 - acc: 0.598 - ETA: 1:08 - loss: 6.3993 - acc: 0.598 - ETA: 1:08 - loss: 6.3989 - acc: 0.598 - ETA: 1:07 - loss: 6.3984 - acc: 0.598 - ETA: 1:07 - loss: 6.3987 - acc: 0.598 - ETA: 1:07 - loss: 6.3992 - acc: 0.598 - ETA: 1:07 - loss: 6.3994 - acc: 0.598 - ETA: 1:07 - loss: 6.3994 - acc: 0.598 - ETA: 1:07 - loss: 6.3995 - acc: 0.598 - ETA: 1:07 - loss: 6.3995 - acc: 0.598 - ETA: 1:07 - loss: 6.3995 - acc: 0.598 - ETA: 1:07 - loss: 6.3996 - acc: 0.598 - ETA: 1:07 - loss: 6.3996 - acc: 0.598 - ETA: 1:07 - loss: 6.3996 - acc: 0.598 - ETA: 1:07 - loss: 6.3996 - acc: 0.598 - ETA: 1:07 - loss: 6.3996 - acc: 0.598 - ETA: 1:07 - loss: 6.3989 - acc: 0.598 - ETA: 1:07 - loss: 6.3985 - acc: 0.598 - ETA: 1:06 - loss: 6.3983 - acc: 0.598 - ETA: 1:06 - loss: 6.3981 - acc: 0.598 - ETA: 1:06 - loss: 6.3979 - acc: 0.598 - ETA: 1:06 - loss: 6.3982 - acc: 0.598 - ETA: 1:06 - loss: 6.3982 - acc: 0.598 - ETA: 1:06 - loss: 6.3980 - acc: 0.598 - ETA: 1:06 - loss: 6.3983 - acc: 0.598 - ETA: 1:06 - loss: 6.3983 - acc: 0.598 - ETA: 1:06 - loss: 6.3984 - acc: 0.598 - ETA: 1:06 - loss: 6.3984 - acc: 0.598 - ETA: 1:06 - loss: 6.3989 - acc: 0.598 - ETA: 1:06 - loss: 6.3990 - acc: 0.598 - ETA: 1:06 - loss: 6.3997 - acc: 0.598 - ETA: 1:06 - loss: 6.3998 - acc: 0.598 - ETA: 1:05 - loss: 6.3996 - acc: 0.598 - ETA: 1:05 - loss: 6.3996 - acc: 0.598 - ETA: 1:05 - loss: 6.3997 - acc: 0.598 - ETA: 1:05 - loss: 6.3999 - acc: 0.598 - ETA: 1:05 - loss: 6.3996 - acc: 0.598 - ETA: 1:05 - loss: 6.3996 - acc: 0.598 - ETA: 1:05 - loss: 6.3997 - acc: 0.598 - ETA: 1:05 - loss: 6.3993 - acc: 0.598 - ETA: 1:05 - loss: 6.3993 - acc: 0.598 - ETA: 1:05 - loss: 6.3990 - acc: 0.598 - ETA: 1:05 - loss: 6.3992 - acc: 0.598 - ETA: 1:05 - loss: 6.3993 - acc: 0.598 - ETA: 1:04 - loss: 6.3997 - acc: 0.598 - ETA: 1:04 - loss: 6.3996 - acc: 0.598 - ETA: 1:04 - loss: 6.3997 - acc: 0.598 - ETA: 1:04 - loss: 6.3996 - acc: 0.598 - ETA: 1:04 - loss: 6.3995 - acc: 0.598 - ETA: 1:04 - loss: 6.3995 - acc: 0.598 - ETA: 1:04 - loss: 6.3993 - acc: 0.598 - ETA: 1:04 - loss: 6.3999 - acc: 0.598 - ETA: 1:04 - loss: 6.3998 - acc: 0.598 - ETA: 1:04 - loss: 6.3998 - acc: 0.598 - ETA: 1:04 - loss: 6.4003 - acc: 0.5985"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700416/969231 [====================>.........] - ETA: 1:04 - loss: 6.4002 - acc: 0.598 - ETA: 1:03 - loss: 6.4003 - acc: 0.598 - ETA: 1:03 - loss: 6.4003 - acc: 0.598 - ETA: 1:03 - loss: 6.4001 - acc: 0.598 - ETA: 1:03 - loss: 6.4005 - acc: 0.598 - ETA: 1:03 - loss: 6.4008 - acc: 0.598 - ETA: 1:03 - loss: 6.4011 - acc: 0.598 - ETA: 1:03 - loss: 6.4011 - acc: 0.598 - ETA: 1:03 - loss: 6.4011 - acc: 0.598 - ETA: 1:03 - loss: 6.4012 - acc: 0.598 - ETA: 1:03 - loss: 6.4012 - acc: 0.598 - ETA: 1:03 - loss: 6.4012 - acc: 0.598 - ETA: 1:03 - loss: 6.4009 - acc: 0.598 - ETA: 1:03 - loss: 6.4008 - acc: 0.598 - ETA: 1:02 - loss: 6.4009 - acc: 0.598 - ETA: 1:02 - loss: 6.4009 - acc: 0.598 - ETA: 1:02 - loss: 6.4007 - acc: 0.598 - ETA: 1:02 - loss: 6.4004 - acc: 0.598 - ETA: 1:02 - loss: 6.4002 - acc: 0.598 - ETA: 1:02 - loss: 6.4000 - acc: 0.598 - ETA: 1:02 - loss: 6.4003 - acc: 0.598 - ETA: 1:01 - loss: 6.4003 - acc: 0.598 - ETA: 1:01 - loss: 6.4000 - acc: 0.598 - ETA: 1:01 - loss: 6.4002 - acc: 0.598 - ETA: 1:01 - loss: 6.4002 - acc: 0.598 - ETA: 1:01 - loss: 6.4001 - acc: 0.598 - ETA: 1:01 - loss: 6.4003 - acc: 0.598 - ETA: 1:01 - loss: 6.4003 - acc: 0.598 - ETA: 1:01 - loss: 6.4006 - acc: 0.598 - ETA: 1:01 - loss: 6.4007 - acc: 0.598 - ETA: 1:01 - loss: 6.4009 - acc: 0.598 - ETA: 1:01 - loss: 6.4008 - acc: 0.598 - ETA: 1:01 - loss: 6.4006 - acc: 0.598 - ETA: 1:01 - loss: 6.4003 - acc: 0.598 - ETA: 1:01 - loss: 6.4005 - acc: 0.598 - ETA: 1:01 - loss: 6.4002 - acc: 0.598 - ETA: 1:01 - loss: 6.4004 - acc: 0.598 - ETA: 1:00 - loss: 6.4005 - acc: 0.598 - ETA: 1:00 - loss: 6.4002 - acc: 0.598 - ETA: 1:00 - loss: 6.4002 - acc: 0.598 - ETA: 1:00 - loss: 6.4000 - acc: 0.598 - ETA: 1:00 - loss: 6.3999 - acc: 0.598 - ETA: 1:00 - loss: 6.3997 - acc: 0.598 - ETA: 1:00 - loss: 6.3998 - acc: 0.598 - ETA: 1:00 - loss: 6.3999 - acc: 0.598 - ETA: 1:00 - loss: 6.4001 - acc: 0.598 - ETA: 1:00 - loss: 6.3999 - acc: 0.598 - ETA: 1:00 - loss: 6.3998 - acc: 0.598 - ETA: 1:00 - loss: 6.4000 - acc: 0.598 - ETA: 1:00 - loss: 6.3996 - acc: 0.598 - ETA: 59s - loss: 6.3996 - acc: 0.598 - ETA: 59s - loss: 6.4001 - acc: 0.59 - ETA: 59s - loss: 6.4004 - acc: 0.59 - ETA: 59s - loss: 6.4006 - acc: 0.59 - ETA: 59s - loss: 6.4007 - acc: 0.59 - ETA: 59s - loss: 6.4007 - acc: 0.59 - ETA: 59s - loss: 6.4006 - acc: 0.59 - ETA: 59s - loss: 6.4005 - acc: 0.59 - ETA: 58s - loss: 6.4005 - acc: 0.59 - ETA: 58s - loss: 6.3999 - acc: 0.59 - ETA: 58s - loss: 6.3997 - acc: 0.59 - ETA: 58s - loss: 6.3998 - acc: 0.59 - ETA: 58s - loss: 6.4001 - acc: 0.59 - ETA: 58s - loss: 6.3997 - acc: 0.59 - ETA: 58s - loss: 6.3993 - acc: 0.59 - ETA: 58s - loss: 6.3990 - acc: 0.59 - ETA: 57s - loss: 6.3991 - acc: 0.59 - ETA: 57s - loss: 6.3992 - acc: 0.59 - ETA: 57s - loss: 6.3990 - acc: 0.59 - ETA: 57s - loss: 6.3991 - acc: 0.59 - ETA: 57s - loss: 6.3990 - acc: 0.59 - ETA: 57s - loss: 6.3988 - acc: 0.59 - ETA: 57s - loss: 6.3987 - acc: 0.59 - ETA: 57s - loss: 6.3988 - acc: 0.59 - ETA: 57s - loss: 6.3989 - acc: 0.59 - ETA: 57s - loss: 6.3991 - acc: 0.59 - ETA: 57s - loss: 6.3994 - acc: 0.59 - ETA: 57s - loss: 6.3994 - acc: 0.59 - ETA: 57s - loss: 6.3989 - acc: 0.59 - ETA: 56s - loss: 6.3991 - acc: 0.59 - ETA: 56s - loss: 6.3991 - acc: 0.59 - ETA: 56s - loss: 6.3992 - acc: 0.59 - ETA: 56s - loss: 6.3993 - acc: 0.59 - ETA: 56s - loss: 6.3996 - acc: 0.59 - ETA: 56s - loss: 6.3994 - acc: 0.59 - ETA: 56s - loss: 6.3994 - acc: 0.59 - ETA: 56s - loss: 6.3993 - acc: 0.59 - ETA: 56s - loss: 6.3994 - acc: 0.59 - ETA: 56s - loss: 6.3991 - acc: 0.59 - ETA: 56s - loss: 6.3986 - acc: 0.59 - ETA: 56s - loss: 6.3986 - acc: 0.59 - ETA: 55s - loss: 6.3989 - acc: 0.59 - ETA: 55s - loss: 6.3992 - acc: 0.59 - ETA: 55s - loss: 6.3993 - acc: 0.59 - ETA: 55s - loss: 6.3990 - acc: 0.59 - ETA: 55s - loss: 6.3990 - acc: 0.59 - ETA: 55s - loss: 6.3990 - acc: 0.59 - ETA: 55s - loss: 6.3988 - acc: 0.59 - ETA: 55s - loss: 6.3989 - acc: 0.59 - ETA: 55s - loss: 6.3989 - acc: 0.59 - ETA: 55s - loss: 6.3989 - acc: 0.59 - ETA: 55s - loss: 6.3987 - acc: 0.59 - ETA: 55s - loss: 6.3987 - acc: 0.59 - ETA: 55s - loss: 6.3989 - acc: 0.59 - ETA: 55s - loss: 6.3987 - acc: 0.59 - ETA: 55s - loss: 6.3987 - acc: 0.59 - ETA: 54s - loss: 6.3987 - acc: 0.59 - ETA: 54s - loss: 6.3992 - acc: 0.59 - ETA: 54s - loss: 6.3991 - acc: 0.59 - ETA: 54s - loss: 6.3993 - acc: 0.59 - ETA: 54s - loss: 6.3992 - acc: 0.59 - ETA: 54s - loss: 6.3991 - acc: 0.59 - ETA: 54s - loss: 6.3988 - acc: 0.59 - ETA: 54s - loss: 6.3989 - acc: 0.59 - ETA: 54s - loss: 6.3989 - acc: 0.59 - ETA: 54s - loss: 6.3990 - acc: 0.59 - ETA: 54s - loss: 6.3991 - acc: 0.59 - ETA: 54s - loss: 6.3996 - acc: 0.59 - ETA: 54s - loss: 6.3993 - acc: 0.59 - ETA: 54s - loss: 6.3988 - acc: 0.59 - ETA: 53s - loss: 6.3988 - acc: 0.59 - ETA: 53s - loss: 6.3986 - acc: 0.59 - ETA: 53s - loss: 6.3984 - acc: 0.59 - ETA: 53s - loss: 6.3983 - acc: 0.59 - ETA: 53s - loss: 6.3985 - acc: 0.59 - ETA: 53s - loss: 6.3984 - acc: 0.59 - ETA: 53s - loss: 6.3986 - acc: 0.59 - ETA: 53s - loss: 6.3986 - acc: 0.59 - ETA: 53s - loss: 6.3987 - acc: 0.59 - ETA: 53s - loss: 6.3989 - acc: 0.59 - ETA: 53s - loss: 6.3990 - acc: 0.59 - ETA: 53s - loss: 6.3992 - acc: 0.59 - ETA: 53s - loss: 6.3993 - acc: 0.59 - ETA: 53s - loss: 6.3998 - acc: 0.59 - ETA: 53s - loss: 6.3998 - acc: 0.59 - ETA: 53s - loss: 6.3997 - acc: 0.59 - ETA: 53s - loss: 6.3998 - acc: 0.59 - ETA: 53s - loss: 6.3999 - acc: 0.59 - ETA: 53s - loss: 6.4000 - acc: 0.59 - ETA: 53s - loss: 6.4000 - acc: 0.59 - ETA: 53s - loss: 6.4001 - acc: 0.59 - ETA: 53s - loss: 6.3998 - acc: 0.59 - ETA: 53s - loss: 6.3996 - acc: 0.59 - ETA: 52s - loss: 6.3995 - acc: 0.59 - ETA: 52s - loss: 6.3994 - acc: 0.59 - ETA: 52s - loss: 6.3998 - acc: 0.59 - ETA: 52s - loss: 6.3994 - acc: 0.59 - ETA: 52s - loss: 6.3993 - acc: 0.59 - ETA: 52s - loss: 6.3990 - acc: 0.59 - ETA: 52s - loss: 6.3990 - acc: 0.59 - ETA: 52s - loss: 6.3992 - acc: 0.59 - ETA: 52s - loss: 6.3990 - acc: 0.59 - ETA: 52s - loss: 6.3990 - acc: 0.59 - ETA: 52s - loss: 6.3993 - acc: 0.59 - ETA: 52s - loss: 6.3993 - acc: 0.59 - ETA: 52s - loss: 6.3995 - acc: 0.59 - ETA: 52s - loss: 6.3997 - acc: 0.59 - ETA: 52s - loss: 6.3994 - acc: 0.59 - ETA: 52s - loss: 6.3993 - acc: 0.59 - ETA: 52s - loss: 6.3993 - acc: 0.59 - ETA: 52s - loss: 6.3993 - acc: 0.59 - ETA: 51s - loss: 6.3993 - acc: 0.59 - ETA: 51s - loss: 6.3992 - acc: 0.59 - ETA: 51s - loss: 6.3995 - acc: 0.59 - ETA: 51s - loss: 6.3993 - acc: 0.59 - ETA: 51s - loss: 6.3994 - acc: 0.59 - ETA: 51s - loss: 6.3994 - acc: 0.59 - ETA: 51s - loss: 6.3993 - acc: 0.59 - ETA: 51s - loss: 6.3996 - acc: 0.59 - ETA: 51s - loss: 6.3998 - acc: 0.59 - ETA: 51s - loss: 6.3997 - acc: 0.59 - ETA: 51s - loss: 6.3995 - acc: 0.59 - ETA: 51s - loss: 6.3997 - acc: 0.59 - ETA: 51s - loss: 6.3998 - acc: 0.59 - ETA: 51s - loss: 6.3999 - acc: 0.59 - ETA: 51s - loss: 6.4000 - acc: 0.59 - ETA: 51s - loss: 6.4002 - acc: 0.59 - ETA: 50s - loss: 6.4002 - acc: 0.59 - ETA: 50s - loss: 6.4003 - acc: 0.59 - ETA: 50s - loss: 6.4004 - acc: 0.59 - ETA: 50s - loss: 6.4004 - acc: 0.59 - ETA: 50s - loss: 6.4003 - acc: 0.59 - ETA: 50s - loss: 6.4003 - acc: 0.59 - ETA: 50s - loss: 6.3999 - acc: 0.59 - ETA: 50s - loss: 6.4001 - acc: 0.59 - ETA: 50s - loss: 6.4001 - acc: 0.59 - ETA: 50s - loss: 6.4002 - acc: 0.59 - ETA: 50s - loss: 6.4001 - acc: 0.59 - ETA: 50s - loss: 6.4002 - acc: 0.59 - ETA: 50s - loss: 6.4000 - acc: 0.59 - ETA: 50s - loss: 6.4002 - acc: 0.59 - ETA: 50s - loss: 6.4002 - acc: 0.59 - ETA: 50s - loss: 6.4004 - acc: 0.59 - ETA: 50s - loss: 6.4003 - acc: 0.59 - ETA: 50s - loss: 6.4004 - acc: 0.59 - ETA: 50s - loss: 6.4004 - acc: 0.59 - ETA: 50s - loss: 6.4004 - acc: 0.59 - ETA: 50s - loss: 6.4005 - acc: 0.59 - ETA: 50s - loss: 6.4004 - acc: 0.59 - ETA: 50s - loss: 6.4003 - acc: 0.59 - ETA: 50s - loss: 6.4003 - acc: 0.59 - ETA: 50s - loss: 6.4002 - acc: 0.59 - ETA: 50s - loss: 6.4001 - acc: 0.59 - ETA: 50s - loss: 6.3997 - acc: 0.59 - ETA: 50s - loss: 6.3996 - acc: 0.59 - ETA: 50s - loss: 6.4001 - acc: 0.59 - ETA: 50s - loss: 6.4000 - acc: 0.59 - ETA: 50s - loss: 6.4003 - acc: 0.59 - ETA: 50s - loss: 6.4002 - acc: 0.59 - ETA: 50s - loss: 6.4001 - acc: 0.59 - ETA: 50s - loss: 6.3999 - acc: 0.59 - ETA: 50s - loss: 6.3997 - acc: 0.5986"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "745216/969231 [======================>.......] - ETA: 50s - loss: 6.3997 - acc: 0.59 - ETA: 50s - loss: 6.3997 - acc: 0.59 - ETA: 50s - loss: 6.3997 - acc: 0.59 - ETA: 50s - loss: 6.3996 - acc: 0.59 - ETA: 50s - loss: 6.3993 - acc: 0.59 - ETA: 49s - loss: 6.3991 - acc: 0.59 - ETA: 49s - loss: 6.3991 - acc: 0.59 - ETA: 49s - loss: 6.3990 - acc: 0.59 - ETA: 49s - loss: 6.3993 - acc: 0.59 - ETA: 49s - loss: 6.3992 - acc: 0.59 - ETA: 49s - loss: 6.3993 - acc: 0.59 - ETA: 49s - loss: 6.3992 - acc: 0.59 - ETA: 49s - loss: 6.3992 - acc: 0.59 - ETA: 49s - loss: 6.3993 - acc: 0.59 - ETA: 49s - loss: 6.3994 - acc: 0.59 - ETA: 49s - loss: 6.3995 - acc: 0.59 - ETA: 49s - loss: 6.3997 - acc: 0.59 - ETA: 49s - loss: 6.3996 - acc: 0.59 - ETA: 49s - loss: 6.3997 - acc: 0.59 - ETA: 49s - loss: 6.3996 - acc: 0.59 - ETA: 49s - loss: 6.3994 - acc: 0.59 - ETA: 49s - loss: 6.3996 - acc: 0.59 - ETA: 49s - loss: 6.3997 - acc: 0.59 - ETA: 49s - loss: 6.3998 - acc: 0.59 - ETA: 49s - loss: 6.3997 - acc: 0.59 - ETA: 49s - loss: 6.4000 - acc: 0.59 - ETA: 49s - loss: 6.3999 - acc: 0.59 - ETA: 49s - loss: 6.3997 - acc: 0.59 - ETA: 49s - loss: 6.3996 - acc: 0.59 - ETA: 49s - loss: 6.3994 - acc: 0.59 - ETA: 49s - loss: 6.3996 - acc: 0.59 - ETA: 49s - loss: 6.3998 - acc: 0.59 - ETA: 49s - loss: 6.3998 - acc: 0.59 - ETA: 49s - loss: 6.3999 - acc: 0.59 - ETA: 49s - loss: 6.3999 - acc: 0.59 - ETA: 49s - loss: 6.3999 - acc: 0.59 - ETA: 49s - loss: 6.3999 - acc: 0.59 - ETA: 49s - loss: 6.3998 - acc: 0.59 - ETA: 49s - loss: 6.4000 - acc: 0.59 - ETA: 49s - loss: 6.3998 - acc: 0.59 - ETA: 49s - loss: 6.3998 - acc: 0.59 - ETA: 49s - loss: 6.3995 - acc: 0.59 - ETA: 49s - loss: 6.3996 - acc: 0.59 - ETA: 49s - loss: 6.3995 - acc: 0.59 - ETA: 49s - loss: 6.3992 - acc: 0.59 - ETA: 48s - loss: 6.3991 - acc: 0.59 - ETA: 48s - loss: 6.3989 - acc: 0.59 - ETA: 48s - loss: 6.3989 - acc: 0.59 - ETA: 48s - loss: 6.3989 - acc: 0.59 - ETA: 48s - loss: 6.3989 - acc: 0.59 - ETA: 48s - loss: 6.3989 - acc: 0.59 - ETA: 48s - loss: 6.3991 - acc: 0.59 - ETA: 48s - loss: 6.3993 - acc: 0.59 - ETA: 48s - loss: 6.3993 - acc: 0.59 - ETA: 48s - loss: 6.3995 - acc: 0.59 - ETA: 48s - loss: 6.3993 - acc: 0.59 - ETA: 48s - loss: 6.3990 - acc: 0.59 - ETA: 48s - loss: 6.3990 - acc: 0.59 - ETA: 48s - loss: 6.3989 - acc: 0.59 - ETA: 48s - loss: 6.3989 - acc: 0.59 - ETA: 48s - loss: 6.3986 - acc: 0.59 - ETA: 48s - loss: 6.3987 - acc: 0.59 - ETA: 48s - loss: 6.3984 - acc: 0.59 - ETA: 48s - loss: 6.3983 - acc: 0.59 - ETA: 48s - loss: 6.3980 - acc: 0.59 - ETA: 48s - loss: 6.3983 - acc: 0.59 - ETA: 48s - loss: 6.3983 - acc: 0.59 - ETA: 48s - loss: 6.3984 - acc: 0.59 - ETA: 48s - loss: 6.3983 - acc: 0.59 - ETA: 48s - loss: 6.3982 - acc: 0.59 - ETA: 48s - loss: 6.3982 - acc: 0.59 - ETA: 48s - loss: 6.3986 - acc: 0.59 - ETA: 48s - loss: 6.3987 - acc: 0.59 - ETA: 48s - loss: 6.3985 - acc: 0.59 - ETA: 48s - loss: 6.3985 - acc: 0.59 - ETA: 48s - loss: 6.3983 - acc: 0.59 - ETA: 48s - loss: 6.3984 - acc: 0.59 - ETA: 48s - loss: 6.3986 - acc: 0.59 - ETA: 48s - loss: 6.3988 - acc: 0.59 - ETA: 48s - loss: 6.3989 - acc: 0.59 - ETA: 48s - loss: 6.3989 - acc: 0.59 - ETA: 48s - loss: 6.3987 - acc: 0.59 - ETA: 48s - loss: 6.3984 - acc: 0.59 - ETA: 48s - loss: 6.3984 - acc: 0.59 - ETA: 48s - loss: 6.3987 - acc: 0.59 - ETA: 48s - loss: 6.3988 - acc: 0.59 - ETA: 48s - loss: 6.3987 - acc: 0.59 - ETA: 47s - loss: 6.3987 - acc: 0.59 - ETA: 47s - loss: 6.3990 - acc: 0.59 - ETA: 47s - loss: 6.3991 - acc: 0.59 - ETA: 47s - loss: 6.3994 - acc: 0.59 - ETA: 47s - loss: 6.3995 - acc: 0.59 - ETA: 47s - loss: 6.3994 - acc: 0.59 - ETA: 47s - loss: 6.3995 - acc: 0.59 - ETA: 47s - loss: 6.3994 - acc: 0.59 - ETA: 47s - loss: 6.3995 - acc: 0.59 - ETA: 47s - loss: 6.3992 - acc: 0.59 - ETA: 47s - loss: 6.3991 - acc: 0.59 - ETA: 47s - loss: 6.3992 - acc: 0.59 - ETA: 47s - loss: 6.3992 - acc: 0.59 - ETA: 47s - loss: 6.3989 - acc: 0.59 - ETA: 47s - loss: 6.3988 - acc: 0.59 - ETA: 47s - loss: 6.3989 - acc: 0.59 - ETA: 47s - loss: 6.3987 - acc: 0.59 - ETA: 47s - loss: 6.3986 - acc: 0.59 - ETA: 47s - loss: 6.3987 - acc: 0.59 - ETA: 47s - loss: 6.3986 - acc: 0.59 - ETA: 47s - loss: 6.3987 - acc: 0.59 - ETA: 47s - loss: 6.3987 - acc: 0.59 - ETA: 47s - loss: 6.3984 - acc: 0.59 - ETA: 47s - loss: 6.3983 - acc: 0.59 - ETA: 47s - loss: 6.3982 - acc: 0.59 - ETA: 47s - loss: 6.3985 - acc: 0.59 - ETA: 47s - loss: 6.3984 - acc: 0.59 - ETA: 47s - loss: 6.3984 - acc: 0.59 - ETA: 47s - loss: 6.3983 - acc: 0.59 - ETA: 47s - loss: 6.3982 - acc: 0.59 - ETA: 47s - loss: 6.3981 - acc: 0.59 - ETA: 47s - loss: 6.3982 - acc: 0.59 - ETA: 46s - loss: 6.3983 - acc: 0.59 - ETA: 46s - loss: 6.3983 - acc: 0.59 - ETA: 46s - loss: 6.3981 - acc: 0.59 - ETA: 46s - loss: 6.3981 - acc: 0.59 - ETA: 46s - loss: 6.3981 - acc: 0.59 - ETA: 46s - loss: 6.3979 - acc: 0.59 - ETA: 46s - loss: 6.3978 - acc: 0.59 - ETA: 46s - loss: 6.3978 - acc: 0.59 - ETA: 46s - loss: 6.3978 - acc: 0.59 - ETA: 46s - loss: 6.3976 - acc: 0.59 - ETA: 46s - loss: 6.3975 - acc: 0.59 - ETA: 46s - loss: 6.3978 - acc: 0.59 - ETA: 46s - loss: 6.3978 - acc: 0.59 - ETA: 46s - loss: 6.3981 - acc: 0.59 - ETA: 46s - loss: 6.3985 - acc: 0.59 - ETA: 46s - loss: 6.3986 - acc: 0.59 - ETA: 46s - loss: 6.3985 - acc: 0.59 - ETA: 46s - loss: 6.3983 - acc: 0.59 - ETA: 46s - loss: 6.3981 - acc: 0.59 - ETA: 46s - loss: 6.3983 - acc: 0.59 - ETA: 46s - loss: 6.3982 - acc: 0.59 - ETA: 46s - loss: 6.3981 - acc: 0.59 - ETA: 46s - loss: 6.3980 - acc: 0.59 - ETA: 46s - loss: 6.3981 - acc: 0.59 - ETA: 46s - loss: 6.3984 - acc: 0.59 - ETA: 46s - loss: 6.3983 - acc: 0.59 - ETA: 46s - loss: 6.3982 - acc: 0.59 - ETA: 46s - loss: 6.3984 - acc: 0.59 - ETA: 46s - loss: 6.3984 - acc: 0.59 - ETA: 46s - loss: 6.3981 - acc: 0.59 - ETA: 46s - loss: 6.3980 - acc: 0.59 - ETA: 46s - loss: 6.3980 - acc: 0.59 - ETA: 46s - loss: 6.3979 - acc: 0.59 - ETA: 46s - loss: 6.3981 - acc: 0.59 - ETA: 46s - loss: 6.3983 - acc: 0.59 - ETA: 46s - loss: 6.3982 - acc: 0.59 - ETA: 46s - loss: 6.3984 - acc: 0.59 - ETA: 46s - loss: 6.3983 - acc: 0.59 - ETA: 46s - loss: 6.3984 - acc: 0.59 - ETA: 46s - loss: 6.3983 - acc: 0.59 - ETA: 45s - loss: 6.3983 - acc: 0.59 - ETA: 45s - loss: 6.3981 - acc: 0.59 - ETA: 45s - loss: 6.3977 - acc: 0.59 - ETA: 45s - loss: 6.3979 - acc: 0.59 - ETA: 45s - loss: 6.3977 - acc: 0.59 - ETA: 45s - loss: 6.3979 - acc: 0.59 - ETA: 45s - loss: 6.3978 - acc: 0.59 - ETA: 45s - loss: 6.3976 - acc: 0.59 - ETA: 45s - loss: 6.3975 - acc: 0.59 - ETA: 45s - loss: 6.3976 - acc: 0.59 - ETA: 45s - loss: 6.3979 - acc: 0.59 - ETA: 45s - loss: 6.3983 - acc: 0.59 - ETA: 45s - loss: 6.3983 - acc: 0.59 - ETA: 45s - loss: 6.3984 - acc: 0.59 - ETA: 45s - loss: 6.3983 - acc: 0.59 - ETA: 45s - loss: 6.3982 - acc: 0.59 - ETA: 45s - loss: 6.3983 - acc: 0.59 - ETA: 45s - loss: 6.3983 - acc: 0.59 - ETA: 44s - loss: 6.3986 - acc: 0.59 - ETA: 44s - loss: 6.3986 - acc: 0.59 - ETA: 44s - loss: 6.3985 - acc: 0.59 - ETA: 44s - loss: 6.3987 - acc: 0.59 - ETA: 44s - loss: 6.3987 - acc: 0.59 - ETA: 44s - loss: 6.3989 - acc: 0.59 - ETA: 44s - loss: 6.3990 - acc: 0.59 - ETA: 44s - loss: 6.3987 - acc: 0.59 - ETA: 44s - loss: 6.3985 - acc: 0.59 - ETA: 44s - loss: 6.3986 - acc: 0.59 - ETA: 44s - loss: 6.3988 - acc: 0.59 - ETA: 44s - loss: 6.3986 - acc: 0.59 - ETA: 44s - loss: 6.3984 - acc: 0.59 - ETA: 44s - loss: 6.3984 - acc: 0.59 - ETA: 44s - loss: 6.3983 - acc: 0.59 - ETA: 44s - loss: 6.3981 - acc: 0.59 - ETA: 44s - loss: 6.3981 - acc: 0.59 - ETA: 44s - loss: 6.3982 - acc: 0.59 - ETA: 44s - loss: 6.3980 - acc: 0.59 - ETA: 44s - loss: 6.3984 - acc: 0.59 - ETA: 44s - loss: 6.3985 - acc: 0.59 - ETA: 44s - loss: 6.3983 - acc: 0.59 - ETA: 44s - loss: 6.3985 - acc: 0.59 - ETA: 44s - loss: 6.3982 - acc: 0.59 - ETA: 44s - loss: 6.3981 - acc: 0.59 - ETA: 43s - loss: 6.3981 - acc: 0.59 - ETA: 43s - loss: 6.3980 - acc: 0.59 - ETA: 43s - loss: 6.3980 - acc: 0.59 - ETA: 43s - loss: 6.3979 - acc: 0.59 - ETA: 43s - loss: 6.3979 - acc: 0.59 - ETA: 43s - loss: 6.3979 - acc: 0.59 - ETA: 43s - loss: 6.3981 - acc: 0.59 - ETA: 43s - loss: 6.3978 - acc: 0.59 - ETA: 43s - loss: 6.3976 - acc: 0.59 - ETA: 43s - loss: 6.3975 - acc: 0.59 - ETA: 43s - loss: 6.3975 - acc: 0.59 - ETA: 43s - loss: 6.3978 - acc: 0.59 - ETA: 43s - loss: 6.3978 - acc: 0.5987"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "802304/969231 [=======================>......] - ETA: 43s - loss: 6.3978 - acc: 0.59 - ETA: 43s - loss: 6.3979 - acc: 0.59 - ETA: 43s - loss: 6.3975 - acc: 0.59 - ETA: 43s - loss: 6.3975 - acc: 0.59 - ETA: 43s - loss: 6.3973 - acc: 0.59 - ETA: 43s - loss: 6.3975 - acc: 0.59 - ETA: 42s - loss: 6.3974 - acc: 0.59 - ETA: 42s - loss: 6.3975 - acc: 0.59 - ETA: 42s - loss: 6.3972 - acc: 0.59 - ETA: 42s - loss: 6.3974 - acc: 0.59 - ETA: 42s - loss: 6.3973 - acc: 0.59 - ETA: 42s - loss: 6.3978 - acc: 0.59 - ETA: 42s - loss: 6.3978 - acc: 0.59 - ETA: 42s - loss: 6.3980 - acc: 0.59 - ETA: 42s - loss: 6.3982 - acc: 0.59 - ETA: 42s - loss: 6.3981 - acc: 0.59 - ETA: 41s - loss: 6.3981 - acc: 0.59 - ETA: 41s - loss: 6.3978 - acc: 0.59 - ETA: 41s - loss: 6.3979 - acc: 0.59 - ETA: 41s - loss: 6.3980 - acc: 0.59 - ETA: 41s - loss: 6.3982 - acc: 0.59 - ETA: 41s - loss: 6.3980 - acc: 0.59 - ETA: 41s - loss: 6.3984 - acc: 0.59 - ETA: 41s - loss: 6.3985 - acc: 0.59 - ETA: 41s - loss: 6.3982 - acc: 0.59 - ETA: 41s - loss: 6.3980 - acc: 0.59 - ETA: 41s - loss: 6.3979 - acc: 0.59 - ETA: 41s - loss: 6.3983 - acc: 0.59 - ETA: 41s - loss: 6.3981 - acc: 0.59 - ETA: 40s - loss: 6.3982 - acc: 0.59 - ETA: 40s - loss: 6.3982 - acc: 0.59 - ETA: 40s - loss: 6.3979 - acc: 0.59 - ETA: 40s - loss: 6.3978 - acc: 0.59 - ETA: 40s - loss: 6.3980 - acc: 0.59 - ETA: 40s - loss: 6.3980 - acc: 0.59 - ETA: 40s - loss: 6.3981 - acc: 0.59 - ETA: 40s - loss: 6.3983 - acc: 0.59 - ETA: 40s - loss: 6.3984 - acc: 0.59 - ETA: 40s - loss: 6.3984 - acc: 0.59 - ETA: 40s - loss: 6.3984 - acc: 0.59 - ETA: 40s - loss: 6.3982 - acc: 0.59 - ETA: 40s - loss: 6.3983 - acc: 0.59 - ETA: 40s - loss: 6.3984 - acc: 0.59 - ETA: 40s - loss: 6.3981 - acc: 0.59 - ETA: 40s - loss: 6.3980 - acc: 0.59 - ETA: 40s - loss: 6.3981 - acc: 0.59 - ETA: 40s - loss: 6.3984 - acc: 0.59 - ETA: 40s - loss: 6.3982 - acc: 0.59 - ETA: 40s - loss: 6.3980 - acc: 0.59 - ETA: 40s - loss: 6.3981 - acc: 0.59 - ETA: 40s - loss: 6.3983 - acc: 0.59 - ETA: 40s - loss: 6.3983 - acc: 0.59 - ETA: 39s - loss: 6.3980 - acc: 0.59 - ETA: 39s - loss: 6.3980 - acc: 0.59 - ETA: 39s - loss: 6.3980 - acc: 0.59 - ETA: 39s - loss: 6.3981 - acc: 0.59 - ETA: 39s - loss: 6.3980 - acc: 0.59 - ETA: 39s - loss: 6.3984 - acc: 0.59 - ETA: 39s - loss: 6.3985 - acc: 0.59 - ETA: 39s - loss: 6.3987 - acc: 0.59 - ETA: 39s - loss: 6.3988 - acc: 0.59 - ETA: 39s - loss: 6.3989 - acc: 0.59 - ETA: 39s - loss: 6.3987 - acc: 0.59 - ETA: 39s - loss: 6.3987 - acc: 0.59 - ETA: 39s - loss: 6.3986 - acc: 0.59 - ETA: 39s - loss: 6.3985 - acc: 0.59 - ETA: 39s - loss: 6.3987 - acc: 0.59 - ETA: 39s - loss: 6.3986 - acc: 0.59 - ETA: 39s - loss: 6.3986 - acc: 0.59 - ETA: 39s - loss: 6.3986 - acc: 0.59 - ETA: 39s - loss: 6.3986 - acc: 0.59 - ETA: 39s - loss: 6.3986 - acc: 0.59 - ETA: 38s - loss: 6.3986 - acc: 0.59 - ETA: 38s - loss: 6.3989 - acc: 0.59 - ETA: 38s - loss: 6.3990 - acc: 0.59 - ETA: 38s - loss: 6.3989 - acc: 0.59 - ETA: 38s - loss: 6.3989 - acc: 0.59 - ETA: 38s - loss: 6.3989 - acc: 0.59 - ETA: 38s - loss: 6.3988 - acc: 0.59 - ETA: 38s - loss: 6.3987 - acc: 0.59 - ETA: 38s - loss: 6.3984 - acc: 0.59 - ETA: 38s - loss: 6.3984 - acc: 0.59 - ETA: 38s - loss: 6.3984 - acc: 0.59 - ETA: 38s - loss: 6.3984 - acc: 0.59 - ETA: 38s - loss: 6.3982 - acc: 0.59 - ETA: 38s - loss: 6.3980 - acc: 0.59 - ETA: 38s - loss: 6.3980 - acc: 0.59 - ETA: 38s - loss: 6.3979 - acc: 0.59 - ETA: 38s - loss: 6.3977 - acc: 0.59 - ETA: 38s - loss: 6.3974 - acc: 0.59 - ETA: 38s - loss: 6.3974 - acc: 0.59 - ETA: 38s - loss: 6.3973 - acc: 0.59 - ETA: 37s - loss: 6.3973 - acc: 0.59 - ETA: 37s - loss: 6.3975 - acc: 0.59 - ETA: 37s - loss: 6.3976 - acc: 0.59 - ETA: 37s - loss: 6.3978 - acc: 0.59 - ETA: 37s - loss: 6.3976 - acc: 0.59 - ETA: 37s - loss: 6.3979 - acc: 0.59 - ETA: 37s - loss: 6.3975 - acc: 0.59 - ETA: 37s - loss: 6.3974 - acc: 0.59 - ETA: 37s - loss: 6.3975 - acc: 0.59 - ETA: 37s - loss: 6.3974 - acc: 0.59 - ETA: 37s - loss: 6.3976 - acc: 0.59 - ETA: 37s - loss: 6.3974 - acc: 0.59 - ETA: 37s - loss: 6.3974 - acc: 0.59 - ETA: 37s - loss: 6.3976 - acc: 0.59 - ETA: 37s - loss: 6.3976 - acc: 0.59 - ETA: 37s - loss: 6.3976 - acc: 0.59 - ETA: 37s - loss: 6.3977 - acc: 0.59 - ETA: 37s - loss: 6.3976 - acc: 0.59 - ETA: 37s - loss: 6.3971 - acc: 0.59 - ETA: 36s - loss: 6.3971 - acc: 0.59 - ETA: 36s - loss: 6.3970 - acc: 0.59 - ETA: 36s - loss: 6.3968 - acc: 0.59 - ETA: 36s - loss: 6.3966 - acc: 0.59 - ETA: 36s - loss: 6.3966 - acc: 0.59 - ETA: 36s - loss: 6.3966 - acc: 0.59 - ETA: 36s - loss: 6.3964 - acc: 0.59 - ETA: 36s - loss: 6.3963 - acc: 0.59 - ETA: 36s - loss: 6.3962 - acc: 0.59 - ETA: 36s - loss: 6.3960 - acc: 0.59 - ETA: 36s - loss: 6.3959 - acc: 0.59 - ETA: 36s - loss: 6.3959 - acc: 0.59 - ETA: 36s - loss: 6.3959 - acc: 0.59 - ETA: 36s - loss: 6.3960 - acc: 0.59 - ETA: 36s - loss: 6.3960 - acc: 0.59 - ETA: 36s - loss: 6.3961 - acc: 0.59 - ETA: 36s - loss: 6.3961 - acc: 0.59 - ETA: 36s - loss: 6.3961 - acc: 0.59 - ETA: 36s - loss: 6.3960 - acc: 0.59 - ETA: 36s - loss: 6.3962 - acc: 0.59 - ETA: 36s - loss: 6.3962 - acc: 0.59 - ETA: 36s - loss: 6.3963 - acc: 0.59 - ETA: 36s - loss: 6.3961 - acc: 0.59 - ETA: 36s - loss: 6.3960 - acc: 0.59 - ETA: 35s - loss: 6.3963 - acc: 0.59 - ETA: 35s - loss: 6.3963 - acc: 0.59 - ETA: 35s - loss: 6.3964 - acc: 0.59 - ETA: 35s - loss: 6.3962 - acc: 0.59 - ETA: 35s - loss: 6.3964 - acc: 0.59 - ETA: 35s - loss: 6.3964 - acc: 0.59 - ETA: 35s - loss: 6.3968 - acc: 0.59 - ETA: 35s - loss: 6.3969 - acc: 0.59 - ETA: 35s - loss: 6.3968 - acc: 0.59 - ETA: 35s - loss: 6.3970 - acc: 0.59 - ETA: 35s - loss: 6.3967 - acc: 0.59 - ETA: 35s - loss: 6.3965 - acc: 0.59 - ETA: 35s - loss: 6.3965 - acc: 0.59 - ETA: 35s - loss: 6.3963 - acc: 0.59 - ETA: 35s - loss: 6.3961 - acc: 0.59 - ETA: 35s - loss: 6.3962 - acc: 0.59 - ETA: 35s - loss: 6.3962 - acc: 0.59 - ETA: 35s - loss: 6.3964 - acc: 0.59 - ETA: 35s - loss: 6.3963 - acc: 0.59 - ETA: 35s - loss: 6.3959 - acc: 0.59 - ETA: 35s - loss: 6.3960 - acc: 0.59 - ETA: 35s - loss: 6.3959 - acc: 0.59 - ETA: 35s - loss: 6.3960 - acc: 0.59 - ETA: 35s - loss: 6.3958 - acc: 0.59 - ETA: 35s - loss: 6.3959 - acc: 0.59 - ETA: 35s - loss: 6.3960 - acc: 0.59 - ETA: 34s - loss: 6.3959 - acc: 0.59 - ETA: 34s - loss: 6.3959 - acc: 0.59 - ETA: 34s - loss: 6.3960 - acc: 0.59 - ETA: 34s - loss: 6.3960 - acc: 0.59 - ETA: 34s - loss: 6.3963 - acc: 0.59 - ETA: 34s - loss: 6.3963 - acc: 0.59 - ETA: 34s - loss: 6.3963 - acc: 0.59 - ETA: 34s - loss: 6.3964 - acc: 0.59 - ETA: 34s - loss: 6.3963 - acc: 0.59 - ETA: 34s - loss: 6.3962 - acc: 0.59 - ETA: 34s - loss: 6.3963 - acc: 0.59 - ETA: 34s - loss: 6.3965 - acc: 0.59 - ETA: 34s - loss: 6.3963 - acc: 0.59 - ETA: 34s - loss: 6.3963 - acc: 0.59 - ETA: 34s - loss: 6.3961 - acc: 0.59 - ETA: 34s - loss: 6.3961 - acc: 0.59 - ETA: 34s - loss: 6.3962 - acc: 0.59 - ETA: 34s - loss: 6.3961 - acc: 0.59 - ETA: 34s - loss: 6.3959 - acc: 0.59 - ETA: 34s - loss: 6.3959 - acc: 0.59 - ETA: 34s - loss: 6.3959 - acc: 0.59 - ETA: 34s - loss: 6.3961 - acc: 0.59 - ETA: 34s - loss: 6.3961 - acc: 0.59 - ETA: 34s - loss: 6.3959 - acc: 0.59 - ETA: 34s - loss: 6.3958 - acc: 0.59 - ETA: 34s - loss: 6.3959 - acc: 0.59 - ETA: 34s - loss: 6.3958 - acc: 0.59 - ETA: 34s - loss: 6.3960 - acc: 0.59 - ETA: 34s - loss: 6.3963 - acc: 0.59 - ETA: 33s - loss: 6.3965 - acc: 0.59 - ETA: 33s - loss: 6.3965 - acc: 0.59 - ETA: 33s - loss: 6.3964 - acc: 0.59 - ETA: 33s - loss: 6.3965 - acc: 0.59 - ETA: 33s - loss: 6.3965 - acc: 0.59 - ETA: 33s - loss: 6.3967 - acc: 0.59 - ETA: 33s - loss: 6.3967 - acc: 0.59 - ETA: 33s - loss: 6.3966 - acc: 0.59 - ETA: 33s - loss: 6.3968 - acc: 0.59 - ETA: 33s - loss: 6.3965 - acc: 0.59 - ETA: 33s - loss: 6.3966 - acc: 0.59 - ETA: 33s - loss: 6.3963 - acc: 0.59 - ETA: 33s - loss: 6.3961 - acc: 0.59 - ETA: 33s - loss: 6.3961 - acc: 0.59 - ETA: 33s - loss: 6.3962 - acc: 0.59 - ETA: 33s - loss: 6.3961 - acc: 0.59 - ETA: 33s - loss: 6.3961 - acc: 0.59 - ETA: 33s - loss: 6.3962 - acc: 0.59 - ETA: 33s - loss: 6.3966 - acc: 0.59 - ETA: 33s - loss: 6.3966 - acc: 0.59 - ETA: 33s - loss: 6.3967 - acc: 0.59 - ETA: 33s - loss: 6.3965 - acc: 0.59 - ETA: 33s - loss: 6.3965 - acc: 0.59 - ETA: 33s - loss: 6.3966 - acc: 0.59 - ETA: 33s - loss: 6.3969 - acc: 0.5988"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "857600/969231 [=========================>....] - ETA: 33s - loss: 6.3970 - acc: 0.59 - ETA: 33s - loss: 6.3970 - acc: 0.59 - ETA: 33s - loss: 6.3970 - acc: 0.59 - ETA: 33s - loss: 6.3971 - acc: 0.59 - ETA: 32s - loss: 6.3970 - acc: 0.59 - ETA: 32s - loss: 6.3967 - acc: 0.59 - ETA: 32s - loss: 6.3969 - acc: 0.59 - ETA: 32s - loss: 6.3969 - acc: 0.59 - ETA: 32s - loss: 6.3968 - acc: 0.59 - ETA: 32s - loss: 6.3970 - acc: 0.59 - ETA: 32s - loss: 6.3970 - acc: 0.59 - ETA: 32s - loss: 6.3970 - acc: 0.59 - ETA: 32s - loss: 6.3971 - acc: 0.59 - ETA: 32s - loss: 6.3970 - acc: 0.59 - ETA: 32s - loss: 6.3970 - acc: 0.59 - ETA: 32s - loss: 6.3970 - acc: 0.59 - ETA: 32s - loss: 6.3970 - acc: 0.59 - ETA: 32s - loss: 6.3969 - acc: 0.59 - ETA: 32s - loss: 6.3970 - acc: 0.59 - ETA: 32s - loss: 6.3968 - acc: 0.59 - ETA: 32s - loss: 6.3970 - acc: 0.59 - ETA: 32s - loss: 6.3970 - acc: 0.59 - ETA: 32s - loss: 6.3971 - acc: 0.59 - ETA: 32s - loss: 6.3971 - acc: 0.59 - ETA: 32s - loss: 6.3972 - acc: 0.59 - ETA: 32s - loss: 6.3969 - acc: 0.59 - ETA: 32s - loss: 6.3969 - acc: 0.59 - ETA: 32s - loss: 6.3969 - acc: 0.59 - ETA: 32s - loss: 6.3969 - acc: 0.59 - ETA: 32s - loss: 6.3970 - acc: 0.59 - ETA: 31s - loss: 6.3970 - acc: 0.59 - ETA: 31s - loss: 6.3969 - acc: 0.59 - ETA: 31s - loss: 6.3970 - acc: 0.59 - ETA: 31s - loss: 6.3972 - acc: 0.59 - ETA: 31s - loss: 6.3971 - acc: 0.59 - ETA: 31s - loss: 6.3971 - acc: 0.59 - ETA: 31s - loss: 6.3971 - acc: 0.59 - ETA: 31s - loss: 6.3970 - acc: 0.59 - ETA: 31s - loss: 6.3970 - acc: 0.59 - ETA: 31s - loss: 6.3971 - acc: 0.59 - ETA: 31s - loss: 6.3971 - acc: 0.59 - ETA: 31s - loss: 6.3971 - acc: 0.59 - ETA: 31s - loss: 6.3971 - acc: 0.59 - ETA: 31s - loss: 6.3976 - acc: 0.59 - ETA: 31s - loss: 6.3976 - acc: 0.59 - ETA: 31s - loss: 6.3975 - acc: 0.59 - ETA: 31s - loss: 6.3976 - acc: 0.59 - ETA: 31s - loss: 6.3976 - acc: 0.59 - ETA: 31s - loss: 6.3976 - acc: 0.59 - ETA: 31s - loss: 6.3975 - acc: 0.59 - ETA: 31s - loss: 6.3975 - acc: 0.59 - ETA: 31s - loss: 6.3974 - acc: 0.59 - ETA: 31s - loss: 6.3973 - acc: 0.59 - ETA: 31s - loss: 6.3973 - acc: 0.59 - ETA: 31s - loss: 6.3974 - acc: 0.59 - ETA: 31s - loss: 6.3975 - acc: 0.59 - ETA: 30s - loss: 6.3974 - acc: 0.59 - ETA: 30s - loss: 6.3974 - acc: 0.59 - ETA: 30s - loss: 6.3972 - acc: 0.59 - ETA: 30s - loss: 6.3972 - acc: 0.59 - ETA: 30s - loss: 6.3972 - acc: 0.59 - ETA: 30s - loss: 6.3973 - acc: 0.59 - ETA: 30s - loss: 6.3972 - acc: 0.59 - ETA: 30s - loss: 6.3972 - acc: 0.59 - ETA: 30s - loss: 6.3973 - acc: 0.59 - ETA: 30s - loss: 6.3970 - acc: 0.59 - ETA: 30s - loss: 6.3975 - acc: 0.59 - ETA: 30s - loss: 6.3975 - acc: 0.59 - ETA: 30s - loss: 6.3974 - acc: 0.59 - ETA: 30s - loss: 6.3974 - acc: 0.59 - ETA: 30s - loss: 6.3974 - acc: 0.59 - ETA: 30s - loss: 6.3974 - acc: 0.59 - ETA: 30s - loss: 6.3975 - acc: 0.59 - ETA: 30s - loss: 6.3977 - acc: 0.59 - ETA: 29s - loss: 6.3979 - acc: 0.59 - ETA: 29s - loss: 6.3978 - acc: 0.59 - ETA: 29s - loss: 6.3978 - acc: 0.59 - ETA: 29s - loss: 6.3976 - acc: 0.59 - ETA: 29s - loss: 6.3976 - acc: 0.59 - ETA: 29s - loss: 6.3976 - acc: 0.59 - ETA: 29s - loss: 6.3975 - acc: 0.59 - ETA: 29s - loss: 6.3975 - acc: 0.59 - ETA: 29s - loss: 6.3975 - acc: 0.59 - ETA: 29s - loss: 6.3976 - acc: 0.59 - ETA: 29s - loss: 6.3979 - acc: 0.59 - ETA: 29s - loss: 6.3981 - acc: 0.59 - ETA: 29s - loss: 6.3980 - acc: 0.59 - ETA: 29s - loss: 6.3980 - acc: 0.59 - ETA: 29s - loss: 6.3982 - acc: 0.59 - ETA: 29s - loss: 6.3983 - acc: 0.59 - ETA: 29s - loss: 6.3983 - acc: 0.59 - ETA: 29s - loss: 6.3982 - acc: 0.59 - ETA: 29s - loss: 6.3983 - acc: 0.59 - ETA: 29s - loss: 6.3983 - acc: 0.59 - ETA: 29s - loss: 6.3982 - acc: 0.59 - ETA: 29s - loss: 6.3982 - acc: 0.59 - ETA: 29s - loss: 6.3981 - acc: 0.59 - ETA: 29s - loss: 6.3981 - acc: 0.59 - ETA: 29s - loss: 6.3980 - acc: 0.59 - ETA: 28s - loss: 6.3978 - acc: 0.59 - ETA: 28s - loss: 6.3980 - acc: 0.59 - ETA: 28s - loss: 6.3980 - acc: 0.59 - ETA: 28s - loss: 6.3981 - acc: 0.59 - ETA: 28s - loss: 6.3980 - acc: 0.59 - ETA: 28s - loss: 6.3982 - acc: 0.59 - ETA: 28s - loss: 6.3981 - acc: 0.59 - ETA: 28s - loss: 6.3978 - acc: 0.59 - ETA: 28s - loss: 6.3978 - acc: 0.59 - ETA: 28s - loss: 6.3978 - acc: 0.59 - ETA: 28s - loss: 6.3979 - acc: 0.59 - ETA: 28s - loss: 6.3976 - acc: 0.59 - ETA: 28s - loss: 6.3976 - acc: 0.59 - ETA: 28s - loss: 6.3975 - acc: 0.59 - ETA: 28s - loss: 6.3976 - acc: 0.59 - ETA: 28s - loss: 6.3975 - acc: 0.59 - ETA: 28s - loss: 6.3975 - acc: 0.59 - ETA: 27s - loss: 6.3977 - acc: 0.59 - ETA: 27s - loss: 6.3976 - acc: 0.59 - ETA: 27s - loss: 6.3977 - acc: 0.59 - ETA: 27s - loss: 6.3976 - acc: 0.59 - ETA: 27s - loss: 6.3977 - acc: 0.59 - ETA: 27s - loss: 6.3977 - acc: 0.59 - ETA: 27s - loss: 6.3977 - acc: 0.59 - ETA: 27s - loss: 6.3978 - acc: 0.59 - ETA: 27s - loss: 6.3979 - acc: 0.59 - ETA: 27s - loss: 6.3980 - acc: 0.59 - ETA: 27s - loss: 6.3979 - acc: 0.59 - ETA: 27s - loss: 6.3977 - acc: 0.59 - ETA: 27s - loss: 6.3975 - acc: 0.59 - ETA: 27s - loss: 6.3977 - acc: 0.59 - ETA: 27s - loss: 6.3977 - acc: 0.59 - ETA: 27s - loss: 6.3976 - acc: 0.59 - ETA: 27s - loss: 6.3976 - acc: 0.59 - ETA: 27s - loss: 6.3977 - acc: 0.59 - ETA: 27s - loss: 6.3976 - acc: 0.59 - ETA: 27s - loss: 6.3976 - acc: 0.59 - ETA: 27s - loss: 6.3974 - acc: 0.59 - ETA: 26s - loss: 6.3972 - acc: 0.59 - ETA: 26s - loss: 6.3974 - acc: 0.59 - ETA: 26s - loss: 6.3975 - acc: 0.59 - ETA: 26s - loss: 6.3977 - acc: 0.59 - ETA: 26s - loss: 6.3978 - acc: 0.59 - ETA: 26s - loss: 6.3978 - acc: 0.59 - ETA: 26s - loss: 6.3977 - acc: 0.59 - ETA: 26s - loss: 6.3974 - acc: 0.59 - ETA: 26s - loss: 6.3974 - acc: 0.59 - ETA: 26s - loss: 6.3972 - acc: 0.59 - ETA: 26s - loss: 6.3971 - acc: 0.59 - ETA: 26s - loss: 6.3970 - acc: 0.59 - ETA: 26s - loss: 6.3968 - acc: 0.59 - ETA: 26s - loss: 6.3966 - acc: 0.59 - ETA: 26s - loss: 6.3968 - acc: 0.59 - ETA: 26s - loss: 6.3968 - acc: 0.59 - ETA: 26s - loss: 6.3967 - acc: 0.59 - ETA: 26s - loss: 6.3967 - acc: 0.59 - ETA: 26s - loss: 6.3966 - acc: 0.59 - ETA: 26s - loss: 6.3967 - acc: 0.59 - ETA: 25s - loss: 6.3968 - acc: 0.59 - ETA: 25s - loss: 6.3965 - acc: 0.59 - ETA: 25s - loss: 6.3965 - acc: 0.59 - ETA: 25s - loss: 6.3962 - acc: 0.59 - ETA: 25s - loss: 6.3958 - acc: 0.59 - ETA: 25s - loss: 6.3959 - acc: 0.59 - ETA: 25s - loss: 6.3958 - acc: 0.59 - ETA: 25s - loss: 6.3963 - acc: 0.59 - ETA: 25s - loss: 6.3961 - acc: 0.59 - ETA: 25s - loss: 6.3961 - acc: 0.59 - ETA: 25s - loss: 6.3964 - acc: 0.59 - ETA: 25s - loss: 6.3962 - acc: 0.59 - ETA: 25s - loss: 6.3961 - acc: 0.59 - ETA: 25s - loss: 6.3960 - acc: 0.59 - ETA: 25s - loss: 6.3957 - acc: 0.59 - ETA: 25s - loss: 6.3955 - acc: 0.59 - ETA: 25s - loss: 6.3956 - acc: 0.59 - ETA: 25s - loss: 6.3956 - acc: 0.59 - ETA: 24s - loss: 6.3955 - acc: 0.59 - ETA: 24s - loss: 6.3957 - acc: 0.59 - ETA: 24s - loss: 6.3958 - acc: 0.59 - ETA: 24s - loss: 6.3958 - acc: 0.59 - ETA: 24s - loss: 6.3959 - acc: 0.59 - ETA: 24s - loss: 6.3960 - acc: 0.59 - ETA: 24s - loss: 6.3959 - acc: 0.59 - ETA: 24s - loss: 6.3962 - acc: 0.59 - ETA: 24s - loss: 6.3962 - acc: 0.59 - ETA: 24s - loss: 6.3965 - acc: 0.59 - ETA: 24s - loss: 6.3963 - acc: 0.59 - ETA: 24s - loss: 6.3960 - acc: 0.59 - ETA: 24s - loss: 6.3960 - acc: 0.59 - ETA: 24s - loss: 6.3960 - acc: 0.59 - ETA: 24s - loss: 6.3960 - acc: 0.59 - ETA: 24s - loss: 6.3958 - acc: 0.59 - ETA: 24s - loss: 6.3958 - acc: 0.59 - ETA: 24s - loss: 6.3959 - acc: 0.59 - ETA: 24s - loss: 6.3959 - acc: 0.59 - ETA: 23s - loss: 6.3961 - acc: 0.59 - ETA: 23s - loss: 6.3960 - acc: 0.59 - ETA: 23s - loss: 6.3960 - acc: 0.59 - ETA: 23s - loss: 6.3959 - acc: 0.59 - ETA: 23s - loss: 6.3959 - acc: 0.59 - ETA: 23s - loss: 6.3955 - acc: 0.59 - ETA: 23s - loss: 6.3955 - acc: 0.59 - ETA: 23s - loss: 6.3954 - acc: 0.59 - ETA: 23s - loss: 6.3954 - acc: 0.59 - ETA: 23s - loss: 6.3955 - acc: 0.59 - ETA: 23s - loss: 6.3952 - acc: 0.59 - ETA: 23s - loss: 6.3953 - acc: 0.59 - ETA: 23s - loss: 6.3952 - acc: 0.59 - ETA: 23s - loss: 6.3952 - acc: 0.59 - ETA: 23s - loss: 6.3952 - acc: 0.59 - ETA: 22s - loss: 6.3953 - acc: 0.59 - ETA: 22s - loss: 6.3953 - acc: 0.59 - ETA: 22s - loss: 6.3951 - acc: 0.59 - ETA: 22s - loss: 6.3956 - acc: 0.59 - ETA: 22s - loss: 6.3957 - acc: 0.59 - ETA: 22s - loss: 6.3959 - acc: 0.5988"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "948352/969231 [============================>.] - ETA: 22s - loss: 6.3959 - acc: 0.59 - ETA: 22s - loss: 6.3961 - acc: 0.59 - ETA: 22s - loss: 6.3960 - acc: 0.59 - ETA: 22s - loss: 6.3958 - acc: 0.59 - ETA: 22s - loss: 6.3957 - acc: 0.59 - ETA: 21s - loss: 6.3958 - acc: 0.59 - ETA: 21s - loss: 6.3957 - acc: 0.59 - ETA: 21s - loss: 6.3956 - acc: 0.59 - ETA: 21s - loss: 6.3955 - acc: 0.59 - ETA: 21s - loss: 6.3956 - acc: 0.59 - ETA: 21s - loss: 6.3956 - acc: 0.59 - ETA: 21s - loss: 6.3955 - acc: 0.59 - ETA: 21s - loss: 6.3953 - acc: 0.59 - ETA: 21s - loss: 6.3953 - acc: 0.59 - ETA: 21s - loss: 6.3953 - acc: 0.59 - ETA: 21s - loss: 6.3953 - acc: 0.59 - ETA: 21s - loss: 6.3954 - acc: 0.59 - ETA: 21s - loss: 6.3955 - acc: 0.59 - ETA: 20s - loss: 6.3956 - acc: 0.59 - ETA: 20s - loss: 6.3959 - acc: 0.59 - ETA: 20s - loss: 6.3961 - acc: 0.59 - ETA: 20s - loss: 6.3962 - acc: 0.59 - ETA: 20s - loss: 6.3964 - acc: 0.59 - ETA: 20s - loss: 6.3967 - acc: 0.59 - ETA: 20s - loss: 6.3969 - acc: 0.59 - ETA: 20s - loss: 6.3969 - acc: 0.59 - ETA: 20s - loss: 6.3969 - acc: 0.59 - ETA: 20s - loss: 6.3968 - acc: 0.59 - ETA: 20s - loss: 6.3965 - acc: 0.59 - ETA: 19s - loss: 6.3963 - acc: 0.59 - ETA: 19s - loss: 6.3962 - acc: 0.59 - ETA: 19s - loss: 6.3961 - acc: 0.59 - ETA: 19s - loss: 6.3957 - acc: 0.59 - ETA: 19s - loss: 6.3958 - acc: 0.59 - ETA: 19s - loss: 6.3960 - acc: 0.59 - ETA: 19s - loss: 6.3958 - acc: 0.59 - ETA: 18s - loss: 6.3955 - acc: 0.59 - ETA: 18s - loss: 6.3953 - acc: 0.59 - ETA: 18s - loss: 6.3955 - acc: 0.59 - ETA: 18s - loss: 6.3956 - acc: 0.59 - ETA: 18s - loss: 6.3955 - acc: 0.59 - ETA: 18s - loss: 6.3954 - acc: 0.59 - ETA: 18s - loss: 6.3955 - acc: 0.59 - ETA: 18s - loss: 6.3955 - acc: 0.59 - ETA: 18s - loss: 6.3956 - acc: 0.59 - ETA: 18s - loss: 6.3957 - acc: 0.59 - ETA: 18s - loss: 6.3959 - acc: 0.59 - ETA: 18s - loss: 6.3959 - acc: 0.59 - ETA: 17s - loss: 6.3959 - acc: 0.59 - ETA: 17s - loss: 6.3959 - acc: 0.59 - ETA: 17s - loss: 6.3960 - acc: 0.59 - ETA: 17s - loss: 6.3961 - acc: 0.59 - ETA: 17s - loss: 6.3961 - acc: 0.59 - ETA: 17s - loss: 6.3963 - acc: 0.59 - ETA: 17s - loss: 6.3964 - acc: 0.59 - ETA: 17s - loss: 6.3963 - acc: 0.59 - ETA: 17s - loss: 6.3968 - acc: 0.59 - ETA: 17s - loss: 6.3968 - acc: 0.59 - ETA: 17s - loss: 6.3970 - acc: 0.59 - ETA: 17s - loss: 6.3970 - acc: 0.59 - ETA: 17s - loss: 6.3969 - acc: 0.59 - ETA: 16s - loss: 6.3969 - acc: 0.59 - ETA: 16s - loss: 6.3971 - acc: 0.59 - ETA: 16s - loss: 6.3974 - acc: 0.59 - ETA: 16s - loss: 6.3977 - acc: 0.59 - ETA: 16s - loss: 6.3978 - acc: 0.59 - ETA: 16s - loss: 6.3977 - acc: 0.59 - ETA: 16s - loss: 6.3977 - acc: 0.59 - ETA: 16s - loss: 6.3977 - acc: 0.59 - ETA: 16s - loss: 6.3975 - acc: 0.59 - ETA: 16s - loss: 6.3974 - acc: 0.59 - ETA: 16s - loss: 6.3970 - acc: 0.59 - ETA: 15s - loss: 6.3969 - acc: 0.59 - ETA: 15s - loss: 6.3971 - acc: 0.59 - ETA: 15s - loss: 6.3969 - acc: 0.59 - ETA: 15s - loss: 6.3969 - acc: 0.59 - ETA: 15s - loss: 6.3966 - acc: 0.59 - ETA: 15s - loss: 6.3966 - acc: 0.59 - ETA: 15s - loss: 6.3970 - acc: 0.59 - ETA: 15s - loss: 6.3969 - acc: 0.59 - ETA: 15s - loss: 6.3971 - acc: 0.59 - ETA: 15s - loss: 6.3969 - acc: 0.59 - ETA: 15s - loss: 6.3973 - acc: 0.59 - ETA: 15s - loss: 6.3971 - acc: 0.59 - ETA: 15s - loss: 6.3971 - acc: 0.59 - ETA: 15s - loss: 6.3970 - acc: 0.59 - ETA: 15s - loss: 6.3969 - acc: 0.59 - ETA: 15s - loss: 6.3970 - acc: 0.59 - ETA: 14s - loss: 6.3966 - acc: 0.59 - ETA: 14s - loss: 6.3965 - acc: 0.59 - ETA: 14s - loss: 6.3965 - acc: 0.59 - ETA: 14s - loss: 6.3964 - acc: 0.59 - ETA: 14s - loss: 6.3964 - acc: 0.59 - ETA: 14s - loss: 6.3963 - acc: 0.59 - ETA: 14s - loss: 6.3963 - acc: 0.59 - ETA: 14s - loss: 6.3962 - acc: 0.59 - ETA: 14s - loss: 6.3964 - acc: 0.59 - ETA: 14s - loss: 6.3962 - acc: 0.59 - ETA: 14s - loss: 6.3961 - acc: 0.59 - ETA: 14s - loss: 6.3961 - acc: 0.59 - ETA: 14s - loss: 6.3963 - acc: 0.59 - ETA: 13s - loss: 6.3963 - acc: 0.59 - ETA: 13s - loss: 6.3964 - acc: 0.59 - ETA: 13s - loss: 6.3965 - acc: 0.59 - ETA: 13s - loss: 6.3964 - acc: 0.59 - ETA: 13s - loss: 6.3966 - acc: 0.59 - ETA: 13s - loss: 6.3965 - acc: 0.59 - ETA: 13s - loss: 6.3965 - acc: 0.59 - ETA: 13s - loss: 6.3967 - acc: 0.59 - ETA: 13s - loss: 6.3964 - acc: 0.59 - ETA: 12s - loss: 6.3964 - acc: 0.59 - ETA: 12s - loss: 6.3965 - acc: 0.59 - ETA: 12s - loss: 6.3965 - acc: 0.59 - ETA: 12s - loss: 6.3965 - acc: 0.59 - ETA: 12s - loss: 6.3961 - acc: 0.59 - ETA: 12s - loss: 6.3962 - acc: 0.59 - ETA: 12s - loss: 6.3963 - acc: 0.59 - ETA: 12s - loss: 6.3962 - acc: 0.59 - ETA: 12s - loss: 6.3962 - acc: 0.59 - ETA: 12s - loss: 6.3963 - acc: 0.59 - ETA: 12s - loss: 6.3964 - acc: 0.59 - ETA: 12s - loss: 6.3964 - acc: 0.59 - ETA: 11s - loss: 6.3966 - acc: 0.59 - ETA: 11s - loss: 6.3966 - acc: 0.59 - ETA: 11s - loss: 6.3969 - acc: 0.59 - ETA: 11s - loss: 6.3969 - acc: 0.59 - ETA: 11s - loss: 6.3968 - acc: 0.59 - ETA: 11s - loss: 6.3969 - acc: 0.59 - ETA: 11s - loss: 6.3968 - acc: 0.59 - ETA: 11s - loss: 6.3969 - acc: 0.59 - ETA: 11s - loss: 6.3971 - acc: 0.59 - ETA: 11s - loss: 6.3972 - acc: 0.59 - ETA: 11s - loss: 6.3974 - acc: 0.59 - ETA: 11s - loss: 6.3976 - acc: 0.59 - ETA: 11s - loss: 6.3980 - acc: 0.59 - ETA: 11s - loss: 6.3980 - acc: 0.59 - ETA: 10s - loss: 6.3981 - acc: 0.59 - ETA: 10s - loss: 6.3978 - acc: 0.59 - ETA: 10s - loss: 6.3979 - acc: 0.59 - ETA: 10s - loss: 6.3980 - acc: 0.59 - ETA: 10s - loss: 6.3980 - acc: 0.59 - ETA: 10s - loss: 6.3984 - acc: 0.59 - ETA: 10s - loss: 6.3984 - acc: 0.59 - ETA: 10s - loss: 6.3984 - acc: 0.59 - ETA: 10s - loss: 6.3984 - acc: 0.59 - ETA: 10s - loss: 6.3984 - acc: 0.59 - ETA: 10s - loss: 6.3984 - acc: 0.59 - ETA: 10s - loss: 6.3985 - acc: 0.59 - ETA: 9s - loss: 6.3987 - acc: 0.5986 - ETA: 9s - loss: 6.3987 - acc: 0.598 - ETA: 9s - loss: 6.3988 - acc: 0.598 - ETA: 9s - loss: 6.3986 - acc: 0.598 - ETA: 9s - loss: 6.3986 - acc: 0.598 - ETA: 9s - loss: 6.3987 - acc: 0.598 - ETA: 9s - loss: 6.3989 - acc: 0.598 - ETA: 9s - loss: 6.3990 - acc: 0.598 - ETA: 9s - loss: 6.3991 - acc: 0.598 - ETA: 9s - loss: 6.3990 - acc: 0.598 - ETA: 9s - loss: 6.3989 - acc: 0.598 - ETA: 8s - loss: 6.3988 - acc: 0.598 - ETA: 8s - loss: 6.3988 - acc: 0.598 - ETA: 8s - loss: 6.3988 - acc: 0.598 - ETA: 8s - loss: 6.3990 - acc: 0.598 - ETA: 8s - loss: 6.3991 - acc: 0.598 - ETA: 8s - loss: 6.3990 - acc: 0.598 - ETA: 8s - loss: 6.3991 - acc: 0.598 - ETA: 8s - loss: 6.3990 - acc: 0.598 - ETA: 8s - loss: 6.3990 - acc: 0.598 - ETA: 8s - loss: 6.3988 - acc: 0.598 - ETA: 7s - loss: 6.3988 - acc: 0.598 - ETA: 7s - loss: 6.3988 - acc: 0.598 - ETA: 7s - loss: 6.3986 - acc: 0.598 - ETA: 7s - loss: 6.3985 - acc: 0.598 - ETA: 7s - loss: 6.3988 - acc: 0.598 - ETA: 7s - loss: 6.3987 - acc: 0.598 - ETA: 7s - loss: 6.3987 - acc: 0.598 - ETA: 7s - loss: 6.3986 - acc: 0.598 - ETA: 7s - loss: 6.3988 - acc: 0.598 - ETA: 7s - loss: 6.3987 - acc: 0.598 - ETA: 7s - loss: 6.3986 - acc: 0.598 - ETA: 7s - loss: 6.3983 - acc: 0.598 - ETA: 7s - loss: 6.3981 - acc: 0.598 - ETA: 7s - loss: 6.3982 - acc: 0.598 - ETA: 6s - loss: 6.3985 - acc: 0.598 - ETA: 6s - loss: 6.3984 - acc: 0.598 - ETA: 6s - loss: 6.3987 - acc: 0.598 - ETA: 6s - loss: 6.3983 - acc: 0.598 - ETA: 6s - loss: 6.3981 - acc: 0.598 - ETA: 6s - loss: 6.3980 - acc: 0.598 - ETA: 6s - loss: 6.3981 - acc: 0.598 - ETA: 6s - loss: 6.3979 - acc: 0.598 - ETA: 6s - loss: 6.3980 - acc: 0.598 - ETA: 6s - loss: 6.3983 - acc: 0.598 - ETA: 6s - loss: 6.3985 - acc: 0.598 - ETA: 6s - loss: 6.3984 - acc: 0.598 - ETA: 5s - loss: 6.3984 - acc: 0.598 - ETA: 5s - loss: 6.3984 - acc: 0.598 - ETA: 5s - loss: 6.3984 - acc: 0.598 - ETA: 5s - loss: 6.3982 - acc: 0.598 - ETA: 5s - loss: 6.3983 - acc: 0.598 - ETA: 5s - loss: 6.3983 - acc: 0.598 - ETA: 5s - loss: 6.3983 - acc: 0.598 - ETA: 5s - loss: 6.3983 - acc: 0.598 - ETA: 5s - loss: 6.3985 - acc: 0.598 - ETA: 4s - loss: 6.3986 - acc: 0.598 - ETA: 4s - loss: 6.3986 - acc: 0.598 - ETA: 4s - loss: 6.3984 - acc: 0.598 - ETA: 4s - loss: 6.3983 - acc: 0.598 - ETA: 4s - loss: 6.3984 - acc: 0.598 - ETA: 4s - loss: 6.3981 - acc: 0.598 - ETA: 4s - loss: 6.3981 - acc: 0.598 - ETA: 4s - loss: 6.3980 - acc: 0.598 - ETA: 4s - loss: 6.3982 - acc: 0.598 - ETA: 4s - loss: 6.3983 - acc: 0.598 - ETA: 4s - loss: 6.3983 - acc: 0.5987"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969231/969231 [==============================] - ETA: 4s - loss: 6.3984 - acc: 0.598 - ETA: 3s - loss: 6.3985 - acc: 0.598 - ETA: 3s - loss: 6.3986 - acc: 0.598 - ETA: 3s - loss: 6.3988 - acc: 0.598 - ETA: 3s - loss: 6.3984 - acc: 0.598 - ETA: 3s - loss: 6.3986 - acc: 0.598 - ETA: 3s - loss: 6.3984 - acc: 0.598 - ETA: 3s - loss: 6.3985 - acc: 0.598 - ETA: 3s - loss: 6.3987 - acc: 0.598 - ETA: 3s - loss: 6.3989 - acc: 0.598 - ETA: 3s - loss: 6.3989 - acc: 0.598 - ETA: 3s - loss: 6.3986 - acc: 0.598 - ETA: 3s - loss: 6.3987 - acc: 0.598 - ETA: 2s - loss: 6.3986 - acc: 0.598 - ETA: 2s - loss: 6.3985 - acc: 0.598 - ETA: 2s - loss: 6.3985 - acc: 0.598 - ETA: 2s - loss: 6.3984 - acc: 0.598 - ETA: 2s - loss: 6.3983 - acc: 0.598 - ETA: 2s - loss: 6.3985 - acc: 0.598 - ETA: 2s - loss: 6.3986 - acc: 0.598 - ETA: 2s - loss: 6.3983 - acc: 0.598 - ETA: 2s - loss: 6.3982 - acc: 0.598 - ETA: 2s - loss: 6.3982 - acc: 0.598 - ETA: 2s - loss: 6.3981 - acc: 0.598 - ETA: 2s - loss: 6.3981 - acc: 0.598 - ETA: 1s - loss: 6.3984 - acc: 0.598 - ETA: 1s - loss: 6.3984 - acc: 0.598 - ETA: 1s - loss: 6.3985 - acc: 0.598 - ETA: 1s - loss: 6.3986 - acc: 0.598 - ETA: 1s - loss: 6.3985 - acc: 0.598 - ETA: 1s - loss: 6.3983 - acc: 0.598 - ETA: 1s - loss: 6.3984 - acc: 0.598 - ETA: 1s - loss: 6.3983 - acc: 0.598 - ETA: 1s - loss: 6.3982 - acc: 0.598 - ETA: 1s - loss: 6.3981 - acc: 0.598 - ETA: 1s - loss: 6.3980 - acc: 0.598 - ETA: 1s - loss: 6.3979 - acc: 0.598 - ETA: 0s - loss: 6.3978 - acc: 0.598 - ETA: 0s - loss: 6.3977 - acc: 0.598 - ETA: 0s - loss: 6.3979 - acc: 0.598 - ETA: 0s - loss: 6.3981 - acc: 0.598 - ETA: 0s - loss: 6.3980 - acc: 0.598 - ETA: 0s - loss: 6.3980 - acc: 0.598 - ETA: 0s - loss: 6.3978 - acc: 0.598 - ETA: 0s - loss: 6.3975 - acc: 0.598 - ETA: 0s - loss: 6.3973 - acc: 0.598 - ETA: 0s - loss: 6.3971 - acc: 0.598 - ETA: 0s - loss: 6.3972 - acc: 0.598 - ETA: 0s - loss: 6.3971 - acc: 0.598 - ETA: 0s - loss: 6.3976 - acc: 0.598 - ETA: 0s - loss: 6.3977 - acc: 0.598 - ETA: 0s - loss: 6.3978 - acc: 0.598 - 208s 214us/step - loss: 6.3979 - acc: 0.5987 - val_loss: 6.3979 - val_acc: 0.5987\n",
      "Epoch 2/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 56448/969231 [>.............................] - ETA: 10:35 - loss: 7.8466 - acc: 0.50 - ETA: 4:32 - loss: 6.4766 - acc: 0.5938 - ETA: 3:31 - loss: 6.5300 - acc: 0.590 - ETA: 3:52 - loss: 6.6323 - acc: 0.584 - ETA: 4:10 - loss: 6.5319 - acc: 0.590 - ETA: 4:49 - loss: 6.5887 - acc: 0.586 - ETA: 3:56 - loss: 6.5834 - acc: 0.587 - ETA: 3:39 - loss: 6.6744 - acc: 0.581 - ETA: 3:30 - loss: 6.6136 - acc: 0.585 - ETA: 3:29 - loss: 6.6125 - acc: 0.585 - ETA: 3:37 - loss: 6.6391 - acc: 0.583 - ETA: 3:27 - loss: 6.6299 - acc: 0.584 - ETA: 3:30 - loss: 6.6234 - acc: 0.584 - ETA: 3:38 - loss: 6.5754 - acc: 0.587 - ETA: 3:38 - loss: 6.5288 - acc: 0.590 - ETA: 3:49 - loss: 6.5194 - acc: 0.591 - ETA: 3:40 - loss: 6.5086 - acc: 0.591 - ETA: 3:40 - loss: 6.4968 - acc: 0.592 - ETA: 3:31 - loss: 6.4948 - acc: 0.592 - ETA: 3:23 - loss: 6.4849 - acc: 0.593 - ETA: 3:14 - loss: 6.4613 - acc: 0.594 - ETA: 3:16 - loss: 6.4546 - acc: 0.595 - ETA: 3:25 - loss: 6.4479 - acc: 0.595 - ETA: 3:34 - loss: 6.4531 - acc: 0.595 - ETA: 3:45 - loss: 6.4743 - acc: 0.593 - ETA: 4:02 - loss: 6.4675 - acc: 0.594 - ETA: 4:06 - loss: 6.4588 - acc: 0.594 - ETA: 4:10 - loss: 6.4591 - acc: 0.594 - ETA: 4:16 - loss: 6.4637 - acc: 0.594 - ETA: 4:18 - loss: 6.4724 - acc: 0.594 - ETA: 4:21 - loss: 6.4643 - acc: 0.594 - ETA: 4:21 - loss: 6.5102 - acc: 0.591 - ETA: 4:25 - loss: 6.5155 - acc: 0.591 - ETA: 4:27 - loss: 6.4996 - acc: 0.592 - ETA: 4:26 - loss: 6.4933 - acc: 0.592 - ETA: 4:20 - loss: 6.5104 - acc: 0.591 - ETA: 4:24 - loss: 6.4906 - acc: 0.592 - ETA: 4:27 - loss: 6.4954 - acc: 0.592 - ETA: 4:29 - loss: 6.4800 - acc: 0.593 - ETA: 4:22 - loss: 6.4830 - acc: 0.593 - ETA: 4:23 - loss: 6.4797 - acc: 0.593 - ETA: 4:16 - loss: 6.4661 - acc: 0.594 - ETA: 4:18 - loss: 6.4499 - acc: 0.595 - ETA: 4:17 - loss: 6.4476 - acc: 0.595 - ETA: 4:15 - loss: 6.4384 - acc: 0.596 - ETA: 4:17 - loss: 6.4416 - acc: 0.595 - ETA: 4:16 - loss: 6.4547 - acc: 0.595 - ETA: 4:17 - loss: 6.4404 - acc: 0.596 - ETA: 4:18 - loss: 6.4448 - acc: 0.595 - ETA: 4:22 - loss: 6.4464 - acc: 0.595 - ETA: 4:26 - loss: 6.4390 - acc: 0.596 - ETA: 4:24 - loss: 6.4270 - acc: 0.596 - ETA: 4:27 - loss: 6.4275 - acc: 0.596 - ETA: 4:28 - loss: 6.4305 - acc: 0.596 - ETA: 4:30 - loss: 6.4310 - acc: 0.596 - ETA: 4:30 - loss: 6.4246 - acc: 0.597 - ETA: 4:33 - loss: 6.4179 - acc: 0.597 - ETA: 4:36 - loss: 6.4280 - acc: 0.596 - ETA: 4:37 - loss: 6.4261 - acc: 0.596 - ETA: 4:39 - loss: 6.4312 - acc: 0.596 - ETA: 4:35 - loss: 6.4347 - acc: 0.596 - ETA: 4:33 - loss: 6.4354 - acc: 0.596 - ETA: 4:39 - loss: 6.4226 - acc: 0.597 - ETA: 4:43 - loss: 6.4187 - acc: 0.597 - ETA: 4:34 - loss: 6.4211 - acc: 0.597 - ETA: 4:33 - loss: 6.4179 - acc: 0.597 - ETA: 4:34 - loss: 6.4102 - acc: 0.597 - ETA: 4:35 - loss: 6.4118 - acc: 0.597 - ETA: 4:33 - loss: 6.4133 - acc: 0.597 - ETA: 4:36 - loss: 6.4099 - acc: 0.597 - ETA: 4:36 - loss: 6.4158 - acc: 0.597 - ETA: 4:35 - loss: 6.4253 - acc: 0.597 - ETA: 4:29 - loss: 6.4277 - acc: 0.596 - ETA: 4:29 - loss: 6.4175 - acc: 0.597 - ETA: 4:29 - loss: 6.4121 - acc: 0.597 - ETA: 4:26 - loss: 6.4187 - acc: 0.597 - ETA: 4:25 - loss: 6.4221 - acc: 0.597 - ETA: 4:22 - loss: 6.4249 - acc: 0.597 - ETA: 4:20 - loss: 6.4193 - acc: 0.597 - ETA: 4:19 - loss: 6.4201 - acc: 0.597 - ETA: 4:19 - loss: 6.4143 - acc: 0.597 - ETA: 4:19 - loss: 6.4231 - acc: 0.597 - ETA: 4:22 - loss: 6.4258 - acc: 0.596 - ETA: 4:25 - loss: 6.4246 - acc: 0.597 - ETA: 4:22 - loss: 6.4070 - acc: 0.598 - ETA: 4:21 - loss: 6.4109 - acc: 0.597 - ETA: 4:21 - loss: 6.4147 - acc: 0.597 - ETA: 4:22 - loss: 6.4192 - acc: 0.597 - ETA: 4:24 - loss: 6.4202 - acc: 0.597 - ETA: 4:26 - loss: 6.4191 - acc: 0.597 - ETA: 4:28 - loss: 6.4268 - acc: 0.596 - ETA: 4:27 - loss: 6.4201 - acc: 0.597 - ETA: 4:23 - loss: 6.4171 - acc: 0.597 - ETA: 4:23 - loss: 6.4206 - acc: 0.597 - ETA: 4:17 - loss: 6.4089 - acc: 0.598 - ETA: 4:15 - loss: 6.4067 - acc: 0.598 - ETA: 4:13 - loss: 6.4117 - acc: 0.597 - ETA: 4:11 - loss: 6.4140 - acc: 0.597 - ETA: 4:09 - loss: 6.4099 - acc: 0.597 - ETA: 4:07 - loss: 6.4121 - acc: 0.597 - ETA: 4:07 - loss: 6.4097 - acc: 0.597 - ETA: 4:07 - loss: 6.4238 - acc: 0.597 - ETA: 4:04 - loss: 6.4261 - acc: 0.596 - ETA: 4:04 - loss: 6.4259 - acc: 0.596 - ETA: 4:02 - loss: 6.4314 - acc: 0.596 - ETA: 4:01 - loss: 6.4360 - acc: 0.596 - ETA: 3:58 - loss: 6.4413 - acc: 0.596 - ETA: 3:57 - loss: 6.4281 - acc: 0.596 - ETA: 3:56 - loss: 6.4316 - acc: 0.596 - ETA: 3:53 - loss: 6.4389 - acc: 0.596 - ETA: 3:53 - loss: 6.4365 - acc: 0.596 - ETA: 3:51 - loss: 6.4367 - acc: 0.596 - ETA: 3:50 - loss: 6.4340 - acc: 0.596 - ETA: 3:50 - loss: 6.4240 - acc: 0.597 - ETA: 3:50 - loss: 6.4249 - acc: 0.597 - ETA: 3:49 - loss: 6.4305 - acc: 0.596 - ETA: 3:47 - loss: 6.4319 - acc: 0.596 - ETA: 3:43 - loss: 6.4207 - acc: 0.597 - ETA: 3:42 - loss: 6.4310 - acc: 0.596 - ETA: 3:41 - loss: 6.4237 - acc: 0.597 - ETA: 3:40 - loss: 6.4205 - acc: 0.597 - ETA: 3:38 - loss: 6.4201 - acc: 0.597 - ETA: 3:36 - loss: 6.4136 - acc: 0.597 - ETA: 3:34 - loss: 6.4233 - acc: 0.597 - ETA: 3:34 - loss: 6.4188 - acc: 0.597 - ETA: 3:33 - loss: 6.4170 - acc: 0.597 - ETA: 3:33 - loss: 6.4156 - acc: 0.597 - ETA: 3:33 - loss: 6.4102 - acc: 0.597 - ETA: 3:32 - loss: 6.4113 - acc: 0.597 - ETA: 3:32 - loss: 6.4126 - acc: 0.597 - ETA: 3:32 - loss: 6.4105 - acc: 0.597 - ETA: 3:32 - loss: 6.4090 - acc: 0.598 - ETA: 3:32 - loss: 6.4080 - acc: 0.598 - ETA: 3:31 - loss: 6.4079 - acc: 0.598 - ETA: 3:30 - loss: 6.4024 - acc: 0.598 - ETA: 3:29 - loss: 6.4104 - acc: 0.597 - ETA: 3:28 - loss: 6.4070 - acc: 0.598 - ETA: 3:28 - loss: 6.4101 - acc: 0.597 - ETA: 3:26 - loss: 6.4114 - acc: 0.597 - ETA: 3:25 - loss: 6.4147 - acc: 0.597 - ETA: 3:25 - loss: 6.4122 - acc: 0.597 - ETA: 3:25 - loss: 6.4118 - acc: 0.597 - ETA: 3:24 - loss: 6.4147 - acc: 0.597 - ETA: 3:25 - loss: 6.4168 - acc: 0.597 - ETA: 3:24 - loss: 6.4143 - acc: 0.597 - ETA: 3:24 - loss: 6.4037 - acc: 0.598 - ETA: 3:24 - loss: 6.3965 - acc: 0.598 - ETA: 3:24 - loss: 6.3937 - acc: 0.599 - ETA: 3:23 - loss: 6.3897 - acc: 0.599 - ETA: 3:23 - loss: 6.3851 - acc: 0.599 - ETA: 3:23 - loss: 6.3878 - acc: 0.599 - ETA: 3:22 - loss: 6.3882 - acc: 0.599 - ETA: 3:22 - loss: 6.3925 - acc: 0.599 - ETA: 3:21 - loss: 6.3937 - acc: 0.599 - ETA: 3:21 - loss: 6.3948 - acc: 0.598 - ETA: 3:21 - loss: 6.3957 - acc: 0.598 - ETA: 3:21 - loss: 6.3978 - acc: 0.598 - ETA: 3:21 - loss: 6.3969 - acc: 0.598 - ETA: 3:21 - loss: 6.3963 - acc: 0.598 - ETA: 3:21 - loss: 6.3963 - acc: 0.598 - ETA: 3:21 - loss: 6.3927 - acc: 0.599 - ETA: 3:21 - loss: 6.3939 - acc: 0.598 - ETA: 3:22 - loss: 6.3948 - acc: 0.598 - ETA: 3:21 - loss: 6.3889 - acc: 0.599 - ETA: 3:21 - loss: 6.3936 - acc: 0.599 - ETA: 3:21 - loss: 6.3930 - acc: 0.599 - ETA: 3:21 - loss: 6.3898 - acc: 0.599 - ETA: 3:21 - loss: 6.3913 - acc: 0.599 - ETA: 3:21 - loss: 6.3891 - acc: 0.599 - ETA: 3:22 - loss: 6.3919 - acc: 0.599 - ETA: 3:22 - loss: 6.3946 - acc: 0.598 - ETA: 3:21 - loss: 6.3941 - acc: 0.598 - ETA: 3:21 - loss: 6.3929 - acc: 0.599 - ETA: 3:21 - loss: 6.3921 - acc: 0.599 - ETA: 3:21 - loss: 6.3900 - acc: 0.599 - ETA: 3:22 - loss: 6.3899 - acc: 0.599 - ETA: 3:22 - loss: 6.3887 - acc: 0.599 - ETA: 3:23 - loss: 6.3915 - acc: 0.599 - ETA: 3:23 - loss: 6.3923 - acc: 0.599 - ETA: 3:23 - loss: 6.3917 - acc: 0.599 - ETA: 3:23 - loss: 6.3946 - acc: 0.598 - ETA: 3:24 - loss: 6.3954 - acc: 0.598 - ETA: 3:25 - loss: 6.3944 - acc: 0.598 - ETA: 3:25 - loss: 6.3920 - acc: 0.599 - ETA: 3:25 - loss: 6.3932 - acc: 0.599 - ETA: 3:25 - loss: 6.3896 - acc: 0.599 - ETA: 3:25 - loss: 6.3870 - acc: 0.599 - ETA: 3:26 - loss: 6.3866 - acc: 0.599 - ETA: 3:27 - loss: 6.3878 - acc: 0.599 - ETA: 3:28 - loss: 6.3877 - acc: 0.599 - ETA: 3:28 - loss: 6.3872 - acc: 0.599 - ETA: 3:28 - loss: 6.3912 - acc: 0.599 - ETA: 3:28 - loss: 6.3967 - acc: 0.598 - ETA: 3:28 - loss: 6.3974 - acc: 0.598 - ETA: 3:29 - loss: 6.3963 - acc: 0.598 - ETA: 3:29 - loss: 6.3961 - acc: 0.598 - ETA: 3:29 - loss: 6.3979 - acc: 0.598 - ETA: 3:29 - loss: 6.3974 - acc: 0.598 - ETA: 3:29 - loss: 6.4021 - acc: 0.598 - ETA: 3:29 - loss: 6.3976 - acc: 0.598 - ETA: 3:29 - loss: 6.3996 - acc: 0.598 - ETA: 3:30 - loss: 6.3981 - acc: 0.598 - ETA: 3:30 - loss: 6.3993 - acc: 0.598 - ETA: 3:30 - loss: 6.4001 - acc: 0.5986"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107392/969231 [==>...........................] - ETA: 3:30 - loss: 6.3987 - acc: 0.598 - ETA: 3:30 - loss: 6.4002 - acc: 0.598 - ETA: 3:30 - loss: 6.3977 - acc: 0.598 - ETA: 3:30 - loss: 6.3982 - acc: 0.598 - ETA: 3:30 - loss: 6.3925 - acc: 0.599 - ETA: 3:31 - loss: 6.3951 - acc: 0.598 - ETA: 3:31 - loss: 6.3941 - acc: 0.598 - ETA: 3:31 - loss: 6.3920 - acc: 0.599 - ETA: 3:31 - loss: 6.3904 - acc: 0.599 - ETA: 3:31 - loss: 6.3916 - acc: 0.599 - ETA: 3:31 - loss: 6.3909 - acc: 0.599 - ETA: 3:31 - loss: 6.3965 - acc: 0.598 - ETA: 3:31 - loss: 6.3982 - acc: 0.598 - ETA: 3:31 - loss: 6.3977 - acc: 0.598 - ETA: 3:31 - loss: 6.3968 - acc: 0.598 - ETA: 3:32 - loss: 6.3967 - acc: 0.598 - ETA: 3:32 - loss: 6.3974 - acc: 0.598 - ETA: 3:32 - loss: 6.3973 - acc: 0.598 - ETA: 3:32 - loss: 6.4016 - acc: 0.598 - ETA: 3:33 - loss: 6.3972 - acc: 0.598 - ETA: 3:33 - loss: 6.3958 - acc: 0.598 - ETA: 3:34 - loss: 6.3931 - acc: 0.599 - ETA: 3:34 - loss: 6.3920 - acc: 0.599 - ETA: 3:34 - loss: 6.3906 - acc: 0.599 - ETA: 3:34 - loss: 6.3930 - acc: 0.599 - ETA: 3:35 - loss: 6.3930 - acc: 0.599 - ETA: 3:35 - loss: 6.3926 - acc: 0.599 - ETA: 3:36 - loss: 6.3919 - acc: 0.599 - ETA: 3:35 - loss: 6.3940 - acc: 0.598 - ETA: 3:35 - loss: 6.3932 - acc: 0.599 - ETA: 3:35 - loss: 6.3918 - acc: 0.599 - ETA: 3:35 - loss: 6.3879 - acc: 0.599 - ETA: 3:35 - loss: 6.3885 - acc: 0.599 - ETA: 3:35 - loss: 6.3877 - acc: 0.599 - ETA: 3:35 - loss: 6.3870 - acc: 0.599 - ETA: 3:36 - loss: 6.3877 - acc: 0.599 - ETA: 3:37 - loss: 6.3891 - acc: 0.599 - ETA: 3:37 - loss: 6.3910 - acc: 0.599 - ETA: 3:37 - loss: 6.3896 - acc: 0.599 - ETA: 3:38 - loss: 6.3900 - acc: 0.599 - ETA: 3:38 - loss: 6.3906 - acc: 0.599 - ETA: 3:38 - loss: 6.3925 - acc: 0.599 - ETA: 3:39 - loss: 6.3910 - acc: 0.599 - ETA: 3:40 - loss: 6.3892 - acc: 0.599 - ETA: 3:41 - loss: 6.3898 - acc: 0.599 - ETA: 3:42 - loss: 6.3919 - acc: 0.599 - ETA: 3:43 - loss: 6.3928 - acc: 0.599 - ETA: 3:42 - loss: 6.3910 - acc: 0.599 - ETA: 3:43 - loss: 6.3904 - acc: 0.599 - ETA: 3:43 - loss: 6.3932 - acc: 0.599 - ETA: 3:43 - loss: 6.3905 - acc: 0.599 - ETA: 3:43 - loss: 6.3863 - acc: 0.599 - ETA: 3:43 - loss: 6.3874 - acc: 0.599 - ETA: 3:43 - loss: 6.3854 - acc: 0.599 - ETA: 3:44 - loss: 6.3832 - acc: 0.599 - ETA: 3:45 - loss: 6.3825 - acc: 0.599 - ETA: 3:45 - loss: 6.3859 - acc: 0.599 - ETA: 3:45 - loss: 6.3861 - acc: 0.599 - ETA: 3:45 - loss: 6.3845 - acc: 0.599 - ETA: 3:45 - loss: 6.3833 - acc: 0.599 - ETA: 3:45 - loss: 6.3842 - acc: 0.599 - ETA: 3:44 - loss: 6.3832 - acc: 0.599 - ETA: 3:45 - loss: 6.3820 - acc: 0.599 - ETA: 3:46 - loss: 6.3851 - acc: 0.599 - ETA: 3:46 - loss: 6.3841 - acc: 0.599 - ETA: 3:46 - loss: 6.3863 - acc: 0.599 - ETA: 3:46 - loss: 6.3869 - acc: 0.599 - ETA: 3:47 - loss: 6.3860 - acc: 0.599 - ETA: 3:46 - loss: 6.3874 - acc: 0.599 - ETA: 3:46 - loss: 6.3871 - acc: 0.599 - ETA: 3:46 - loss: 6.3856 - acc: 0.599 - ETA: 3:46 - loss: 6.3856 - acc: 0.599 - ETA: 3:45 - loss: 6.3864 - acc: 0.599 - ETA: 3:45 - loss: 6.3901 - acc: 0.599 - ETA: 3:45 - loss: 6.3881 - acc: 0.599 - ETA: 3:44 - loss: 6.3892 - acc: 0.599 - ETA: 3:44 - loss: 6.3890 - acc: 0.599 - ETA: 3:44 - loss: 6.3904 - acc: 0.599 - ETA: 3:43 - loss: 6.3896 - acc: 0.599 - ETA: 3:43 - loss: 6.3875 - acc: 0.599 - ETA: 3:42 - loss: 6.3886 - acc: 0.599 - ETA: 3:42 - loss: 6.3923 - acc: 0.599 - ETA: 3:42 - loss: 6.3939 - acc: 0.598 - ETA: 3:43 - loss: 6.3943 - acc: 0.598 - ETA: 3:43 - loss: 6.3965 - acc: 0.598 - ETA: 3:43 - loss: 6.3971 - acc: 0.598 - ETA: 3:44 - loss: 6.3968 - acc: 0.598 - ETA: 3:44 - loss: 6.3962 - acc: 0.598 - ETA: 3:43 - loss: 6.3924 - acc: 0.599 - ETA: 3:43 - loss: 6.3923 - acc: 0.599 - ETA: 3:43 - loss: 6.3915 - acc: 0.599 - ETA: 3:43 - loss: 6.3912 - acc: 0.599 - ETA: 3:43 - loss: 6.3936 - acc: 0.599 - ETA: 3:42 - loss: 6.3903 - acc: 0.599 - ETA: 3:42 - loss: 6.3930 - acc: 0.599 - ETA: 3:43 - loss: 6.3903 - acc: 0.599 - ETA: 3:43 - loss: 6.3902 - acc: 0.599 - ETA: 3:44 - loss: 6.3901 - acc: 0.599 - ETA: 3:44 - loss: 6.3901 - acc: 0.599 - ETA: 3:44 - loss: 6.3896 - acc: 0.599 - ETA: 3:43 - loss: 6.3892 - acc: 0.599 - ETA: 3:44 - loss: 6.3889 - acc: 0.599 - ETA: 3:44 - loss: 6.3866 - acc: 0.599 - ETA: 3:45 - loss: 6.3863 - acc: 0.599 - ETA: 3:44 - loss: 6.3865 - acc: 0.599 - ETA: 3:43 - loss: 6.3884 - acc: 0.599 - ETA: 3:44 - loss: 6.3873 - acc: 0.599 - ETA: 3:44 - loss: 6.3892 - acc: 0.599 - ETA: 3:43 - loss: 6.3895 - acc: 0.599 - ETA: 3:43 - loss: 6.3923 - acc: 0.599 - ETA: 3:43 - loss: 6.3923 - acc: 0.599 - ETA: 3:43 - loss: 6.3922 - acc: 0.599 - ETA: 3:42 - loss: 6.3934 - acc: 0.599 - ETA: 3:42 - loss: 6.3956 - acc: 0.598 - ETA: 3:43 - loss: 6.3955 - acc: 0.598 - ETA: 3:42 - loss: 6.3958 - acc: 0.598 - ETA: 3:42 - loss: 6.3969 - acc: 0.598 - ETA: 3:42 - loss: 6.3981 - acc: 0.598 - ETA: 3:42 - loss: 6.3983 - acc: 0.598 - ETA: 3:42 - loss: 6.4001 - acc: 0.598 - ETA: 3:42 - loss: 6.3981 - acc: 0.598 - ETA: 3:42 - loss: 6.3994 - acc: 0.598 - ETA: 3:42 - loss: 6.3963 - acc: 0.598 - ETA: 3:42 - loss: 6.3962 - acc: 0.598 - ETA: 3:42 - loss: 6.3984 - acc: 0.598 - ETA: 3:41 - loss: 6.3994 - acc: 0.598 - ETA: 3:41 - loss: 6.4009 - acc: 0.598 - ETA: 3:41 - loss: 6.4002 - acc: 0.598 - ETA: 3:41 - loss: 6.4031 - acc: 0.598 - ETA: 3:41 - loss: 6.4018 - acc: 0.598 - ETA: 3:41 - loss: 6.4035 - acc: 0.598 - ETA: 3:41 - loss: 6.4056 - acc: 0.598 - ETA: 3:41 - loss: 6.4045 - acc: 0.598 - ETA: 3:40 - loss: 6.4045 - acc: 0.598 - ETA: 3:40 - loss: 6.4049 - acc: 0.598 - ETA: 3:40 - loss: 6.4042 - acc: 0.598 - ETA: 3:39 - loss: 6.4046 - acc: 0.598 - ETA: 3:39 - loss: 6.4062 - acc: 0.598 - ETA: 3:39 - loss: 6.4041 - acc: 0.598 - ETA: 3:39 - loss: 6.4028 - acc: 0.598 - ETA: 3:38 - loss: 6.4054 - acc: 0.598 - ETA: 3:38 - loss: 6.4070 - acc: 0.598 - ETA: 3:38 - loss: 6.4062 - acc: 0.598 - ETA: 3:38 - loss: 6.4064 - acc: 0.598 - ETA: 3:38 - loss: 6.4068 - acc: 0.598 - ETA: 3:38 - loss: 6.4077 - acc: 0.598 - ETA: 3:37 - loss: 6.4084 - acc: 0.598 - ETA: 3:37 - loss: 6.4088 - acc: 0.598 - ETA: 3:37 - loss: 6.4084 - acc: 0.598 - ETA: 3:37 - loss: 6.4070 - acc: 0.598 - ETA: 3:36 - loss: 6.4077 - acc: 0.598 - ETA: 3:37 - loss: 6.4080 - acc: 0.598 - ETA: 3:36 - loss: 6.4107 - acc: 0.597 - ETA: 3:35 - loss: 6.4101 - acc: 0.597 - ETA: 3:35 - loss: 6.4108 - acc: 0.597 - ETA: 3:34 - loss: 6.4109 - acc: 0.597 - ETA: 3:35 - loss: 6.4093 - acc: 0.598 - ETA: 3:34 - loss: 6.4095 - acc: 0.598 - ETA: 3:34 - loss: 6.4103 - acc: 0.597 - ETA: 3:35 - loss: 6.4107 - acc: 0.597 - ETA: 3:35 - loss: 6.4119 - acc: 0.597 - ETA: 3:34 - loss: 6.4137 - acc: 0.597 - ETA: 3:34 - loss: 6.4132 - acc: 0.597 - ETA: 3:35 - loss: 6.4137 - acc: 0.597 - ETA: 3:35 - loss: 6.4130 - acc: 0.597 - ETA: 3:35 - loss: 6.4109 - acc: 0.597 - ETA: 3:34 - loss: 6.4149 - acc: 0.597 - ETA: 3:34 - loss: 6.4164 - acc: 0.597 - ETA: 3:34 - loss: 6.4186 - acc: 0.597 - ETA: 3:33 - loss: 6.4202 - acc: 0.597 - ETA: 3:33 - loss: 6.4175 - acc: 0.597 - ETA: 3:32 - loss: 6.4166 - acc: 0.597 - ETA: 3:32 - loss: 6.4159 - acc: 0.597 - ETA: 3:32 - loss: 6.4140 - acc: 0.597 - ETA: 3:32 - loss: 6.4134 - acc: 0.597 - ETA: 3:31 - loss: 6.4130 - acc: 0.597 - ETA: 3:31 - loss: 6.4130 - acc: 0.597 - ETA: 3:31 - loss: 6.4149 - acc: 0.597 - ETA: 3:31 - loss: 6.4115 - acc: 0.597 - ETA: 3:31 - loss: 6.4099 - acc: 0.597 - ETA: 3:31 - loss: 6.4092 - acc: 0.598 - ETA: 3:31 - loss: 6.4088 - acc: 0.598 - ETA: 3:30 - loss: 6.4086 - acc: 0.598 - ETA: 3:30 - loss: 6.4089 - acc: 0.598 - ETA: 3:30 - loss: 6.4076 - acc: 0.598 - ETA: 3:30 - loss: 6.4069 - acc: 0.598 - ETA: 3:30 - loss: 6.4062 - acc: 0.598 - ETA: 3:30 - loss: 6.4056 - acc: 0.598 - ETA: 3:30 - loss: 6.4063 - acc: 0.598 - ETA: 3:31 - loss: 6.4053 - acc: 0.598 - ETA: 3:31 - loss: 6.4055 - acc: 0.598 - ETA: 3:31 - loss: 6.4047 - acc: 0.598 - ETA: 3:31 - loss: 6.4070 - acc: 0.598 - ETA: 3:31 - loss: 6.4065 - acc: 0.598 - ETA: 3:31 - loss: 6.4080 - acc: 0.598 - ETA: 3:31 - loss: 6.4073 - acc: 0.598 - ETA: 3:31 - loss: 6.4073 - acc: 0.598 - ETA: 3:31 - loss: 6.4066 - acc: 0.598 - ETA: 3:31 - loss: 6.4068 - acc: 0.598 - ETA: 3:31 - loss: 6.4085 - acc: 0.598 - ETA: 3:31 - loss: 6.4097 - acc: 0.597 - ETA: 3:31 - loss: 6.4088 - acc: 0.598 - ETA: 3:31 - loss: 6.4096 - acc: 0.598 - ETA: 3:30 - loss: 6.4105 - acc: 0.5979"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160896/969231 [===>..........................] - ETA: 3:30 - loss: 6.4100 - acc: 0.597 - ETA: 3:30 - loss: 6.4097 - acc: 0.597 - ETA: 3:30 - loss: 6.4084 - acc: 0.598 - ETA: 3:30 - loss: 6.4086 - acc: 0.598 - ETA: 3:30 - loss: 6.4094 - acc: 0.598 - ETA: 3:30 - loss: 6.4091 - acc: 0.598 - ETA: 3:30 - loss: 6.4092 - acc: 0.598 - ETA: 3:30 - loss: 6.4101 - acc: 0.597 - ETA: 3:30 - loss: 6.4085 - acc: 0.598 - ETA: 3:30 - loss: 6.4073 - acc: 0.598 - ETA: 3:30 - loss: 6.4054 - acc: 0.598 - ETA: 3:29 - loss: 6.4039 - acc: 0.598 - ETA: 3:29 - loss: 6.4053 - acc: 0.598 - ETA: 3:29 - loss: 6.4062 - acc: 0.598 - ETA: 3:29 - loss: 6.4069 - acc: 0.598 - ETA: 3:29 - loss: 6.4062 - acc: 0.598 - ETA: 3:29 - loss: 6.4063 - acc: 0.598 - ETA: 3:29 - loss: 6.4067 - acc: 0.598 - ETA: 3:29 - loss: 6.4088 - acc: 0.598 - ETA: 3:29 - loss: 6.4083 - acc: 0.598 - ETA: 3:29 - loss: 6.4085 - acc: 0.598 - ETA: 3:29 - loss: 6.4086 - acc: 0.598 - ETA: 3:29 - loss: 6.4093 - acc: 0.598 - ETA: 3:29 - loss: 6.4082 - acc: 0.598 - ETA: 3:29 - loss: 6.4072 - acc: 0.598 - ETA: 3:29 - loss: 6.4071 - acc: 0.598 - ETA: 3:29 - loss: 6.4078 - acc: 0.598 - ETA: 3:29 - loss: 6.4082 - acc: 0.598 - ETA: 3:29 - loss: 6.4086 - acc: 0.598 - ETA: 3:29 - loss: 6.4103 - acc: 0.597 - ETA: 3:29 - loss: 6.4100 - acc: 0.597 - ETA: 3:28 - loss: 6.4111 - acc: 0.597 - ETA: 3:28 - loss: 6.4096 - acc: 0.598 - ETA: 3:28 - loss: 6.4101 - acc: 0.597 - ETA: 3:28 - loss: 6.4114 - acc: 0.597 - ETA: 3:28 - loss: 6.4119 - acc: 0.597 - ETA: 3:28 - loss: 6.4123 - acc: 0.597 - ETA: 3:27 - loss: 6.4124 - acc: 0.597 - ETA: 3:27 - loss: 6.4143 - acc: 0.597 - ETA: 3:27 - loss: 6.4145 - acc: 0.597 - ETA: 3:27 - loss: 6.4141 - acc: 0.597 - ETA: 3:27 - loss: 6.4134 - acc: 0.597 - ETA: 3:27 - loss: 6.4133 - acc: 0.597 - ETA: 3:27 - loss: 6.4134 - acc: 0.597 - ETA: 3:27 - loss: 6.4157 - acc: 0.597 - ETA: 3:27 - loss: 6.4155 - acc: 0.597 - ETA: 3:27 - loss: 6.4149 - acc: 0.597 - ETA: 3:27 - loss: 6.4137 - acc: 0.597 - ETA: 3:28 - loss: 6.4141 - acc: 0.597 - ETA: 3:28 - loss: 6.4131 - acc: 0.597 - ETA: 3:27 - loss: 6.4121 - acc: 0.597 - ETA: 3:27 - loss: 6.4121 - acc: 0.597 - ETA: 3:27 - loss: 6.4123 - acc: 0.597 - ETA: 3:27 - loss: 6.4129 - acc: 0.597 - ETA: 3:27 - loss: 6.4121 - acc: 0.597 - ETA: 3:27 - loss: 6.4117 - acc: 0.597 - ETA: 3:27 - loss: 6.4100 - acc: 0.597 - ETA: 3:27 - loss: 6.4092 - acc: 0.598 - ETA: 3:27 - loss: 6.4078 - acc: 0.598 - ETA: 3:27 - loss: 6.4063 - acc: 0.598 - ETA: 3:27 - loss: 6.4075 - acc: 0.598 - ETA: 3:26 - loss: 6.4096 - acc: 0.598 - ETA: 3:26 - loss: 6.4093 - acc: 0.598 - ETA: 3:26 - loss: 6.4105 - acc: 0.597 - ETA: 3:26 - loss: 6.4095 - acc: 0.598 - ETA: 3:25 - loss: 6.4099 - acc: 0.597 - ETA: 3:25 - loss: 6.4096 - acc: 0.598 - ETA: 3:25 - loss: 6.4084 - acc: 0.598 - ETA: 3:25 - loss: 6.4084 - acc: 0.598 - ETA: 3:25 - loss: 6.4081 - acc: 0.598 - ETA: 3:24 - loss: 6.4099 - acc: 0.597 - ETA: 3:24 - loss: 6.4117 - acc: 0.597 - ETA: 3:24 - loss: 6.4108 - acc: 0.597 - ETA: 3:23 - loss: 6.4118 - acc: 0.597 - ETA: 3:23 - loss: 6.4137 - acc: 0.597 - ETA: 3:24 - loss: 6.4136 - acc: 0.597 - ETA: 3:23 - loss: 6.4116 - acc: 0.597 - ETA: 3:23 - loss: 6.4104 - acc: 0.597 - ETA: 3:23 - loss: 6.4113 - acc: 0.597 - ETA: 3:22 - loss: 6.4117 - acc: 0.597 - ETA: 3:22 - loss: 6.4112 - acc: 0.597 - ETA: 3:22 - loss: 6.4090 - acc: 0.598 - ETA: 3:22 - loss: 6.4085 - acc: 0.598 - ETA: 3:22 - loss: 6.4092 - acc: 0.598 - ETA: 3:22 - loss: 6.4091 - acc: 0.598 - ETA: 3:22 - loss: 6.4085 - acc: 0.598 - ETA: 3:22 - loss: 6.4081 - acc: 0.598 - ETA: 3:22 - loss: 6.4091 - acc: 0.598 - ETA: 3:22 - loss: 6.4085 - acc: 0.598 - ETA: 3:22 - loss: 6.4078 - acc: 0.598 - ETA: 3:22 - loss: 6.4076 - acc: 0.598 - ETA: 3:22 - loss: 6.4073 - acc: 0.598 - ETA: 3:21 - loss: 6.4070 - acc: 0.598 - ETA: 3:21 - loss: 6.4049 - acc: 0.598 - ETA: 3:21 - loss: 6.4037 - acc: 0.598 - ETA: 3:21 - loss: 6.4032 - acc: 0.598 - ETA: 3:21 - loss: 6.4024 - acc: 0.598 - ETA: 3:21 - loss: 6.4037 - acc: 0.598 - ETA: 3:21 - loss: 6.4039 - acc: 0.598 - ETA: 3:21 - loss: 6.4047 - acc: 0.598 - ETA: 3:21 - loss: 6.4052 - acc: 0.598 - ETA: 3:21 - loss: 6.4047 - acc: 0.598 - ETA: 3:21 - loss: 6.4044 - acc: 0.598 - ETA: 3:21 - loss: 6.4056 - acc: 0.598 - ETA: 3:21 - loss: 6.4045 - acc: 0.598 - ETA: 3:21 - loss: 6.4045 - acc: 0.598 - ETA: 3:21 - loss: 6.4050 - acc: 0.598 - ETA: 3:20 - loss: 6.4052 - acc: 0.598 - ETA: 3:20 - loss: 6.4048 - acc: 0.598 - ETA: 3:20 - loss: 6.4048 - acc: 0.598 - ETA: 3:20 - loss: 6.4057 - acc: 0.598 - ETA: 3:20 - loss: 6.4060 - acc: 0.598 - ETA: 3:20 - loss: 6.4057 - acc: 0.598 - ETA: 3:20 - loss: 6.4059 - acc: 0.598 - ETA: 3:20 - loss: 6.4045 - acc: 0.598 - ETA: 3:20 - loss: 6.4045 - acc: 0.598 - ETA: 3:20 - loss: 6.4044 - acc: 0.598 - ETA: 3:19 - loss: 6.4045 - acc: 0.598 - ETA: 3:20 - loss: 6.4037 - acc: 0.598 - ETA: 3:20 - loss: 6.4047 - acc: 0.598 - ETA: 3:19 - loss: 6.4034 - acc: 0.598 - ETA: 3:19 - loss: 6.4035 - acc: 0.598 - ETA: 3:19 - loss: 6.4035 - acc: 0.598 - ETA: 3:19 - loss: 6.4030 - acc: 0.598 - ETA: 3:19 - loss: 6.4032 - acc: 0.598 - ETA: 3:19 - loss: 6.4041 - acc: 0.598 - ETA: 3:18 - loss: 6.4043 - acc: 0.598 - ETA: 3:18 - loss: 6.4036 - acc: 0.598 - ETA: 3:18 - loss: 6.4034 - acc: 0.598 - ETA: 3:17 - loss: 6.4035 - acc: 0.598 - ETA: 3:17 - loss: 6.4039 - acc: 0.598 - ETA: 3:18 - loss: 6.4040 - acc: 0.598 - ETA: 3:18 - loss: 6.4045 - acc: 0.598 - ETA: 3:17 - loss: 6.4045 - acc: 0.598 - ETA: 3:17 - loss: 6.4036 - acc: 0.598 - ETA: 3:17 - loss: 6.4046 - acc: 0.598 - ETA: 3:17 - loss: 6.4039 - acc: 0.598 - ETA: 3:17 - loss: 6.4027 - acc: 0.598 - ETA: 3:17 - loss: 6.4008 - acc: 0.598 - ETA: 3:16 - loss: 6.3996 - acc: 0.598 - ETA: 3:16 - loss: 6.3989 - acc: 0.598 - ETA: 3:16 - loss: 6.3995 - acc: 0.598 - ETA: 3:16 - loss: 6.3999 - acc: 0.598 - ETA: 3:16 - loss: 6.3999 - acc: 0.598 - ETA: 3:16 - loss: 6.3988 - acc: 0.598 - ETA: 3:16 - loss: 6.3984 - acc: 0.598 - ETA: 3:16 - loss: 6.3982 - acc: 0.598 - ETA: 3:16 - loss: 6.3977 - acc: 0.598 - ETA: 3:16 - loss: 6.3971 - acc: 0.598 - ETA: 3:16 - loss: 6.3960 - acc: 0.598 - ETA: 3:16 - loss: 6.3960 - acc: 0.598 - ETA: 3:16 - loss: 6.3953 - acc: 0.598 - ETA: 3:15 - loss: 6.3946 - acc: 0.598 - ETA: 3:15 - loss: 6.3943 - acc: 0.598 - ETA: 3:15 - loss: 6.3947 - acc: 0.598 - ETA: 3:15 - loss: 6.3949 - acc: 0.598 - ETA: 3:15 - loss: 6.3946 - acc: 0.598 - ETA: 3:15 - loss: 6.3956 - acc: 0.598 - ETA: 3:15 - loss: 6.3952 - acc: 0.598 - ETA: 3:15 - loss: 6.3937 - acc: 0.599 - ETA: 3:15 - loss: 6.3943 - acc: 0.598 - ETA: 3:15 - loss: 6.3941 - acc: 0.598 - ETA: 3:15 - loss: 6.3958 - acc: 0.598 - ETA: 3:15 - loss: 6.3954 - acc: 0.598 - ETA: 3:15 - loss: 6.3953 - acc: 0.598 - ETA: 3:14 - loss: 6.3948 - acc: 0.598 - ETA: 3:14 - loss: 6.3956 - acc: 0.598 - ETA: 3:14 - loss: 6.3954 - acc: 0.598 - ETA: 3:14 - loss: 6.3958 - acc: 0.598 - ETA: 3:14 - loss: 6.3964 - acc: 0.598 - ETA: 3:14 - loss: 6.3973 - acc: 0.598 - ETA: 3:14 - loss: 6.3974 - acc: 0.598 - ETA: 3:13 - loss: 6.3972 - acc: 0.598 - ETA: 3:13 - loss: 6.3970 - acc: 0.598 - ETA: 3:14 - loss: 6.3977 - acc: 0.598 - ETA: 3:14 - loss: 6.3984 - acc: 0.598 - ETA: 3:14 - loss: 6.3993 - acc: 0.598 - ETA: 3:13 - loss: 6.3988 - acc: 0.598 - ETA: 3:13 - loss: 6.3976 - acc: 0.598 - ETA: 3:13 - loss: 6.3973 - acc: 0.598 - ETA: 3:13 - loss: 6.3983 - acc: 0.598 - ETA: 3:13 - loss: 6.3988 - acc: 0.598 - ETA: 3:13 - loss: 6.3982 - acc: 0.598 - ETA: 3:13 - loss: 6.3985 - acc: 0.598 - ETA: 3:13 - loss: 6.3984 - acc: 0.598 - ETA: 3:13 - loss: 6.3985 - acc: 0.598 - ETA: 3:13 - loss: 6.3988 - acc: 0.598 - ETA: 3:13 - loss: 6.3987 - acc: 0.598 - ETA: 3:13 - loss: 6.3997 - acc: 0.598 - ETA: 3:13 - loss: 6.4001 - acc: 0.598 - ETA: 3:13 - loss: 6.4007 - acc: 0.598 - ETA: 3:13 - loss: 6.4008 - acc: 0.598 - ETA: 3:13 - loss: 6.4010 - acc: 0.598 - ETA: 3:13 - loss: 6.3997 - acc: 0.598 - ETA: 3:13 - loss: 6.3994 - acc: 0.598 - ETA: 3:13 - loss: 6.4002 - acc: 0.598 - ETA: 3:13 - loss: 6.4000 - acc: 0.598 - ETA: 3:13 - loss: 6.3997 - acc: 0.598 - ETA: 3:13 - loss: 6.3994 - acc: 0.598 - ETA: 3:13 - loss: 6.3990 - acc: 0.598 - ETA: 3:13 - loss: 6.3986 - acc: 0.598 - ETA: 3:13 - loss: 6.3991 - acc: 0.598 - ETA: 3:13 - loss: 6.4002 - acc: 0.598 - ETA: 3:13 - loss: 6.4011 - acc: 0.5985"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "221056/969231 [=====>........................] - ETA: 3:13 - loss: 6.4010 - acc: 0.598 - ETA: 3:13 - loss: 6.4007 - acc: 0.598 - ETA: 3:13 - loss: 6.4012 - acc: 0.598 - ETA: 3:13 - loss: 6.4012 - acc: 0.598 - ETA: 3:13 - loss: 6.4015 - acc: 0.598 - ETA: 3:13 - loss: 6.4024 - acc: 0.598 - ETA: 3:13 - loss: 6.4036 - acc: 0.598 - ETA: 3:13 - loss: 6.4037 - acc: 0.598 - ETA: 3:13 - loss: 6.4030 - acc: 0.598 - ETA: 3:13 - loss: 6.4029 - acc: 0.598 - ETA: 3:13 - loss: 6.4023 - acc: 0.598 - ETA: 3:13 - loss: 6.4019 - acc: 0.598 - ETA: 3:13 - loss: 6.4023 - acc: 0.598 - ETA: 3:13 - loss: 6.4007 - acc: 0.598 - ETA: 3:13 - loss: 6.4014 - acc: 0.598 - ETA: 3:13 - loss: 6.4011 - acc: 0.598 - ETA: 3:13 - loss: 6.4011 - acc: 0.598 - ETA: 3:13 - loss: 6.4008 - acc: 0.598 - ETA: 3:12 - loss: 6.4008 - acc: 0.598 - ETA: 3:12 - loss: 6.4009 - acc: 0.598 - ETA: 3:12 - loss: 6.4011 - acc: 0.598 - ETA: 3:12 - loss: 6.4009 - acc: 0.598 - ETA: 3:12 - loss: 6.4009 - acc: 0.598 - ETA: 3:12 - loss: 6.3999 - acc: 0.598 - ETA: 3:12 - loss: 6.4000 - acc: 0.598 - ETA: 3:12 - loss: 6.4006 - acc: 0.598 - ETA: 3:12 - loss: 6.4007 - acc: 0.598 - ETA: 3:11 - loss: 6.4020 - acc: 0.598 - ETA: 3:11 - loss: 6.4039 - acc: 0.598 - ETA: 3:11 - loss: 6.4044 - acc: 0.598 - ETA: 3:11 - loss: 6.4043 - acc: 0.598 - ETA: 3:11 - loss: 6.4040 - acc: 0.598 - ETA: 3:11 - loss: 6.4039 - acc: 0.598 - ETA: 3:11 - loss: 6.4042 - acc: 0.598 - ETA: 3:11 - loss: 6.4041 - acc: 0.598 - ETA: 3:11 - loss: 6.4048 - acc: 0.598 - ETA: 3:10 - loss: 6.4043 - acc: 0.598 - ETA: 3:10 - loss: 6.4034 - acc: 0.598 - ETA: 3:10 - loss: 6.4024 - acc: 0.598 - ETA: 3:10 - loss: 6.4020 - acc: 0.598 - ETA: 3:10 - loss: 6.4021 - acc: 0.598 - ETA: 3:10 - loss: 6.4020 - acc: 0.598 - ETA: 3:10 - loss: 6.4026 - acc: 0.598 - ETA: 3:09 - loss: 6.4035 - acc: 0.598 - ETA: 3:10 - loss: 6.4031 - acc: 0.598 - ETA: 3:10 - loss: 6.4036 - acc: 0.598 - ETA: 3:10 - loss: 6.4038 - acc: 0.598 - ETA: 3:10 - loss: 6.4032 - acc: 0.598 - ETA: 3:10 - loss: 6.4030 - acc: 0.598 - ETA: 3:10 - loss: 6.4035 - acc: 0.598 - ETA: 3:10 - loss: 6.4043 - acc: 0.598 - ETA: 3:10 - loss: 6.4035 - acc: 0.598 - ETA: 3:10 - loss: 6.4035 - acc: 0.598 - ETA: 3:10 - loss: 6.4051 - acc: 0.598 - ETA: 3:10 - loss: 6.4050 - acc: 0.598 - ETA: 3:10 - loss: 6.4055 - acc: 0.598 - ETA: 3:10 - loss: 6.4055 - acc: 0.598 - ETA: 3:10 - loss: 6.4049 - acc: 0.598 - ETA: 3:10 - loss: 6.4054 - acc: 0.598 - ETA: 3:10 - loss: 6.4046 - acc: 0.598 - ETA: 3:10 - loss: 6.4041 - acc: 0.598 - ETA: 3:09 - loss: 6.4029 - acc: 0.598 - ETA: 3:09 - loss: 6.4030 - acc: 0.598 - ETA: 3:09 - loss: 6.4040 - acc: 0.598 - ETA: 3:09 - loss: 6.4047 - acc: 0.598 - ETA: 3:09 - loss: 6.4048 - acc: 0.598 - ETA: 3:09 - loss: 6.4037 - acc: 0.598 - ETA: 3:08 - loss: 6.4038 - acc: 0.598 - ETA: 3:08 - loss: 6.4040 - acc: 0.598 - ETA: 3:08 - loss: 6.4033 - acc: 0.598 - ETA: 3:08 - loss: 6.4028 - acc: 0.598 - ETA: 3:08 - loss: 6.4030 - acc: 0.598 - ETA: 3:08 - loss: 6.4029 - acc: 0.598 - ETA: 3:08 - loss: 6.4030 - acc: 0.598 - ETA: 3:08 - loss: 6.4027 - acc: 0.598 - ETA: 3:08 - loss: 6.4029 - acc: 0.598 - ETA: 3:08 - loss: 6.4032 - acc: 0.598 - ETA: 3:08 - loss: 6.4022 - acc: 0.598 - ETA: 3:08 - loss: 6.4020 - acc: 0.598 - ETA: 3:08 - loss: 6.4014 - acc: 0.598 - ETA: 3:08 - loss: 6.4009 - acc: 0.598 - ETA: 3:08 - loss: 6.4005 - acc: 0.598 - ETA: 3:08 - loss: 6.3984 - acc: 0.598 - ETA: 3:08 - loss: 6.3988 - acc: 0.598 - ETA: 3:08 - loss: 6.3982 - acc: 0.598 - ETA: 3:08 - loss: 6.3984 - acc: 0.598 - ETA: 3:08 - loss: 6.3987 - acc: 0.598 - ETA: 3:08 - loss: 6.3987 - acc: 0.598 - ETA: 3:08 - loss: 6.3989 - acc: 0.598 - ETA: 3:08 - loss: 6.3987 - acc: 0.598 - ETA: 3:08 - loss: 6.3987 - acc: 0.598 - ETA: 3:08 - loss: 6.3990 - acc: 0.598 - ETA: 3:08 - loss: 6.3978 - acc: 0.598 - ETA: 3:08 - loss: 6.3970 - acc: 0.598 - ETA: 3:08 - loss: 6.3974 - acc: 0.598 - ETA: 3:08 - loss: 6.3979 - acc: 0.598 - ETA: 3:08 - loss: 6.3980 - acc: 0.598 - ETA: 3:08 - loss: 6.3980 - acc: 0.598 - ETA: 3:08 - loss: 6.3989 - acc: 0.598 - ETA: 3:08 - loss: 6.3987 - acc: 0.598 - ETA: 3:08 - loss: 6.3981 - acc: 0.598 - ETA: 3:08 - loss: 6.3993 - acc: 0.598 - ETA: 3:08 - loss: 6.3996 - acc: 0.598 - ETA: 3:08 - loss: 6.4001 - acc: 0.598 - ETA: 3:08 - loss: 6.3997 - acc: 0.598 - ETA: 3:08 - loss: 6.3986 - acc: 0.598 - ETA: 3:08 - loss: 6.3983 - acc: 0.598 - ETA: 3:08 - loss: 6.3973 - acc: 0.598 - ETA: 3:07 - loss: 6.3974 - acc: 0.598 - ETA: 3:07 - loss: 6.3975 - acc: 0.598 - ETA: 3:07 - loss: 6.3979 - acc: 0.598 - ETA: 3:07 - loss: 6.3982 - acc: 0.598 - ETA: 3:07 - loss: 6.3976 - acc: 0.598 - ETA: 3:07 - loss: 6.3974 - acc: 0.598 - ETA: 3:07 - loss: 6.3979 - acc: 0.598 - ETA: 3:07 - loss: 6.3987 - acc: 0.598 - ETA: 3:07 - loss: 6.3992 - acc: 0.598 - ETA: 3:07 - loss: 6.4001 - acc: 0.598 - ETA: 3:07 - loss: 6.3996 - acc: 0.598 - ETA: 3:07 - loss: 6.3993 - acc: 0.598 - ETA: 3:07 - loss: 6.3993 - acc: 0.598 - ETA: 3:07 - loss: 6.3994 - acc: 0.598 - ETA: 3:07 - loss: 6.3986 - acc: 0.598 - ETA: 3:07 - loss: 6.3991 - acc: 0.598 - ETA: 3:06 - loss: 6.3986 - acc: 0.598 - ETA: 3:06 - loss: 6.3985 - acc: 0.598 - ETA: 3:06 - loss: 6.3996 - acc: 0.598 - ETA: 3:06 - loss: 6.3991 - acc: 0.598 - ETA: 3:06 - loss: 6.3989 - acc: 0.598 - ETA: 3:06 - loss: 6.3988 - acc: 0.598 - ETA: 3:06 - loss: 6.3981 - acc: 0.598 - ETA: 3:06 - loss: 6.3988 - acc: 0.598 - ETA: 3:06 - loss: 6.3990 - acc: 0.598 - ETA: 3:06 - loss: 6.3999 - acc: 0.598 - ETA: 3:05 - loss: 6.3993 - acc: 0.598 - ETA: 3:05 - loss: 6.3992 - acc: 0.598 - ETA: 3:05 - loss: 6.3979 - acc: 0.598 - ETA: 3:05 - loss: 6.3967 - acc: 0.598 - ETA: 3:05 - loss: 6.3975 - acc: 0.598 - ETA: 3:05 - loss: 6.3969 - acc: 0.598 - ETA: 3:05 - loss: 6.3969 - acc: 0.598 - ETA: 3:05 - loss: 6.3970 - acc: 0.598 - ETA: 3:05 - loss: 6.3968 - acc: 0.598 - ETA: 3:05 - loss: 6.3970 - acc: 0.598 - ETA: 3:05 - loss: 6.3972 - acc: 0.598 - ETA: 3:05 - loss: 6.3958 - acc: 0.598 - ETA: 3:05 - loss: 6.3959 - acc: 0.598 - ETA: 3:05 - loss: 6.3958 - acc: 0.598 - ETA: 3:05 - loss: 6.3961 - acc: 0.598 - ETA: 3:04 - loss: 6.3975 - acc: 0.598 - ETA: 3:04 - loss: 6.3978 - acc: 0.598 - ETA: 3:04 - loss: 6.3985 - acc: 0.598 - ETA: 3:04 - loss: 6.3988 - acc: 0.598 - ETA: 3:04 - loss: 6.3987 - acc: 0.598 - ETA: 3:04 - loss: 6.3981 - acc: 0.598 - ETA: 3:04 - loss: 6.3978 - acc: 0.598 - ETA: 3:04 - loss: 6.3965 - acc: 0.598 - ETA: 3:04 - loss: 6.3962 - acc: 0.598 - ETA: 3:03 - loss: 6.3945 - acc: 0.598 - ETA: 3:03 - loss: 6.3943 - acc: 0.598 - ETA: 3:03 - loss: 6.3947 - acc: 0.598 - ETA: 3:03 - loss: 6.3953 - acc: 0.598 - ETA: 3:03 - loss: 6.3963 - acc: 0.598 - ETA: 3:02 - loss: 6.3972 - acc: 0.598 - ETA: 3:02 - loss: 6.3955 - acc: 0.598 - ETA: 3:01 - loss: 6.3954 - acc: 0.598 - ETA: 3:01 - loss: 6.3959 - acc: 0.598 - ETA: 3:01 - loss: 6.3951 - acc: 0.598 - ETA: 3:01 - loss: 6.3945 - acc: 0.598 - ETA: 3:01 - loss: 6.3946 - acc: 0.598 - ETA: 3:00 - loss: 6.3936 - acc: 0.599 - ETA: 3:00 - loss: 6.3923 - acc: 0.599 - ETA: 3:00 - loss: 6.3929 - acc: 0.599 - ETA: 2:59 - loss: 6.3923 - acc: 0.599 - ETA: 2:59 - loss: 6.3914 - acc: 0.599 - ETA: 2:59 - loss: 6.3912 - acc: 0.599 - ETA: 2:59 - loss: 6.3918 - acc: 0.599 - ETA: 2:58 - loss: 6.3899 - acc: 0.599 - ETA: 2:58 - loss: 6.3904 - acc: 0.599 - ETA: 2:58 - loss: 6.3913 - acc: 0.599 - ETA: 2:57 - loss: 6.3901 - acc: 0.599 - ETA: 2:57 - loss: 6.3886 - acc: 0.599 - ETA: 2:57 - loss: 6.3880 - acc: 0.599 - ETA: 2:57 - loss: 6.3884 - acc: 0.599 - ETA: 2:57 - loss: 6.3879 - acc: 0.599 - ETA: 2:57 - loss: 6.3881 - acc: 0.599 - ETA: 2:57 - loss: 6.3879 - acc: 0.599 - ETA: 2:56 - loss: 6.3880 - acc: 0.599 - ETA: 2:56 - loss: 6.3894 - acc: 0.599 - ETA: 2:56 - loss: 6.3903 - acc: 0.599 - ETA: 2:56 - loss: 6.3899 - acc: 0.599 - ETA: 2:56 - loss: 6.3888 - acc: 0.599 - ETA: 2:55 - loss: 6.3884 - acc: 0.599 - ETA: 2:55 - loss: 6.3896 - acc: 0.599 - ETA: 2:55 - loss: 6.3902 - acc: 0.599 - ETA: 2:54 - loss: 6.3906 - acc: 0.599 - ETA: 2:54 - loss: 6.3889 - acc: 0.599 - ETA: 2:53 - loss: 6.3896 - acc: 0.599 - ETA: 2:53 - loss: 6.3894 - acc: 0.599 - ETA: 2:53 - loss: 6.3889 - acc: 0.599 - ETA: 2:53 - loss: 6.3897 - acc: 0.599 - ETA: 2:52 - loss: 6.3897 - acc: 0.599 - ETA: 2:52 - loss: 6.3893 - acc: 0.599 - ETA: 2:52 - loss: 6.3909 - acc: 0.5991"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307840/969231 [========>.....................] - ETA: 2:52 - loss: 6.3900 - acc: 0.599 - ETA: 2:52 - loss: 6.3895 - acc: 0.599 - ETA: 2:51 - loss: 6.3911 - acc: 0.599 - ETA: 2:51 - loss: 6.3911 - acc: 0.599 - ETA: 2:51 - loss: 6.3900 - acc: 0.599 - ETA: 2:50 - loss: 6.3899 - acc: 0.599 - ETA: 2:50 - loss: 6.3898 - acc: 0.599 - ETA: 2:50 - loss: 6.3906 - acc: 0.599 - ETA: 2:50 - loss: 6.3910 - acc: 0.599 - ETA: 2:50 - loss: 6.3916 - acc: 0.599 - ETA: 2:50 - loss: 6.3917 - acc: 0.599 - ETA: 2:49 - loss: 6.3933 - acc: 0.599 - ETA: 2:49 - loss: 6.3940 - acc: 0.598 - ETA: 2:49 - loss: 6.3941 - acc: 0.598 - ETA: 2:48 - loss: 6.3953 - acc: 0.598 - ETA: 2:48 - loss: 6.3953 - acc: 0.598 - ETA: 2:48 - loss: 6.3965 - acc: 0.598 - ETA: 2:47 - loss: 6.3968 - acc: 0.598 - ETA: 2:47 - loss: 6.3966 - acc: 0.598 - ETA: 2:47 - loss: 6.3964 - acc: 0.598 - ETA: 2:47 - loss: 6.3964 - acc: 0.598 - ETA: 2:47 - loss: 6.3968 - acc: 0.598 - ETA: 2:47 - loss: 6.3985 - acc: 0.598 - ETA: 2:46 - loss: 6.3989 - acc: 0.598 - ETA: 2:46 - loss: 6.3984 - acc: 0.598 - ETA: 2:45 - loss: 6.3983 - acc: 0.598 - ETA: 2:45 - loss: 6.3981 - acc: 0.598 - ETA: 2:45 - loss: 6.3987 - acc: 0.598 - ETA: 2:45 - loss: 6.3988 - acc: 0.598 - ETA: 2:45 - loss: 6.3990 - acc: 0.598 - ETA: 2:45 - loss: 6.3991 - acc: 0.598 - ETA: 2:44 - loss: 6.3992 - acc: 0.598 - ETA: 2:44 - loss: 6.3988 - acc: 0.598 - ETA: 2:44 - loss: 6.3996 - acc: 0.598 - ETA: 2:44 - loss: 6.4003 - acc: 0.598 - ETA: 2:44 - loss: 6.3997 - acc: 0.598 - ETA: 2:43 - loss: 6.3993 - acc: 0.598 - ETA: 2:43 - loss: 6.3999 - acc: 0.598 - ETA: 2:43 - loss: 6.3991 - acc: 0.598 - ETA: 2:43 - loss: 6.3989 - acc: 0.598 - ETA: 2:43 - loss: 6.3996 - acc: 0.598 - ETA: 2:43 - loss: 6.3998 - acc: 0.598 - ETA: 2:42 - loss: 6.3998 - acc: 0.598 - ETA: 2:42 - loss: 6.4001 - acc: 0.598 - ETA: 2:42 - loss: 6.4005 - acc: 0.598 - ETA: 2:42 - loss: 6.3992 - acc: 0.598 - ETA: 2:41 - loss: 6.3987 - acc: 0.598 - ETA: 2:41 - loss: 6.3995 - acc: 0.598 - ETA: 2:41 - loss: 6.3993 - acc: 0.598 - ETA: 2:41 - loss: 6.3988 - acc: 0.598 - ETA: 2:41 - loss: 6.3985 - acc: 0.598 - ETA: 2:41 - loss: 6.3981 - acc: 0.598 - ETA: 2:40 - loss: 6.3974 - acc: 0.598 - ETA: 2:40 - loss: 6.3971 - acc: 0.598 - ETA: 2:40 - loss: 6.3983 - acc: 0.598 - ETA: 2:40 - loss: 6.3968 - acc: 0.598 - ETA: 2:39 - loss: 6.3967 - acc: 0.598 - ETA: 2:39 - loss: 6.3962 - acc: 0.598 - ETA: 2:39 - loss: 6.3959 - acc: 0.598 - ETA: 2:39 - loss: 6.3956 - acc: 0.598 - ETA: 2:39 - loss: 6.3960 - acc: 0.598 - ETA: 2:38 - loss: 6.3966 - acc: 0.598 - ETA: 2:38 - loss: 6.3964 - acc: 0.598 - ETA: 2:38 - loss: 6.3972 - acc: 0.598 - ETA: 2:37 - loss: 6.3968 - acc: 0.598 - ETA: 2:37 - loss: 6.3963 - acc: 0.598 - ETA: 2:37 - loss: 6.3966 - acc: 0.598 - ETA: 2:37 - loss: 6.3976 - acc: 0.598 - ETA: 2:37 - loss: 6.3978 - acc: 0.598 - ETA: 2:37 - loss: 6.3973 - acc: 0.598 - ETA: 2:37 - loss: 6.3974 - acc: 0.598 - ETA: 2:37 - loss: 6.3965 - acc: 0.598 - ETA: 2:36 - loss: 6.3963 - acc: 0.598 - ETA: 2:36 - loss: 6.3964 - acc: 0.598 - ETA: 2:36 - loss: 6.3958 - acc: 0.598 - ETA: 2:36 - loss: 6.3960 - acc: 0.598 - ETA: 2:36 - loss: 6.3956 - acc: 0.598 - ETA: 2:36 - loss: 6.3966 - acc: 0.598 - ETA: 2:36 - loss: 6.3970 - acc: 0.598 - ETA: 2:35 - loss: 6.3976 - acc: 0.598 - ETA: 2:35 - loss: 6.3975 - acc: 0.598 - ETA: 2:35 - loss: 6.3968 - acc: 0.598 - ETA: 2:35 - loss: 6.3963 - acc: 0.598 - ETA: 2:35 - loss: 6.3968 - acc: 0.598 - ETA: 2:34 - loss: 6.3975 - acc: 0.598 - ETA: 2:34 - loss: 6.3983 - acc: 0.598 - ETA: 2:34 - loss: 6.3976 - acc: 0.598 - ETA: 2:33 - loss: 6.3982 - acc: 0.598 - ETA: 2:33 - loss: 6.3988 - acc: 0.598 - ETA: 2:33 - loss: 6.3995 - acc: 0.598 - ETA: 2:33 - loss: 6.4005 - acc: 0.598 - ETA: 2:33 - loss: 6.4006 - acc: 0.598 - ETA: 2:33 - loss: 6.4002 - acc: 0.598 - ETA: 2:33 - loss: 6.4000 - acc: 0.598 - ETA: 2:33 - loss: 6.3985 - acc: 0.598 - ETA: 2:32 - loss: 6.3996 - acc: 0.598 - ETA: 2:32 - loss: 6.3993 - acc: 0.598 - ETA: 2:32 - loss: 6.4001 - acc: 0.598 - ETA: 2:32 - loss: 6.4002 - acc: 0.598 - ETA: 2:31 - loss: 6.4005 - acc: 0.598 - ETA: 2:31 - loss: 6.3998 - acc: 0.598 - ETA: 2:31 - loss: 6.4008 - acc: 0.598 - ETA: 2:30 - loss: 6.4015 - acc: 0.598 - ETA: 2:30 - loss: 6.4011 - acc: 0.598 - ETA: 2:30 - loss: 6.4014 - acc: 0.598 - ETA: 2:30 - loss: 6.4009 - acc: 0.598 - ETA: 2:30 - loss: 6.4001 - acc: 0.598 - ETA: 2:30 - loss: 6.4006 - acc: 0.598 - ETA: 2:29 - loss: 6.4005 - acc: 0.598 - ETA: 2:29 - loss: 6.4008 - acc: 0.598 - ETA: 2:29 - loss: 6.4014 - acc: 0.598 - ETA: 2:29 - loss: 6.4010 - acc: 0.598 - ETA: 2:29 - loss: 6.4022 - acc: 0.598 - ETA: 2:29 - loss: 6.4021 - acc: 0.598 - ETA: 2:29 - loss: 6.4025 - acc: 0.598 - ETA: 2:29 - loss: 6.4025 - acc: 0.598 - ETA: 2:29 - loss: 6.4032 - acc: 0.598 - ETA: 2:28 - loss: 6.4031 - acc: 0.598 - ETA: 2:28 - loss: 6.4032 - acc: 0.598 - ETA: 2:28 - loss: 6.4033 - acc: 0.598 - ETA: 2:28 - loss: 6.4029 - acc: 0.598 - ETA: 2:28 - loss: 6.4020 - acc: 0.598 - ETA: 2:27 - loss: 6.4020 - acc: 0.598 - ETA: 2:27 - loss: 6.4017 - acc: 0.598 - ETA: 2:27 - loss: 6.4018 - acc: 0.598 - ETA: 2:27 - loss: 6.4014 - acc: 0.598 - ETA: 2:27 - loss: 6.4016 - acc: 0.598 - ETA: 2:26 - loss: 6.4015 - acc: 0.598 - ETA: 2:26 - loss: 6.4018 - acc: 0.598 - ETA: 2:26 - loss: 6.4023 - acc: 0.598 - ETA: 2:26 - loss: 6.4019 - acc: 0.598 - ETA: 2:25 - loss: 6.4016 - acc: 0.598 - ETA: 2:25 - loss: 6.4021 - acc: 0.598 - ETA: 2:25 - loss: 6.4019 - acc: 0.598 - ETA: 2:25 - loss: 6.4011 - acc: 0.598 - ETA: 2:25 - loss: 6.4007 - acc: 0.598 - ETA: 2:25 - loss: 6.4005 - acc: 0.598 - ETA: 2:25 - loss: 6.4007 - acc: 0.598 - ETA: 2:25 - loss: 6.4004 - acc: 0.598 - ETA: 2:24 - loss: 6.4001 - acc: 0.598 - ETA: 2:24 - loss: 6.3999 - acc: 0.598 - ETA: 2:24 - loss: 6.3994 - acc: 0.598 - ETA: 2:24 - loss: 6.3997 - acc: 0.598 - ETA: 2:23 - loss: 6.4001 - acc: 0.598 - ETA: 2:23 - loss: 6.4004 - acc: 0.598 - ETA: 2:23 - loss: 6.4001 - acc: 0.598 - ETA: 2:23 - loss: 6.3994 - acc: 0.598 - ETA: 2:23 - loss: 6.3993 - acc: 0.598 - ETA: 2:23 - loss: 6.4002 - acc: 0.598 - ETA: 2:23 - loss: 6.3995 - acc: 0.598 - ETA: 2:22 - loss: 6.3995 - acc: 0.598 - ETA: 2:22 - loss: 6.3999 - acc: 0.598 - ETA: 2:22 - loss: 6.4000 - acc: 0.598 - ETA: 2:22 - loss: 6.3995 - acc: 0.598 - ETA: 2:22 - loss: 6.3997 - acc: 0.598 - ETA: 2:22 - loss: 6.4013 - acc: 0.598 - ETA: 2:22 - loss: 6.4010 - acc: 0.598 - ETA: 2:21 - loss: 6.4011 - acc: 0.598 - ETA: 2:21 - loss: 6.4017 - acc: 0.598 - ETA: 2:21 - loss: 6.4011 - acc: 0.598 - ETA: 2:21 - loss: 6.4009 - acc: 0.598 - ETA: 2:21 - loss: 6.4006 - acc: 0.598 - ETA: 2:21 - loss: 6.4002 - acc: 0.598 - ETA: 2:21 - loss: 6.4011 - acc: 0.598 - ETA: 2:20 - loss: 6.4004 - acc: 0.598 - ETA: 2:20 - loss: 6.4010 - acc: 0.598 - ETA: 2:20 - loss: 6.4015 - acc: 0.598 - ETA: 2:20 - loss: 6.4009 - acc: 0.598 - ETA: 2:19 - loss: 6.4008 - acc: 0.598 - ETA: 2:19 - loss: 6.4002 - acc: 0.598 - ETA: 2:19 - loss: 6.4000 - acc: 0.598 - ETA: 2:19 - loss: 6.3997 - acc: 0.598 - ETA: 2:19 - loss: 6.4002 - acc: 0.598 - ETA: 2:19 - loss: 6.4004 - acc: 0.598 - ETA: 2:19 - loss: 6.4004 - acc: 0.598 - ETA: 2:18 - loss: 6.4009 - acc: 0.598 - ETA: 2:18 - loss: 6.4007 - acc: 0.598 - ETA: 2:18 - loss: 6.4002 - acc: 0.598 - ETA: 2:18 - loss: 6.4011 - acc: 0.598 - ETA: 2:18 - loss: 6.4013 - acc: 0.598 - ETA: 2:18 - loss: 6.4007 - acc: 0.598 - ETA: 2:17 - loss: 6.4016 - acc: 0.598 - ETA: 2:17 - loss: 6.4017 - acc: 0.598 - ETA: 2:17 - loss: 6.4021 - acc: 0.598 - ETA: 2:17 - loss: 6.4019 - acc: 0.598 - ETA: 2:17 - loss: 6.4017 - acc: 0.598 - ETA: 2:17 - loss: 6.4021 - acc: 0.598 - ETA: 2:17 - loss: 6.4014 - acc: 0.598 - ETA: 2:16 - loss: 6.4013 - acc: 0.598 - ETA: 2:16 - loss: 6.4015 - acc: 0.598 - ETA: 2:16 - loss: 6.4016 - acc: 0.598 - ETA: 2:16 - loss: 6.4019 - acc: 0.598 - ETA: 2:16 - loss: 6.4014 - acc: 0.598 - ETA: 2:16 - loss: 6.4014 - acc: 0.598 - ETA: 2:16 - loss: 6.4014 - acc: 0.598 - ETA: 2:16 - loss: 6.4013 - acc: 0.598 - ETA: 2:15 - loss: 6.4010 - acc: 0.598 - ETA: 2:15 - loss: 6.4006 - acc: 0.598 - ETA: 2:15 - loss: 6.4013 - acc: 0.598 - ETA: 2:15 - loss: 6.4007 - acc: 0.598 - ETA: 2:15 - loss: 6.4005 - acc: 0.598 - ETA: 2:15 - loss: 6.4011 - acc: 0.598 - ETA: 2:14 - loss: 6.4001 - acc: 0.598 - ETA: 2:14 - loss: 6.3996 - acc: 0.5986"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392704/969231 [===========>..................] - ETA: 2:14 - loss: 6.3996 - acc: 0.598 - ETA: 2:14 - loss: 6.3997 - acc: 0.598 - ETA: 2:14 - loss: 6.3993 - acc: 0.598 - ETA: 2:14 - loss: 6.3997 - acc: 0.598 - ETA: 2:13 - loss: 6.4001 - acc: 0.598 - ETA: 2:13 - loss: 6.4009 - acc: 0.598 - ETA: 2:13 - loss: 6.4006 - acc: 0.598 - ETA: 2:12 - loss: 6.4010 - acc: 0.598 - ETA: 2:12 - loss: 6.4010 - acc: 0.598 - ETA: 2:12 - loss: 6.4014 - acc: 0.598 - ETA: 2:12 - loss: 6.4019 - acc: 0.598 - ETA: 2:11 - loss: 6.4021 - acc: 0.598 - ETA: 2:11 - loss: 6.4018 - acc: 0.598 - ETA: 2:11 - loss: 6.4015 - acc: 0.598 - ETA: 2:11 - loss: 6.4022 - acc: 0.598 - ETA: 2:11 - loss: 6.4017 - acc: 0.598 - ETA: 2:11 - loss: 6.4012 - acc: 0.598 - ETA: 2:11 - loss: 6.4014 - acc: 0.598 - ETA: 2:11 - loss: 6.4009 - acc: 0.598 - ETA: 2:11 - loss: 6.4010 - acc: 0.598 - ETA: 2:10 - loss: 6.4003 - acc: 0.598 - ETA: 2:10 - loss: 6.4002 - acc: 0.598 - ETA: 2:10 - loss: 6.4003 - acc: 0.598 - ETA: 2:10 - loss: 6.4010 - acc: 0.598 - ETA: 2:10 - loss: 6.4014 - acc: 0.598 - ETA: 2:10 - loss: 6.4018 - acc: 0.598 - ETA: 2:10 - loss: 6.4017 - acc: 0.598 - ETA: 2:10 - loss: 6.4016 - acc: 0.598 - ETA: 2:10 - loss: 6.4019 - acc: 0.598 - ETA: 2:10 - loss: 6.4034 - acc: 0.598 - ETA: 2:10 - loss: 6.4030 - acc: 0.598 - ETA: 2:09 - loss: 6.4029 - acc: 0.598 - ETA: 2:09 - loss: 6.4024 - acc: 0.598 - ETA: 2:09 - loss: 6.4026 - acc: 0.598 - ETA: 2:09 - loss: 6.4031 - acc: 0.598 - ETA: 2:09 - loss: 6.4026 - acc: 0.598 - ETA: 2:09 - loss: 6.4027 - acc: 0.598 - ETA: 2:08 - loss: 6.4021 - acc: 0.598 - ETA: 2:08 - loss: 6.4018 - acc: 0.598 - ETA: 2:08 - loss: 6.4021 - acc: 0.598 - ETA: 2:08 - loss: 6.4015 - acc: 0.598 - ETA: 2:08 - loss: 6.4014 - acc: 0.598 - ETA: 2:07 - loss: 6.4014 - acc: 0.598 - ETA: 2:07 - loss: 6.4013 - acc: 0.598 - ETA: 2:07 - loss: 6.4016 - acc: 0.598 - ETA: 2:07 - loss: 6.4018 - acc: 0.598 - ETA: 2:07 - loss: 6.4016 - acc: 0.598 - ETA: 2:07 - loss: 6.4020 - acc: 0.598 - ETA: 2:07 - loss: 6.4012 - acc: 0.598 - ETA: 2:06 - loss: 6.4010 - acc: 0.598 - ETA: 2:06 - loss: 6.4019 - acc: 0.598 - ETA: 2:06 - loss: 6.4021 - acc: 0.598 - ETA: 2:06 - loss: 6.4022 - acc: 0.598 - ETA: 2:06 - loss: 6.4017 - acc: 0.598 - ETA: 2:06 - loss: 6.4019 - acc: 0.598 - ETA: 2:06 - loss: 6.4029 - acc: 0.598 - ETA: 2:05 - loss: 6.4022 - acc: 0.598 - ETA: 2:05 - loss: 6.4027 - acc: 0.598 - ETA: 2:05 - loss: 6.4029 - acc: 0.598 - ETA: 2:05 - loss: 6.4020 - acc: 0.598 - ETA: 2:05 - loss: 6.4020 - acc: 0.598 - ETA: 2:05 - loss: 6.4019 - acc: 0.598 - ETA: 2:05 - loss: 6.4020 - acc: 0.598 - ETA: 2:05 - loss: 6.4020 - acc: 0.598 - ETA: 2:05 - loss: 6.4024 - acc: 0.598 - ETA: 2:05 - loss: 6.4020 - acc: 0.598 - ETA: 2:04 - loss: 6.4014 - acc: 0.598 - ETA: 2:04 - loss: 6.4016 - acc: 0.598 - ETA: 2:04 - loss: 6.4017 - acc: 0.598 - ETA: 2:04 - loss: 6.4015 - acc: 0.598 - ETA: 2:04 - loss: 6.4013 - acc: 0.598 - ETA: 2:04 - loss: 6.4017 - acc: 0.598 - ETA: 2:04 - loss: 6.4013 - acc: 0.598 - ETA: 2:04 - loss: 6.4015 - acc: 0.598 - ETA: 2:03 - loss: 6.4012 - acc: 0.598 - ETA: 2:03 - loss: 6.4010 - acc: 0.598 - ETA: 2:03 - loss: 6.4006 - acc: 0.598 - ETA: 2:03 - loss: 6.4011 - acc: 0.598 - ETA: 2:03 - loss: 6.4008 - acc: 0.598 - ETA: 2:03 - loss: 6.4000 - acc: 0.598 - ETA: 2:03 - loss: 6.4000 - acc: 0.598 - ETA: 2:03 - loss: 6.4003 - acc: 0.598 - ETA: 2:03 - loss: 6.3994 - acc: 0.598 - ETA: 2:03 - loss: 6.3989 - acc: 0.598 - ETA: 2:03 - loss: 6.3985 - acc: 0.598 - ETA: 2:02 - loss: 6.3981 - acc: 0.598 - ETA: 2:02 - loss: 6.3981 - acc: 0.598 - ETA: 2:02 - loss: 6.3978 - acc: 0.598 - ETA: 2:02 - loss: 6.3973 - acc: 0.598 - ETA: 2:02 - loss: 6.3981 - acc: 0.598 - ETA: 2:02 - loss: 6.3984 - acc: 0.598 - ETA: 2:01 - loss: 6.3981 - acc: 0.598 - ETA: 2:01 - loss: 6.3977 - acc: 0.598 - ETA: 2:01 - loss: 6.3976 - acc: 0.598 - ETA: 2:01 - loss: 6.3974 - acc: 0.598 - ETA: 2:01 - loss: 6.3976 - acc: 0.598 - ETA: 2:01 - loss: 6.3975 - acc: 0.598 - ETA: 2:01 - loss: 6.3979 - acc: 0.598 - ETA: 2:01 - loss: 6.3975 - acc: 0.598 - ETA: 2:01 - loss: 6.3965 - acc: 0.598 - ETA: 2:01 - loss: 6.3965 - acc: 0.598 - ETA: 2:00 - loss: 6.3966 - acc: 0.598 - ETA: 2:01 - loss: 6.3965 - acc: 0.598 - ETA: 2:00 - loss: 6.3972 - acc: 0.598 - ETA: 2:00 - loss: 6.3964 - acc: 0.598 - ETA: 2:00 - loss: 6.3962 - acc: 0.598 - ETA: 2:00 - loss: 6.3962 - acc: 0.598 - ETA: 2:00 - loss: 6.3957 - acc: 0.598 - ETA: 2:00 - loss: 6.3955 - acc: 0.598 - ETA: 2:00 - loss: 6.3959 - acc: 0.598 - ETA: 1:59 - loss: 6.3967 - acc: 0.598 - ETA: 1:59 - loss: 6.3970 - acc: 0.598 - ETA: 1:59 - loss: 6.3962 - acc: 0.598 - ETA: 1:59 - loss: 6.3962 - acc: 0.598 - ETA: 1:59 - loss: 6.3949 - acc: 0.598 - ETA: 1:59 - loss: 6.3947 - acc: 0.598 - ETA: 1:59 - loss: 6.3953 - acc: 0.598 - ETA: 1:59 - loss: 6.3957 - acc: 0.598 - ETA: 1:58 - loss: 6.3960 - acc: 0.598 - ETA: 1:58 - loss: 6.3961 - acc: 0.598 - ETA: 1:58 - loss: 6.3954 - acc: 0.598 - ETA: 1:58 - loss: 6.3958 - acc: 0.598 - ETA: 1:58 - loss: 6.3955 - acc: 0.598 - ETA: 1:58 - loss: 6.3955 - acc: 0.598 - ETA: 1:58 - loss: 6.3958 - acc: 0.598 - ETA: 1:58 - loss: 6.3960 - acc: 0.598 - ETA: 1:58 - loss: 6.3960 - acc: 0.598 - ETA: 1:58 - loss: 6.3957 - acc: 0.598 - ETA: 1:57 - loss: 6.3942 - acc: 0.598 - ETA: 1:57 - loss: 6.3939 - acc: 0.598 - ETA: 1:57 - loss: 6.3933 - acc: 0.599 - ETA: 1:57 - loss: 6.3922 - acc: 0.599 - ETA: 1:57 - loss: 6.3915 - acc: 0.599 - ETA: 1:57 - loss: 6.3916 - acc: 0.599 - ETA: 1:57 - loss: 6.3924 - acc: 0.599 - ETA: 1:57 - loss: 6.3922 - acc: 0.599 - ETA: 1:56 - loss: 6.3922 - acc: 0.599 - ETA: 1:56 - loss: 6.3923 - acc: 0.599 - ETA: 1:56 - loss: 6.3928 - acc: 0.599 - ETA: 1:56 - loss: 6.3929 - acc: 0.599 - ETA: 1:56 - loss: 6.3923 - acc: 0.599 - ETA: 1:56 - loss: 6.3926 - acc: 0.599 - ETA: 1:56 - loss: 6.3931 - acc: 0.599 - ETA: 1:56 - loss: 6.3931 - acc: 0.599 - ETA: 1:56 - loss: 6.3935 - acc: 0.599 - ETA: 1:55 - loss: 6.3939 - acc: 0.598 - ETA: 1:55 - loss: 6.3938 - acc: 0.598 - ETA: 1:55 - loss: 6.3927 - acc: 0.599 - ETA: 1:55 - loss: 6.3929 - acc: 0.599 - ETA: 1:55 - loss: 6.3928 - acc: 0.599 - ETA: 1:55 - loss: 6.3921 - acc: 0.599 - ETA: 1:54 - loss: 6.3925 - acc: 0.599 - ETA: 1:54 - loss: 6.3923 - acc: 0.599 - ETA: 1:54 - loss: 6.3930 - acc: 0.599 - ETA: 1:54 - loss: 6.3927 - acc: 0.599 - ETA: 1:54 - loss: 6.3921 - acc: 0.599 - ETA: 1:54 - loss: 6.3927 - acc: 0.599 - ETA: 1:54 - loss: 6.3925 - acc: 0.599 - ETA: 1:53 - loss: 6.3926 - acc: 0.599 - ETA: 1:53 - loss: 6.3935 - acc: 0.599 - ETA: 1:53 - loss: 6.3929 - acc: 0.599 - ETA: 1:53 - loss: 6.3929 - acc: 0.599 - ETA: 1:53 - loss: 6.3928 - acc: 0.599 - ETA: 1:53 - loss: 6.3928 - acc: 0.599 - ETA: 1:53 - loss: 6.3920 - acc: 0.599 - ETA: 1:53 - loss: 6.3918 - acc: 0.599 - ETA: 1:53 - loss: 6.3923 - acc: 0.599 - ETA: 1:53 - loss: 6.3926 - acc: 0.599 - ETA: 1:53 - loss: 6.3924 - acc: 0.599 - ETA: 1:52 - loss: 6.3918 - acc: 0.599 - ETA: 1:52 - loss: 6.3915 - acc: 0.599 - ETA: 1:52 - loss: 6.3921 - acc: 0.599 - ETA: 1:52 - loss: 6.3919 - acc: 0.599 - ETA: 1:52 - loss: 6.3921 - acc: 0.599 - ETA: 1:52 - loss: 6.3923 - acc: 0.599 - ETA: 1:52 - loss: 6.3931 - acc: 0.599 - ETA: 1:52 - loss: 6.3932 - acc: 0.599 - ETA: 1:52 - loss: 6.3926 - acc: 0.599 - ETA: 1:52 - loss: 6.3928 - acc: 0.599 - ETA: 1:51 - loss: 6.3935 - acc: 0.599 - ETA: 1:51 - loss: 6.3931 - acc: 0.599 - ETA: 1:51 - loss: 6.3931 - acc: 0.599 - ETA: 1:51 - loss: 6.3937 - acc: 0.598 - ETA: 1:51 - loss: 6.3941 - acc: 0.598 - ETA: 1:51 - loss: 6.3938 - acc: 0.598 - ETA: 1:51 - loss: 6.3940 - acc: 0.598 - ETA: 1:51 - loss: 6.3940 - acc: 0.598 - ETA: 1:51 - loss: 6.3934 - acc: 0.599 - ETA: 1:50 - loss: 6.3939 - acc: 0.598 - ETA: 1:50 - loss: 6.3932 - acc: 0.599 - ETA: 1:50 - loss: 6.3926 - acc: 0.599 - ETA: 1:50 - loss: 6.3928 - acc: 0.599 - ETA: 1:50 - loss: 6.3922 - acc: 0.599 - ETA: 1:50 - loss: 6.3921 - acc: 0.599 - ETA: 1:50 - loss: 6.3927 - acc: 0.599 - ETA: 1:50 - loss: 6.3924 - acc: 0.599 - ETA: 1:50 - loss: 6.3923 - acc: 0.599 - ETA: 1:49 - loss: 6.3927 - acc: 0.599 - ETA: 1:49 - loss: 6.3938 - acc: 0.598 - ETA: 1:49 - loss: 6.3942 - acc: 0.598 - ETA: 1:49 - loss: 6.3946 - acc: 0.598 - ETA: 1:49 - loss: 6.3949 - acc: 0.598 - ETA: 1:49 - loss: 6.3946 - acc: 0.598 - ETA: 1:49 - loss: 6.3948 - acc: 0.5989"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "477056/969231 [=============>................] - ETA: 1:49 - loss: 6.3947 - acc: 0.598 - ETA: 1:48 - loss: 6.3945 - acc: 0.598 - ETA: 1:48 - loss: 6.3947 - acc: 0.598 - ETA: 1:48 - loss: 6.3952 - acc: 0.598 - ETA: 1:48 - loss: 6.3957 - acc: 0.598 - ETA: 1:48 - loss: 6.3964 - acc: 0.598 - ETA: 1:48 - loss: 6.3967 - acc: 0.598 - ETA: 1:48 - loss: 6.3965 - acc: 0.598 - ETA: 1:48 - loss: 6.3967 - acc: 0.598 - ETA: 1:48 - loss: 6.3968 - acc: 0.598 - ETA: 1:48 - loss: 6.3973 - acc: 0.598 - ETA: 1:48 - loss: 6.3982 - acc: 0.598 - ETA: 1:47 - loss: 6.3978 - acc: 0.598 - ETA: 1:47 - loss: 6.3977 - acc: 0.598 - ETA: 1:47 - loss: 6.3971 - acc: 0.598 - ETA: 1:47 - loss: 6.3972 - acc: 0.598 - ETA: 1:47 - loss: 6.3969 - acc: 0.598 - ETA: 1:47 - loss: 6.3971 - acc: 0.598 - ETA: 1:47 - loss: 6.3973 - acc: 0.598 - ETA: 1:47 - loss: 6.3979 - acc: 0.598 - ETA: 1:46 - loss: 6.3979 - acc: 0.598 - ETA: 1:46 - loss: 6.3976 - acc: 0.598 - ETA: 1:46 - loss: 6.3971 - acc: 0.598 - ETA: 1:46 - loss: 6.3971 - acc: 0.598 - ETA: 1:46 - loss: 6.3978 - acc: 0.598 - ETA: 1:46 - loss: 6.3979 - acc: 0.598 - ETA: 1:46 - loss: 6.3980 - acc: 0.598 - ETA: 1:46 - loss: 6.3982 - acc: 0.598 - ETA: 1:46 - loss: 6.3985 - acc: 0.598 - ETA: 1:46 - loss: 6.3990 - acc: 0.598 - ETA: 1:46 - loss: 6.3990 - acc: 0.598 - ETA: 1:46 - loss: 6.3989 - acc: 0.598 - ETA: 1:45 - loss: 6.3997 - acc: 0.598 - ETA: 1:45 - loss: 6.3994 - acc: 0.598 - ETA: 1:45 - loss: 6.4003 - acc: 0.598 - ETA: 1:45 - loss: 6.4004 - acc: 0.598 - ETA: 1:45 - loss: 6.4005 - acc: 0.598 - ETA: 1:45 - loss: 6.4010 - acc: 0.598 - ETA: 1:45 - loss: 6.4011 - acc: 0.598 - ETA: 1:45 - loss: 6.4018 - acc: 0.598 - ETA: 1:45 - loss: 6.4017 - acc: 0.598 - ETA: 1:45 - loss: 6.4014 - acc: 0.598 - ETA: 1:44 - loss: 6.4013 - acc: 0.598 - ETA: 1:44 - loss: 6.4014 - acc: 0.598 - ETA: 1:44 - loss: 6.4011 - acc: 0.598 - ETA: 1:44 - loss: 6.4007 - acc: 0.598 - ETA: 1:44 - loss: 6.4007 - acc: 0.598 - ETA: 1:44 - loss: 6.4006 - acc: 0.598 - ETA: 1:44 - loss: 6.4005 - acc: 0.598 - ETA: 1:44 - loss: 6.4012 - acc: 0.598 - ETA: 1:44 - loss: 6.4014 - acc: 0.598 - ETA: 1:44 - loss: 6.4021 - acc: 0.598 - ETA: 1:44 - loss: 6.4021 - acc: 0.598 - ETA: 1:44 - loss: 6.4027 - acc: 0.598 - ETA: 1:43 - loss: 6.4031 - acc: 0.598 - ETA: 1:43 - loss: 6.4041 - acc: 0.598 - ETA: 1:43 - loss: 6.4043 - acc: 0.598 - ETA: 1:43 - loss: 6.4046 - acc: 0.598 - ETA: 1:43 - loss: 6.4050 - acc: 0.598 - ETA: 1:43 - loss: 6.4053 - acc: 0.598 - ETA: 1:42 - loss: 6.4042 - acc: 0.598 - ETA: 1:42 - loss: 6.4043 - acc: 0.598 - ETA: 1:42 - loss: 6.4051 - acc: 0.598 - ETA: 1:42 - loss: 6.4053 - acc: 0.598 - ETA: 1:42 - loss: 6.4055 - acc: 0.598 - ETA: 1:42 - loss: 6.4057 - acc: 0.598 - ETA: 1:42 - loss: 6.4054 - acc: 0.598 - ETA: 1:42 - loss: 6.4050 - acc: 0.598 - ETA: 1:42 - loss: 6.4050 - acc: 0.598 - ETA: 1:42 - loss: 6.4051 - acc: 0.598 - ETA: 1:42 - loss: 6.4049 - acc: 0.598 - ETA: 1:42 - loss: 6.4049 - acc: 0.598 - ETA: 1:41 - loss: 6.4044 - acc: 0.598 - ETA: 1:41 - loss: 6.4041 - acc: 0.598 - ETA: 1:41 - loss: 6.4039 - acc: 0.598 - ETA: 1:41 - loss: 6.4041 - acc: 0.598 - ETA: 1:41 - loss: 6.4039 - acc: 0.598 - ETA: 1:41 - loss: 6.4039 - acc: 0.598 - ETA: 1:41 - loss: 6.4041 - acc: 0.598 - ETA: 1:41 - loss: 6.4043 - acc: 0.598 - ETA: 1:41 - loss: 6.4037 - acc: 0.598 - ETA: 1:40 - loss: 6.4038 - acc: 0.598 - ETA: 1:40 - loss: 6.4039 - acc: 0.598 - ETA: 1:40 - loss: 6.4042 - acc: 0.598 - ETA: 1:40 - loss: 6.4046 - acc: 0.598 - ETA: 1:40 - loss: 6.4048 - acc: 0.598 - ETA: 1:40 - loss: 6.4044 - acc: 0.598 - ETA: 1:39 - loss: 6.4046 - acc: 0.598 - ETA: 1:40 - loss: 6.4046 - acc: 0.598 - ETA: 1:39 - loss: 6.4050 - acc: 0.598 - ETA: 1:39 - loss: 6.4050 - acc: 0.598 - ETA: 1:39 - loss: 6.4051 - acc: 0.598 - ETA: 1:39 - loss: 6.4054 - acc: 0.598 - ETA: 1:39 - loss: 6.4050 - acc: 0.598 - ETA: 1:39 - loss: 6.4050 - acc: 0.598 - ETA: 1:39 - loss: 6.4047 - acc: 0.598 - ETA: 1:39 - loss: 6.4038 - acc: 0.598 - ETA: 1:39 - loss: 6.4034 - acc: 0.598 - ETA: 1:39 - loss: 6.4027 - acc: 0.598 - ETA: 1:39 - loss: 6.4023 - acc: 0.598 - ETA: 1:38 - loss: 6.4021 - acc: 0.598 - ETA: 1:38 - loss: 6.4028 - acc: 0.598 - ETA: 1:38 - loss: 6.4029 - acc: 0.598 - ETA: 1:38 - loss: 6.4033 - acc: 0.598 - ETA: 1:38 - loss: 6.4025 - acc: 0.598 - ETA: 1:38 - loss: 6.4022 - acc: 0.598 - ETA: 1:38 - loss: 6.4018 - acc: 0.598 - ETA: 1:38 - loss: 6.4018 - acc: 0.598 - ETA: 1:38 - loss: 6.4014 - acc: 0.598 - ETA: 1:37 - loss: 6.4010 - acc: 0.598 - ETA: 1:37 - loss: 6.4016 - acc: 0.598 - ETA: 1:37 - loss: 6.4018 - acc: 0.598 - ETA: 1:37 - loss: 6.4024 - acc: 0.598 - ETA: 1:37 - loss: 6.4024 - acc: 0.598 - ETA: 1:37 - loss: 6.4021 - acc: 0.598 - ETA: 1:37 - loss: 6.4024 - acc: 0.598 - ETA: 1:37 - loss: 6.4025 - acc: 0.598 - ETA: 1:37 - loss: 6.4025 - acc: 0.598 - ETA: 1:37 - loss: 6.4021 - acc: 0.598 - ETA: 1:37 - loss: 6.4025 - acc: 0.598 - ETA: 1:36 - loss: 6.4028 - acc: 0.598 - ETA: 1:36 - loss: 6.4030 - acc: 0.598 - ETA: 1:36 - loss: 6.4027 - acc: 0.598 - ETA: 1:36 - loss: 6.4024 - acc: 0.598 - ETA: 1:36 - loss: 6.4023 - acc: 0.598 - ETA: 1:36 - loss: 6.4026 - acc: 0.598 - ETA: 1:36 - loss: 6.4023 - acc: 0.598 - ETA: 1:36 - loss: 6.4026 - acc: 0.598 - ETA: 1:36 - loss: 6.4017 - acc: 0.598 - ETA: 1:35 - loss: 6.4017 - acc: 0.598 - ETA: 1:35 - loss: 6.4020 - acc: 0.598 - ETA: 1:35 - loss: 6.4021 - acc: 0.598 - ETA: 1:35 - loss: 6.4019 - acc: 0.598 - ETA: 1:35 - loss: 6.4016 - acc: 0.598 - ETA: 1:35 - loss: 6.4014 - acc: 0.598 - ETA: 1:35 - loss: 6.4017 - acc: 0.598 - ETA: 1:35 - loss: 6.4015 - acc: 0.598 - ETA: 1:35 - loss: 6.4013 - acc: 0.598 - ETA: 1:35 - loss: 6.4013 - acc: 0.598 - ETA: 1:35 - loss: 6.4014 - acc: 0.598 - ETA: 1:34 - loss: 6.4011 - acc: 0.598 - ETA: 1:34 - loss: 6.4013 - acc: 0.598 - ETA: 1:34 - loss: 6.4010 - acc: 0.598 - ETA: 1:34 - loss: 6.4008 - acc: 0.598 - ETA: 1:34 - loss: 6.4010 - acc: 0.598 - ETA: 1:34 - loss: 6.4008 - acc: 0.598 - ETA: 1:34 - loss: 6.4005 - acc: 0.598 - ETA: 1:34 - loss: 6.4001 - acc: 0.598 - ETA: 1:34 - loss: 6.4003 - acc: 0.598 - ETA: 1:34 - loss: 6.4007 - acc: 0.598 - ETA: 1:33 - loss: 6.4002 - acc: 0.598 - ETA: 1:33 - loss: 6.4001 - acc: 0.598 - ETA: 1:33 - loss: 6.4001 - acc: 0.598 - ETA: 1:33 - loss: 6.4000 - acc: 0.598 - ETA: 1:33 - loss: 6.4001 - acc: 0.598 - ETA: 1:33 - loss: 6.4000 - acc: 0.598 - ETA: 1:33 - loss: 6.4000 - acc: 0.598 - ETA: 1:33 - loss: 6.4001 - acc: 0.598 - ETA: 1:33 - loss: 6.4003 - acc: 0.598 - ETA: 1:33 - loss: 6.4001 - acc: 0.598 - ETA: 1:33 - loss: 6.4000 - acc: 0.598 - ETA: 1:33 - loss: 6.3996 - acc: 0.598 - ETA: 1:32 - loss: 6.3991 - acc: 0.598 - ETA: 1:32 - loss: 6.3992 - acc: 0.598 - ETA: 1:32 - loss: 6.3995 - acc: 0.598 - ETA: 1:32 - loss: 6.3995 - acc: 0.598 - ETA: 1:32 - loss: 6.3995 - acc: 0.598 - ETA: 1:32 - loss: 6.3989 - acc: 0.598 - ETA: 1:32 - loss: 6.3988 - acc: 0.598 - ETA: 1:32 - loss: 6.3988 - acc: 0.598 - ETA: 1:31 - loss: 6.3984 - acc: 0.598 - ETA: 1:31 - loss: 6.3984 - acc: 0.598 - ETA: 1:31 - loss: 6.3984 - acc: 0.598 - ETA: 1:31 - loss: 6.3984 - acc: 0.598 - ETA: 1:31 - loss: 6.3982 - acc: 0.598 - ETA: 1:31 - loss: 6.3979 - acc: 0.598 - ETA: 1:31 - loss: 6.3980 - acc: 0.598 - ETA: 1:31 - loss: 6.3974 - acc: 0.598 - ETA: 1:31 - loss: 6.3973 - acc: 0.598 - ETA: 1:31 - loss: 6.3972 - acc: 0.598 - ETA: 1:30 - loss: 6.3972 - acc: 0.598 - ETA: 1:30 - loss: 6.3972 - acc: 0.598 - ETA: 1:30 - loss: 6.3975 - acc: 0.598 - ETA: 1:30 - loss: 6.3977 - acc: 0.598 - ETA: 1:30 - loss: 6.3978 - acc: 0.598 - ETA: 1:30 - loss: 6.3974 - acc: 0.598 - ETA: 1:30 - loss: 6.3977 - acc: 0.598 - ETA: 1:30 - loss: 6.3979 - acc: 0.598 - ETA: 1:30 - loss: 6.3980 - acc: 0.598 - ETA: 1:30 - loss: 6.3986 - acc: 0.598 - ETA: 1:30 - loss: 6.3983 - acc: 0.598 - ETA: 1:30 - loss: 6.3981 - acc: 0.598 - ETA: 1:29 - loss: 6.3978 - acc: 0.598 - ETA: 1:29 - loss: 6.3980 - acc: 0.598 - ETA: 1:29 - loss: 6.3978 - acc: 0.598 - ETA: 1:29 - loss: 6.3977 - acc: 0.598 - ETA: 1:29 - loss: 6.3980 - acc: 0.598 - ETA: 1:29 - loss: 6.3983 - acc: 0.598 - ETA: 1:29 - loss: 6.3984 - acc: 0.598 - ETA: 1:29 - loss: 6.3989 - acc: 0.598 - ETA: 1:29 - loss: 6.3989 - acc: 0.598 - ETA: 1:29 - loss: 6.3986 - acc: 0.598 - ETA: 1:28 - loss: 6.3985 - acc: 0.598 - ETA: 1:28 - loss: 6.3983 - acc: 0.5987"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569344/969231 [================>.............] - ETA: 1:28 - loss: 6.3984 - acc: 0.598 - ETA: 1:28 - loss: 6.3985 - acc: 0.598 - ETA: 1:28 - loss: 6.3987 - acc: 0.598 - ETA: 1:28 - loss: 6.3988 - acc: 0.598 - ETA: 1:28 - loss: 6.3993 - acc: 0.598 - ETA: 1:28 - loss: 6.3995 - acc: 0.598 - ETA: 1:28 - loss: 6.3995 - acc: 0.598 - ETA: 1:28 - loss: 6.3991 - acc: 0.598 - ETA: 1:27 - loss: 6.3995 - acc: 0.598 - ETA: 1:27 - loss: 6.3999 - acc: 0.598 - ETA: 1:27 - loss: 6.4003 - acc: 0.598 - ETA: 1:27 - loss: 6.3999 - acc: 0.598 - ETA: 1:27 - loss: 6.4000 - acc: 0.598 - ETA: 1:27 - loss: 6.4000 - acc: 0.598 - ETA: 1:27 - loss: 6.4002 - acc: 0.598 - ETA: 1:26 - loss: 6.4007 - acc: 0.598 - ETA: 1:26 - loss: 6.4005 - acc: 0.598 - ETA: 1:26 - loss: 6.4007 - acc: 0.598 - ETA: 1:26 - loss: 6.4002 - acc: 0.598 - ETA: 1:25 - loss: 6.3991 - acc: 0.598 - ETA: 1:25 - loss: 6.3990 - acc: 0.598 - ETA: 1:25 - loss: 6.3988 - acc: 0.598 - ETA: 1:25 - loss: 6.3990 - acc: 0.598 - ETA: 1:25 - loss: 6.3992 - acc: 0.598 - ETA: 1:25 - loss: 6.3995 - acc: 0.598 - ETA: 1:25 - loss: 6.3995 - acc: 0.598 - ETA: 1:25 - loss: 6.4000 - acc: 0.598 - ETA: 1:25 - loss: 6.3996 - acc: 0.598 - ETA: 1:25 - loss: 6.3997 - acc: 0.598 - ETA: 1:25 - loss: 6.3994 - acc: 0.598 - ETA: 1:25 - loss: 6.3991 - acc: 0.598 - ETA: 1:24 - loss: 6.3992 - acc: 0.598 - ETA: 1:24 - loss: 6.3994 - acc: 0.598 - ETA: 1:24 - loss: 6.3992 - acc: 0.598 - ETA: 1:24 - loss: 6.3993 - acc: 0.598 - ETA: 1:24 - loss: 6.3996 - acc: 0.598 - ETA: 1:24 - loss: 6.3999 - acc: 0.598 - ETA: 1:24 - loss: 6.3999 - acc: 0.598 - ETA: 1:24 - loss: 6.3999 - acc: 0.598 - ETA: 1:24 - loss: 6.3998 - acc: 0.598 - ETA: 1:24 - loss: 6.3998 - acc: 0.598 - ETA: 1:24 - loss: 6.3993 - acc: 0.598 - ETA: 1:24 - loss: 6.3994 - acc: 0.598 - ETA: 1:23 - loss: 6.3998 - acc: 0.598 - ETA: 1:23 - loss: 6.3999 - acc: 0.598 - ETA: 1:23 - loss: 6.4001 - acc: 0.598 - ETA: 1:23 - loss: 6.4002 - acc: 0.598 - ETA: 1:23 - loss: 6.4006 - acc: 0.598 - ETA: 1:23 - loss: 6.4005 - acc: 0.598 - ETA: 1:23 - loss: 6.4005 - acc: 0.598 - ETA: 1:23 - loss: 6.4004 - acc: 0.598 - ETA: 1:23 - loss: 6.4005 - acc: 0.598 - ETA: 1:23 - loss: 6.4006 - acc: 0.598 - ETA: 1:23 - loss: 6.4005 - acc: 0.598 - ETA: 1:23 - loss: 6.4000 - acc: 0.598 - ETA: 1:23 - loss: 6.3999 - acc: 0.598 - ETA: 1:22 - loss: 6.4001 - acc: 0.598 - ETA: 1:22 - loss: 6.3998 - acc: 0.598 - ETA: 1:22 - loss: 6.3999 - acc: 0.598 - ETA: 1:22 - loss: 6.4001 - acc: 0.598 - ETA: 1:22 - loss: 6.4006 - acc: 0.598 - ETA: 1:22 - loss: 6.4010 - acc: 0.598 - ETA: 1:22 - loss: 6.4003 - acc: 0.598 - ETA: 1:21 - loss: 6.4005 - acc: 0.598 - ETA: 1:21 - loss: 6.4006 - acc: 0.598 - ETA: 1:21 - loss: 6.4006 - acc: 0.598 - ETA: 1:21 - loss: 6.4002 - acc: 0.598 - ETA: 1:21 - loss: 6.4005 - acc: 0.598 - ETA: 1:21 - loss: 6.4008 - acc: 0.598 - ETA: 1:21 - loss: 6.4007 - acc: 0.598 - ETA: 1:21 - loss: 6.4009 - acc: 0.598 - ETA: 1:20 - loss: 6.4011 - acc: 0.598 - ETA: 1:20 - loss: 6.4010 - acc: 0.598 - ETA: 1:20 - loss: 6.4012 - acc: 0.598 - ETA: 1:20 - loss: 6.4008 - acc: 0.598 - ETA: 1:20 - loss: 6.4006 - acc: 0.598 - ETA: 1:20 - loss: 6.4006 - acc: 0.598 - ETA: 1:20 - loss: 6.4002 - acc: 0.598 - ETA: 1:20 - loss: 6.4003 - acc: 0.598 - ETA: 1:20 - loss: 6.4008 - acc: 0.598 - ETA: 1:20 - loss: 6.4003 - acc: 0.598 - ETA: 1:20 - loss: 6.4004 - acc: 0.598 - ETA: 1:20 - loss: 6.4005 - acc: 0.598 - ETA: 1:20 - loss: 6.4001 - acc: 0.598 - ETA: 1:19 - loss: 6.4004 - acc: 0.598 - ETA: 1:19 - loss: 6.3998 - acc: 0.598 - ETA: 1:19 - loss: 6.4006 - acc: 0.598 - ETA: 1:19 - loss: 6.4006 - acc: 0.598 - ETA: 1:19 - loss: 6.4006 - acc: 0.598 - ETA: 1:19 - loss: 6.4006 - acc: 0.598 - ETA: 1:19 - loss: 6.4007 - acc: 0.598 - ETA: 1:19 - loss: 6.4008 - acc: 0.598 - ETA: 1:19 - loss: 6.4010 - acc: 0.598 - ETA: 1:19 - loss: 6.4016 - acc: 0.598 - ETA: 1:19 - loss: 6.4026 - acc: 0.598 - ETA: 1:19 - loss: 6.4023 - acc: 0.598 - ETA: 1:19 - loss: 6.4018 - acc: 0.598 - ETA: 1:18 - loss: 6.4018 - acc: 0.598 - ETA: 1:18 - loss: 6.4019 - acc: 0.598 - ETA: 1:18 - loss: 6.4016 - acc: 0.598 - ETA: 1:18 - loss: 6.4017 - acc: 0.598 - ETA: 1:18 - loss: 6.4020 - acc: 0.598 - ETA: 1:18 - loss: 6.4025 - acc: 0.598 - ETA: 1:18 - loss: 6.4024 - acc: 0.598 - ETA: 1:18 - loss: 6.4026 - acc: 0.598 - ETA: 1:18 - loss: 6.4028 - acc: 0.598 - ETA: 1:18 - loss: 6.4026 - acc: 0.598 - ETA: 1:18 - loss: 6.4025 - acc: 0.598 - ETA: 1:17 - loss: 6.4025 - acc: 0.598 - ETA: 1:17 - loss: 6.4027 - acc: 0.598 - ETA: 1:17 - loss: 6.4031 - acc: 0.598 - ETA: 1:17 - loss: 6.4030 - acc: 0.598 - ETA: 1:17 - loss: 6.4027 - acc: 0.598 - ETA: 1:17 - loss: 6.4028 - acc: 0.598 - ETA: 1:17 - loss: 6.4029 - acc: 0.598 - ETA: 1:17 - loss: 6.4035 - acc: 0.598 - ETA: 1:16 - loss: 6.4034 - acc: 0.598 - ETA: 1:16 - loss: 6.4033 - acc: 0.598 - ETA: 1:16 - loss: 6.4037 - acc: 0.598 - ETA: 1:16 - loss: 6.4036 - acc: 0.598 - ETA: 1:16 - loss: 6.4035 - acc: 0.598 - ETA: 1:16 - loss: 6.4034 - acc: 0.598 - ETA: 1:16 - loss: 6.4039 - acc: 0.598 - ETA: 1:16 - loss: 6.4038 - acc: 0.598 - ETA: 1:16 - loss: 6.4032 - acc: 0.598 - ETA: 1:16 - loss: 6.4034 - acc: 0.598 - ETA: 1:16 - loss: 6.4043 - acc: 0.598 - ETA: 1:15 - loss: 6.4051 - acc: 0.598 - ETA: 1:15 - loss: 6.4050 - acc: 0.598 - ETA: 1:15 - loss: 6.4053 - acc: 0.598 - ETA: 1:15 - loss: 6.4054 - acc: 0.598 - ETA: 1:15 - loss: 6.4054 - acc: 0.598 - ETA: 1:15 - loss: 6.4055 - acc: 0.598 - ETA: 1:15 - loss: 6.4055 - acc: 0.598 - ETA: 1:15 - loss: 6.4056 - acc: 0.598 - ETA: 1:15 - loss: 6.4049 - acc: 0.598 - ETA: 1:15 - loss: 6.4048 - acc: 0.598 - ETA: 1:14 - loss: 6.4048 - acc: 0.598 - ETA: 1:14 - loss: 6.4051 - acc: 0.598 - ETA: 1:14 - loss: 6.4053 - acc: 0.598 - ETA: 1:14 - loss: 6.4051 - acc: 0.598 - ETA: 1:14 - loss: 6.4051 - acc: 0.598 - ETA: 1:14 - loss: 6.4051 - acc: 0.598 - ETA: 1:14 - loss: 6.4047 - acc: 0.598 - ETA: 1:14 - loss: 6.4050 - acc: 0.598 - ETA: 1:14 - loss: 6.4053 - acc: 0.598 - ETA: 1:14 - loss: 6.4050 - acc: 0.598 - ETA: 1:14 - loss: 6.4048 - acc: 0.598 - ETA: 1:13 - loss: 6.4052 - acc: 0.598 - ETA: 1:13 - loss: 6.4056 - acc: 0.598 - ETA: 1:13 - loss: 6.4057 - acc: 0.598 - ETA: 1:13 - loss: 6.4059 - acc: 0.598 - ETA: 1:13 - loss: 6.4061 - acc: 0.598 - ETA: 1:13 - loss: 6.4056 - acc: 0.598 - ETA: 1:13 - loss: 6.4053 - acc: 0.598 - ETA: 1:13 - loss: 6.4053 - acc: 0.598 - ETA: 1:13 - loss: 6.4056 - acc: 0.598 - ETA: 1:13 - loss: 6.4053 - acc: 0.598 - ETA: 1:13 - loss: 6.4055 - acc: 0.598 - ETA: 1:13 - loss: 6.4051 - acc: 0.598 - ETA: 1:12 - loss: 6.4049 - acc: 0.598 - ETA: 1:12 - loss: 6.4046 - acc: 0.598 - ETA: 1:12 - loss: 6.4043 - acc: 0.598 - ETA: 1:12 - loss: 6.4044 - acc: 0.598 - ETA: 1:12 - loss: 6.4048 - acc: 0.598 - ETA: 1:12 - loss: 6.4049 - acc: 0.598 - ETA: 1:12 - loss: 6.4052 - acc: 0.598 - ETA: 1:12 - loss: 6.4052 - acc: 0.598 - ETA: 1:12 - loss: 6.4050 - acc: 0.598 - ETA: 1:12 - loss: 6.4051 - acc: 0.598 - ETA: 1:11 - loss: 6.4055 - acc: 0.598 - ETA: 1:11 - loss: 6.4056 - acc: 0.598 - ETA: 1:11 - loss: 6.4056 - acc: 0.598 - ETA: 1:11 - loss: 6.4056 - acc: 0.598 - ETA: 1:11 - loss: 6.4057 - acc: 0.598 - ETA: 1:11 - loss: 6.4052 - acc: 0.598 - ETA: 1:11 - loss: 6.4051 - acc: 0.598 - ETA: 1:11 - loss: 6.4051 - acc: 0.598 - ETA: 1:11 - loss: 6.4054 - acc: 0.598 - ETA: 1:11 - loss: 6.4049 - acc: 0.598 - ETA: 1:11 - loss: 6.4050 - acc: 0.598 - ETA: 1:11 - loss: 6.4053 - acc: 0.598 - ETA: 1:11 - loss: 6.4052 - acc: 0.598 - ETA: 1:10 - loss: 6.4049 - acc: 0.598 - ETA: 1:10 - loss: 6.4048 - acc: 0.598 - ETA: 1:10 - loss: 6.4047 - acc: 0.598 - ETA: 1:10 - loss: 6.4047 - acc: 0.598 - ETA: 1:10 - loss: 6.4048 - acc: 0.598 - ETA: 1:10 - loss: 6.4048 - acc: 0.598 - ETA: 1:10 - loss: 6.4047 - acc: 0.598 - ETA: 1:09 - loss: 6.4048 - acc: 0.598 - ETA: 1:09 - loss: 6.4046 - acc: 0.598 - ETA: 1:09 - loss: 6.4045 - acc: 0.598 - ETA: 1:09 - loss: 6.4043 - acc: 0.598 - ETA: 1:09 - loss: 6.4038 - acc: 0.598 - ETA: 1:09 - loss: 6.4034 - acc: 0.598 - ETA: 1:09 - loss: 6.4033 - acc: 0.598 - ETA: 1:09 - loss: 6.4035 - acc: 0.598 - ETA: 1:09 - loss: 6.4034 - acc: 0.598 - ETA: 1:09 - loss: 6.4037 - acc: 0.598 - ETA: 1:09 - loss: 6.4037 - acc: 0.598 - ETA: 1:09 - loss: 6.4032 - acc: 0.598 - ETA: 1:08 - loss: 6.4033 - acc: 0.598 - ETA: 1:08 - loss: 6.4028 - acc: 0.5984"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "631168/969231 [==================>...........] - ETA: 1:08 - loss: 6.4029 - acc: 0.598 - ETA: 1:08 - loss: 6.4026 - acc: 0.598 - ETA: 1:08 - loss: 6.4021 - acc: 0.598 - ETA: 1:08 - loss: 6.4021 - acc: 0.598 - ETA: 1:08 - loss: 6.4019 - acc: 0.598 - ETA: 1:08 - loss: 6.4020 - acc: 0.598 - ETA: 1:08 - loss: 6.4019 - acc: 0.598 - ETA: 1:08 - loss: 6.4014 - acc: 0.598 - ETA: 1:08 - loss: 6.4010 - acc: 0.598 - ETA: 1:08 - loss: 6.4007 - acc: 0.598 - ETA: 1:07 - loss: 6.4008 - acc: 0.598 - ETA: 1:07 - loss: 6.4009 - acc: 0.598 - ETA: 1:07 - loss: 6.4004 - acc: 0.598 - ETA: 1:07 - loss: 6.4006 - acc: 0.598 - ETA: 1:07 - loss: 6.4006 - acc: 0.598 - ETA: 1:07 - loss: 6.4007 - acc: 0.598 - ETA: 1:07 - loss: 6.4009 - acc: 0.598 - ETA: 1:07 - loss: 6.4011 - acc: 0.598 - ETA: 1:07 - loss: 6.4007 - acc: 0.598 - ETA: 1:07 - loss: 6.4004 - acc: 0.598 - ETA: 1:07 - loss: 6.4004 - acc: 0.598 - ETA: 1:07 - loss: 6.4003 - acc: 0.598 - ETA: 1:06 - loss: 6.4002 - acc: 0.598 - ETA: 1:06 - loss: 6.4003 - acc: 0.598 - ETA: 1:06 - loss: 6.3999 - acc: 0.598 - ETA: 1:06 - loss: 6.3997 - acc: 0.598 - ETA: 1:06 - loss: 6.3998 - acc: 0.598 - ETA: 1:06 - loss: 6.3995 - acc: 0.598 - ETA: 1:06 - loss: 6.3996 - acc: 0.598 - ETA: 1:06 - loss: 6.3997 - acc: 0.598 - ETA: 1:06 - loss: 6.3997 - acc: 0.598 - ETA: 1:06 - loss: 6.3995 - acc: 0.598 - ETA: 1:06 - loss: 6.3993 - acc: 0.598 - ETA: 1:06 - loss: 6.3993 - acc: 0.598 - ETA: 1:06 - loss: 6.3992 - acc: 0.598 - ETA: 1:05 - loss: 6.3990 - acc: 0.598 - ETA: 1:05 - loss: 6.3987 - acc: 0.598 - ETA: 1:05 - loss: 6.3989 - acc: 0.598 - ETA: 1:05 - loss: 6.3990 - acc: 0.598 - ETA: 1:05 - loss: 6.3992 - acc: 0.598 - ETA: 1:05 - loss: 6.3990 - acc: 0.598 - ETA: 1:05 - loss: 6.3988 - acc: 0.598 - ETA: 1:05 - loss: 6.3990 - acc: 0.598 - ETA: 1:05 - loss: 6.3988 - acc: 0.598 - ETA: 1:04 - loss: 6.3990 - acc: 0.598 - ETA: 1:04 - loss: 6.3989 - acc: 0.598 - ETA: 1:04 - loss: 6.3987 - acc: 0.598 - ETA: 1:04 - loss: 6.3990 - acc: 0.598 - ETA: 1:04 - loss: 6.3987 - acc: 0.598 - ETA: 1:04 - loss: 6.3989 - acc: 0.598 - ETA: 1:04 - loss: 6.3984 - acc: 0.598 - ETA: 1:04 - loss: 6.3984 - acc: 0.598 - ETA: 1:04 - loss: 6.3985 - acc: 0.598 - ETA: 1:04 - loss: 6.3982 - acc: 0.598 - ETA: 1:04 - loss: 6.3982 - acc: 0.598 - ETA: 1:04 - loss: 6.3985 - acc: 0.598 - ETA: 1:03 - loss: 6.3978 - acc: 0.598 - ETA: 1:03 - loss: 6.3978 - acc: 0.598 - ETA: 1:03 - loss: 6.3981 - acc: 0.598 - ETA: 1:03 - loss: 6.3980 - acc: 0.598 - ETA: 1:03 - loss: 6.3983 - acc: 0.598 - ETA: 1:03 - loss: 6.3985 - acc: 0.598 - ETA: 1:03 - loss: 6.3983 - acc: 0.598 - ETA: 1:03 - loss: 6.3983 - acc: 0.598 - ETA: 1:03 - loss: 6.3983 - acc: 0.598 - ETA: 1:03 - loss: 6.3980 - acc: 0.598 - ETA: 1:03 - loss: 6.3980 - acc: 0.598 - ETA: 1:03 - loss: 6.3977 - acc: 0.598 - ETA: 1:03 - loss: 6.3976 - acc: 0.598 - ETA: 1:03 - loss: 6.3979 - acc: 0.598 - ETA: 1:03 - loss: 6.3983 - acc: 0.598 - ETA: 1:03 - loss: 6.3983 - acc: 0.598 - ETA: 1:03 - loss: 6.3985 - acc: 0.598 - ETA: 1:03 - loss: 6.3986 - acc: 0.598 - ETA: 1:03 - loss: 6.3983 - acc: 0.598 - ETA: 1:03 - loss: 6.3985 - acc: 0.598 - ETA: 1:03 - loss: 6.3984 - acc: 0.598 - ETA: 1:03 - loss: 6.3983 - acc: 0.598 - ETA: 1:03 - loss: 6.3986 - acc: 0.598 - ETA: 1:03 - loss: 6.3986 - acc: 0.598 - ETA: 1:03 - loss: 6.3988 - acc: 0.598 - ETA: 1:03 - loss: 6.3988 - acc: 0.598 - ETA: 1:03 - loss: 6.3985 - acc: 0.598 - ETA: 1:03 - loss: 6.3987 - acc: 0.598 - ETA: 1:03 - loss: 6.3985 - acc: 0.598 - ETA: 1:03 - loss: 6.3988 - acc: 0.598 - ETA: 1:03 - loss: 6.3987 - acc: 0.598 - ETA: 1:03 - loss: 6.3990 - acc: 0.598 - ETA: 1:03 - loss: 6.3990 - acc: 0.598 - ETA: 1:03 - loss: 6.3990 - acc: 0.598 - ETA: 1:03 - loss: 6.3993 - acc: 0.598 - ETA: 1:03 - loss: 6.3992 - acc: 0.598 - ETA: 1:03 - loss: 6.3994 - acc: 0.598 - ETA: 1:03 - loss: 6.3995 - acc: 0.598 - ETA: 1:03 - loss: 6.3996 - acc: 0.598 - ETA: 1:03 - loss: 6.3993 - acc: 0.598 - ETA: 1:03 - loss: 6.3993 - acc: 0.598 - ETA: 1:03 - loss: 6.3992 - acc: 0.598 - ETA: 1:03 - loss: 6.3992 - acc: 0.598 - ETA: 1:03 - loss: 6.3991 - acc: 0.598 - ETA: 1:03 - loss: 6.3988 - acc: 0.598 - ETA: 1:03 - loss: 6.3989 - acc: 0.598 - ETA: 1:03 - loss: 6.3989 - acc: 0.598 - ETA: 1:03 - loss: 6.3991 - acc: 0.598 - ETA: 1:02 - loss: 6.3994 - acc: 0.598 - ETA: 1:02 - loss: 6.3994 - acc: 0.598 - ETA: 1:02 - loss: 6.3995 - acc: 0.598 - ETA: 1:02 - loss: 6.3993 - acc: 0.598 - ETA: 1:02 - loss: 6.3997 - acc: 0.598 - ETA: 1:02 - loss: 6.3996 - acc: 0.598 - ETA: 1:02 - loss: 6.3997 - acc: 0.598 - ETA: 1:02 - loss: 6.3997 - acc: 0.598 - ETA: 1:02 - loss: 6.3997 - acc: 0.598 - ETA: 1:02 - loss: 6.3997 - acc: 0.598 - ETA: 1:02 - loss: 6.3997 - acc: 0.598 - ETA: 1:02 - loss: 6.4000 - acc: 0.598 - ETA: 1:02 - loss: 6.3998 - acc: 0.598 - ETA: 1:02 - loss: 6.4000 - acc: 0.598 - ETA: 1:02 - loss: 6.3999 - acc: 0.598 - ETA: 1:02 - loss: 6.3996 - acc: 0.598 - ETA: 1:02 - loss: 6.3998 - acc: 0.598 - ETA: 1:02 - loss: 6.3996 - acc: 0.598 - ETA: 1:02 - loss: 6.4000 - acc: 0.598 - ETA: 1:02 - loss: 6.4003 - acc: 0.598 - ETA: 1:02 - loss: 6.4003 - acc: 0.598 - ETA: 1:02 - loss: 6.4003 - acc: 0.598 - ETA: 1:02 - loss: 6.4005 - acc: 0.598 - ETA: 1:02 - loss: 6.4007 - acc: 0.598 - ETA: 1:02 - loss: 6.4003 - acc: 0.598 - ETA: 1:01 - loss: 6.4008 - acc: 0.598 - ETA: 1:01 - loss: 6.4009 - acc: 0.598 - ETA: 1:01 - loss: 6.4007 - acc: 0.598 - ETA: 1:01 - loss: 6.4013 - acc: 0.598 - ETA: 1:01 - loss: 6.4012 - acc: 0.598 - ETA: 1:01 - loss: 6.4009 - acc: 0.598 - ETA: 1:01 - loss: 6.4015 - acc: 0.598 - ETA: 1:01 - loss: 6.4013 - acc: 0.598 - ETA: 1:01 - loss: 6.4011 - acc: 0.598 - ETA: 1:01 - loss: 6.4014 - acc: 0.598 - ETA: 1:01 - loss: 6.4016 - acc: 0.598 - ETA: 1:01 - loss: 6.4017 - acc: 0.598 - ETA: 1:01 - loss: 6.4016 - acc: 0.598 - ETA: 1:01 - loss: 6.4018 - acc: 0.598 - ETA: 1:01 - loss: 6.4020 - acc: 0.598 - ETA: 1:01 - loss: 6.4017 - acc: 0.598 - ETA: 1:01 - loss: 6.4020 - acc: 0.598 - ETA: 1:01 - loss: 6.4015 - acc: 0.598 - ETA: 1:01 - loss: 6.4015 - acc: 0.598 - ETA: 1:01 - loss: 6.4016 - acc: 0.598 - ETA: 1:01 - loss: 6.4014 - acc: 0.598 - ETA: 1:01 - loss: 6.4015 - acc: 0.598 - ETA: 1:01 - loss: 6.4013 - acc: 0.598 - ETA: 1:01 - loss: 6.4017 - acc: 0.598 - ETA: 1:01 - loss: 6.4020 - acc: 0.598 - ETA: 1:01 - loss: 6.4018 - acc: 0.598 - ETA: 1:00 - loss: 6.4020 - acc: 0.598 - ETA: 1:00 - loss: 6.4017 - acc: 0.598 - ETA: 1:00 - loss: 6.4016 - acc: 0.598 - ETA: 1:00 - loss: 6.4018 - acc: 0.598 - ETA: 1:00 - loss: 6.4022 - acc: 0.598 - ETA: 1:00 - loss: 6.4021 - acc: 0.598 - ETA: 1:00 - loss: 6.4019 - acc: 0.598 - ETA: 1:00 - loss: 6.4017 - acc: 0.598 - ETA: 1:00 - loss: 6.4016 - acc: 0.598 - ETA: 1:00 - loss: 6.4019 - acc: 0.598 - ETA: 1:00 - loss: 6.4018 - acc: 0.598 - ETA: 1:00 - loss: 6.4020 - acc: 0.598 - ETA: 1:00 - loss: 6.4019 - acc: 0.598 - ETA: 1:00 - loss: 6.4020 - acc: 0.598 - ETA: 1:00 - loss: 6.4019 - acc: 0.598 - ETA: 1:00 - loss: 6.4017 - acc: 0.598 - ETA: 1:00 - loss: 6.4018 - acc: 0.598 - ETA: 1:00 - loss: 6.4017 - acc: 0.598 - ETA: 1:00 - loss: 6.4014 - acc: 0.598 - ETA: 1:00 - loss: 6.4011 - acc: 0.598 - ETA: 1:00 - loss: 6.4007 - acc: 0.598 - ETA: 1:00 - loss: 6.4006 - acc: 0.598 - ETA: 1:00 - loss: 6.4009 - acc: 0.598 - ETA: 1:00 - loss: 6.4006 - acc: 0.598 - ETA: 1:00 - loss: 6.4009 - acc: 0.598 - ETA: 1:00 - loss: 6.4007 - acc: 0.598 - ETA: 1:00 - loss: 6.4006 - acc: 0.598 - ETA: 1:00 - loss: 6.4007 - acc: 0.598 - ETA: 1:00 - loss: 6.4008 - acc: 0.598 - ETA: 59s - loss: 6.4008 - acc: 0.598 - ETA: 59s - loss: 6.4006 - acc: 0.59 - ETA: 59s - loss: 6.4005 - acc: 0.59 - ETA: 59s - loss: 6.4008 - acc: 0.59 - ETA: 59s - loss: 6.4004 - acc: 0.59 - ETA: 59s - loss: 6.4006 - acc: 0.59 - ETA: 59s - loss: 6.4008 - acc: 0.59 - ETA: 59s - loss: 6.4008 - acc: 0.59 - ETA: 59s - loss: 6.4011 - acc: 0.59 - ETA: 59s - loss: 6.4008 - acc: 0.59 - ETA: 59s - loss: 6.4007 - acc: 0.59 - ETA: 59s - loss: 6.4005 - acc: 0.59 - ETA: 59s - loss: 6.4007 - acc: 0.59 - ETA: 59s - loss: 6.4010 - acc: 0.59 - ETA: 59s - loss: 6.4012 - acc: 0.59 - ETA: 59s - loss: 6.4012 - acc: 0.59 - ETA: 59s - loss: 6.4013 - acc: 0.59 - ETA: 59s - loss: 6.4016 - acc: 0.59 - ETA: 59s - loss: 6.4017 - acc: 0.59 - ETA: 59s - loss: 6.4018 - acc: 0.59 - ETA: 59s - loss: 6.4018 - acc: 0.5984"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "689152/969231 [====================>.........] - ETA: 59s - loss: 6.4017 - acc: 0.59 - ETA: 59s - loss: 6.4015 - acc: 0.59 - ETA: 58s - loss: 6.4012 - acc: 0.59 - ETA: 58s - loss: 6.4012 - acc: 0.59 - ETA: 58s - loss: 6.4009 - acc: 0.59 - ETA: 58s - loss: 6.4008 - acc: 0.59 - ETA: 58s - loss: 6.4009 - acc: 0.59 - ETA: 58s - loss: 6.4007 - acc: 0.59 - ETA: 58s - loss: 6.4007 - acc: 0.59 - ETA: 58s - loss: 6.4007 - acc: 0.59 - ETA: 58s - loss: 6.4006 - acc: 0.59 - ETA: 58s - loss: 6.4007 - acc: 0.59 - ETA: 58s - loss: 6.4002 - acc: 0.59 - ETA: 58s - loss: 6.4002 - acc: 0.59 - ETA: 58s - loss: 6.4006 - acc: 0.59 - ETA: 58s - loss: 6.4006 - acc: 0.59 - ETA: 58s - loss: 6.4005 - acc: 0.59 - ETA: 58s - loss: 6.4004 - acc: 0.59 - ETA: 58s - loss: 6.4003 - acc: 0.59 - ETA: 58s - loss: 6.4002 - acc: 0.59 - ETA: 58s - loss: 6.4001 - acc: 0.59 - ETA: 58s - loss: 6.3997 - acc: 0.59 - ETA: 58s - loss: 6.3999 - acc: 0.59 - ETA: 57s - loss: 6.4003 - acc: 0.59 - ETA: 57s - loss: 6.4003 - acc: 0.59 - ETA: 57s - loss: 6.4003 - acc: 0.59 - ETA: 57s - loss: 6.4004 - acc: 0.59 - ETA: 57s - loss: 6.4002 - acc: 0.59 - ETA: 57s - loss: 6.4002 - acc: 0.59 - ETA: 57s - loss: 6.4004 - acc: 0.59 - ETA: 57s - loss: 6.4002 - acc: 0.59 - ETA: 57s - loss: 6.4002 - acc: 0.59 - ETA: 57s - loss: 6.4001 - acc: 0.59 - ETA: 57s - loss: 6.3999 - acc: 0.59 - ETA: 57s - loss: 6.3998 - acc: 0.59 - ETA: 57s - loss: 6.4000 - acc: 0.59 - ETA: 57s - loss: 6.4000 - acc: 0.59 - ETA: 57s - loss: 6.4000 - acc: 0.59 - ETA: 57s - loss: 6.3999 - acc: 0.59 - ETA: 57s - loss: 6.4000 - acc: 0.59 - ETA: 57s - loss: 6.3998 - acc: 0.59 - ETA: 57s - loss: 6.3996 - acc: 0.59 - ETA: 57s - loss: 6.3996 - acc: 0.59 - ETA: 57s - loss: 6.3996 - acc: 0.59 - ETA: 57s - loss: 6.3994 - acc: 0.59 - ETA: 57s - loss: 6.3999 - acc: 0.59 - ETA: 57s - loss: 6.3998 - acc: 0.59 - ETA: 56s - loss: 6.4003 - acc: 0.59 - ETA: 56s - loss: 6.4002 - acc: 0.59 - ETA: 56s - loss: 6.4005 - acc: 0.59 - ETA: 56s - loss: 6.4006 - acc: 0.59 - ETA: 56s - loss: 6.4008 - acc: 0.59 - ETA: 56s - loss: 6.4008 - acc: 0.59 - ETA: 56s - loss: 6.4009 - acc: 0.59 - ETA: 56s - loss: 6.4008 - acc: 0.59 - ETA: 56s - loss: 6.4010 - acc: 0.59 - ETA: 56s - loss: 6.4009 - acc: 0.59 - ETA: 56s - loss: 6.4012 - acc: 0.59 - ETA: 56s - loss: 6.4011 - acc: 0.59 - ETA: 56s - loss: 6.4009 - acc: 0.59 - ETA: 56s - loss: 6.4008 - acc: 0.59 - ETA: 56s - loss: 6.4004 - acc: 0.59 - ETA: 56s - loss: 6.4004 - acc: 0.59 - ETA: 56s - loss: 6.4002 - acc: 0.59 - ETA: 56s - loss: 6.4002 - acc: 0.59 - ETA: 56s - loss: 6.4004 - acc: 0.59 - ETA: 56s - loss: 6.4006 - acc: 0.59 - ETA: 56s - loss: 6.4005 - acc: 0.59 - ETA: 56s - loss: 6.4006 - acc: 0.59 - ETA: 56s - loss: 6.4007 - acc: 0.59 - ETA: 56s - loss: 6.4007 - acc: 0.59 - ETA: 56s - loss: 6.4007 - acc: 0.59 - ETA: 55s - loss: 6.4007 - acc: 0.59 - ETA: 55s - loss: 6.4008 - acc: 0.59 - ETA: 55s - loss: 6.4010 - acc: 0.59 - ETA: 55s - loss: 6.4015 - acc: 0.59 - ETA: 55s - loss: 6.4012 - acc: 0.59 - ETA: 55s - loss: 6.4013 - acc: 0.59 - ETA: 55s - loss: 6.4016 - acc: 0.59 - ETA: 55s - loss: 6.4013 - acc: 0.59 - ETA: 55s - loss: 6.4014 - acc: 0.59 - ETA: 55s - loss: 6.4015 - acc: 0.59 - ETA: 55s - loss: 6.4014 - acc: 0.59 - ETA: 55s - loss: 6.4012 - acc: 0.59 - ETA: 55s - loss: 6.4012 - acc: 0.59 - ETA: 55s - loss: 6.4014 - acc: 0.59 - ETA: 55s - loss: 6.4013 - acc: 0.59 - ETA: 55s - loss: 6.4013 - acc: 0.59 - ETA: 55s - loss: 6.4014 - acc: 0.59 - ETA: 55s - loss: 6.4016 - acc: 0.59 - ETA: 55s - loss: 6.4017 - acc: 0.59 - ETA: 55s - loss: 6.4016 - acc: 0.59 - ETA: 55s - loss: 6.4015 - acc: 0.59 - ETA: 55s - loss: 6.4015 - acc: 0.59 - ETA: 55s - loss: 6.4019 - acc: 0.59 - ETA: 55s - loss: 6.4019 - acc: 0.59 - ETA: 55s - loss: 6.4019 - acc: 0.59 - ETA: 55s - loss: 6.4020 - acc: 0.59 - ETA: 55s - loss: 6.4018 - acc: 0.59 - ETA: 55s - loss: 6.4018 - acc: 0.59 - ETA: 55s - loss: 6.4017 - acc: 0.59 - ETA: 54s - loss: 6.4017 - acc: 0.59 - ETA: 54s - loss: 6.4013 - acc: 0.59 - ETA: 54s - loss: 6.4013 - acc: 0.59 - ETA: 54s - loss: 6.4014 - acc: 0.59 - ETA: 54s - loss: 6.4016 - acc: 0.59 - ETA: 54s - loss: 6.4016 - acc: 0.59 - ETA: 54s - loss: 6.4017 - acc: 0.59 - ETA: 54s - loss: 6.4018 - acc: 0.59 - ETA: 54s - loss: 6.4020 - acc: 0.59 - ETA: 54s - loss: 6.4015 - acc: 0.59 - ETA: 54s - loss: 6.4016 - acc: 0.59 - ETA: 54s - loss: 6.4018 - acc: 0.59 - ETA: 54s - loss: 6.4021 - acc: 0.59 - ETA: 54s - loss: 6.4020 - acc: 0.59 - ETA: 54s - loss: 6.4022 - acc: 0.59 - ETA: 54s - loss: 6.4021 - acc: 0.59 - ETA: 54s - loss: 6.4020 - acc: 0.59 - ETA: 54s - loss: 6.4021 - acc: 0.59 - ETA: 54s - loss: 6.4021 - acc: 0.59 - ETA: 54s - loss: 6.4021 - acc: 0.59 - ETA: 54s - loss: 6.4022 - acc: 0.59 - ETA: 54s - loss: 6.4019 - acc: 0.59 - ETA: 54s - loss: 6.4018 - acc: 0.59 - ETA: 54s - loss: 6.4017 - acc: 0.59 - ETA: 53s - loss: 6.4014 - acc: 0.59 - ETA: 53s - loss: 6.4015 - acc: 0.59 - ETA: 53s - loss: 6.4013 - acc: 0.59 - ETA: 53s - loss: 6.4014 - acc: 0.59 - ETA: 53s - loss: 6.4016 - acc: 0.59 - ETA: 53s - loss: 6.4015 - acc: 0.59 - ETA: 53s - loss: 6.4016 - acc: 0.59 - ETA: 53s - loss: 6.4017 - acc: 0.59 - ETA: 53s - loss: 6.4016 - acc: 0.59 - ETA: 53s - loss: 6.4015 - acc: 0.59 - ETA: 53s - loss: 6.4014 - acc: 0.59 - ETA: 53s - loss: 6.4013 - acc: 0.59 - ETA: 53s - loss: 6.4011 - acc: 0.59 - ETA: 53s - loss: 6.4012 - acc: 0.59 - ETA: 53s - loss: 6.4012 - acc: 0.59 - ETA: 53s - loss: 6.4011 - acc: 0.59 - ETA: 53s - loss: 6.4012 - acc: 0.59 - ETA: 53s - loss: 6.4012 - acc: 0.59 - ETA: 53s - loss: 6.4007 - acc: 0.59 - ETA: 53s - loss: 6.4007 - acc: 0.59 - ETA: 52s - loss: 6.4006 - acc: 0.59 - ETA: 52s - loss: 6.4003 - acc: 0.59 - ETA: 52s - loss: 6.4008 - acc: 0.59 - ETA: 52s - loss: 6.4006 - acc: 0.59 - ETA: 52s - loss: 6.4007 - acc: 0.59 - ETA: 52s - loss: 6.4006 - acc: 0.59 - ETA: 52s - loss: 6.4007 - acc: 0.59 - ETA: 52s - loss: 6.4005 - acc: 0.59 - ETA: 52s - loss: 6.4005 - acc: 0.59 - ETA: 52s - loss: 6.4005 - acc: 0.59 - ETA: 52s - loss: 6.4004 - acc: 0.59 - ETA: 52s - loss: 6.4004 - acc: 0.59 - ETA: 52s - loss: 6.4004 - acc: 0.59 - ETA: 52s - loss: 6.4002 - acc: 0.59 - ETA: 52s - loss: 6.4003 - acc: 0.59 - ETA: 52s - loss: 6.4001 - acc: 0.59 - ETA: 52s - loss: 6.4001 - acc: 0.59 - ETA: 52s - loss: 6.3999 - acc: 0.59 - ETA: 52s - loss: 6.3999 - acc: 0.59 - ETA: 52s - loss: 6.3996 - acc: 0.59 - ETA: 52s - loss: 6.3998 - acc: 0.59 - ETA: 52s - loss: 6.3999 - acc: 0.59 - ETA: 52s - loss: 6.3995 - acc: 0.59 - ETA: 52s - loss: 6.3993 - acc: 0.59 - ETA: 52s - loss: 6.3990 - acc: 0.59 - ETA: 52s - loss: 6.3990 - acc: 0.59 - ETA: 52s - loss: 6.3994 - acc: 0.59 - ETA: 52s - loss: 6.3995 - acc: 0.59 - ETA: 52s - loss: 6.3995 - acc: 0.59 - ETA: 52s - loss: 6.3994 - acc: 0.59 - ETA: 52s - loss: 6.3997 - acc: 0.59 - ETA: 52s - loss: 6.3997 - acc: 0.59 - ETA: 52s - loss: 6.3998 - acc: 0.59 - ETA: 51s - loss: 6.3997 - acc: 0.59 - ETA: 51s - loss: 6.3997 - acc: 0.59 - ETA: 51s - loss: 6.3996 - acc: 0.59 - ETA: 51s - loss: 6.3994 - acc: 0.59 - ETA: 51s - loss: 6.3994 - acc: 0.59 - ETA: 51s - loss: 6.3996 - acc: 0.59 - ETA: 51s - loss: 6.3994 - acc: 0.59 - ETA: 51s - loss: 6.3995 - acc: 0.59 - ETA: 51s - loss: 6.3995 - acc: 0.59 - ETA: 51s - loss: 6.3994 - acc: 0.59 - ETA: 51s - loss: 6.3991 - acc: 0.59 - ETA: 51s - loss: 6.3993 - acc: 0.59 - ETA: 51s - loss: 6.3992 - acc: 0.59 - ETA: 51s - loss: 6.3989 - acc: 0.59 - ETA: 51s - loss: 6.3994 - acc: 0.59 - ETA: 51s - loss: 6.3995 - acc: 0.59 - ETA: 51s - loss: 6.3995 - acc: 0.59 - ETA: 51s - loss: 6.3994 - acc: 0.59 - ETA: 51s - loss: 6.3995 - acc: 0.59 - ETA: 51s - loss: 6.3995 - acc: 0.59 - ETA: 51s - loss: 6.3992 - acc: 0.59 - ETA: 51s - loss: 6.3991 - acc: 0.59 - ETA: 50s - loss: 6.3992 - acc: 0.59 - ETA: 50s - loss: 6.3993 - acc: 0.59 - ETA: 50s - loss: 6.3995 - acc: 0.59 - ETA: 50s - loss: 6.3999 - acc: 0.59 - ETA: 50s - loss: 6.4000 - acc: 0.59 - ETA: 50s - loss: 6.3999 - acc: 0.59 - ETA: 50s - loss: 6.3997 - acc: 0.59 - ETA: 50s - loss: 6.4000 - acc: 0.59 - ETA: 50s - loss: 6.4001 - acc: 0.59 - ETA: 50s - loss: 6.4003 - acc: 0.59 - ETA: 50s - loss: 6.4003 - acc: 0.59 - ETA: 50s - loss: 6.4003 - acc: 0.59 - ETA: 50s - loss: 6.4003 - acc: 0.59 - ETA: 50s - loss: 6.4000 - acc: 0.59 - ETA: 50s - loss: 6.4000 - acc: 0.5986"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "743808/969231 [======================>.......] - ETA: 50s - loss: 6.3999 - acc: 0.59 - ETA: 50s - loss: 6.3997 - acc: 0.59 - ETA: 50s - loss: 6.3995 - acc: 0.59 - ETA: 50s - loss: 6.3994 - acc: 0.59 - ETA: 50s - loss: 6.3989 - acc: 0.59 - ETA: 49s - loss: 6.3990 - acc: 0.59 - ETA: 49s - loss: 6.3985 - acc: 0.59 - ETA: 49s - loss: 6.3985 - acc: 0.59 - ETA: 49s - loss: 6.3982 - acc: 0.59 - ETA: 49s - loss: 6.3983 - acc: 0.59 - ETA: 49s - loss: 6.3985 - acc: 0.59 - ETA: 49s - loss: 6.3986 - acc: 0.59 - ETA: 49s - loss: 6.3987 - acc: 0.59 - ETA: 49s - loss: 6.3991 - acc: 0.59 - ETA: 49s - loss: 6.3993 - acc: 0.59 - ETA: 49s - loss: 6.3991 - acc: 0.59 - ETA: 49s - loss: 6.3992 - acc: 0.59 - ETA: 49s - loss: 6.3990 - acc: 0.59 - ETA: 49s - loss: 6.3991 - acc: 0.59 - ETA: 49s - loss: 6.3988 - acc: 0.59 - ETA: 49s - loss: 6.3991 - acc: 0.59 - ETA: 49s - loss: 6.3991 - acc: 0.59 - ETA: 49s - loss: 6.3992 - acc: 0.59 - ETA: 49s - loss: 6.3993 - acc: 0.59 - ETA: 48s - loss: 6.3995 - acc: 0.59 - ETA: 48s - loss: 6.3992 - acc: 0.59 - ETA: 48s - loss: 6.3996 - acc: 0.59 - ETA: 48s - loss: 6.4000 - acc: 0.59 - ETA: 48s - loss: 6.4002 - acc: 0.59 - ETA: 48s - loss: 6.4000 - acc: 0.59 - ETA: 48s - loss: 6.4001 - acc: 0.59 - ETA: 48s - loss: 6.3999 - acc: 0.59 - ETA: 48s - loss: 6.4000 - acc: 0.59 - ETA: 48s - loss: 6.4002 - acc: 0.59 - ETA: 48s - loss: 6.4001 - acc: 0.59 - ETA: 48s - loss: 6.3993 - acc: 0.59 - ETA: 48s - loss: 6.3994 - acc: 0.59 - ETA: 48s - loss: 6.3994 - acc: 0.59 - ETA: 48s - loss: 6.3992 - acc: 0.59 - ETA: 48s - loss: 6.3993 - acc: 0.59 - ETA: 48s - loss: 6.3993 - acc: 0.59 - ETA: 48s - loss: 6.3990 - acc: 0.59 - ETA: 48s - loss: 6.3991 - acc: 0.59 - ETA: 48s - loss: 6.3992 - acc: 0.59 - ETA: 48s - loss: 6.3991 - acc: 0.59 - ETA: 48s - loss: 6.3990 - acc: 0.59 - ETA: 48s - loss: 6.3991 - acc: 0.59 - ETA: 48s - loss: 6.3991 - acc: 0.59 - ETA: 48s - loss: 6.3992 - acc: 0.59 - ETA: 48s - loss: 6.3992 - acc: 0.59 - ETA: 48s - loss: 6.3994 - acc: 0.59 - ETA: 47s - loss: 6.3993 - acc: 0.59 - ETA: 47s - loss: 6.3994 - acc: 0.59 - ETA: 47s - loss: 6.3991 - acc: 0.59 - ETA: 47s - loss: 6.3991 - acc: 0.59 - ETA: 47s - loss: 6.3992 - acc: 0.59 - ETA: 47s - loss: 6.3992 - acc: 0.59 - ETA: 47s - loss: 6.3988 - acc: 0.59 - ETA: 47s - loss: 6.3987 - acc: 0.59 - ETA: 47s - loss: 6.3988 - acc: 0.59 - ETA: 47s - loss: 6.3988 - acc: 0.59 - ETA: 47s - loss: 6.3988 - acc: 0.59 - ETA: 47s - loss: 6.3990 - acc: 0.59 - ETA: 47s - loss: 6.3991 - acc: 0.59 - ETA: 47s - loss: 6.3991 - acc: 0.59 - ETA: 47s - loss: 6.3992 - acc: 0.59 - ETA: 47s - loss: 6.3992 - acc: 0.59 - ETA: 47s - loss: 6.3991 - acc: 0.59 - ETA: 47s - loss: 6.3993 - acc: 0.59 - ETA: 47s - loss: 6.3990 - acc: 0.59 - ETA: 47s - loss: 6.3990 - acc: 0.59 - ETA: 47s - loss: 6.3992 - acc: 0.59 - ETA: 47s - loss: 6.3995 - acc: 0.59 - ETA: 47s - loss: 6.3995 - acc: 0.59 - ETA: 47s - loss: 6.3995 - acc: 0.59 - ETA: 47s - loss: 6.3996 - acc: 0.59 - ETA: 47s - loss: 6.3994 - acc: 0.59 - ETA: 47s - loss: 6.3995 - acc: 0.59 - ETA: 47s - loss: 6.3996 - acc: 0.59 - ETA: 47s - loss: 6.3994 - acc: 0.59 - ETA: 47s - loss: 6.3991 - acc: 0.59 - ETA: 47s - loss: 6.3992 - acc: 0.59 - ETA: 47s - loss: 6.3992 - acc: 0.59 - ETA: 46s - loss: 6.3992 - acc: 0.59 - ETA: 46s - loss: 6.3993 - acc: 0.59 - ETA: 46s - loss: 6.3993 - acc: 0.59 - ETA: 46s - loss: 6.3990 - acc: 0.59 - ETA: 46s - loss: 6.3991 - acc: 0.59 - ETA: 46s - loss: 6.3992 - acc: 0.59 - ETA: 46s - loss: 6.3991 - acc: 0.59 - ETA: 46s - loss: 6.3985 - acc: 0.59 - ETA: 46s - loss: 6.3987 - acc: 0.59 - ETA: 46s - loss: 6.3985 - acc: 0.59 - ETA: 46s - loss: 6.3985 - acc: 0.59 - ETA: 46s - loss: 6.3984 - acc: 0.59 - ETA: 46s - loss: 6.3982 - acc: 0.59 - ETA: 46s - loss: 6.3981 - acc: 0.59 - ETA: 46s - loss: 6.3983 - acc: 0.59 - ETA: 46s - loss: 6.3984 - acc: 0.59 - ETA: 46s - loss: 6.3984 - acc: 0.59 - ETA: 46s - loss: 6.3982 - acc: 0.59 - ETA: 46s - loss: 6.3983 - acc: 0.59 - ETA: 46s - loss: 6.3981 - acc: 0.59 - ETA: 46s - loss: 6.3980 - acc: 0.59 - ETA: 46s - loss: 6.3979 - acc: 0.59 - ETA: 45s - loss: 6.3979 - acc: 0.59 - ETA: 45s - loss: 6.3976 - acc: 0.59 - ETA: 45s - loss: 6.3976 - acc: 0.59 - ETA: 45s - loss: 6.3976 - acc: 0.59 - ETA: 45s - loss: 6.3975 - acc: 0.59 - ETA: 45s - loss: 6.3976 - acc: 0.59 - ETA: 45s - loss: 6.3974 - acc: 0.59 - ETA: 45s - loss: 6.3974 - acc: 0.59 - ETA: 45s - loss: 6.3974 - acc: 0.59 - ETA: 45s - loss: 6.3974 - acc: 0.59 - ETA: 45s - loss: 6.3973 - acc: 0.59 - ETA: 45s - loss: 6.3974 - acc: 0.59 - ETA: 45s - loss: 6.3972 - acc: 0.59 - ETA: 45s - loss: 6.3971 - acc: 0.59 - ETA: 45s - loss: 6.3971 - acc: 0.59 - ETA: 45s - loss: 6.3973 - acc: 0.59 - ETA: 45s - loss: 6.3976 - acc: 0.59 - ETA: 45s - loss: 6.3976 - acc: 0.59 - ETA: 45s - loss: 6.3977 - acc: 0.59 - ETA: 45s - loss: 6.3977 - acc: 0.59 - ETA: 44s - loss: 6.3978 - acc: 0.59 - ETA: 44s - loss: 6.3978 - acc: 0.59 - ETA: 44s - loss: 6.3977 - acc: 0.59 - ETA: 44s - loss: 6.3980 - acc: 0.59 - ETA: 44s - loss: 6.3982 - acc: 0.59 - ETA: 44s - loss: 6.3980 - acc: 0.59 - ETA: 44s - loss: 6.3981 - acc: 0.59 - ETA: 44s - loss: 6.3981 - acc: 0.59 - ETA: 44s - loss: 6.3983 - acc: 0.59 - ETA: 44s - loss: 6.3983 - acc: 0.59 - ETA: 44s - loss: 6.3981 - acc: 0.59 - ETA: 44s - loss: 6.3981 - acc: 0.59 - ETA: 44s - loss: 6.3981 - acc: 0.59 - ETA: 44s - loss: 6.3980 - acc: 0.59 - ETA: 44s - loss: 6.3981 - acc: 0.59 - ETA: 44s - loss: 6.3979 - acc: 0.59 - ETA: 44s - loss: 6.3977 - acc: 0.59 - ETA: 44s - loss: 6.3977 - acc: 0.59 - ETA: 44s - loss: 6.3978 - acc: 0.59 - ETA: 44s - loss: 6.3979 - acc: 0.59 - ETA: 44s - loss: 6.3979 - acc: 0.59 - ETA: 44s - loss: 6.3976 - acc: 0.59 - ETA: 44s - loss: 6.3975 - acc: 0.59 - ETA: 44s - loss: 6.3978 - acc: 0.59 - ETA: 44s - loss: 6.3981 - acc: 0.59 - ETA: 43s - loss: 6.3981 - acc: 0.59 - ETA: 43s - loss: 6.3979 - acc: 0.59 - ETA: 43s - loss: 6.3979 - acc: 0.59 - ETA: 43s - loss: 6.3977 - acc: 0.59 - ETA: 43s - loss: 6.3978 - acc: 0.59 - ETA: 43s - loss: 6.3977 - acc: 0.59 - ETA: 43s - loss: 6.3977 - acc: 0.59 - ETA: 43s - loss: 6.3980 - acc: 0.59 - ETA: 43s - loss: 6.3983 - acc: 0.59 - ETA: 43s - loss: 6.3981 - acc: 0.59 - ETA: 43s - loss: 6.3980 - acc: 0.59 - ETA: 43s - loss: 6.3980 - acc: 0.59 - ETA: 43s - loss: 6.3979 - acc: 0.59 - ETA: 43s - loss: 6.3981 - acc: 0.59 - ETA: 43s - loss: 6.3983 - acc: 0.59 - ETA: 43s - loss: 6.3987 - acc: 0.59 - ETA: 43s - loss: 6.3986 - acc: 0.59 - ETA: 43s - loss: 6.3984 - acc: 0.59 - ETA: 43s - loss: 6.3986 - acc: 0.59 - ETA: 43s - loss: 6.3988 - acc: 0.59 - ETA: 43s - loss: 6.3989 - acc: 0.59 - ETA: 43s - loss: 6.3988 - acc: 0.59 - ETA: 43s - loss: 6.3986 - acc: 0.59 - ETA: 43s - loss: 6.3985 - acc: 0.59 - ETA: 43s - loss: 6.3986 - acc: 0.59 - ETA: 43s - loss: 6.3985 - acc: 0.59 - ETA: 43s - loss: 6.3981 - acc: 0.59 - ETA: 43s - loss: 6.3983 - acc: 0.59 - ETA: 43s - loss: 6.3982 - acc: 0.59 - ETA: 43s - loss: 6.3981 - acc: 0.59 - ETA: 42s - loss: 6.3981 - acc: 0.59 - ETA: 42s - loss: 6.3979 - acc: 0.59 - ETA: 42s - loss: 6.3982 - acc: 0.59 - ETA: 42s - loss: 6.3986 - acc: 0.59 - ETA: 42s - loss: 6.3988 - acc: 0.59 - ETA: 42s - loss: 6.3990 - acc: 0.59 - ETA: 42s - loss: 6.3994 - acc: 0.59 - ETA: 42s - loss: 6.3995 - acc: 0.59 - ETA: 42s - loss: 6.3993 - acc: 0.59 - ETA: 42s - loss: 6.3993 - acc: 0.59 - ETA: 42s - loss: 6.3995 - acc: 0.59 - ETA: 42s - loss: 6.3994 - acc: 0.59 - ETA: 42s - loss: 6.3991 - acc: 0.59 - ETA: 42s - loss: 6.3992 - acc: 0.59 - ETA: 42s - loss: 6.3992 - acc: 0.59 - ETA: 42s - loss: 6.3992 - acc: 0.59 - ETA: 42s - loss: 6.3993 - acc: 0.59 - ETA: 42s - loss: 6.3997 - acc: 0.59 - ETA: 42s - loss: 6.3995 - acc: 0.59 - ETA: 42s - loss: 6.3996 - acc: 0.59 - ETA: 42s - loss: 6.3994 - acc: 0.59 - ETA: 41s - loss: 6.3994 - acc: 0.59 - ETA: 41s - loss: 6.3991 - acc: 0.59 - ETA: 41s - loss: 6.3990 - acc: 0.59 - ETA: 41s - loss: 6.3989 - acc: 0.59 - ETA: 41s - loss: 6.3990 - acc: 0.59 - ETA: 41s - loss: 6.3992 - acc: 0.59 - ETA: 41s - loss: 6.3997 - acc: 0.59 - ETA: 41s - loss: 6.3997 - acc: 0.59 - ETA: 41s - loss: 6.3998 - acc: 0.59 - ETA: 41s - loss: 6.3996 - acc: 0.59 - ETA: 41s - loss: 6.3996 - acc: 0.59 - ETA: 41s - loss: 6.3997 - acc: 0.59 - ETA: 41s - loss: 6.3996 - acc: 0.59 - ETA: 41s - loss: 6.3996 - acc: 0.5986"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "830848/969231 [========================>.....] - ETA: 41s - loss: 6.3995 - acc: 0.59 - ETA: 41s - loss: 6.3995 - acc: 0.59 - ETA: 41s - loss: 6.3993 - acc: 0.59 - ETA: 41s - loss: 6.3993 - acc: 0.59 - ETA: 41s - loss: 6.3993 - acc: 0.59 - ETA: 41s - loss: 6.3993 - acc: 0.59 - ETA: 41s - loss: 6.3993 - acc: 0.59 - ETA: 41s - loss: 6.3992 - acc: 0.59 - ETA: 41s - loss: 6.3992 - acc: 0.59 - ETA: 41s - loss: 6.3991 - acc: 0.59 - ETA: 41s - loss: 6.3990 - acc: 0.59 - ETA: 41s - loss: 6.3991 - acc: 0.59 - ETA: 41s - loss: 6.3991 - acc: 0.59 - ETA: 41s - loss: 6.3993 - acc: 0.59 - ETA: 41s - loss: 6.3997 - acc: 0.59 - ETA: 41s - loss: 6.3998 - acc: 0.59 - ETA: 41s - loss: 6.3999 - acc: 0.59 - ETA: 41s - loss: 6.4000 - acc: 0.59 - ETA: 41s - loss: 6.4002 - acc: 0.59 - ETA: 40s - loss: 6.4006 - acc: 0.59 - ETA: 40s - loss: 6.4009 - acc: 0.59 - ETA: 40s - loss: 6.4008 - acc: 0.59 - ETA: 40s - loss: 6.4008 - acc: 0.59 - ETA: 40s - loss: 6.4005 - acc: 0.59 - ETA: 40s - loss: 6.4006 - acc: 0.59 - ETA: 40s - loss: 6.4003 - acc: 0.59 - ETA: 40s - loss: 6.4005 - acc: 0.59 - ETA: 40s - loss: 6.4005 - acc: 0.59 - ETA: 40s - loss: 6.4005 - acc: 0.59 - ETA: 40s - loss: 6.4007 - acc: 0.59 - ETA: 40s - loss: 6.4009 - acc: 0.59 - ETA: 40s - loss: 6.4010 - acc: 0.59 - ETA: 39s - loss: 6.4012 - acc: 0.59 - ETA: 39s - loss: 6.4009 - acc: 0.59 - ETA: 39s - loss: 6.4012 - acc: 0.59 - ETA: 39s - loss: 6.4010 - acc: 0.59 - ETA: 39s - loss: 6.4007 - acc: 0.59 - ETA: 39s - loss: 6.4007 - acc: 0.59 - ETA: 39s - loss: 6.4009 - acc: 0.59 - ETA: 39s - loss: 6.4007 - acc: 0.59 - ETA: 39s - loss: 6.4007 - acc: 0.59 - ETA: 39s - loss: 6.4004 - acc: 0.59 - ETA: 39s - loss: 6.4005 - acc: 0.59 - ETA: 38s - loss: 6.4006 - acc: 0.59 - ETA: 38s - loss: 6.4007 - acc: 0.59 - ETA: 38s - loss: 6.4007 - acc: 0.59 - ETA: 38s - loss: 6.4011 - acc: 0.59 - ETA: 38s - loss: 6.4014 - acc: 0.59 - ETA: 38s - loss: 6.4012 - acc: 0.59 - ETA: 38s - loss: 6.4010 - acc: 0.59 - ETA: 38s - loss: 6.4010 - acc: 0.59 - ETA: 38s - loss: 6.4010 - acc: 0.59 - ETA: 37s - loss: 6.4006 - acc: 0.59 - ETA: 37s - loss: 6.4005 - acc: 0.59 - ETA: 37s - loss: 6.4004 - acc: 0.59 - ETA: 37s - loss: 6.4004 - acc: 0.59 - ETA: 37s - loss: 6.4007 - acc: 0.59 - ETA: 37s - loss: 6.4008 - acc: 0.59 - ETA: 37s - loss: 6.4006 - acc: 0.59 - ETA: 37s - loss: 6.4010 - acc: 0.59 - ETA: 37s - loss: 6.4013 - acc: 0.59 - ETA: 37s - loss: 6.4012 - acc: 0.59 - ETA: 37s - loss: 6.4015 - acc: 0.59 - ETA: 37s - loss: 6.4014 - acc: 0.59 - ETA: 37s - loss: 6.4013 - acc: 0.59 - ETA: 37s - loss: 6.4011 - acc: 0.59 - ETA: 36s - loss: 6.4012 - acc: 0.59 - ETA: 36s - loss: 6.4010 - acc: 0.59 - ETA: 36s - loss: 6.4009 - acc: 0.59 - ETA: 36s - loss: 6.4010 - acc: 0.59 - ETA: 36s - loss: 6.4011 - acc: 0.59 - ETA: 36s - loss: 6.4012 - acc: 0.59 - ETA: 36s - loss: 6.4013 - acc: 0.59 - ETA: 36s - loss: 6.4009 - acc: 0.59 - ETA: 36s - loss: 6.4013 - acc: 0.59 - ETA: 36s - loss: 6.4013 - acc: 0.59 - ETA: 36s - loss: 6.4016 - acc: 0.59 - ETA: 35s - loss: 6.4015 - acc: 0.59 - ETA: 35s - loss: 6.4012 - acc: 0.59 - ETA: 35s - loss: 6.4012 - acc: 0.59 - ETA: 35s - loss: 6.4016 - acc: 0.59 - ETA: 35s - loss: 6.4016 - acc: 0.59 - ETA: 35s - loss: 6.4016 - acc: 0.59 - ETA: 35s - loss: 6.4017 - acc: 0.59 - ETA: 35s - loss: 6.4018 - acc: 0.59 - ETA: 35s - loss: 6.4020 - acc: 0.59 - ETA: 35s - loss: 6.4020 - acc: 0.59 - ETA: 35s - loss: 6.4016 - acc: 0.59 - ETA: 34s - loss: 6.4010 - acc: 0.59 - ETA: 34s - loss: 6.4013 - acc: 0.59 - ETA: 34s - loss: 6.4014 - acc: 0.59 - ETA: 34s - loss: 6.4013 - acc: 0.59 - ETA: 34s - loss: 6.4011 - acc: 0.59 - ETA: 34s - loss: 6.4012 - acc: 0.59 - ETA: 34s - loss: 6.4008 - acc: 0.59 - ETA: 34s - loss: 6.4012 - acc: 0.59 - ETA: 34s - loss: 6.4014 - acc: 0.59 - ETA: 34s - loss: 6.4015 - acc: 0.59 - ETA: 34s - loss: 6.4015 - acc: 0.59 - ETA: 34s - loss: 6.4017 - acc: 0.59 - ETA: 33s - loss: 6.4018 - acc: 0.59 - ETA: 33s - loss: 6.4019 - acc: 0.59 - ETA: 33s - loss: 6.4018 - acc: 0.59 - ETA: 33s - loss: 6.4018 - acc: 0.59 - ETA: 33s - loss: 6.4018 - acc: 0.59 - ETA: 33s - loss: 6.4018 - acc: 0.59 - ETA: 33s - loss: 6.4022 - acc: 0.59 - ETA: 33s - loss: 6.4022 - acc: 0.59 - ETA: 33s - loss: 6.4022 - acc: 0.59 - ETA: 33s - loss: 6.4019 - acc: 0.59 - ETA: 33s - loss: 6.4020 - acc: 0.59 - ETA: 33s - loss: 6.4018 - acc: 0.59 - ETA: 33s - loss: 6.4021 - acc: 0.59 - ETA: 32s - loss: 6.4020 - acc: 0.59 - ETA: 32s - loss: 6.4022 - acc: 0.59 - ETA: 32s - loss: 6.4019 - acc: 0.59 - ETA: 32s - loss: 6.4019 - acc: 0.59 - ETA: 32s - loss: 6.4018 - acc: 0.59 - ETA: 32s - loss: 6.4017 - acc: 0.59 - ETA: 32s - loss: 6.4016 - acc: 0.59 - ETA: 32s - loss: 6.4016 - acc: 0.59 - ETA: 32s - loss: 6.4012 - acc: 0.59 - ETA: 32s - loss: 6.4014 - acc: 0.59 - ETA: 32s - loss: 6.4014 - acc: 0.59 - ETA: 32s - loss: 6.4013 - acc: 0.59 - ETA: 32s - loss: 6.4014 - acc: 0.59 - ETA: 32s - loss: 6.4013 - acc: 0.59 - ETA: 32s - loss: 6.4014 - acc: 0.59 - ETA: 31s - loss: 6.4013 - acc: 0.59 - ETA: 31s - loss: 6.4015 - acc: 0.59 - ETA: 31s - loss: 6.4017 - acc: 0.59 - ETA: 31s - loss: 6.4017 - acc: 0.59 - ETA: 31s - loss: 6.4019 - acc: 0.59 - ETA: 31s - loss: 6.4017 - acc: 0.59 - ETA: 31s - loss: 6.4017 - acc: 0.59 - ETA: 31s - loss: 6.4016 - acc: 0.59 - ETA: 31s - loss: 6.4019 - acc: 0.59 - ETA: 31s - loss: 6.4022 - acc: 0.59 - ETA: 31s - loss: 6.4023 - acc: 0.59 - ETA: 31s - loss: 6.4022 - acc: 0.59 - ETA: 30s - loss: 6.4023 - acc: 0.59 - ETA: 30s - loss: 6.4024 - acc: 0.59 - ETA: 30s - loss: 6.4023 - acc: 0.59 - ETA: 30s - loss: 6.4025 - acc: 0.59 - ETA: 30s - loss: 6.4024 - acc: 0.59 - ETA: 30s - loss: 6.4023 - acc: 0.59 - ETA: 30s - loss: 6.4023 - acc: 0.59 - ETA: 30s - loss: 6.4021 - acc: 0.59 - ETA: 30s - loss: 6.4023 - acc: 0.59 - ETA: 30s - loss: 6.4024 - acc: 0.59 - ETA: 30s - loss: 6.4025 - acc: 0.59 - ETA: 30s - loss: 6.4024 - acc: 0.59 - ETA: 30s - loss: 6.4023 - acc: 0.59 - ETA: 29s - loss: 6.4019 - acc: 0.59 - ETA: 29s - loss: 6.4020 - acc: 0.59 - ETA: 29s - loss: 6.4021 - acc: 0.59 - ETA: 29s - loss: 6.4025 - acc: 0.59 - ETA: 29s - loss: 6.4024 - acc: 0.59 - ETA: 29s - loss: 6.4025 - acc: 0.59 - ETA: 29s - loss: 6.4027 - acc: 0.59 - ETA: 29s - loss: 6.4029 - acc: 0.59 - ETA: 29s - loss: 6.4029 - acc: 0.59 - ETA: 29s - loss: 6.4027 - acc: 0.59 - ETA: 29s - loss: 6.4025 - acc: 0.59 - ETA: 29s - loss: 6.4030 - acc: 0.59 - ETA: 28s - loss: 6.4029 - acc: 0.59 - ETA: 28s - loss: 6.4032 - acc: 0.59 - ETA: 28s - loss: 6.4031 - acc: 0.59 - ETA: 28s - loss: 6.4031 - acc: 0.59 - ETA: 28s - loss: 6.4032 - acc: 0.59 - ETA: 28s - loss: 6.4032 - acc: 0.59 - ETA: 28s - loss: 6.4032 - acc: 0.59 - ETA: 28s - loss: 6.4031 - acc: 0.59 - ETA: 28s - loss: 6.4030 - acc: 0.59 - ETA: 28s - loss: 6.4029 - acc: 0.59 - ETA: 28s - loss: 6.4028 - acc: 0.59 - ETA: 28s - loss: 6.4028 - acc: 0.59 - ETA: 27s - loss: 6.4029 - acc: 0.59 - ETA: 27s - loss: 6.4027 - acc: 0.59 - ETA: 27s - loss: 6.4026 - acc: 0.59 - ETA: 27s - loss: 6.4026 - acc: 0.59 - ETA: 27s - loss: 6.4026 - acc: 0.59 - ETA: 27s - loss: 6.4027 - acc: 0.59 - ETA: 27s - loss: 6.4025 - acc: 0.59 - ETA: 27s - loss: 6.4023 - acc: 0.59 - ETA: 27s - loss: 6.4026 - acc: 0.59 - ETA: 27s - loss: 6.4025 - acc: 0.59 - ETA: 27s - loss: 6.4028 - acc: 0.59 - ETA: 27s - loss: 6.4031 - acc: 0.59 - ETA: 27s - loss: 6.4028 - acc: 0.59 - ETA: 26s - loss: 6.4031 - acc: 0.59 - ETA: 26s - loss: 6.4030 - acc: 0.59 - ETA: 26s - loss: 6.4031 - acc: 0.59 - ETA: 26s - loss: 6.4033 - acc: 0.59 - ETA: 26s - loss: 6.4034 - acc: 0.59 - ETA: 26s - loss: 6.4035 - acc: 0.59 - ETA: 26s - loss: 6.4035 - acc: 0.59 - ETA: 26s - loss: 6.4037 - acc: 0.59 - ETA: 26s - loss: 6.4037 - acc: 0.59 - ETA: 26s - loss: 6.4035 - acc: 0.59 - ETA: 26s - loss: 6.4033 - acc: 0.59 - ETA: 26s - loss: 6.4034 - acc: 0.59 - ETA: 25s - loss: 6.4036 - acc: 0.59 - ETA: 25s - loss: 6.4034 - acc: 0.59 - ETA: 25s - loss: 6.4034 - acc: 0.59 - ETA: 25s - loss: 6.4036 - acc: 0.59 - ETA: 25s - loss: 6.4035 - acc: 0.59 - ETA: 25s - loss: 6.4039 - acc: 0.59 - ETA: 25s - loss: 6.4039 - acc: 0.59 - ETA: 25s - loss: 6.4040 - acc: 0.59 - ETA: 25s - loss: 6.4039 - acc: 0.59 - ETA: 25s - loss: 6.4039 - acc: 0.59 - ETA: 25s - loss: 6.4039 - acc: 0.59 - ETA: 25s - loss: 6.4039 - acc: 0.59 - ETA: 24s - loss: 6.4041 - acc: 0.5983"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "912640/969231 [===========================>..] - ETA: 24s - loss: 6.4040 - acc: 0.59 - ETA: 24s - loss: 6.4041 - acc: 0.59 - ETA: 24s - loss: 6.4038 - acc: 0.59 - ETA: 24s - loss: 6.4041 - acc: 0.59 - ETA: 24s - loss: 6.4042 - acc: 0.59 - ETA: 24s - loss: 6.4044 - acc: 0.59 - ETA: 24s - loss: 6.4042 - acc: 0.59 - ETA: 24s - loss: 6.4039 - acc: 0.59 - ETA: 24s - loss: 6.4041 - acc: 0.59 - ETA: 24s - loss: 6.4042 - acc: 0.59 - ETA: 24s - loss: 6.4044 - acc: 0.59 - ETA: 24s - loss: 6.4045 - acc: 0.59 - ETA: 23s - loss: 6.4047 - acc: 0.59 - ETA: 23s - loss: 6.4047 - acc: 0.59 - ETA: 23s - loss: 6.4044 - acc: 0.59 - ETA: 23s - loss: 6.4044 - acc: 0.59 - ETA: 23s - loss: 6.4045 - acc: 0.59 - ETA: 23s - loss: 6.4046 - acc: 0.59 - ETA: 23s - loss: 6.4048 - acc: 0.59 - ETA: 23s - loss: 6.4049 - acc: 0.59 - ETA: 23s - loss: 6.4049 - acc: 0.59 - ETA: 23s - loss: 6.4049 - acc: 0.59 - ETA: 23s - loss: 6.4045 - acc: 0.59 - ETA: 23s - loss: 6.4044 - acc: 0.59 - ETA: 23s - loss: 6.4042 - acc: 0.59 - ETA: 23s - loss: 6.4040 - acc: 0.59 - ETA: 22s - loss: 6.4038 - acc: 0.59 - ETA: 22s - loss: 6.4038 - acc: 0.59 - ETA: 22s - loss: 6.4038 - acc: 0.59 - ETA: 22s - loss: 6.4035 - acc: 0.59 - ETA: 22s - loss: 6.4036 - acc: 0.59 - ETA: 22s - loss: 6.4035 - acc: 0.59 - ETA: 22s - loss: 6.4036 - acc: 0.59 - ETA: 22s - loss: 6.4037 - acc: 0.59 - ETA: 22s - loss: 6.4038 - acc: 0.59 - ETA: 22s - loss: 6.4040 - acc: 0.59 - ETA: 22s - loss: 6.4036 - acc: 0.59 - ETA: 22s - loss: 6.4035 - acc: 0.59 - ETA: 22s - loss: 6.4034 - acc: 0.59 - ETA: 22s - loss: 6.4035 - acc: 0.59 - ETA: 21s - loss: 6.4035 - acc: 0.59 - ETA: 21s - loss: 6.4038 - acc: 0.59 - ETA: 21s - loss: 6.4037 - acc: 0.59 - ETA: 21s - loss: 6.4036 - acc: 0.59 - ETA: 21s - loss: 6.4033 - acc: 0.59 - ETA: 21s - loss: 6.4034 - acc: 0.59 - ETA: 21s - loss: 6.4036 - acc: 0.59 - ETA: 21s - loss: 6.4037 - acc: 0.59 - ETA: 21s - loss: 6.4036 - acc: 0.59 - ETA: 21s - loss: 6.4036 - acc: 0.59 - ETA: 21s - loss: 6.4032 - acc: 0.59 - ETA: 21s - loss: 6.4036 - acc: 0.59 - ETA: 21s - loss: 6.4033 - acc: 0.59 - ETA: 20s - loss: 6.4033 - acc: 0.59 - ETA: 20s - loss: 6.4034 - acc: 0.59 - ETA: 20s - loss: 6.4033 - acc: 0.59 - ETA: 20s - loss: 6.4030 - acc: 0.59 - ETA: 20s - loss: 6.4028 - acc: 0.59 - ETA: 20s - loss: 6.4030 - acc: 0.59 - ETA: 20s - loss: 6.4030 - acc: 0.59 - ETA: 20s - loss: 6.4028 - acc: 0.59 - ETA: 20s - loss: 6.4028 - acc: 0.59 - ETA: 20s - loss: 6.4026 - acc: 0.59 - ETA: 20s - loss: 6.4029 - acc: 0.59 - ETA: 20s - loss: 6.4027 - acc: 0.59 - ETA: 20s - loss: 6.4029 - acc: 0.59 - ETA: 19s - loss: 6.4028 - acc: 0.59 - ETA: 19s - loss: 6.4028 - acc: 0.59 - ETA: 19s - loss: 6.4028 - acc: 0.59 - ETA: 19s - loss: 6.4026 - acc: 0.59 - ETA: 19s - loss: 6.4028 - acc: 0.59 - ETA: 19s - loss: 6.4030 - acc: 0.59 - ETA: 19s - loss: 6.4032 - acc: 0.59 - ETA: 19s - loss: 6.4031 - acc: 0.59 - ETA: 19s - loss: 6.4029 - acc: 0.59 - ETA: 19s - loss: 6.4027 - acc: 0.59 - ETA: 19s - loss: 6.4027 - acc: 0.59 - ETA: 19s - loss: 6.4030 - acc: 0.59 - ETA: 18s - loss: 6.4025 - acc: 0.59 - ETA: 18s - loss: 6.4024 - acc: 0.59 - ETA: 18s - loss: 6.4025 - acc: 0.59 - ETA: 18s - loss: 6.4023 - acc: 0.59 - ETA: 18s - loss: 6.4021 - acc: 0.59 - ETA: 18s - loss: 6.4023 - acc: 0.59 - ETA: 18s - loss: 6.4023 - acc: 0.59 - ETA: 18s - loss: 6.4024 - acc: 0.59 - ETA: 18s - loss: 6.4022 - acc: 0.59 - ETA: 18s - loss: 6.4023 - acc: 0.59 - ETA: 18s - loss: 6.4022 - acc: 0.59 - ETA: 18s - loss: 6.4021 - acc: 0.59 - ETA: 18s - loss: 6.4023 - acc: 0.59 - ETA: 18s - loss: 6.4021 - acc: 0.59 - ETA: 17s - loss: 6.4023 - acc: 0.59 - ETA: 17s - loss: 6.4023 - acc: 0.59 - ETA: 17s - loss: 6.4018 - acc: 0.59 - ETA: 17s - loss: 6.4016 - acc: 0.59 - ETA: 17s - loss: 6.4016 - acc: 0.59 - ETA: 17s - loss: 6.4018 - acc: 0.59 - ETA: 17s - loss: 6.4018 - acc: 0.59 - ETA: 17s - loss: 6.4014 - acc: 0.59 - ETA: 17s - loss: 6.4013 - acc: 0.59 - ETA: 17s - loss: 6.4010 - acc: 0.59 - ETA: 17s - loss: 6.4011 - acc: 0.59 - ETA: 17s - loss: 6.4010 - acc: 0.59 - ETA: 17s - loss: 6.4010 - acc: 0.59 - ETA: 17s - loss: 6.4010 - acc: 0.59 - ETA: 17s - loss: 6.4009 - acc: 0.59 - ETA: 17s - loss: 6.4007 - acc: 0.59 - ETA: 17s - loss: 6.4010 - acc: 0.59 - ETA: 17s - loss: 6.4008 - acc: 0.59 - ETA: 17s - loss: 6.4008 - acc: 0.59 - ETA: 17s - loss: 6.4008 - acc: 0.59 - ETA: 16s - loss: 6.4008 - acc: 0.59 - ETA: 16s - loss: 6.4008 - acc: 0.59 - ETA: 16s - loss: 6.4006 - acc: 0.59 - ETA: 16s - loss: 6.4004 - acc: 0.59 - ETA: 16s - loss: 6.4004 - acc: 0.59 - ETA: 16s - loss: 6.4005 - acc: 0.59 - ETA: 16s - loss: 6.4004 - acc: 0.59 - ETA: 16s - loss: 6.4003 - acc: 0.59 - ETA: 16s - loss: 6.4003 - acc: 0.59 - ETA: 16s - loss: 6.4003 - acc: 0.59 - ETA: 16s - loss: 6.4001 - acc: 0.59 - ETA: 16s - loss: 6.4001 - acc: 0.59 - ETA: 16s - loss: 6.4003 - acc: 0.59 - ETA: 16s - loss: 6.4003 - acc: 0.59 - ETA: 16s - loss: 6.4003 - acc: 0.59 - ETA: 16s - loss: 6.4002 - acc: 0.59 - ETA: 16s - loss: 6.4003 - acc: 0.59 - ETA: 16s - loss: 6.4004 - acc: 0.59 - ETA: 16s - loss: 6.4004 - acc: 0.59 - ETA: 16s - loss: 6.4004 - acc: 0.59 - ETA: 16s - loss: 6.4002 - acc: 0.59 - ETA: 16s - loss: 6.4003 - acc: 0.59 - ETA: 16s - loss: 6.4003 - acc: 0.59 - ETA: 16s - loss: 6.4002 - acc: 0.59 - ETA: 16s - loss: 6.4001 - acc: 0.59 - ETA: 16s - loss: 6.3998 - acc: 0.59 - ETA: 15s - loss: 6.3997 - acc: 0.59 - ETA: 15s - loss: 6.3994 - acc: 0.59 - ETA: 15s - loss: 6.3994 - acc: 0.59 - ETA: 15s - loss: 6.3994 - acc: 0.59 - ETA: 15s - loss: 6.3993 - acc: 0.59 - ETA: 15s - loss: 6.3994 - acc: 0.59 - ETA: 15s - loss: 6.3991 - acc: 0.59 - ETA: 15s - loss: 6.3993 - acc: 0.59 - ETA: 15s - loss: 6.3993 - acc: 0.59 - ETA: 15s - loss: 6.3995 - acc: 0.59 - ETA: 15s - loss: 6.3995 - acc: 0.59 - ETA: 15s - loss: 6.3993 - acc: 0.59 - ETA: 15s - loss: 6.3990 - acc: 0.59 - ETA: 15s - loss: 6.3991 - acc: 0.59 - ETA: 15s - loss: 6.3991 - acc: 0.59 - ETA: 14s - loss: 6.3992 - acc: 0.59 - ETA: 14s - loss: 6.3993 - acc: 0.59 - ETA: 14s - loss: 6.3990 - acc: 0.59 - ETA: 14s - loss: 6.3991 - acc: 0.59 - ETA: 14s - loss: 6.3987 - acc: 0.59 - ETA: 14s - loss: 6.3988 - acc: 0.59 - ETA: 14s - loss: 6.3989 - acc: 0.59 - ETA: 14s - loss: 6.3989 - acc: 0.59 - ETA: 14s - loss: 6.3990 - acc: 0.59 - ETA: 14s - loss: 6.3991 - acc: 0.59 - ETA: 14s - loss: 6.3989 - acc: 0.59 - ETA: 13s - loss: 6.3992 - acc: 0.59 - ETA: 13s - loss: 6.3992 - acc: 0.59 - ETA: 13s - loss: 6.3991 - acc: 0.59 - ETA: 13s - loss: 6.3991 - acc: 0.59 - ETA: 13s - loss: 6.3990 - acc: 0.59 - ETA: 13s - loss: 6.3992 - acc: 0.59 - ETA: 13s - loss: 6.3990 - acc: 0.59 - ETA: 13s - loss: 6.3989 - acc: 0.59 - ETA: 13s - loss: 6.3989 - acc: 0.59 - ETA: 13s - loss: 6.3992 - acc: 0.59 - ETA: 13s - loss: 6.3991 - acc: 0.59 - ETA: 13s - loss: 6.3988 - acc: 0.59 - ETA: 13s - loss: 6.3986 - acc: 0.59 - ETA: 12s - loss: 6.3984 - acc: 0.59 - ETA: 12s - loss: 6.3983 - acc: 0.59 - ETA: 12s - loss: 6.3984 - acc: 0.59 - ETA: 12s - loss: 6.3986 - acc: 0.59 - ETA: 12s - loss: 6.3988 - acc: 0.59 - ETA: 12s - loss: 6.3988 - acc: 0.59 - ETA: 12s - loss: 6.3986 - acc: 0.59 - ETA: 12s - loss: 6.3985 - acc: 0.59 - ETA: 12s - loss: 6.3984 - acc: 0.59 - ETA: 12s - loss: 6.3988 - acc: 0.59 - ETA: 12s - loss: 6.3989 - acc: 0.59 - ETA: 12s - loss: 6.3989 - acc: 0.59 - ETA: 11s - loss: 6.3990 - acc: 0.59 - ETA: 11s - loss: 6.3990 - acc: 0.59 - ETA: 11s - loss: 6.3988 - acc: 0.59 - ETA: 11s - loss: 6.3990 - acc: 0.59 - ETA: 11s - loss: 6.3987 - acc: 0.59 - ETA: 11s - loss: 6.3988 - acc: 0.59 - ETA: 11s - loss: 6.3987 - acc: 0.59 - ETA: 11s - loss: 6.3985 - acc: 0.59 - ETA: 11s - loss: 6.3985 - acc: 0.59 - ETA: 11s - loss: 6.3986 - acc: 0.59 - ETA: 11s - loss: 6.3984 - acc: 0.59 - ETA: 11s - loss: 6.3982 - acc: 0.59 - ETA: 11s - loss: 6.3985 - acc: 0.59 - ETA: 11s - loss: 6.3986 - acc: 0.59 - ETA: 10s - loss: 6.3985 - acc: 0.59 - ETA: 10s - loss: 6.3984 - acc: 0.59 - ETA: 10s - loss: 6.3988 - acc: 0.59 - ETA: 10s - loss: 6.3988 - acc: 0.59 - ETA: 10s - loss: 6.3988 - acc: 0.59 - ETA: 10s - loss: 6.3988 - acc: 0.59 - ETA: 10s - loss: 6.3987 - acc: 0.59 - ETA: 10s - loss: 6.3991 - acc: 0.59 - ETA: 10s - loss: 6.3990 - acc: 0.59 - ETA: 10s - loss: 6.3987 - acc: 0.59 - ETA: 10s - loss: 6.3987 - acc: 0.59 - ETA: 10s - loss: 6.3987 - acc: 0.5986"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969231/969231 [==============================] - ETA: 10s - loss: 6.3990 - acc: 0.59 - ETA: 9s - loss: 6.3990 - acc: 0.5986 - ETA: 9s - loss: 6.3990 - acc: 0.598 - ETA: 9s - loss: 6.3988 - acc: 0.598 - ETA: 9s - loss: 6.3985 - acc: 0.598 - ETA: 9s - loss: 6.3985 - acc: 0.598 - ETA: 9s - loss: 6.3984 - acc: 0.598 - ETA: 9s - loss: 6.3985 - acc: 0.598 - ETA: 9s - loss: 6.3982 - acc: 0.598 - ETA: 9s - loss: 6.3982 - acc: 0.598 - ETA: 9s - loss: 6.3981 - acc: 0.598 - ETA: 9s - loss: 6.3982 - acc: 0.598 - ETA: 9s - loss: 6.3982 - acc: 0.598 - ETA: 9s - loss: 6.3983 - acc: 0.598 - ETA: 8s - loss: 6.3986 - acc: 0.598 - ETA: 8s - loss: 6.3985 - acc: 0.598 - ETA: 8s - loss: 6.3984 - acc: 0.598 - ETA: 8s - loss: 6.3986 - acc: 0.598 - ETA: 8s - loss: 6.3987 - acc: 0.598 - ETA: 8s - loss: 6.3987 - acc: 0.598 - ETA: 8s - loss: 6.3988 - acc: 0.598 - ETA: 8s - loss: 6.3988 - acc: 0.598 - ETA: 8s - loss: 6.3986 - acc: 0.598 - ETA: 8s - loss: 6.3985 - acc: 0.598 - ETA: 8s - loss: 6.3987 - acc: 0.598 - ETA: 8s - loss: 6.3988 - acc: 0.598 - ETA: 8s - loss: 6.3989 - acc: 0.598 - ETA: 8s - loss: 6.3987 - acc: 0.598 - ETA: 8s - loss: 6.3987 - acc: 0.598 - ETA: 8s - loss: 6.3988 - acc: 0.598 - ETA: 8s - loss: 6.3990 - acc: 0.598 - ETA: 7s - loss: 6.3989 - acc: 0.598 - ETA: 7s - loss: 6.3992 - acc: 0.598 - ETA: 7s - loss: 6.3992 - acc: 0.598 - ETA: 7s - loss: 6.3991 - acc: 0.598 - ETA: 7s - loss: 6.3991 - acc: 0.598 - ETA: 7s - loss: 6.3990 - acc: 0.598 - ETA: 7s - loss: 6.3992 - acc: 0.598 - ETA: 7s - loss: 6.3993 - acc: 0.598 - ETA: 7s - loss: 6.3992 - acc: 0.598 - ETA: 7s - loss: 6.3989 - acc: 0.598 - ETA: 7s - loss: 6.3983 - acc: 0.598 - ETA: 6s - loss: 6.3984 - acc: 0.598 - ETA: 6s - loss: 6.3982 - acc: 0.598 - ETA: 6s - loss: 6.3985 - acc: 0.598 - ETA: 6s - loss: 6.3982 - acc: 0.598 - ETA: 6s - loss: 6.3981 - acc: 0.598 - ETA: 6s - loss: 6.3983 - acc: 0.598 - ETA: 6s - loss: 6.3981 - acc: 0.598 - ETA: 6s - loss: 6.3983 - acc: 0.598 - ETA: 6s - loss: 6.3985 - acc: 0.598 - ETA: 5s - loss: 6.3984 - acc: 0.598 - ETA: 5s - loss: 6.3983 - acc: 0.598 - ETA: 5s - loss: 6.3984 - acc: 0.598 - ETA: 5s - loss: 6.3984 - acc: 0.598 - ETA: 5s - loss: 6.3985 - acc: 0.598 - ETA: 5s - loss: 6.3985 - acc: 0.598 - ETA: 5s - loss: 6.3985 - acc: 0.598 - ETA: 5s - loss: 6.3985 - acc: 0.598 - ETA: 5s - loss: 6.3985 - acc: 0.598 - ETA: 5s - loss: 6.3982 - acc: 0.598 - ETA: 5s - loss: 6.3980 - acc: 0.598 - ETA: 5s - loss: 6.3980 - acc: 0.598 - ETA: 5s - loss: 6.3981 - acc: 0.598 - ETA: 5s - loss: 6.3984 - acc: 0.598 - ETA: 5s - loss: 6.3982 - acc: 0.598 - ETA: 5s - loss: 6.3987 - acc: 0.598 - ETA: 5s - loss: 6.3985 - acc: 0.598 - ETA: 4s - loss: 6.3982 - acc: 0.598 - ETA: 4s - loss: 6.3983 - acc: 0.598 - ETA: 4s - loss: 6.3984 - acc: 0.598 - ETA: 4s - loss: 6.3985 - acc: 0.598 - ETA: 4s - loss: 6.3986 - acc: 0.598 - ETA: 4s - loss: 6.3985 - acc: 0.598 - ETA: 4s - loss: 6.3986 - acc: 0.598 - ETA: 4s - loss: 6.3985 - acc: 0.598 - ETA: 4s - loss: 6.3985 - acc: 0.598 - ETA: 4s - loss: 6.3983 - acc: 0.598 - ETA: 4s - loss: 6.3983 - acc: 0.598 - ETA: 4s - loss: 6.3983 - acc: 0.598 - ETA: 4s - loss: 6.3983 - acc: 0.598 - ETA: 3s - loss: 6.3980 - acc: 0.598 - ETA: 3s - loss: 6.3979 - acc: 0.598 - ETA: 3s - loss: 6.3982 - acc: 0.598 - ETA: 3s - loss: 6.3979 - acc: 0.598 - ETA: 3s - loss: 6.3979 - acc: 0.598 - ETA: 3s - loss: 6.3979 - acc: 0.598 - ETA: 3s - loss: 6.3978 - acc: 0.598 - ETA: 3s - loss: 6.3979 - acc: 0.598 - ETA: 3s - loss: 6.3981 - acc: 0.598 - ETA: 3s - loss: 6.3981 - acc: 0.598 - ETA: 3s - loss: 6.3980 - acc: 0.598 - ETA: 3s - loss: 6.3979 - acc: 0.598 - ETA: 3s - loss: 6.3983 - acc: 0.598 - ETA: 3s - loss: 6.3985 - acc: 0.598 - ETA: 3s - loss: 6.3984 - acc: 0.598 - ETA: 2s - loss: 6.3985 - acc: 0.598 - ETA: 2s - loss: 6.3985 - acc: 0.598 - ETA: 2s - loss: 6.3988 - acc: 0.598 - ETA: 2s - loss: 6.3985 - acc: 0.598 - ETA: 2s - loss: 6.3985 - acc: 0.598 - ETA: 2s - loss: 6.3984 - acc: 0.598 - ETA: 2s - loss: 6.3982 - acc: 0.598 - ETA: 2s - loss: 6.3982 - acc: 0.598 - ETA: 2s - loss: 6.3982 - acc: 0.598 - ETA: 2s - loss: 6.3979 - acc: 0.598 - ETA: 2s - loss: 6.3979 - acc: 0.598 - ETA: 2s - loss: 6.3978 - acc: 0.598 - ETA: 2s - loss: 6.3980 - acc: 0.598 - ETA: 1s - loss: 6.3978 - acc: 0.598 - ETA: 1s - loss: 6.3980 - acc: 0.598 - ETA: 1s - loss: 6.3982 - acc: 0.598 - ETA: 1s - loss: 6.3985 - acc: 0.598 - ETA: 1s - loss: 6.3987 - acc: 0.598 - ETA: 1s - loss: 6.3986 - acc: 0.598 - ETA: 1s - loss: 6.3984 - acc: 0.598 - ETA: 1s - loss: 6.3981 - acc: 0.598 - ETA: 1s - loss: 6.3982 - acc: 0.598 - ETA: 1s - loss: 6.3981 - acc: 0.598 - ETA: 1s - loss: 6.3982 - acc: 0.598 - ETA: 1s - loss: 6.3980 - acc: 0.598 - ETA: 1s - loss: 6.3979 - acc: 0.598 - ETA: 1s - loss: 6.3979 - acc: 0.598 - ETA: 0s - loss: 6.3978 - acc: 0.598 - ETA: 0s - loss: 6.3981 - acc: 0.598 - ETA: 0s - loss: 6.3977 - acc: 0.598 - ETA: 0s - loss: 6.3974 - acc: 0.598 - ETA: 0s - loss: 6.3973 - acc: 0.598 - ETA: 0s - loss: 6.3972 - acc: 0.598 - ETA: 0s - loss: 6.3974 - acc: 0.598 - ETA: 0s - loss: 6.3973 - acc: 0.598 - ETA: 0s - loss: 6.3974 - acc: 0.598 - ETA: 0s - loss: 6.3976 - acc: 0.598 - ETA: 0s - loss: 6.3977 - acc: 0.598 - ETA: 0s - loss: 6.3979 - acc: 0.598 - ETA: 0s - loss: 6.3979 - acc: 0.598 - 186s 192us/step - loss: 6.3979 - acc: 0.5987 - val_loss: 6.3979 - val_acc: 0.5987\n",
      "Epoch 3/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 69504/969231 [=>............................] - ETA: 9:00 - loss: 5.3556 - acc: 0.664 - ETA: 3:53 - loss: 5.8227 - acc: 0.634 - ETA: 3:35 - loss: 6.1385 - acc: 0.615 - ETA: 3:31 - loss: 6.1583 - acc: 0.613 - ETA: 2:58 - loss: 6.2946 - acc: 0.605 - ETA: 2:54 - loss: 6.2353 - acc: 0.608 - ETA: 2:48 - loss: 6.1619 - acc: 0.613 - ETA: 2:51 - loss: 6.0852 - acc: 0.618 - ETA: 2:37 - loss: 6.1317 - acc: 0.615 - ETA: 2:27 - loss: 6.1471 - acc: 0.614 - ETA: 2:25 - loss: 6.1359 - acc: 0.615 - ETA: 2:28 - loss: 6.1237 - acc: 0.615 - ETA: 2:28 - loss: 6.1988 - acc: 0.611 - ETA: 2:27 - loss: 6.1919 - acc: 0.611 - ETA: 2:23 - loss: 6.2356 - acc: 0.608 - ETA: 2:22 - loss: 6.2097 - acc: 0.610 - ETA: 2:20 - loss: 6.1852 - acc: 0.612 - ETA: 2:20 - loss: 6.2075 - acc: 0.610 - ETA: 2:19 - loss: 6.1958 - acc: 0.611 - ETA: 2:24 - loss: 6.2150 - acc: 0.610 - ETA: 2:23 - loss: 6.2295 - acc: 0.609 - ETA: 2:23 - loss: 6.2388 - acc: 0.608 - ETA: 2:19 - loss: 6.2503 - acc: 0.607 - ETA: 2:16 - loss: 6.2717 - acc: 0.606 - ETA: 2:16 - loss: 6.2748 - acc: 0.606 - ETA: 2:18 - loss: 6.2644 - acc: 0.607 - ETA: 2:21 - loss: 6.2755 - acc: 0.606 - ETA: 2:18 - loss: 6.2586 - acc: 0.607 - ETA: 2:18 - loss: 6.2768 - acc: 0.606 - ETA: 2:17 - loss: 6.2786 - acc: 0.606 - ETA: 2:18 - loss: 6.2707 - acc: 0.606 - ETA: 2:17 - loss: 6.2776 - acc: 0.606 - ETA: 2:16 - loss: 6.2839 - acc: 0.605 - ETA: 2:15 - loss: 6.2954 - acc: 0.605 - ETA: 2:15 - loss: 6.2958 - acc: 0.605 - ETA: 2:15 - loss: 6.2914 - acc: 0.605 - ETA: 2:13 - loss: 6.2954 - acc: 0.605 - ETA: 2:12 - loss: 6.2863 - acc: 0.605 - ETA: 2:12 - loss: 6.2732 - acc: 0.606 - ETA: 2:14 - loss: 6.2779 - acc: 0.606 - ETA: 2:14 - loss: 6.2842 - acc: 0.605 - ETA: 2:14 - loss: 6.2875 - acc: 0.605 - ETA: 2:13 - loss: 6.2937 - acc: 0.605 - ETA: 2:12 - loss: 6.2833 - acc: 0.605 - ETA: 2:11 - loss: 6.2793 - acc: 0.606 - ETA: 2:11 - loss: 6.2796 - acc: 0.606 - ETA: 2:12 - loss: 6.2866 - acc: 0.605 - ETA: 2:12 - loss: 6.2992 - acc: 0.604 - ETA: 2:13 - loss: 6.2979 - acc: 0.605 - ETA: 2:12 - loss: 6.2969 - acc: 0.605 - ETA: 2:12 - loss: 6.2987 - acc: 0.604 - ETA: 2:12 - loss: 6.2843 - acc: 0.605 - ETA: 2:11 - loss: 6.2851 - acc: 0.605 - ETA: 2:11 - loss: 6.2901 - acc: 0.605 - ETA: 2:11 - loss: 6.3048 - acc: 0.604 - ETA: 2:10 - loss: 6.3032 - acc: 0.604 - ETA: 2:10 - loss: 6.2963 - acc: 0.605 - ETA: 2:09 - loss: 6.2943 - acc: 0.605 - ETA: 2:08 - loss: 6.3068 - acc: 0.604 - ETA: 2:08 - loss: 6.3003 - acc: 0.604 - ETA: 2:08 - loss: 6.3055 - acc: 0.604 - ETA: 2:07 - loss: 6.3099 - acc: 0.604 - ETA: 2:07 - loss: 6.3105 - acc: 0.604 - ETA: 2:06 - loss: 6.3274 - acc: 0.603 - ETA: 2:07 - loss: 6.3316 - acc: 0.602 - ETA: 2:07 - loss: 6.3223 - acc: 0.603 - ETA: 2:07 - loss: 6.3217 - acc: 0.603 - ETA: 2:07 - loss: 6.3276 - acc: 0.603 - ETA: 2:07 - loss: 6.3349 - acc: 0.602 - ETA: 2:07 - loss: 6.3351 - acc: 0.602 - ETA: 2:08 - loss: 6.3358 - acc: 0.602 - ETA: 2:07 - loss: 6.3334 - acc: 0.602 - ETA: 2:07 - loss: 6.3342 - acc: 0.602 - ETA: 2:08 - loss: 6.3374 - acc: 0.602 - ETA: 2:08 - loss: 6.3436 - acc: 0.602 - ETA: 2:08 - loss: 6.3466 - acc: 0.601 - ETA: 2:09 - loss: 6.3516 - acc: 0.601 - ETA: 2:10 - loss: 6.3549 - acc: 0.601 - ETA: 2:10 - loss: 6.3625 - acc: 0.600 - ETA: 2:10 - loss: 6.3638 - acc: 0.600 - ETA: 2:11 - loss: 6.3619 - acc: 0.600 - ETA: 2:11 - loss: 6.3688 - acc: 0.600 - ETA: 2:11 - loss: 6.3677 - acc: 0.600 - ETA: 2:11 - loss: 6.3729 - acc: 0.600 - ETA: 2:11 - loss: 6.3744 - acc: 0.600 - ETA: 2:11 - loss: 6.3751 - acc: 0.600 - ETA: 2:11 - loss: 6.3811 - acc: 0.599 - ETA: 2:11 - loss: 6.3904 - acc: 0.599 - ETA: 2:11 - loss: 6.3878 - acc: 0.599 - ETA: 2:11 - loss: 6.3913 - acc: 0.599 - ETA: 2:11 - loss: 6.3917 - acc: 0.599 - ETA: 2:11 - loss: 6.3930 - acc: 0.599 - ETA: 2:11 - loss: 6.3956 - acc: 0.598 - ETA: 2:11 - loss: 6.3941 - acc: 0.598 - ETA: 2:12 - loss: 6.3847 - acc: 0.599 - ETA: 2:12 - loss: 6.3836 - acc: 0.599 - ETA: 2:13 - loss: 6.3823 - acc: 0.599 - ETA: 2:13 - loss: 6.3889 - acc: 0.599 - ETA: 2:14 - loss: 6.3912 - acc: 0.599 - ETA: 2:15 - loss: 6.3850 - acc: 0.599 - ETA: 2:16 - loss: 6.3860 - acc: 0.599 - ETA: 2:16 - loss: 6.3853 - acc: 0.599 - ETA: 2:16 - loss: 6.3890 - acc: 0.599 - ETA: 2:17 - loss: 6.3884 - acc: 0.599 - ETA: 2:17 - loss: 6.3896 - acc: 0.599 - ETA: 2:17 - loss: 6.3858 - acc: 0.599 - ETA: 2:18 - loss: 6.3876 - acc: 0.599 - ETA: 2:20 - loss: 6.3883 - acc: 0.599 - ETA: 2:20 - loss: 6.3843 - acc: 0.599 - ETA: 2:21 - loss: 6.3841 - acc: 0.599 - ETA: 2:21 - loss: 6.3880 - acc: 0.599 - ETA: 2:22 - loss: 6.3871 - acc: 0.599 - ETA: 2:23 - loss: 6.3899 - acc: 0.599 - ETA: 2:22 - loss: 6.3943 - acc: 0.598 - ETA: 2:23 - loss: 6.3911 - acc: 0.599 - ETA: 2:23 - loss: 6.3934 - acc: 0.599 - ETA: 2:24 - loss: 6.3962 - acc: 0.598 - ETA: 2:24 - loss: 6.3963 - acc: 0.598 - ETA: 2:25 - loss: 6.3919 - acc: 0.599 - ETA: 2:25 - loss: 6.3903 - acc: 0.599 - ETA: 2:27 - loss: 6.3940 - acc: 0.598 - ETA: 2:27 - loss: 6.3927 - acc: 0.599 - ETA: 2:28 - loss: 6.3926 - acc: 0.599 - ETA: 2:29 - loss: 6.3931 - acc: 0.599 - ETA: 2:30 - loss: 6.3937 - acc: 0.599 - ETA: 2:30 - loss: 6.3963 - acc: 0.598 - ETA: 2:31 - loss: 6.3981 - acc: 0.598 - ETA: 2:31 - loss: 6.3999 - acc: 0.598 - ETA: 2:32 - loss: 6.4004 - acc: 0.598 - ETA: 2:33 - loss: 6.4042 - acc: 0.598 - ETA: 2:33 - loss: 6.4032 - acc: 0.598 - ETA: 2:33 - loss: 6.4011 - acc: 0.598 - ETA: 2:34 - loss: 6.4013 - acc: 0.598 - ETA: 2:34 - loss: 6.3991 - acc: 0.598 - ETA: 2:35 - loss: 6.3962 - acc: 0.598 - ETA: 2:34 - loss: 6.4008 - acc: 0.598 - ETA: 2:35 - loss: 6.4034 - acc: 0.598 - ETA: 2:35 - loss: 6.4091 - acc: 0.598 - ETA: 2:36 - loss: 6.4063 - acc: 0.598 - ETA: 2:36 - loss: 6.4042 - acc: 0.598 - ETA: 2:37 - loss: 6.4050 - acc: 0.598 - ETA: 2:37 - loss: 6.4070 - acc: 0.598 - ETA: 2:37 - loss: 6.4108 - acc: 0.597 - ETA: 2:37 - loss: 6.4143 - acc: 0.597 - ETA: 2:38 - loss: 6.4212 - acc: 0.597 - ETA: 2:37 - loss: 6.4182 - acc: 0.597 - ETA: 2:37 - loss: 6.4196 - acc: 0.597 - ETA: 2:37 - loss: 6.4166 - acc: 0.597 - ETA: 2:37 - loss: 6.4148 - acc: 0.597 - ETA: 2:37 - loss: 6.4195 - acc: 0.597 - ETA: 2:37 - loss: 6.4194 - acc: 0.597 - ETA: 2:38 - loss: 6.4200 - acc: 0.597 - ETA: 2:38 - loss: 6.4209 - acc: 0.597 - ETA: 2:38 - loss: 6.4204 - acc: 0.597 - ETA: 2:39 - loss: 6.4165 - acc: 0.597 - ETA: 2:39 - loss: 6.4189 - acc: 0.597 - ETA: 2:39 - loss: 6.4192 - acc: 0.597 - ETA: 2:39 - loss: 6.4172 - acc: 0.597 - ETA: 2:40 - loss: 6.4143 - acc: 0.597 - ETA: 2:40 - loss: 6.4140 - acc: 0.597 - ETA: 2:39 - loss: 6.4162 - acc: 0.597 - ETA: 2:39 - loss: 6.4147 - acc: 0.597 - ETA: 2:39 - loss: 6.4176 - acc: 0.597 - ETA: 2:39 - loss: 6.4194 - acc: 0.597 - ETA: 2:39 - loss: 6.4181 - acc: 0.597 - ETA: 2:40 - loss: 6.4201 - acc: 0.597 - ETA: 2:40 - loss: 6.4170 - acc: 0.597 - ETA: 2:40 - loss: 6.4164 - acc: 0.597 - ETA: 2:40 - loss: 6.4179 - acc: 0.597 - ETA: 2:41 - loss: 6.4190 - acc: 0.597 - ETA: 2:40 - loss: 6.4213 - acc: 0.597 - ETA: 2:41 - loss: 6.4195 - acc: 0.597 - ETA: 2:40 - loss: 6.4161 - acc: 0.597 - ETA: 2:40 - loss: 6.4176 - acc: 0.597 - ETA: 2:41 - loss: 6.4189 - acc: 0.597 - ETA: 2:41 - loss: 6.4187 - acc: 0.597 - ETA: 2:41 - loss: 6.4195 - acc: 0.597 - ETA: 2:42 - loss: 6.4235 - acc: 0.597 - ETA: 2:42 - loss: 6.4257 - acc: 0.596 - ETA: 2:42 - loss: 6.4249 - acc: 0.597 - ETA: 2:42 - loss: 6.4216 - acc: 0.597 - ETA: 2:41 - loss: 6.4211 - acc: 0.597 - ETA: 2:41 - loss: 6.4212 - acc: 0.597 - ETA: 2:41 - loss: 6.4180 - acc: 0.597 - ETA: 2:40 - loss: 6.4155 - acc: 0.597 - ETA: 2:39 - loss: 6.4144 - acc: 0.597 - ETA: 2:39 - loss: 6.4187 - acc: 0.597 - ETA: 2:39 - loss: 6.4136 - acc: 0.597 - ETA: 2:38 - loss: 6.4126 - acc: 0.597 - ETA: 2:38 - loss: 6.4174 - acc: 0.597 - ETA: 2:37 - loss: 6.4152 - acc: 0.597 - ETA: 2:37 - loss: 6.4146 - acc: 0.597 - ETA: 2:37 - loss: 6.4137 - acc: 0.597 - ETA: 2:37 - loss: 6.4136 - acc: 0.597 - ETA: 2:37 - loss: 6.4102 - acc: 0.597 - ETA: 2:37 - loss: 6.4087 - acc: 0.598 - ETA: 2:37 - loss: 6.4076 - acc: 0.598 - ETA: 2:37 - loss: 6.4069 - acc: 0.598 - ETA: 2:38 - loss: 6.4080 - acc: 0.598 - ETA: 2:38 - loss: 6.4092 - acc: 0.598 - ETA: 2:38 - loss: 6.4099 - acc: 0.597 - ETA: 2:39 - loss: 6.4103 - acc: 0.597 - ETA: 2:39 - loss: 6.4091 - acc: 0.598 - ETA: 2:39 - loss: 6.4115 - acc: 0.5978"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "123264/969231 [==>...........................] - ETA: 2:40 - loss: 6.4136 - acc: 0.597 - ETA: 2:40 - loss: 6.4143 - acc: 0.597 - ETA: 2:40 - loss: 6.4115 - acc: 0.597 - ETA: 2:41 - loss: 6.4119 - acc: 0.597 - ETA: 2:41 - loss: 6.4123 - acc: 0.597 - ETA: 2:41 - loss: 6.4115 - acc: 0.597 - ETA: 2:42 - loss: 6.4118 - acc: 0.597 - ETA: 2:42 - loss: 6.4132 - acc: 0.597 - ETA: 2:42 - loss: 6.4141 - acc: 0.597 - ETA: 2:42 - loss: 6.4128 - acc: 0.597 - ETA: 2:42 - loss: 6.4119 - acc: 0.597 - ETA: 2:42 - loss: 6.4112 - acc: 0.597 - ETA: 2:42 - loss: 6.4077 - acc: 0.598 - ETA: 2:43 - loss: 6.4052 - acc: 0.598 - ETA: 2:43 - loss: 6.4060 - acc: 0.598 - ETA: 2:44 - loss: 6.4070 - acc: 0.598 - ETA: 2:43 - loss: 6.4047 - acc: 0.598 - ETA: 2:43 - loss: 6.4039 - acc: 0.598 - ETA: 2:43 - loss: 6.4055 - acc: 0.598 - ETA: 2:44 - loss: 6.4073 - acc: 0.598 - ETA: 2:44 - loss: 6.4086 - acc: 0.598 - ETA: 2:44 - loss: 6.4086 - acc: 0.598 - ETA: 2:44 - loss: 6.4113 - acc: 0.597 - ETA: 2:45 - loss: 6.4106 - acc: 0.597 - ETA: 2:45 - loss: 6.4110 - acc: 0.597 - ETA: 2:45 - loss: 6.4098 - acc: 0.597 - ETA: 2:45 - loss: 6.4088 - acc: 0.598 - ETA: 2:45 - loss: 6.4079 - acc: 0.598 - ETA: 2:45 - loss: 6.4084 - acc: 0.598 - ETA: 2:46 - loss: 6.4102 - acc: 0.597 - ETA: 2:46 - loss: 6.4084 - acc: 0.598 - ETA: 2:46 - loss: 6.4080 - acc: 0.598 - ETA: 2:46 - loss: 6.4101 - acc: 0.597 - ETA: 2:47 - loss: 6.4095 - acc: 0.598 - ETA: 2:47 - loss: 6.4097 - acc: 0.597 - ETA: 2:47 - loss: 6.4124 - acc: 0.597 - ETA: 2:47 - loss: 6.4143 - acc: 0.597 - ETA: 2:47 - loss: 6.4130 - acc: 0.597 - ETA: 2:47 - loss: 6.4110 - acc: 0.597 - ETA: 2:47 - loss: 6.4083 - acc: 0.598 - ETA: 2:47 - loss: 6.4094 - acc: 0.598 - ETA: 2:47 - loss: 6.4101 - acc: 0.597 - ETA: 2:47 - loss: 6.4102 - acc: 0.597 - ETA: 2:47 - loss: 6.4094 - acc: 0.598 - ETA: 2:47 - loss: 6.4117 - acc: 0.597 - ETA: 2:47 - loss: 6.4102 - acc: 0.597 - ETA: 2:47 - loss: 6.4122 - acc: 0.597 - ETA: 2:47 - loss: 6.4098 - acc: 0.597 - ETA: 2:47 - loss: 6.4122 - acc: 0.597 - ETA: 2:48 - loss: 6.4117 - acc: 0.597 - ETA: 2:48 - loss: 6.4093 - acc: 0.598 - ETA: 2:48 - loss: 6.4121 - acc: 0.597 - ETA: 2:48 - loss: 6.4097 - acc: 0.597 - ETA: 2:48 - loss: 6.4093 - acc: 0.598 - ETA: 2:47 - loss: 6.4053 - acc: 0.598 - ETA: 2:47 - loss: 6.4054 - acc: 0.598 - ETA: 2:47 - loss: 6.4081 - acc: 0.598 - ETA: 2:47 - loss: 6.4071 - acc: 0.598 - ETA: 2:47 - loss: 6.4044 - acc: 0.598 - ETA: 2:47 - loss: 6.4016 - acc: 0.598 - ETA: 2:47 - loss: 6.3990 - acc: 0.598 - ETA: 2:47 - loss: 6.3979 - acc: 0.598 - ETA: 2:48 - loss: 6.3999 - acc: 0.598 - ETA: 2:48 - loss: 6.3984 - acc: 0.598 - ETA: 2:47 - loss: 6.3977 - acc: 0.598 - ETA: 2:47 - loss: 6.3996 - acc: 0.598 - ETA: 2:48 - loss: 6.4011 - acc: 0.598 - ETA: 2:47 - loss: 6.4027 - acc: 0.598 - ETA: 2:48 - loss: 6.4011 - acc: 0.598 - ETA: 2:47 - loss: 6.3981 - acc: 0.598 - ETA: 2:48 - loss: 6.3991 - acc: 0.598 - ETA: 2:48 - loss: 6.3966 - acc: 0.598 - ETA: 2:48 - loss: 6.3958 - acc: 0.598 - ETA: 2:48 - loss: 6.3942 - acc: 0.598 - ETA: 2:48 - loss: 6.3946 - acc: 0.598 - ETA: 2:48 - loss: 6.3946 - acc: 0.598 - ETA: 2:48 - loss: 6.3945 - acc: 0.598 - ETA: 2:48 - loss: 6.3954 - acc: 0.598 - ETA: 2:48 - loss: 6.3963 - acc: 0.598 - ETA: 2:48 - loss: 6.3987 - acc: 0.598 - ETA: 2:48 - loss: 6.3995 - acc: 0.598 - ETA: 2:48 - loss: 6.3996 - acc: 0.598 - ETA: 2:48 - loss: 6.3998 - acc: 0.598 - ETA: 2:48 - loss: 6.4013 - acc: 0.598 - ETA: 2:48 - loss: 6.4025 - acc: 0.598 - ETA: 2:47 - loss: 6.4030 - acc: 0.598 - ETA: 2:47 - loss: 6.4040 - acc: 0.598 - ETA: 2:47 - loss: 6.4025 - acc: 0.598 - ETA: 2:47 - loss: 6.4024 - acc: 0.598 - ETA: 2:47 - loss: 6.4045 - acc: 0.598 - ETA: 2:47 - loss: 6.4027 - acc: 0.598 - ETA: 2:47 - loss: 6.4019 - acc: 0.598 - ETA: 2:47 - loss: 6.4010 - acc: 0.598 - ETA: 2:48 - loss: 6.4007 - acc: 0.598 - ETA: 2:47 - loss: 6.4013 - acc: 0.598 - ETA: 2:47 - loss: 6.4033 - acc: 0.598 - ETA: 2:47 - loss: 6.4028 - acc: 0.598 - ETA: 2:47 - loss: 6.4005 - acc: 0.598 - ETA: 2:47 - loss: 6.3994 - acc: 0.598 - ETA: 2:47 - loss: 6.3985 - acc: 0.598 - ETA: 2:47 - loss: 6.3970 - acc: 0.598 - ETA: 2:48 - loss: 6.3971 - acc: 0.598 - ETA: 2:48 - loss: 6.3973 - acc: 0.598 - ETA: 2:48 - loss: 6.4002 - acc: 0.598 - ETA: 2:48 - loss: 6.4019 - acc: 0.598 - ETA: 2:48 - loss: 6.4016 - acc: 0.598 - ETA: 2:48 - loss: 6.4005 - acc: 0.598 - ETA: 2:48 - loss: 6.4002 - acc: 0.598 - ETA: 2:49 - loss: 6.4007 - acc: 0.598 - ETA: 2:49 - loss: 6.4020 - acc: 0.598 - ETA: 2:49 - loss: 6.4027 - acc: 0.598 - ETA: 2:49 - loss: 6.4017 - acc: 0.598 - ETA: 2:49 - loss: 6.4044 - acc: 0.598 - ETA: 2:49 - loss: 6.4035 - acc: 0.598 - ETA: 2:49 - loss: 6.4030 - acc: 0.598 - ETA: 2:49 - loss: 6.4030 - acc: 0.598 - ETA: 2:49 - loss: 6.4034 - acc: 0.598 - ETA: 2:50 - loss: 6.4046 - acc: 0.598 - ETA: 2:50 - loss: 6.4032 - acc: 0.598 - ETA: 2:50 - loss: 6.4030 - acc: 0.598 - ETA: 2:50 - loss: 6.4038 - acc: 0.598 - ETA: 2:50 - loss: 6.4037 - acc: 0.598 - ETA: 2:50 - loss: 6.4036 - acc: 0.598 - ETA: 2:51 - loss: 6.4035 - acc: 0.598 - ETA: 2:51 - loss: 6.4034 - acc: 0.598 - ETA: 2:51 - loss: 6.4020 - acc: 0.598 - ETA: 2:51 - loss: 6.4014 - acc: 0.598 - ETA: 2:51 - loss: 6.4009 - acc: 0.598 - ETA: 2:51 - loss: 6.4018 - acc: 0.598 - ETA: 2:51 - loss: 6.4006 - acc: 0.598 - ETA: 2:51 - loss: 6.3999 - acc: 0.598 - ETA: 2:51 - loss: 6.3987 - acc: 0.598 - ETA: 2:51 - loss: 6.3983 - acc: 0.598 - ETA: 2:52 - loss: 6.3968 - acc: 0.598 - ETA: 2:52 - loss: 6.3980 - acc: 0.598 - ETA: 2:52 - loss: 6.3982 - acc: 0.598 - ETA: 2:52 - loss: 6.3984 - acc: 0.598 - ETA: 2:53 - loss: 6.3971 - acc: 0.598 - ETA: 2:53 - loss: 6.3966 - acc: 0.598 - ETA: 2:53 - loss: 6.3980 - acc: 0.598 - ETA: 2:52 - loss: 6.3936 - acc: 0.599 - ETA: 2:52 - loss: 6.3926 - acc: 0.599 - ETA: 2:52 - loss: 6.3914 - acc: 0.599 - ETA: 2:52 - loss: 6.3919 - acc: 0.599 - ETA: 2:52 - loss: 6.3942 - acc: 0.598 - ETA: 2:52 - loss: 6.3941 - acc: 0.598 - ETA: 2:52 - loss: 6.3965 - acc: 0.598 - ETA: 2:52 - loss: 6.3941 - acc: 0.598 - ETA: 2:52 - loss: 6.3935 - acc: 0.599 - ETA: 2:52 - loss: 6.3926 - acc: 0.599 - ETA: 2:51 - loss: 6.3966 - acc: 0.598 - ETA: 2:51 - loss: 6.3975 - acc: 0.598 - ETA: 2:51 - loss: 6.3971 - acc: 0.598 - ETA: 2:51 - loss: 6.3984 - acc: 0.598 - ETA: 2:51 - loss: 6.3980 - acc: 0.598 - ETA: 2:51 - loss: 6.3975 - acc: 0.598 - ETA: 2:51 - loss: 6.3994 - acc: 0.598 - ETA: 2:51 - loss: 6.4015 - acc: 0.598 - ETA: 2:52 - loss: 6.4017 - acc: 0.598 - ETA: 2:51 - loss: 6.4037 - acc: 0.598 - ETA: 2:51 - loss: 6.4063 - acc: 0.598 - ETA: 2:52 - loss: 6.4062 - acc: 0.598 - ETA: 2:52 - loss: 6.4064 - acc: 0.598 - ETA: 2:52 - loss: 6.4065 - acc: 0.598 - ETA: 2:52 - loss: 6.4058 - acc: 0.598 - ETA: 2:52 - loss: 6.4059 - acc: 0.598 - ETA: 2:53 - loss: 6.4037 - acc: 0.598 - ETA: 2:52 - loss: 6.4041 - acc: 0.598 - ETA: 2:52 - loss: 6.4044 - acc: 0.598 - ETA: 2:53 - loss: 6.4032 - acc: 0.598 - ETA: 2:52 - loss: 6.4043 - acc: 0.598 - ETA: 2:52 - loss: 6.4033 - acc: 0.598 - ETA: 2:52 - loss: 6.4047 - acc: 0.598 - ETA: 2:52 - loss: 6.4058 - acc: 0.598 - ETA: 2:52 - loss: 6.4047 - acc: 0.598 - ETA: 2:52 - loss: 6.4032 - acc: 0.598 - ETA: 2:52 - loss: 6.4034 - acc: 0.598 - ETA: 2:52 - loss: 6.4036 - acc: 0.598 - ETA: 2:52 - loss: 6.4030 - acc: 0.598 - ETA: 2:52 - loss: 6.4040 - acc: 0.598 - ETA: 2:52 - loss: 6.4027 - acc: 0.598 - ETA: 2:51 - loss: 6.4042 - acc: 0.598 - ETA: 2:51 - loss: 6.4025 - acc: 0.598 - ETA: 2:50 - loss: 6.4005 - acc: 0.598 - ETA: 2:50 - loss: 6.4002 - acc: 0.598 - ETA: 2:50 - loss: 6.3997 - acc: 0.598 - ETA: 2:50 - loss: 6.4007 - acc: 0.598 - ETA: 2:50 - loss: 6.3990 - acc: 0.598 - ETA: 2:50 - loss: 6.3991 - acc: 0.598 - ETA: 2:49 - loss: 6.3964 - acc: 0.598 - ETA: 2:49 - loss: 6.3950 - acc: 0.598 - ETA: 2:49 - loss: 6.3941 - acc: 0.598 - ETA: 2:50 - loss: 6.3948 - acc: 0.598 - ETA: 2:50 - loss: 6.3968 - acc: 0.598 - ETA: 2:49 - loss: 6.3960 - acc: 0.598 - ETA: 2:49 - loss: 6.3949 - acc: 0.598 - ETA: 2:49 - loss: 6.3957 - acc: 0.598 - ETA: 2:49 - loss: 6.3961 - acc: 0.598 - ETA: 2:49 - loss: 6.3971 - acc: 0.598 - ETA: 2:49 - loss: 6.3972 - acc: 0.598 - ETA: 2:50 - loss: 6.3962 - acc: 0.598 - ETA: 2:50 - loss: 6.3958 - acc: 0.598 - ETA: 2:50 - loss: 6.3957 - acc: 0.598 - ETA: 2:50 - loss: 6.3958 - acc: 0.5988"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179840/969231 [====>.........................] - ETA: 2:50 - loss: 6.3944 - acc: 0.598 - ETA: 2:50 - loss: 6.3948 - acc: 0.598 - ETA: 2:50 - loss: 6.3948 - acc: 0.598 - ETA: 2:50 - loss: 6.3946 - acc: 0.598 - ETA: 2:51 - loss: 6.3952 - acc: 0.598 - ETA: 2:51 - loss: 6.3937 - acc: 0.599 - ETA: 2:51 - loss: 6.3931 - acc: 0.599 - ETA: 2:51 - loss: 6.3923 - acc: 0.599 - ETA: 2:51 - loss: 6.3916 - acc: 0.599 - ETA: 2:51 - loss: 6.3905 - acc: 0.599 - ETA: 2:51 - loss: 6.3903 - acc: 0.599 - ETA: 2:50 - loss: 6.3904 - acc: 0.599 - ETA: 2:50 - loss: 6.3909 - acc: 0.599 - ETA: 2:50 - loss: 6.3909 - acc: 0.599 - ETA: 2:50 - loss: 6.3907 - acc: 0.599 - ETA: 2:50 - loss: 6.3897 - acc: 0.599 - ETA: 2:50 - loss: 6.3902 - acc: 0.599 - ETA: 2:50 - loss: 6.3910 - acc: 0.599 - ETA: 2:51 - loss: 6.3901 - acc: 0.599 - ETA: 2:51 - loss: 6.3904 - acc: 0.599 - ETA: 2:51 - loss: 6.3895 - acc: 0.599 - ETA: 2:51 - loss: 6.3897 - acc: 0.599 - ETA: 2:51 - loss: 6.3884 - acc: 0.599 - ETA: 2:51 - loss: 6.3892 - acc: 0.599 - ETA: 2:51 - loss: 6.3896 - acc: 0.599 - ETA: 2:50 - loss: 6.3882 - acc: 0.599 - ETA: 2:51 - loss: 6.3884 - acc: 0.599 - ETA: 2:51 - loss: 6.3891 - acc: 0.599 - ETA: 2:51 - loss: 6.3899 - acc: 0.599 - ETA: 2:51 - loss: 6.3908 - acc: 0.599 - ETA: 2:51 - loss: 6.3897 - acc: 0.599 - ETA: 2:51 - loss: 6.3908 - acc: 0.599 - ETA: 2:51 - loss: 6.3898 - acc: 0.599 - ETA: 2:51 - loss: 6.3900 - acc: 0.599 - ETA: 2:51 - loss: 6.3911 - acc: 0.599 - ETA: 2:51 - loss: 6.3909 - acc: 0.599 - ETA: 2:51 - loss: 6.3915 - acc: 0.599 - ETA: 2:51 - loss: 6.3911 - acc: 0.599 - ETA: 2:52 - loss: 6.3910 - acc: 0.599 - ETA: 2:52 - loss: 6.3907 - acc: 0.599 - ETA: 2:52 - loss: 6.3894 - acc: 0.599 - ETA: 2:52 - loss: 6.3921 - acc: 0.599 - ETA: 2:52 - loss: 6.3933 - acc: 0.599 - ETA: 2:51 - loss: 6.3946 - acc: 0.598 - ETA: 2:51 - loss: 6.3946 - acc: 0.598 - ETA: 2:51 - loss: 6.3956 - acc: 0.598 - ETA: 2:51 - loss: 6.3959 - acc: 0.598 - ETA: 2:51 - loss: 6.3957 - acc: 0.598 - ETA: 2:51 - loss: 6.3972 - acc: 0.598 - ETA: 2:51 - loss: 6.3980 - acc: 0.598 - ETA: 2:51 - loss: 6.3971 - acc: 0.598 - ETA: 2:51 - loss: 6.3959 - acc: 0.598 - ETA: 2:51 - loss: 6.3962 - acc: 0.598 - ETA: 2:51 - loss: 6.3968 - acc: 0.598 - ETA: 2:51 - loss: 6.3958 - acc: 0.598 - ETA: 2:51 - loss: 6.3962 - acc: 0.598 - ETA: 2:50 - loss: 6.3960 - acc: 0.598 - ETA: 2:50 - loss: 6.3953 - acc: 0.598 - ETA: 2:50 - loss: 6.3958 - acc: 0.598 - ETA: 2:50 - loss: 6.3951 - acc: 0.598 - ETA: 2:50 - loss: 6.3951 - acc: 0.598 - ETA: 2:51 - loss: 6.3952 - acc: 0.598 - ETA: 2:51 - loss: 6.3955 - acc: 0.598 - ETA: 2:51 - loss: 6.3952 - acc: 0.598 - ETA: 2:51 - loss: 6.3960 - acc: 0.598 - ETA: 2:51 - loss: 6.3973 - acc: 0.598 - ETA: 2:51 - loss: 6.3976 - acc: 0.598 - ETA: 2:51 - loss: 6.3988 - acc: 0.598 - ETA: 2:51 - loss: 6.3987 - acc: 0.598 - ETA: 2:51 - loss: 6.3990 - acc: 0.598 - ETA: 2:51 - loss: 6.3975 - acc: 0.598 - ETA: 2:51 - loss: 6.3985 - acc: 0.598 - ETA: 2:51 - loss: 6.4001 - acc: 0.598 - ETA: 2:51 - loss: 6.3998 - acc: 0.598 - ETA: 2:51 - loss: 6.3997 - acc: 0.598 - ETA: 2:51 - loss: 6.3987 - acc: 0.598 - ETA: 2:51 - loss: 6.3978 - acc: 0.598 - ETA: 2:51 - loss: 6.3972 - acc: 0.598 - ETA: 2:51 - loss: 6.3971 - acc: 0.598 - ETA: 2:51 - loss: 6.3965 - acc: 0.598 - ETA: 2:51 - loss: 6.3980 - acc: 0.598 - ETA: 2:51 - loss: 6.3974 - acc: 0.598 - ETA: 2:51 - loss: 6.3960 - acc: 0.598 - ETA: 2:51 - loss: 6.3957 - acc: 0.598 - ETA: 2:51 - loss: 6.3956 - acc: 0.598 - ETA: 2:51 - loss: 6.3957 - acc: 0.598 - ETA: 2:51 - loss: 6.3961 - acc: 0.598 - ETA: 2:50 - loss: 6.3964 - acc: 0.598 - ETA: 2:50 - loss: 6.3980 - acc: 0.598 - ETA: 2:50 - loss: 6.3992 - acc: 0.598 - ETA: 2:50 - loss: 6.3977 - acc: 0.598 - ETA: 2:49 - loss: 6.3969 - acc: 0.598 - ETA: 2:49 - loss: 6.3966 - acc: 0.598 - ETA: 2:49 - loss: 6.3955 - acc: 0.598 - ETA: 2:49 - loss: 6.3958 - acc: 0.598 - ETA: 2:49 - loss: 6.3965 - acc: 0.598 - ETA: 2:48 - loss: 6.3949 - acc: 0.598 - ETA: 2:48 - loss: 6.3961 - acc: 0.598 - ETA: 2:48 - loss: 6.3952 - acc: 0.598 - ETA: 2:48 - loss: 6.3946 - acc: 0.598 - ETA: 2:47 - loss: 6.3949 - acc: 0.598 - ETA: 2:47 - loss: 6.3955 - acc: 0.598 - ETA: 2:47 - loss: 6.3943 - acc: 0.598 - ETA: 2:47 - loss: 6.3955 - acc: 0.598 - ETA: 2:47 - loss: 6.3955 - acc: 0.598 - ETA: 2:47 - loss: 6.3945 - acc: 0.598 - ETA: 2:47 - loss: 6.3935 - acc: 0.599 - ETA: 2:47 - loss: 6.3929 - acc: 0.599 - ETA: 2:47 - loss: 6.3931 - acc: 0.599 - ETA: 2:47 - loss: 6.3933 - acc: 0.599 - ETA: 2:47 - loss: 6.3909 - acc: 0.599 - ETA: 2:47 - loss: 6.3901 - acc: 0.599 - ETA: 2:47 - loss: 6.3888 - acc: 0.599 - ETA: 2:47 - loss: 6.3904 - acc: 0.599 - ETA: 2:47 - loss: 6.3902 - acc: 0.599 - ETA: 2:47 - loss: 6.3902 - acc: 0.599 - ETA: 2:47 - loss: 6.3903 - acc: 0.599 - ETA: 2:47 - loss: 6.3910 - acc: 0.599 - ETA: 2:47 - loss: 6.3913 - acc: 0.599 - ETA: 2:47 - loss: 6.3924 - acc: 0.599 - ETA: 2:47 - loss: 6.3919 - acc: 0.599 - ETA: 2:47 - loss: 6.3925 - acc: 0.599 - ETA: 2:47 - loss: 6.3921 - acc: 0.599 - ETA: 2:47 - loss: 6.3934 - acc: 0.599 - ETA: 2:47 - loss: 6.3927 - acc: 0.599 - ETA: 2:47 - loss: 6.3932 - acc: 0.599 - ETA: 2:48 - loss: 6.3928 - acc: 0.599 - ETA: 2:48 - loss: 6.3922 - acc: 0.599 - ETA: 2:48 - loss: 6.3931 - acc: 0.599 - ETA: 2:48 - loss: 6.3937 - acc: 0.599 - ETA: 2:48 - loss: 6.3945 - acc: 0.598 - ETA: 2:48 - loss: 6.3933 - acc: 0.599 - ETA: 2:48 - loss: 6.3946 - acc: 0.598 - ETA: 2:48 - loss: 6.3951 - acc: 0.598 - ETA: 2:48 - loss: 6.3950 - acc: 0.598 - ETA: 2:48 - loss: 6.3944 - acc: 0.598 - ETA: 2:48 - loss: 6.3937 - acc: 0.598 - ETA: 2:48 - loss: 6.3936 - acc: 0.599 - ETA: 2:48 - loss: 6.3935 - acc: 0.599 - ETA: 2:48 - loss: 6.3935 - acc: 0.599 - ETA: 2:48 - loss: 6.3938 - acc: 0.598 - ETA: 2:48 - loss: 6.3942 - acc: 0.598 - ETA: 2:48 - loss: 6.3935 - acc: 0.599 - ETA: 2:48 - loss: 6.3937 - acc: 0.599 - ETA: 2:48 - loss: 6.3942 - acc: 0.598 - ETA: 2:48 - loss: 6.3948 - acc: 0.598 - ETA: 2:48 - loss: 6.3943 - acc: 0.598 - ETA: 2:49 - loss: 6.3936 - acc: 0.599 - ETA: 2:49 - loss: 6.3937 - acc: 0.599 - ETA: 2:48 - loss: 6.3945 - acc: 0.598 - ETA: 2:48 - loss: 6.3951 - acc: 0.598 - ETA: 2:48 - loss: 6.3955 - acc: 0.598 - ETA: 2:48 - loss: 6.3968 - acc: 0.598 - ETA: 2:48 - loss: 6.3969 - acc: 0.598 - ETA: 2:48 - loss: 6.3970 - acc: 0.598 - ETA: 2:48 - loss: 6.3960 - acc: 0.598 - ETA: 2:48 - loss: 6.3974 - acc: 0.598 - ETA: 2:47 - loss: 6.3974 - acc: 0.598 - ETA: 2:47 - loss: 6.3969 - acc: 0.598 - ETA: 2:47 - loss: 6.3980 - acc: 0.598 - ETA: 2:47 - loss: 6.3968 - acc: 0.598 - ETA: 2:47 - loss: 6.3958 - acc: 0.598 - ETA: 2:47 - loss: 6.3954 - acc: 0.598 - ETA: 2:47 - loss: 6.3959 - acc: 0.598 - ETA: 2:47 - loss: 6.3954 - acc: 0.598 - ETA: 2:47 - loss: 6.3969 - acc: 0.598 - ETA: 2:47 - loss: 6.3974 - acc: 0.598 - ETA: 2:47 - loss: 6.3971 - acc: 0.598 - ETA: 2:47 - loss: 6.3968 - acc: 0.598 - ETA: 2:47 - loss: 6.3974 - acc: 0.598 - ETA: 2:47 - loss: 6.3971 - acc: 0.598 - ETA: 2:47 - loss: 6.3970 - acc: 0.598 - ETA: 2:47 - loss: 6.3982 - acc: 0.598 - ETA: 2:47 - loss: 6.3989 - acc: 0.598 - ETA: 2:47 - loss: 6.3990 - acc: 0.598 - ETA: 2:47 - loss: 6.3971 - acc: 0.598 - ETA: 2:46 - loss: 6.3970 - acc: 0.598 - ETA: 2:46 - loss: 6.3959 - acc: 0.598 - ETA: 2:46 - loss: 6.3972 - acc: 0.598 - ETA: 2:46 - loss: 6.3979 - acc: 0.598 - ETA: 2:46 - loss: 6.3984 - acc: 0.598 - ETA: 2:46 - loss: 6.3964 - acc: 0.598 - ETA: 2:46 - loss: 6.3954 - acc: 0.598 - ETA: 2:46 - loss: 6.3960 - acc: 0.598 - ETA: 2:46 - loss: 6.3971 - acc: 0.598 - ETA: 2:46 - loss: 6.3975 - acc: 0.598 - ETA: 2:46 - loss: 6.3957 - acc: 0.598 - ETA: 2:46 - loss: 6.3952 - acc: 0.598 - ETA: 2:46 - loss: 6.3961 - acc: 0.598 - ETA: 2:45 - loss: 6.3957 - acc: 0.598 - ETA: 2:45 - loss: 6.3952 - acc: 0.598 - ETA: 2:45 - loss: 6.3948 - acc: 0.598 - ETA: 2:45 - loss: 6.3950 - acc: 0.598 - ETA: 2:44 - loss: 6.3933 - acc: 0.599 - ETA: 2:44 - loss: 6.3928 - acc: 0.599 - ETA: 2:44 - loss: 6.3910 - acc: 0.599 - ETA: 2:44 - loss: 6.3928 - acc: 0.599 - ETA: 2:43 - loss: 6.3919 - acc: 0.599 - ETA: 2:43 - loss: 6.3925 - acc: 0.599 - ETA: 2:43 - loss: 6.3927 - acc: 0.599 - ETA: 2:43 - loss: 6.3932 - acc: 0.599 - ETA: 2:43 - loss: 6.3942 - acc: 0.598 - ETA: 2:43 - loss: 6.3939 - acc: 0.598 - ETA: 2:43 - loss: 6.3934 - acc: 0.5990"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250624/969231 [======>.......................] - ETA: 2:43 - loss: 6.3939 - acc: 0.598 - ETA: 2:44 - loss: 6.3931 - acc: 0.599 - ETA: 2:44 - loss: 6.3934 - acc: 0.599 - ETA: 2:44 - loss: 6.3928 - acc: 0.599 - ETA: 2:44 - loss: 6.3928 - acc: 0.599 - ETA: 2:44 - loss: 6.3924 - acc: 0.599 - ETA: 2:44 - loss: 6.3922 - acc: 0.599 - ETA: 2:44 - loss: 6.3919 - acc: 0.599 - ETA: 2:44 - loss: 6.3926 - acc: 0.599 - ETA: 2:44 - loss: 6.3926 - acc: 0.599 - ETA: 2:44 - loss: 6.3913 - acc: 0.599 - ETA: 2:44 - loss: 6.3917 - acc: 0.599 - ETA: 2:44 - loss: 6.3917 - acc: 0.599 - ETA: 2:44 - loss: 6.3935 - acc: 0.599 - ETA: 2:44 - loss: 6.3937 - acc: 0.599 - ETA: 2:44 - loss: 6.3934 - acc: 0.599 - ETA: 2:44 - loss: 6.3948 - acc: 0.598 - ETA: 2:44 - loss: 6.3948 - acc: 0.598 - ETA: 2:44 - loss: 6.3945 - acc: 0.598 - ETA: 2:44 - loss: 6.3944 - acc: 0.598 - ETA: 2:44 - loss: 6.3943 - acc: 0.598 - ETA: 2:44 - loss: 6.3944 - acc: 0.598 - ETA: 2:44 - loss: 6.3940 - acc: 0.598 - ETA: 2:44 - loss: 6.3941 - acc: 0.598 - ETA: 2:44 - loss: 6.3943 - acc: 0.598 - ETA: 2:44 - loss: 6.3954 - acc: 0.598 - ETA: 2:44 - loss: 6.3960 - acc: 0.598 - ETA: 2:44 - loss: 6.3956 - acc: 0.598 - ETA: 2:44 - loss: 6.3959 - acc: 0.598 - ETA: 2:44 - loss: 6.3962 - acc: 0.598 - ETA: 2:44 - loss: 6.3962 - acc: 0.598 - ETA: 2:44 - loss: 6.3958 - acc: 0.598 - ETA: 2:44 - loss: 6.3956 - acc: 0.598 - ETA: 2:44 - loss: 6.3955 - acc: 0.598 - ETA: 2:44 - loss: 6.3952 - acc: 0.598 - ETA: 2:44 - loss: 6.3950 - acc: 0.598 - ETA: 2:44 - loss: 6.3950 - acc: 0.598 - ETA: 2:44 - loss: 6.3951 - acc: 0.598 - ETA: 2:44 - loss: 6.3952 - acc: 0.598 - ETA: 2:44 - loss: 6.3940 - acc: 0.598 - ETA: 2:44 - loss: 6.3945 - acc: 0.598 - ETA: 2:44 - loss: 6.3943 - acc: 0.598 - ETA: 2:44 - loss: 6.3924 - acc: 0.599 - ETA: 2:44 - loss: 6.3908 - acc: 0.599 - ETA: 2:44 - loss: 6.3901 - acc: 0.599 - ETA: 2:44 - loss: 6.3899 - acc: 0.599 - ETA: 2:44 - loss: 6.3902 - acc: 0.599 - ETA: 2:44 - loss: 6.3888 - acc: 0.599 - ETA: 2:44 - loss: 6.3889 - acc: 0.599 - ETA: 2:44 - loss: 6.3900 - acc: 0.599 - ETA: 2:44 - loss: 6.3907 - acc: 0.599 - ETA: 2:44 - loss: 6.3911 - acc: 0.599 - ETA: 2:44 - loss: 6.3915 - acc: 0.599 - ETA: 2:44 - loss: 6.3911 - acc: 0.599 - ETA: 2:44 - loss: 6.3911 - acc: 0.599 - ETA: 2:44 - loss: 6.3908 - acc: 0.599 - ETA: 2:44 - loss: 6.3905 - acc: 0.599 - ETA: 2:44 - loss: 6.3898 - acc: 0.599 - ETA: 2:44 - loss: 6.3902 - acc: 0.599 - ETA: 2:44 - loss: 6.3904 - acc: 0.599 - ETA: 2:44 - loss: 6.3909 - acc: 0.599 - ETA: 2:43 - loss: 6.3904 - acc: 0.599 - ETA: 2:43 - loss: 6.3908 - acc: 0.599 - ETA: 2:43 - loss: 6.3912 - acc: 0.599 - ETA: 2:43 - loss: 6.3900 - acc: 0.599 - ETA: 2:43 - loss: 6.3892 - acc: 0.599 - ETA: 2:43 - loss: 6.3887 - acc: 0.599 - ETA: 2:43 - loss: 6.3897 - acc: 0.599 - ETA: 2:43 - loss: 6.3894 - acc: 0.599 - ETA: 2:43 - loss: 6.3892 - acc: 0.599 - ETA: 2:43 - loss: 6.3887 - acc: 0.599 - ETA: 2:43 - loss: 6.3884 - acc: 0.599 - ETA: 2:43 - loss: 6.3886 - acc: 0.599 - ETA: 2:43 - loss: 6.3890 - acc: 0.599 - ETA: 2:43 - loss: 6.3885 - acc: 0.599 - ETA: 2:43 - loss: 6.3880 - acc: 0.599 - ETA: 2:43 - loss: 6.3877 - acc: 0.599 - ETA: 2:42 - loss: 6.3881 - acc: 0.599 - ETA: 2:42 - loss: 6.3873 - acc: 0.599 - ETA: 2:42 - loss: 6.3868 - acc: 0.599 - ETA: 2:42 - loss: 6.3867 - acc: 0.599 - ETA: 2:42 - loss: 6.3858 - acc: 0.599 - ETA: 2:42 - loss: 6.3866 - acc: 0.599 - ETA: 2:42 - loss: 6.3874 - acc: 0.599 - ETA: 2:42 - loss: 6.3880 - acc: 0.599 - ETA: 2:42 - loss: 6.3885 - acc: 0.599 - ETA: 2:42 - loss: 6.3887 - acc: 0.599 - ETA: 2:42 - loss: 6.3887 - acc: 0.599 - ETA: 2:42 - loss: 6.3889 - acc: 0.599 - ETA: 2:42 - loss: 6.3876 - acc: 0.599 - ETA: 2:42 - loss: 6.3876 - acc: 0.599 - ETA: 2:42 - loss: 6.3892 - acc: 0.599 - ETA: 2:42 - loss: 6.3895 - acc: 0.599 - ETA: 2:42 - loss: 6.3892 - acc: 0.599 - ETA: 2:41 - loss: 6.3893 - acc: 0.599 - ETA: 2:41 - loss: 6.3892 - acc: 0.599 - ETA: 2:41 - loss: 6.3893 - acc: 0.599 - ETA: 2:41 - loss: 6.3884 - acc: 0.599 - ETA: 2:41 - loss: 6.3898 - acc: 0.599 - ETA: 2:41 - loss: 6.3905 - acc: 0.599 - ETA: 2:40 - loss: 6.3907 - acc: 0.599 - ETA: 2:40 - loss: 6.3904 - acc: 0.599 - ETA: 2:39 - loss: 6.3921 - acc: 0.599 - ETA: 2:39 - loss: 6.3921 - acc: 0.599 - ETA: 2:39 - loss: 6.3922 - acc: 0.599 - ETA: 2:39 - loss: 6.3910 - acc: 0.599 - ETA: 2:39 - loss: 6.3906 - acc: 0.599 - ETA: 2:39 - loss: 6.3915 - acc: 0.599 - ETA: 2:38 - loss: 6.3920 - acc: 0.599 - ETA: 2:38 - loss: 6.3921 - acc: 0.599 - ETA: 2:38 - loss: 6.3922 - acc: 0.599 - ETA: 2:38 - loss: 6.3933 - acc: 0.599 - ETA: 2:38 - loss: 6.3930 - acc: 0.599 - ETA: 2:38 - loss: 6.3927 - acc: 0.599 - ETA: 2:37 - loss: 6.3924 - acc: 0.599 - ETA: 2:37 - loss: 6.3912 - acc: 0.599 - ETA: 2:37 - loss: 6.3923 - acc: 0.599 - ETA: 2:37 - loss: 6.3931 - acc: 0.599 - ETA: 2:37 - loss: 6.3933 - acc: 0.599 - ETA: 2:36 - loss: 6.3941 - acc: 0.598 - ETA: 2:36 - loss: 6.3928 - acc: 0.599 - ETA: 2:36 - loss: 6.3923 - acc: 0.599 - ETA: 2:36 - loss: 6.3907 - acc: 0.599 - ETA: 2:36 - loss: 6.3911 - acc: 0.599 - ETA: 2:36 - loss: 6.3915 - acc: 0.599 - ETA: 2:35 - loss: 6.3911 - acc: 0.599 - ETA: 2:35 - loss: 6.3904 - acc: 0.599 - ETA: 2:35 - loss: 6.3902 - acc: 0.599 - ETA: 2:35 - loss: 6.3901 - acc: 0.599 - ETA: 2:35 - loss: 6.3907 - acc: 0.599 - ETA: 2:35 - loss: 6.3899 - acc: 0.599 - ETA: 2:34 - loss: 6.3896 - acc: 0.599 - ETA: 2:34 - loss: 6.3885 - acc: 0.599 - ETA: 2:34 - loss: 6.3883 - acc: 0.599 - ETA: 2:34 - loss: 6.3885 - acc: 0.599 - ETA: 2:34 - loss: 6.3881 - acc: 0.599 - ETA: 2:34 - loss: 6.3894 - acc: 0.599 - ETA: 2:33 - loss: 6.3901 - acc: 0.599 - ETA: 2:33 - loss: 6.3892 - acc: 0.599 - ETA: 2:33 - loss: 6.3886 - acc: 0.599 - ETA: 2:33 - loss: 6.3884 - acc: 0.599 - ETA: 2:33 - loss: 6.3885 - acc: 0.599 - ETA: 2:32 - loss: 6.3890 - acc: 0.599 - ETA: 2:32 - loss: 6.3885 - acc: 0.599 - ETA: 2:32 - loss: 6.3881 - acc: 0.599 - ETA: 2:32 - loss: 6.3874 - acc: 0.599 - ETA: 2:31 - loss: 6.3881 - acc: 0.599 - ETA: 2:31 - loss: 6.3887 - acc: 0.599 - ETA: 2:31 - loss: 6.3895 - acc: 0.599 - ETA: 2:30 - loss: 6.3899 - acc: 0.599 - ETA: 2:30 - loss: 6.3900 - acc: 0.599 - ETA: 2:30 - loss: 6.3900 - acc: 0.599 - ETA: 2:30 - loss: 6.3900 - acc: 0.599 - ETA: 2:30 - loss: 6.3899 - acc: 0.599 - ETA: 2:29 - loss: 6.3899 - acc: 0.599 - ETA: 2:29 - loss: 6.3888 - acc: 0.599 - ETA: 2:29 - loss: 6.3882 - acc: 0.599 - ETA: 2:29 - loss: 6.3881 - acc: 0.599 - ETA: 2:29 - loss: 6.3874 - acc: 0.599 - ETA: 2:29 - loss: 6.3870 - acc: 0.599 - ETA: 2:28 - loss: 6.3860 - acc: 0.599 - ETA: 2:28 - loss: 6.3866 - acc: 0.599 - ETA: 2:28 - loss: 6.3870 - acc: 0.599 - ETA: 2:28 - loss: 6.3876 - acc: 0.599 - ETA: 2:28 - loss: 6.3881 - acc: 0.599 - ETA: 2:28 - loss: 6.3877 - acc: 0.599 - ETA: 2:28 - loss: 6.3876 - acc: 0.599 - ETA: 2:27 - loss: 6.3868 - acc: 0.599 - ETA: 2:27 - loss: 6.3870 - acc: 0.599 - ETA: 2:27 - loss: 6.3869 - acc: 0.599 - ETA: 2:27 - loss: 6.3869 - acc: 0.599 - ETA: 2:27 - loss: 6.3862 - acc: 0.599 - ETA: 2:27 - loss: 6.3872 - acc: 0.599 - ETA: 2:26 - loss: 6.3886 - acc: 0.599 - ETA: 2:26 - loss: 6.3875 - acc: 0.599 - ETA: 2:26 - loss: 6.3866 - acc: 0.599 - ETA: 2:26 - loss: 6.3871 - acc: 0.599 - ETA: 2:26 - loss: 6.3870 - acc: 0.599 - ETA: 2:26 - loss: 6.3864 - acc: 0.599 - ETA: 2:25 - loss: 6.3853 - acc: 0.599 - ETA: 2:25 - loss: 6.3852 - acc: 0.599 - ETA: 2:25 - loss: 6.3839 - acc: 0.599 - ETA: 2:25 - loss: 6.3837 - acc: 0.599 - ETA: 2:25 - loss: 6.3846 - acc: 0.599 - ETA: 2:25 - loss: 6.3834 - acc: 0.599 - ETA: 2:24 - loss: 6.3830 - acc: 0.599 - ETA: 2:24 - loss: 6.3826 - acc: 0.599 - ETA: 2:24 - loss: 6.3814 - acc: 0.599 - ETA: 2:24 - loss: 6.3821 - acc: 0.599 - ETA: 2:24 - loss: 6.3824 - acc: 0.599 - ETA: 2:24 - loss: 6.3825 - acc: 0.599 - ETA: 2:23 - loss: 6.3831 - acc: 0.599 - ETA: 2:23 - loss: 6.3831 - acc: 0.599 - ETA: 2:23 - loss: 6.3837 - acc: 0.599 - ETA: 2:23 - loss: 6.3833 - acc: 0.599 - ETA: 2:23 - loss: 6.3838 - acc: 0.599 - ETA: 2:23 - loss: 6.3856 - acc: 0.599 - ETA: 2:22 - loss: 6.3862 - acc: 0.599 - ETA: 2:22 - loss: 6.3865 - acc: 0.599 - ETA: 2:22 - loss: 6.3869 - acc: 0.599 - ETA: 2:22 - loss: 6.3877 - acc: 0.599 - ETA: 2:22 - loss: 6.3881 - acc: 0.599 - ETA: 2:22 - loss: 6.3881 - acc: 0.599 - ETA: 2:21 - loss: 6.3879 - acc: 0.5993"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340480/969231 [=========>....................] - ETA: 2:21 - loss: 6.3881 - acc: 0.599 - ETA: 2:21 - loss: 6.3884 - acc: 0.599 - ETA: 2:21 - loss: 6.3883 - acc: 0.599 - ETA: 2:21 - loss: 6.3874 - acc: 0.599 - ETA: 2:21 - loss: 6.3882 - acc: 0.599 - ETA: 2:21 - loss: 6.3874 - acc: 0.599 - ETA: 2:21 - loss: 6.3874 - acc: 0.599 - ETA: 2:20 - loss: 6.3870 - acc: 0.599 - ETA: 2:20 - loss: 6.3866 - acc: 0.599 - ETA: 2:20 - loss: 6.3872 - acc: 0.599 - ETA: 2:20 - loss: 6.3880 - acc: 0.599 - ETA: 2:19 - loss: 6.3881 - acc: 0.599 - ETA: 2:19 - loss: 6.3875 - acc: 0.599 - ETA: 2:19 - loss: 6.3876 - acc: 0.599 - ETA: 2:19 - loss: 6.3877 - acc: 0.599 - ETA: 2:19 - loss: 6.3884 - acc: 0.599 - ETA: 2:19 - loss: 6.3890 - acc: 0.599 - ETA: 2:19 - loss: 6.3897 - acc: 0.599 - ETA: 2:19 - loss: 6.3893 - acc: 0.599 - ETA: 2:19 - loss: 6.3882 - acc: 0.599 - ETA: 2:19 - loss: 6.3884 - acc: 0.599 - ETA: 2:19 - loss: 6.3881 - acc: 0.599 - ETA: 2:18 - loss: 6.3885 - acc: 0.599 - ETA: 2:18 - loss: 6.3893 - acc: 0.599 - ETA: 2:18 - loss: 6.3890 - acc: 0.599 - ETA: 2:17 - loss: 6.3894 - acc: 0.599 - ETA: 2:17 - loss: 6.3890 - acc: 0.599 - ETA: 2:17 - loss: 6.3880 - acc: 0.599 - ETA: 2:17 - loss: 6.3873 - acc: 0.599 - ETA: 2:16 - loss: 6.3862 - acc: 0.599 - ETA: 2:16 - loss: 6.3857 - acc: 0.599 - ETA: 2:16 - loss: 6.3856 - acc: 0.599 - ETA: 2:16 - loss: 6.3853 - acc: 0.599 - ETA: 2:16 - loss: 6.3855 - acc: 0.599 - ETA: 2:16 - loss: 6.3854 - acc: 0.599 - ETA: 2:16 - loss: 6.3853 - acc: 0.599 - ETA: 2:15 - loss: 6.3856 - acc: 0.599 - ETA: 2:15 - loss: 6.3861 - acc: 0.599 - ETA: 2:15 - loss: 6.3856 - acc: 0.599 - ETA: 2:15 - loss: 6.3850 - acc: 0.599 - ETA: 2:15 - loss: 6.3854 - acc: 0.599 - ETA: 2:15 - loss: 6.3856 - acc: 0.599 - ETA: 2:15 - loss: 6.3855 - acc: 0.599 - ETA: 2:14 - loss: 6.3867 - acc: 0.599 - ETA: 2:14 - loss: 6.3864 - acc: 0.599 - ETA: 2:14 - loss: 6.3867 - acc: 0.599 - ETA: 2:14 - loss: 6.3869 - acc: 0.599 - ETA: 2:14 - loss: 6.3880 - acc: 0.599 - ETA: 2:14 - loss: 6.3887 - acc: 0.599 - ETA: 2:14 - loss: 6.3873 - acc: 0.599 - ETA: 2:13 - loss: 6.3878 - acc: 0.599 - ETA: 2:13 - loss: 6.3872 - acc: 0.599 - ETA: 2:13 - loss: 6.3871 - acc: 0.599 - ETA: 2:13 - loss: 6.3871 - acc: 0.599 - ETA: 2:13 - loss: 6.3872 - acc: 0.599 - ETA: 2:13 - loss: 6.3872 - acc: 0.599 - ETA: 2:13 - loss: 6.3871 - acc: 0.599 - ETA: 2:13 - loss: 6.3868 - acc: 0.599 - ETA: 2:12 - loss: 6.3870 - acc: 0.599 - ETA: 2:12 - loss: 6.3881 - acc: 0.599 - ETA: 2:12 - loss: 6.3875 - acc: 0.599 - ETA: 2:12 - loss: 6.3867 - acc: 0.599 - ETA: 2:11 - loss: 6.3871 - acc: 0.599 - ETA: 2:11 - loss: 6.3878 - acc: 0.599 - ETA: 2:11 - loss: 6.3878 - acc: 0.599 - ETA: 2:11 - loss: 6.3876 - acc: 0.599 - ETA: 2:11 - loss: 6.3869 - acc: 0.599 - ETA: 2:10 - loss: 6.3865 - acc: 0.599 - ETA: 2:10 - loss: 6.3864 - acc: 0.599 - ETA: 2:10 - loss: 6.3862 - acc: 0.599 - ETA: 2:10 - loss: 6.3868 - acc: 0.599 - ETA: 2:10 - loss: 6.3868 - acc: 0.599 - ETA: 2:10 - loss: 6.3872 - acc: 0.599 - ETA: 2:10 - loss: 6.3864 - acc: 0.599 - ETA: 2:10 - loss: 6.3869 - acc: 0.599 - ETA: 2:09 - loss: 6.3862 - acc: 0.599 - ETA: 2:09 - loss: 6.3861 - acc: 0.599 - ETA: 2:09 - loss: 6.3859 - acc: 0.599 - ETA: 2:09 - loss: 6.3858 - acc: 0.599 - ETA: 2:09 - loss: 6.3851 - acc: 0.599 - ETA: 2:09 - loss: 6.3856 - acc: 0.599 - ETA: 2:08 - loss: 6.3857 - acc: 0.599 - ETA: 2:08 - loss: 6.3849 - acc: 0.599 - ETA: 2:08 - loss: 6.3850 - acc: 0.599 - ETA: 2:07 - loss: 6.3841 - acc: 0.599 - ETA: 2:07 - loss: 6.3841 - acc: 0.599 - ETA: 2:07 - loss: 6.3834 - acc: 0.599 - ETA: 2:07 - loss: 6.3836 - acc: 0.599 - ETA: 2:07 - loss: 6.3841 - acc: 0.599 - ETA: 2:07 - loss: 6.3828 - acc: 0.599 - ETA: 2:07 - loss: 6.3839 - acc: 0.599 - ETA: 2:07 - loss: 6.3840 - acc: 0.599 - ETA: 2:06 - loss: 6.3840 - acc: 0.599 - ETA: 2:06 - loss: 6.3840 - acc: 0.599 - ETA: 2:06 - loss: 6.3842 - acc: 0.599 - ETA: 2:06 - loss: 6.3841 - acc: 0.599 - ETA: 2:06 - loss: 6.3840 - acc: 0.599 - ETA: 2:06 - loss: 6.3841 - acc: 0.599 - ETA: 2:06 - loss: 6.3845 - acc: 0.599 - ETA: 2:06 - loss: 6.3843 - acc: 0.599 - ETA: 2:06 - loss: 6.3827 - acc: 0.599 - ETA: 2:05 - loss: 6.3822 - acc: 0.599 - ETA: 2:05 - loss: 6.3825 - acc: 0.599 - ETA: 2:05 - loss: 6.3823 - acc: 0.599 - ETA: 2:05 - loss: 6.3829 - acc: 0.599 - ETA: 2:05 - loss: 6.3823 - acc: 0.599 - ETA: 2:05 - loss: 6.3816 - acc: 0.599 - ETA: 2:05 - loss: 6.3819 - acc: 0.599 - ETA: 2:05 - loss: 6.3829 - acc: 0.599 - ETA: 2:04 - loss: 6.3825 - acc: 0.599 - ETA: 2:04 - loss: 6.3819 - acc: 0.599 - ETA: 2:04 - loss: 6.3816 - acc: 0.599 - ETA: 2:04 - loss: 6.3816 - acc: 0.599 - ETA: 2:04 - loss: 6.3822 - acc: 0.599 - ETA: 2:04 - loss: 6.3821 - acc: 0.599 - ETA: 2:04 - loss: 6.3822 - acc: 0.599 - ETA: 2:04 - loss: 6.3831 - acc: 0.599 - ETA: 2:04 - loss: 6.3838 - acc: 0.599 - ETA: 2:04 - loss: 6.3835 - acc: 0.599 - ETA: 2:03 - loss: 6.3824 - acc: 0.599 - ETA: 2:03 - loss: 6.3830 - acc: 0.599 - ETA: 2:03 - loss: 6.3829 - acc: 0.599 - ETA: 2:03 - loss: 6.3822 - acc: 0.599 - ETA: 2:03 - loss: 6.3833 - acc: 0.599 - ETA: 2:03 - loss: 6.3842 - acc: 0.599 - ETA: 2:02 - loss: 6.3841 - acc: 0.599 - ETA: 2:02 - loss: 6.3836 - acc: 0.599 - ETA: 2:02 - loss: 6.3837 - acc: 0.599 - ETA: 2:02 - loss: 6.3835 - acc: 0.599 - ETA: 2:02 - loss: 6.3828 - acc: 0.599 - ETA: 2:02 - loss: 6.3823 - acc: 0.599 - ETA: 2:02 - loss: 6.3829 - acc: 0.599 - ETA: 2:02 - loss: 6.3825 - acc: 0.599 - ETA: 2:02 - loss: 6.3827 - acc: 0.599 - ETA: 2:02 - loss: 6.3822 - acc: 0.599 - ETA: 2:02 - loss: 6.3821 - acc: 0.599 - ETA: 2:01 - loss: 6.3820 - acc: 0.599 - ETA: 2:01 - loss: 6.3818 - acc: 0.599 - ETA: 2:01 - loss: 6.3820 - acc: 0.599 - ETA: 2:01 - loss: 6.3816 - acc: 0.599 - ETA: 2:01 - loss: 6.3816 - acc: 0.599 - ETA: 2:01 - loss: 6.3822 - acc: 0.599 - ETA: 2:01 - loss: 6.3834 - acc: 0.599 - ETA: 2:00 - loss: 6.3837 - acc: 0.599 - ETA: 2:00 - loss: 6.3842 - acc: 0.599 - ETA: 2:00 - loss: 6.3830 - acc: 0.599 - ETA: 2:00 - loss: 6.3832 - acc: 0.599 - ETA: 2:00 - loss: 6.3838 - acc: 0.599 - ETA: 2:00 - loss: 6.3841 - acc: 0.599 - ETA: 1:59 - loss: 6.3838 - acc: 0.599 - ETA: 1:59 - loss: 6.3833 - acc: 0.599 - ETA: 1:59 - loss: 6.3835 - acc: 0.599 - ETA: 1:59 - loss: 6.3831 - acc: 0.599 - ETA: 1:59 - loss: 6.3827 - acc: 0.599 - ETA: 1:59 - loss: 6.3827 - acc: 0.599 - ETA: 1:58 - loss: 6.3830 - acc: 0.599 - ETA: 1:58 - loss: 6.3825 - acc: 0.599 - ETA: 1:58 - loss: 6.3832 - acc: 0.599 - ETA: 1:58 - loss: 6.3850 - acc: 0.599 - ETA: 1:58 - loss: 6.3847 - acc: 0.599 - ETA: 1:58 - loss: 6.3843 - acc: 0.599 - ETA: 1:58 - loss: 6.3838 - acc: 0.599 - ETA: 1:58 - loss: 6.3839 - acc: 0.599 - ETA: 1:57 - loss: 6.3830 - acc: 0.599 - ETA: 1:57 - loss: 6.3828 - acc: 0.599 - ETA: 1:57 - loss: 6.3833 - acc: 0.599 - ETA: 1:57 - loss: 6.3839 - acc: 0.599 - ETA: 1:57 - loss: 6.3835 - acc: 0.599 - ETA: 1:57 - loss: 6.3843 - acc: 0.599 - ETA: 1:57 - loss: 6.3838 - acc: 0.599 - ETA: 1:57 - loss: 6.3836 - acc: 0.599 - ETA: 1:57 - loss: 6.3832 - acc: 0.599 - ETA: 1:56 - loss: 6.3834 - acc: 0.599 - ETA: 1:56 - loss: 6.3834 - acc: 0.599 - ETA: 1:56 - loss: 6.3841 - acc: 0.599 - ETA: 1:56 - loss: 6.3838 - acc: 0.599 - ETA: 1:56 - loss: 6.3837 - acc: 0.599 - ETA: 1:56 - loss: 6.3847 - acc: 0.599 - ETA: 1:56 - loss: 6.3847 - acc: 0.599 - ETA: 1:55 - loss: 6.3848 - acc: 0.599 - ETA: 1:55 - loss: 6.3845 - acc: 0.599 - ETA: 1:55 - loss: 6.3849 - acc: 0.599 - ETA: 1:55 - loss: 6.3845 - acc: 0.599 - ETA: 1:55 - loss: 6.3846 - acc: 0.599 - ETA: 1:55 - loss: 6.3843 - acc: 0.599 - ETA: 1:55 - loss: 6.3830 - acc: 0.599 - ETA: 1:54 - loss: 6.3835 - acc: 0.599 - ETA: 1:54 - loss: 6.3836 - acc: 0.599 - ETA: 1:54 - loss: 6.3841 - acc: 0.599 - ETA: 1:54 - loss: 6.3842 - acc: 0.599 - ETA: 1:54 - loss: 6.3840 - acc: 0.599 - ETA: 1:54 - loss: 6.3840 - acc: 0.599 - ETA: 1:53 - loss: 6.3845 - acc: 0.599 - ETA: 1:53 - loss: 6.3848 - acc: 0.599 - ETA: 1:53 - loss: 6.3852 - acc: 0.599 - ETA: 1:53 - loss: 6.3860 - acc: 0.599 - ETA: 1:53 - loss: 6.3856 - acc: 0.599 - ETA: 1:53 - loss: 6.3864 - acc: 0.599 - ETA: 1:53 - loss: 6.3864 - acc: 0.599 - ETA: 1:53 - loss: 6.3865 - acc: 0.599 - ETA: 1:53 - loss: 6.3866 - acc: 0.599 - ETA: 1:53 - loss: 6.3869 - acc: 0.599 - ETA: 1:53 - loss: 6.3870 - acc: 0.599 - ETA: 1:53 - loss: 6.3870 - acc: 0.5994"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "410240/969231 [===========>..................] - ETA: 1:53 - loss: 6.3863 - acc: 0.599 - ETA: 1:52 - loss: 6.3853 - acc: 0.599 - ETA: 1:52 - loss: 6.3858 - acc: 0.599 - ETA: 1:52 - loss: 6.3859 - acc: 0.599 - ETA: 1:52 - loss: 6.3853 - acc: 0.599 - ETA: 1:52 - loss: 6.3859 - acc: 0.599 - ETA: 1:52 - loss: 6.3855 - acc: 0.599 - ETA: 1:52 - loss: 6.3862 - acc: 0.599 - ETA: 1:52 - loss: 6.3867 - acc: 0.599 - ETA: 1:52 - loss: 6.3868 - acc: 0.599 - ETA: 1:52 - loss: 6.3872 - acc: 0.599 - ETA: 1:52 - loss: 6.3877 - acc: 0.599 - ETA: 1:52 - loss: 6.3874 - acc: 0.599 - ETA: 1:51 - loss: 6.3870 - acc: 0.599 - ETA: 1:51 - loss: 6.3874 - acc: 0.599 - ETA: 1:51 - loss: 6.3877 - acc: 0.599 - ETA: 1:52 - loss: 6.3877 - acc: 0.599 - ETA: 1:52 - loss: 6.3876 - acc: 0.599 - ETA: 1:51 - loss: 6.3874 - acc: 0.599 - ETA: 1:51 - loss: 6.3866 - acc: 0.599 - ETA: 1:51 - loss: 6.3863 - acc: 0.599 - ETA: 1:51 - loss: 6.3863 - acc: 0.599 - ETA: 1:51 - loss: 6.3863 - acc: 0.599 - ETA: 1:51 - loss: 6.3864 - acc: 0.599 - ETA: 1:51 - loss: 6.3866 - acc: 0.599 - ETA: 1:51 - loss: 6.3862 - acc: 0.599 - ETA: 1:51 - loss: 6.3859 - acc: 0.599 - ETA: 1:51 - loss: 6.3858 - acc: 0.599 - ETA: 1:51 - loss: 6.3854 - acc: 0.599 - ETA: 1:51 - loss: 6.3847 - acc: 0.599 - ETA: 1:51 - loss: 6.3841 - acc: 0.599 - ETA: 1:51 - loss: 6.3850 - acc: 0.599 - ETA: 1:51 - loss: 6.3848 - acc: 0.599 - ETA: 1:51 - loss: 6.3844 - acc: 0.599 - ETA: 1:50 - loss: 6.3845 - acc: 0.599 - ETA: 1:50 - loss: 6.3842 - acc: 0.599 - ETA: 1:50 - loss: 6.3843 - acc: 0.599 - ETA: 1:50 - loss: 6.3839 - acc: 0.599 - ETA: 1:50 - loss: 6.3842 - acc: 0.599 - ETA: 1:50 - loss: 6.3849 - acc: 0.599 - ETA: 1:50 - loss: 6.3848 - acc: 0.599 - ETA: 1:50 - loss: 6.3850 - acc: 0.599 - ETA: 1:50 - loss: 6.3848 - acc: 0.599 - ETA: 1:50 - loss: 6.3845 - acc: 0.599 - ETA: 1:49 - loss: 6.3848 - acc: 0.599 - ETA: 1:49 - loss: 6.3845 - acc: 0.599 - ETA: 1:49 - loss: 6.3850 - acc: 0.599 - ETA: 1:49 - loss: 6.3854 - acc: 0.599 - ETA: 1:49 - loss: 6.3856 - acc: 0.599 - ETA: 1:49 - loss: 6.3860 - acc: 0.599 - ETA: 1:49 - loss: 6.3856 - acc: 0.599 - ETA: 1:49 - loss: 6.3849 - acc: 0.599 - ETA: 1:49 - loss: 6.3849 - acc: 0.599 - ETA: 1:49 - loss: 6.3851 - acc: 0.599 - ETA: 1:49 - loss: 6.3855 - acc: 0.599 - ETA: 1:49 - loss: 6.3855 - acc: 0.599 - ETA: 1:49 - loss: 6.3857 - acc: 0.599 - ETA: 1:48 - loss: 6.3857 - acc: 0.599 - ETA: 1:48 - loss: 6.3862 - acc: 0.599 - ETA: 1:48 - loss: 6.3861 - acc: 0.599 - ETA: 1:48 - loss: 6.3866 - acc: 0.599 - ETA: 1:48 - loss: 6.3872 - acc: 0.599 - ETA: 1:48 - loss: 6.3877 - acc: 0.599 - ETA: 1:48 - loss: 6.3871 - acc: 0.599 - ETA: 1:48 - loss: 6.3871 - acc: 0.599 - ETA: 1:48 - loss: 6.3871 - acc: 0.599 - ETA: 1:48 - loss: 6.3873 - acc: 0.599 - ETA: 1:48 - loss: 6.3877 - acc: 0.599 - ETA: 1:47 - loss: 6.3872 - acc: 0.599 - ETA: 1:47 - loss: 6.3878 - acc: 0.599 - ETA: 1:47 - loss: 6.3872 - acc: 0.599 - ETA: 1:47 - loss: 6.3880 - acc: 0.599 - ETA: 1:47 - loss: 6.3879 - acc: 0.599 - ETA: 1:47 - loss: 6.3884 - acc: 0.599 - ETA: 1:47 - loss: 6.3880 - acc: 0.599 - ETA: 1:47 - loss: 6.3869 - acc: 0.599 - ETA: 1:46 - loss: 6.3868 - acc: 0.599 - ETA: 1:46 - loss: 6.3872 - acc: 0.599 - ETA: 1:46 - loss: 6.3877 - acc: 0.599 - ETA: 1:46 - loss: 6.3873 - acc: 0.599 - ETA: 1:46 - loss: 6.3875 - acc: 0.599 - ETA: 1:46 - loss: 6.3877 - acc: 0.599 - ETA: 1:46 - loss: 6.3876 - acc: 0.599 - ETA: 1:46 - loss: 6.3873 - acc: 0.599 - ETA: 1:46 - loss: 6.3873 - acc: 0.599 - ETA: 1:46 - loss: 6.3876 - acc: 0.599 - ETA: 1:46 - loss: 6.3878 - acc: 0.599 - ETA: 1:46 - loss: 6.3878 - acc: 0.599 - ETA: 1:46 - loss: 6.3876 - acc: 0.599 - ETA: 1:46 - loss: 6.3878 - acc: 0.599 - ETA: 1:46 - loss: 6.3877 - acc: 0.599 - ETA: 1:46 - loss: 6.3874 - acc: 0.599 - ETA: 1:46 - loss: 6.3873 - acc: 0.599 - ETA: 1:46 - loss: 6.3873 - acc: 0.599 - ETA: 1:46 - loss: 6.3869 - acc: 0.599 - ETA: 1:46 - loss: 6.3873 - acc: 0.599 - ETA: 1:46 - loss: 6.3874 - acc: 0.599 - ETA: 1:46 - loss: 6.3877 - acc: 0.599 - ETA: 1:46 - loss: 6.3874 - acc: 0.599 - ETA: 1:46 - loss: 6.3871 - acc: 0.599 - ETA: 1:46 - loss: 6.3870 - acc: 0.599 - ETA: 1:46 - loss: 6.3871 - acc: 0.599 - ETA: 1:46 - loss: 6.3869 - acc: 0.599 - ETA: 1:46 - loss: 6.3863 - acc: 0.599 - ETA: 1:46 - loss: 6.3852 - acc: 0.599 - ETA: 1:46 - loss: 6.3854 - acc: 0.599 - ETA: 1:46 - loss: 6.3858 - acc: 0.599 - ETA: 1:46 - loss: 6.3852 - acc: 0.599 - ETA: 1:46 - loss: 6.3848 - acc: 0.599 - ETA: 1:46 - loss: 6.3844 - acc: 0.599 - ETA: 1:46 - loss: 6.3839 - acc: 0.599 - ETA: 1:45 - loss: 6.3830 - acc: 0.599 - ETA: 1:45 - loss: 6.3829 - acc: 0.599 - ETA: 1:45 - loss: 6.3829 - acc: 0.599 - ETA: 1:45 - loss: 6.3834 - acc: 0.599 - ETA: 1:45 - loss: 6.3831 - acc: 0.599 - ETA: 1:45 - loss: 6.3831 - acc: 0.599 - ETA: 1:45 - loss: 6.3833 - acc: 0.599 - ETA: 1:45 - loss: 6.3836 - acc: 0.599 - ETA: 1:45 - loss: 6.3839 - acc: 0.599 - ETA: 1:45 - loss: 6.3842 - acc: 0.599 - ETA: 1:45 - loss: 6.3839 - acc: 0.599 - ETA: 1:45 - loss: 6.3842 - acc: 0.599 - ETA: 1:45 - loss: 6.3843 - acc: 0.599 - ETA: 1:45 - loss: 6.3845 - acc: 0.599 - ETA: 1:45 - loss: 6.3844 - acc: 0.599 - ETA: 1:45 - loss: 6.3849 - acc: 0.599 - ETA: 1:45 - loss: 6.3848 - acc: 0.599 - ETA: 1:44 - loss: 6.3846 - acc: 0.599 - ETA: 1:44 - loss: 6.3850 - acc: 0.599 - ETA: 1:44 - loss: 6.3852 - acc: 0.599 - ETA: 1:44 - loss: 6.3852 - acc: 0.599 - ETA: 1:44 - loss: 6.3851 - acc: 0.599 - ETA: 1:44 - loss: 6.3848 - acc: 0.599 - ETA: 1:44 - loss: 6.3850 - acc: 0.599 - ETA: 1:44 - loss: 6.3854 - acc: 0.599 - ETA: 1:44 - loss: 6.3859 - acc: 0.599 - ETA: 1:44 - loss: 6.3857 - acc: 0.599 - ETA: 1:43 - loss: 6.3861 - acc: 0.599 - ETA: 1:43 - loss: 6.3855 - acc: 0.599 - ETA: 1:43 - loss: 6.3855 - acc: 0.599 - ETA: 1:43 - loss: 6.3856 - acc: 0.599 - ETA: 1:43 - loss: 6.3860 - acc: 0.599 - ETA: 1:43 - loss: 6.3853 - acc: 0.599 - ETA: 1:43 - loss: 6.3859 - acc: 0.599 - ETA: 1:43 - loss: 6.3863 - acc: 0.599 - ETA: 1:43 - loss: 6.3862 - acc: 0.599 - ETA: 1:43 - loss: 6.3864 - acc: 0.599 - ETA: 1:43 - loss: 6.3864 - acc: 0.599 - ETA: 1:43 - loss: 6.3866 - acc: 0.599 - ETA: 1:43 - loss: 6.3863 - acc: 0.599 - ETA: 1:43 - loss: 6.3860 - acc: 0.599 - ETA: 1:43 - loss: 6.3857 - acc: 0.599 - ETA: 1:43 - loss: 6.3857 - acc: 0.599 - ETA: 1:43 - loss: 6.3856 - acc: 0.599 - ETA: 1:43 - loss: 6.3854 - acc: 0.599 - ETA: 1:42 - loss: 6.3856 - acc: 0.599 - ETA: 1:42 - loss: 6.3853 - acc: 0.599 - ETA: 1:42 - loss: 6.3849 - acc: 0.599 - ETA: 1:42 - loss: 6.3853 - acc: 0.599 - ETA: 1:42 - loss: 6.3851 - acc: 0.599 - ETA: 1:42 - loss: 6.3852 - acc: 0.599 - ETA: 1:42 - loss: 6.3849 - acc: 0.599 - ETA: 1:42 - loss: 6.3854 - acc: 0.599 - ETA: 1:42 - loss: 6.3858 - acc: 0.599 - ETA: 1:42 - loss: 6.3860 - acc: 0.599 - ETA: 1:42 - loss: 6.3859 - acc: 0.599 - ETA: 1:42 - loss: 6.3854 - acc: 0.599 - ETA: 1:42 - loss: 6.3859 - acc: 0.599 - ETA: 1:42 - loss: 6.3855 - acc: 0.599 - ETA: 1:42 - loss: 6.3854 - acc: 0.599 - ETA: 1:42 - loss: 6.3857 - acc: 0.599 - ETA: 1:42 - loss: 6.3855 - acc: 0.599 - ETA: 1:41 - loss: 6.3849 - acc: 0.599 - ETA: 1:41 - loss: 6.3848 - acc: 0.599 - ETA: 1:41 - loss: 6.3845 - acc: 0.599 - ETA: 1:41 - loss: 6.3851 - acc: 0.599 - ETA: 1:41 - loss: 6.3852 - acc: 0.599 - ETA: 1:41 - loss: 6.3849 - acc: 0.599 - ETA: 1:41 - loss: 6.3845 - acc: 0.599 - ETA: 1:41 - loss: 6.3845 - acc: 0.599 - ETA: 1:41 - loss: 6.3837 - acc: 0.599 - ETA: 1:40 - loss: 6.3835 - acc: 0.599 - ETA: 1:40 - loss: 6.3834 - acc: 0.599 - ETA: 1:40 - loss: 6.3829 - acc: 0.599 - ETA: 1:40 - loss: 6.3829 - acc: 0.599 - ETA: 1:40 - loss: 6.3827 - acc: 0.599 - ETA: 1:40 - loss: 6.3827 - acc: 0.599 - ETA: 1:40 - loss: 6.3832 - acc: 0.599 - ETA: 1:40 - loss: 6.3826 - acc: 0.599 - ETA: 1:40 - loss: 6.3824 - acc: 0.599 - ETA: 1:40 - loss: 6.3821 - acc: 0.599 - ETA: 1:40 - loss: 6.3821 - acc: 0.599 - ETA: 1:40 - loss: 6.3820 - acc: 0.599 - ETA: 1:40 - loss: 6.3820 - acc: 0.599 - ETA: 1:40 - loss: 6.3818 - acc: 0.599 - ETA: 1:40 - loss: 6.3817 - acc: 0.599 - ETA: 1:40 - loss: 6.3814 - acc: 0.599 - ETA: 1:40 - loss: 6.3817 - acc: 0.599 - ETA: 1:40 - loss: 6.3810 - acc: 0.599 - ETA: 1:40 - loss: 6.3808 - acc: 0.599 - ETA: 1:40 - loss: 6.3808 - acc: 0.599 - ETA: 1:40 - loss: 6.3809 - acc: 0.599 - ETA: 1:39 - loss: 6.3808 - acc: 0.5998"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "493952/969231 [==============>...............] - ETA: 1:39 - loss: 6.3807 - acc: 0.599 - ETA: 1:39 - loss: 6.3806 - acc: 0.599 - ETA: 1:39 - loss: 6.3806 - acc: 0.599 - ETA: 1:39 - loss: 6.3812 - acc: 0.599 - ETA: 1:39 - loss: 6.3818 - acc: 0.599 - ETA: 1:39 - loss: 6.3815 - acc: 0.599 - ETA: 1:39 - loss: 6.3815 - acc: 0.599 - ETA: 1:39 - loss: 6.3815 - acc: 0.599 - ETA: 1:39 - loss: 6.3813 - acc: 0.599 - ETA: 1:39 - loss: 6.3811 - acc: 0.599 - ETA: 1:39 - loss: 6.3814 - acc: 0.599 - ETA: 1:39 - loss: 6.3812 - acc: 0.599 - ETA: 1:39 - loss: 6.3812 - acc: 0.599 - ETA: 1:39 - loss: 6.3816 - acc: 0.599 - ETA: 1:39 - loss: 6.3813 - acc: 0.599 - ETA: 1:39 - loss: 6.3821 - acc: 0.599 - ETA: 1:39 - loss: 6.3822 - acc: 0.599 - ETA: 1:39 - loss: 6.3819 - acc: 0.599 - ETA: 1:39 - loss: 6.3819 - acc: 0.599 - ETA: 1:39 - loss: 6.3821 - acc: 0.599 - ETA: 1:39 - loss: 6.3821 - acc: 0.599 - ETA: 1:38 - loss: 6.3820 - acc: 0.599 - ETA: 1:38 - loss: 6.3819 - acc: 0.599 - ETA: 1:38 - loss: 6.3820 - acc: 0.599 - ETA: 1:38 - loss: 6.3826 - acc: 0.599 - ETA: 1:38 - loss: 6.3827 - acc: 0.599 - ETA: 1:38 - loss: 6.3828 - acc: 0.599 - ETA: 1:38 - loss: 6.3823 - acc: 0.599 - ETA: 1:38 - loss: 6.3821 - acc: 0.599 - ETA: 1:38 - loss: 6.3827 - acc: 0.599 - ETA: 1:38 - loss: 6.3832 - acc: 0.599 - ETA: 1:38 - loss: 6.3834 - acc: 0.599 - ETA: 1:38 - loss: 6.3839 - acc: 0.599 - ETA: 1:38 - loss: 6.3843 - acc: 0.599 - ETA: 1:38 - loss: 6.3848 - acc: 0.599 - ETA: 1:38 - loss: 6.3844 - acc: 0.599 - ETA: 1:38 - loss: 6.3842 - acc: 0.599 - ETA: 1:38 - loss: 6.3840 - acc: 0.599 - ETA: 1:37 - loss: 6.3838 - acc: 0.599 - ETA: 1:37 - loss: 6.3847 - acc: 0.599 - ETA: 1:37 - loss: 6.3843 - acc: 0.599 - ETA: 1:37 - loss: 6.3841 - acc: 0.599 - ETA: 1:37 - loss: 6.3844 - acc: 0.599 - ETA: 1:37 - loss: 6.3845 - acc: 0.599 - ETA: 1:37 - loss: 6.3846 - acc: 0.599 - ETA: 1:37 - loss: 6.3840 - acc: 0.599 - ETA: 1:37 - loss: 6.3842 - acc: 0.599 - ETA: 1:37 - loss: 6.3848 - acc: 0.599 - ETA: 1:37 - loss: 6.3838 - acc: 0.599 - ETA: 1:36 - loss: 6.3845 - acc: 0.599 - ETA: 1:36 - loss: 6.3842 - acc: 0.599 - ETA: 1:36 - loss: 6.3836 - acc: 0.599 - ETA: 1:36 - loss: 6.3835 - acc: 0.599 - ETA: 1:36 - loss: 6.3835 - acc: 0.599 - ETA: 1:36 - loss: 6.3833 - acc: 0.599 - ETA: 1:36 - loss: 6.3828 - acc: 0.599 - ETA: 1:36 - loss: 6.3837 - acc: 0.599 - ETA: 1:36 - loss: 6.3840 - acc: 0.599 - ETA: 1:35 - loss: 6.3848 - acc: 0.599 - ETA: 1:35 - loss: 6.3847 - acc: 0.599 - ETA: 1:35 - loss: 6.3844 - acc: 0.599 - ETA: 1:35 - loss: 6.3841 - acc: 0.599 - ETA: 1:35 - loss: 6.3834 - acc: 0.599 - ETA: 1:35 - loss: 6.3835 - acc: 0.599 - ETA: 1:35 - loss: 6.3840 - acc: 0.599 - ETA: 1:35 - loss: 6.3843 - acc: 0.599 - ETA: 1:35 - loss: 6.3845 - acc: 0.599 - ETA: 1:35 - loss: 6.3846 - acc: 0.599 - ETA: 1:35 - loss: 6.3845 - acc: 0.599 - ETA: 1:35 - loss: 6.3849 - acc: 0.599 - ETA: 1:35 - loss: 6.3846 - acc: 0.599 - ETA: 1:34 - loss: 6.3851 - acc: 0.599 - ETA: 1:34 - loss: 6.3861 - acc: 0.599 - ETA: 1:34 - loss: 6.3856 - acc: 0.599 - ETA: 1:34 - loss: 6.3860 - acc: 0.599 - ETA: 1:34 - loss: 6.3862 - acc: 0.599 - ETA: 1:34 - loss: 6.3864 - acc: 0.599 - ETA: 1:34 - loss: 6.3862 - acc: 0.599 - ETA: 1:34 - loss: 6.3862 - acc: 0.599 - ETA: 1:34 - loss: 6.3865 - acc: 0.599 - ETA: 1:33 - loss: 6.3870 - acc: 0.599 - ETA: 1:33 - loss: 6.3872 - acc: 0.599 - ETA: 1:33 - loss: 6.3877 - acc: 0.599 - ETA: 1:33 - loss: 6.3876 - acc: 0.599 - ETA: 1:33 - loss: 6.3884 - acc: 0.599 - ETA: 1:33 - loss: 6.3896 - acc: 0.599 - ETA: 1:32 - loss: 6.3888 - acc: 0.599 - ETA: 1:32 - loss: 6.3890 - acc: 0.599 - ETA: 1:32 - loss: 6.3893 - acc: 0.599 - ETA: 1:32 - loss: 6.3897 - acc: 0.599 - ETA: 1:32 - loss: 6.3896 - acc: 0.599 - ETA: 1:32 - loss: 6.3896 - acc: 0.599 - ETA: 1:32 - loss: 6.3891 - acc: 0.599 - ETA: 1:32 - loss: 6.3896 - acc: 0.599 - ETA: 1:32 - loss: 6.3895 - acc: 0.599 - ETA: 1:32 - loss: 6.3894 - acc: 0.599 - ETA: 1:32 - loss: 6.3894 - acc: 0.599 - ETA: 1:31 - loss: 6.3895 - acc: 0.599 - ETA: 1:31 - loss: 6.3894 - acc: 0.599 - ETA: 1:31 - loss: 6.3894 - acc: 0.599 - ETA: 1:31 - loss: 6.3899 - acc: 0.599 - ETA: 1:31 - loss: 6.3901 - acc: 0.599 - ETA: 1:31 - loss: 6.3902 - acc: 0.599 - ETA: 1:31 - loss: 6.3899 - acc: 0.599 - ETA: 1:31 - loss: 6.3906 - acc: 0.599 - ETA: 1:31 - loss: 6.3902 - acc: 0.599 - ETA: 1:30 - loss: 6.3907 - acc: 0.599 - ETA: 1:30 - loss: 6.3917 - acc: 0.599 - ETA: 1:30 - loss: 6.3924 - acc: 0.599 - ETA: 1:30 - loss: 6.3922 - acc: 0.599 - ETA: 1:30 - loss: 6.3919 - acc: 0.599 - ETA: 1:30 - loss: 6.3921 - acc: 0.599 - ETA: 1:30 - loss: 6.3925 - acc: 0.599 - ETA: 1:29 - loss: 6.3925 - acc: 0.599 - ETA: 1:29 - loss: 6.3921 - acc: 0.599 - ETA: 1:29 - loss: 6.3925 - acc: 0.599 - ETA: 1:29 - loss: 6.3922 - acc: 0.599 - ETA: 1:29 - loss: 6.3924 - acc: 0.599 - ETA: 1:29 - loss: 6.3927 - acc: 0.599 - ETA: 1:29 - loss: 6.3932 - acc: 0.599 - ETA: 1:29 - loss: 6.3928 - acc: 0.599 - ETA: 1:29 - loss: 6.3927 - acc: 0.599 - ETA: 1:29 - loss: 6.3928 - acc: 0.599 - ETA: 1:29 - loss: 6.3926 - acc: 0.599 - ETA: 1:29 - loss: 6.3918 - acc: 0.599 - ETA: 1:28 - loss: 6.3915 - acc: 0.599 - ETA: 1:28 - loss: 6.3917 - acc: 0.599 - ETA: 1:28 - loss: 6.3916 - acc: 0.599 - ETA: 1:28 - loss: 6.3913 - acc: 0.599 - ETA: 1:28 - loss: 6.3909 - acc: 0.599 - ETA: 1:28 - loss: 6.3910 - acc: 0.599 - ETA: 1:28 - loss: 6.3906 - acc: 0.599 - ETA: 1:28 - loss: 6.3910 - acc: 0.599 - ETA: 1:28 - loss: 6.3912 - acc: 0.599 - ETA: 1:28 - loss: 6.3908 - acc: 0.599 - ETA: 1:28 - loss: 6.3908 - acc: 0.599 - ETA: 1:28 - loss: 6.3912 - acc: 0.599 - ETA: 1:27 - loss: 6.3915 - acc: 0.599 - ETA: 1:27 - loss: 6.3911 - acc: 0.599 - ETA: 1:27 - loss: 6.3915 - acc: 0.599 - ETA: 1:27 - loss: 6.3917 - acc: 0.599 - ETA: 1:27 - loss: 6.3912 - acc: 0.599 - ETA: 1:27 - loss: 6.3911 - acc: 0.599 - ETA: 1:27 - loss: 6.3913 - acc: 0.599 - ETA: 1:27 - loss: 6.3912 - acc: 0.599 - ETA: 1:27 - loss: 6.3915 - acc: 0.599 - ETA: 1:27 - loss: 6.3918 - acc: 0.599 - ETA: 1:27 - loss: 6.3919 - acc: 0.599 - ETA: 1:27 - loss: 6.3917 - acc: 0.599 - ETA: 1:26 - loss: 6.3917 - acc: 0.599 - ETA: 1:26 - loss: 6.3911 - acc: 0.599 - ETA: 1:26 - loss: 6.3913 - acc: 0.599 - ETA: 1:26 - loss: 6.3911 - acc: 0.599 - ETA: 1:26 - loss: 6.3913 - acc: 0.599 - ETA: 1:26 - loss: 6.3915 - acc: 0.599 - ETA: 1:26 - loss: 6.3917 - acc: 0.599 - ETA: 1:26 - loss: 6.3922 - acc: 0.599 - ETA: 1:26 - loss: 6.3924 - acc: 0.599 - ETA: 1:26 - loss: 6.3925 - acc: 0.599 - ETA: 1:26 - loss: 6.3932 - acc: 0.599 - ETA: 1:25 - loss: 6.3936 - acc: 0.599 - ETA: 1:25 - loss: 6.3940 - acc: 0.598 - ETA: 1:25 - loss: 6.3939 - acc: 0.598 - ETA: 1:25 - loss: 6.3942 - acc: 0.598 - ETA: 1:25 - loss: 6.3942 - acc: 0.598 - ETA: 1:25 - loss: 6.3940 - acc: 0.598 - ETA: 1:25 - loss: 6.3938 - acc: 0.598 - ETA: 1:25 - loss: 6.3940 - acc: 0.598 - ETA: 1:25 - loss: 6.3948 - acc: 0.598 - ETA: 1:25 - loss: 6.3948 - acc: 0.598 - ETA: 1:25 - loss: 6.3948 - acc: 0.598 - ETA: 1:25 - loss: 6.3949 - acc: 0.598 - ETA: 1:24 - loss: 6.3944 - acc: 0.598 - ETA: 1:24 - loss: 6.3947 - acc: 0.598 - ETA: 1:24 - loss: 6.3943 - acc: 0.598 - ETA: 1:24 - loss: 6.3941 - acc: 0.598 - ETA: 1:24 - loss: 6.3943 - acc: 0.598 - ETA: 1:24 - loss: 6.3943 - acc: 0.598 - ETA: 1:24 - loss: 6.3940 - acc: 0.598 - ETA: 1:24 - loss: 6.3943 - acc: 0.598 - ETA: 1:24 - loss: 6.3941 - acc: 0.598 - ETA: 1:23 - loss: 6.3944 - acc: 0.598 - ETA: 1:23 - loss: 6.3944 - acc: 0.598 - ETA: 1:23 - loss: 6.3945 - acc: 0.598 - ETA: 1:23 - loss: 6.3944 - acc: 0.598 - ETA: 1:23 - loss: 6.3940 - acc: 0.598 - ETA: 1:23 - loss: 6.3938 - acc: 0.598 - ETA: 1:23 - loss: 6.3936 - acc: 0.599 - ETA: 1:23 - loss: 6.3933 - acc: 0.599 - ETA: 1:23 - loss: 6.3934 - acc: 0.599 - ETA: 1:23 - loss: 6.3932 - acc: 0.599 - ETA: 1:23 - loss: 6.3935 - acc: 0.599 - ETA: 1:23 - loss: 6.3936 - acc: 0.599 - ETA: 1:23 - loss: 6.3938 - acc: 0.598 - ETA: 1:22 - loss: 6.3938 - acc: 0.598 - ETA: 1:22 - loss: 6.3941 - acc: 0.598 - ETA: 1:22 - loss: 6.3939 - acc: 0.598 - ETA: 1:22 - loss: 6.3939 - acc: 0.598 - ETA: 1:22 - loss: 6.3934 - acc: 0.599 - ETA: 1:22 - loss: 6.3934 - acc: 0.599 - ETA: 1:22 - loss: 6.3939 - acc: 0.598 - ETA: 1:22 - loss: 6.3943 - acc: 0.598 - ETA: 1:22 - loss: 6.3943 - acc: 0.598 - ETA: 1:21 - loss: 6.3945 - acc: 0.5989"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "575744/969231 [================>.............] - ETA: 1:21 - loss: 6.3946 - acc: 0.598 - ETA: 1:21 - loss: 6.3946 - acc: 0.598 - ETA: 1:21 - loss: 6.3943 - acc: 0.598 - ETA: 1:21 - loss: 6.3940 - acc: 0.598 - ETA: 1:21 - loss: 6.3940 - acc: 0.598 - ETA: 1:21 - loss: 6.3939 - acc: 0.598 - ETA: 1:21 - loss: 6.3936 - acc: 0.599 - ETA: 1:21 - loss: 6.3938 - acc: 0.598 - ETA: 1:21 - loss: 6.3938 - acc: 0.598 - ETA: 1:21 - loss: 6.3933 - acc: 0.599 - ETA: 1:20 - loss: 6.3936 - acc: 0.599 - ETA: 1:20 - loss: 6.3936 - acc: 0.599 - ETA: 1:20 - loss: 6.3936 - acc: 0.599 - ETA: 1:20 - loss: 6.3937 - acc: 0.599 - ETA: 1:20 - loss: 6.3938 - acc: 0.598 - ETA: 1:20 - loss: 6.3940 - acc: 0.598 - ETA: 1:20 - loss: 6.3942 - acc: 0.598 - ETA: 1:20 - loss: 6.3944 - acc: 0.598 - ETA: 1:20 - loss: 6.3944 - acc: 0.598 - ETA: 1:20 - loss: 6.3948 - acc: 0.598 - ETA: 1:20 - loss: 6.3947 - acc: 0.598 - ETA: 1:20 - loss: 6.3949 - acc: 0.598 - ETA: 1:20 - loss: 6.3948 - acc: 0.598 - ETA: 1:20 - loss: 6.3948 - acc: 0.598 - ETA: 1:20 - loss: 6.3947 - acc: 0.598 - ETA: 1:19 - loss: 6.3946 - acc: 0.598 - ETA: 1:19 - loss: 6.3950 - acc: 0.598 - ETA: 1:19 - loss: 6.3951 - acc: 0.598 - ETA: 1:19 - loss: 6.3956 - acc: 0.598 - ETA: 1:19 - loss: 6.3957 - acc: 0.598 - ETA: 1:19 - loss: 6.3947 - acc: 0.598 - ETA: 1:19 - loss: 6.3951 - acc: 0.598 - ETA: 1:19 - loss: 6.3949 - acc: 0.598 - ETA: 1:18 - loss: 6.3950 - acc: 0.598 - ETA: 1:18 - loss: 6.3949 - acc: 0.598 - ETA: 1:18 - loss: 6.3949 - acc: 0.598 - ETA: 1:18 - loss: 6.3948 - acc: 0.598 - ETA: 1:18 - loss: 6.3943 - acc: 0.598 - ETA: 1:18 - loss: 6.3940 - acc: 0.598 - ETA: 1:18 - loss: 6.3936 - acc: 0.599 - ETA: 1:18 - loss: 6.3936 - acc: 0.599 - ETA: 1:18 - loss: 6.3936 - acc: 0.599 - ETA: 1:17 - loss: 6.3939 - acc: 0.598 - ETA: 1:17 - loss: 6.3939 - acc: 0.598 - ETA: 1:17 - loss: 6.3940 - acc: 0.598 - ETA: 1:17 - loss: 6.3937 - acc: 0.598 - ETA: 1:17 - loss: 6.3937 - acc: 0.599 - ETA: 1:17 - loss: 6.3941 - acc: 0.598 - ETA: 1:17 - loss: 6.3936 - acc: 0.599 - ETA: 1:17 - loss: 6.3942 - acc: 0.598 - ETA: 1:17 - loss: 6.3947 - acc: 0.598 - ETA: 1:17 - loss: 6.3941 - acc: 0.598 - ETA: 1:17 - loss: 6.3940 - acc: 0.598 - ETA: 1:17 - loss: 6.3940 - acc: 0.598 - ETA: 1:17 - loss: 6.3940 - acc: 0.598 - ETA: 1:16 - loss: 6.3941 - acc: 0.598 - ETA: 1:16 - loss: 6.3936 - acc: 0.599 - ETA: 1:16 - loss: 6.3940 - acc: 0.598 - ETA: 1:16 - loss: 6.3945 - acc: 0.598 - ETA: 1:16 - loss: 6.3945 - acc: 0.598 - ETA: 1:16 - loss: 6.3945 - acc: 0.598 - ETA: 1:16 - loss: 6.3944 - acc: 0.598 - ETA: 1:16 - loss: 6.3944 - acc: 0.598 - ETA: 1:16 - loss: 6.3942 - acc: 0.598 - ETA: 1:16 - loss: 6.3949 - acc: 0.598 - ETA: 1:15 - loss: 6.3949 - acc: 0.598 - ETA: 1:15 - loss: 6.3952 - acc: 0.598 - ETA: 1:15 - loss: 6.3953 - acc: 0.598 - ETA: 1:15 - loss: 6.3953 - acc: 0.598 - ETA: 1:15 - loss: 6.3952 - acc: 0.598 - ETA: 1:15 - loss: 6.3950 - acc: 0.598 - ETA: 1:15 - loss: 6.3946 - acc: 0.598 - ETA: 1:15 - loss: 6.3947 - acc: 0.598 - ETA: 1:15 - loss: 6.3951 - acc: 0.598 - ETA: 1:15 - loss: 6.3953 - acc: 0.598 - ETA: 1:15 - loss: 6.3950 - acc: 0.598 - ETA: 1:15 - loss: 6.3947 - acc: 0.598 - ETA: 1:15 - loss: 6.3954 - acc: 0.598 - ETA: 1:14 - loss: 6.3958 - acc: 0.598 - ETA: 1:14 - loss: 6.3958 - acc: 0.598 - ETA: 1:14 - loss: 6.3961 - acc: 0.598 - ETA: 1:14 - loss: 6.3961 - acc: 0.598 - ETA: 1:14 - loss: 6.3965 - acc: 0.598 - ETA: 1:14 - loss: 6.3955 - acc: 0.598 - ETA: 1:14 - loss: 6.3952 - acc: 0.598 - ETA: 1:14 - loss: 6.3952 - acc: 0.598 - ETA: 1:14 - loss: 6.3953 - acc: 0.598 - ETA: 1:14 - loss: 6.3957 - acc: 0.598 - ETA: 1:14 - loss: 6.3961 - acc: 0.598 - ETA: 1:14 - loss: 6.3962 - acc: 0.598 - ETA: 1:14 - loss: 6.3963 - acc: 0.598 - ETA: 1:13 - loss: 6.3967 - acc: 0.598 - ETA: 1:13 - loss: 6.3965 - acc: 0.598 - ETA: 1:13 - loss: 6.3965 - acc: 0.598 - ETA: 1:13 - loss: 6.3964 - acc: 0.598 - ETA: 1:13 - loss: 6.3961 - acc: 0.598 - ETA: 1:13 - loss: 6.3964 - acc: 0.598 - ETA: 1:13 - loss: 6.3964 - acc: 0.598 - ETA: 1:13 - loss: 6.3965 - acc: 0.598 - ETA: 1:13 - loss: 6.3970 - acc: 0.598 - ETA: 1:13 - loss: 6.3967 - acc: 0.598 - ETA: 1:13 - loss: 6.3968 - acc: 0.598 - ETA: 1:13 - loss: 6.3966 - acc: 0.598 - ETA: 1:13 - loss: 6.3967 - acc: 0.598 - ETA: 1:12 - loss: 6.3967 - acc: 0.598 - ETA: 1:12 - loss: 6.3966 - acc: 0.598 - ETA: 1:12 - loss: 6.3965 - acc: 0.598 - ETA: 1:12 - loss: 6.3961 - acc: 0.598 - ETA: 1:12 - loss: 6.3966 - acc: 0.598 - ETA: 1:12 - loss: 6.3965 - acc: 0.598 - ETA: 1:12 - loss: 6.3965 - acc: 0.598 - ETA: 1:12 - loss: 6.3971 - acc: 0.598 - ETA: 1:12 - loss: 6.3970 - acc: 0.598 - ETA: 1:12 - loss: 6.3971 - acc: 0.598 - ETA: 1:12 - loss: 6.3969 - acc: 0.598 - ETA: 1:12 - loss: 6.3968 - acc: 0.598 - ETA: 1:11 - loss: 6.3971 - acc: 0.598 - ETA: 1:11 - loss: 6.3975 - acc: 0.598 - ETA: 1:11 - loss: 6.3974 - acc: 0.598 - ETA: 1:11 - loss: 6.3975 - acc: 0.598 - ETA: 1:11 - loss: 6.3971 - acc: 0.598 - ETA: 1:11 - loss: 6.3969 - acc: 0.598 - ETA: 1:11 - loss: 6.3970 - acc: 0.598 - ETA: 1:11 - loss: 6.3973 - acc: 0.598 - ETA: 1:11 - loss: 6.3976 - acc: 0.598 - ETA: 1:11 - loss: 6.3974 - acc: 0.598 - ETA: 1:11 - loss: 6.3972 - acc: 0.598 - ETA: 1:11 - loss: 6.3968 - acc: 0.598 - ETA: 1:10 - loss: 6.3971 - acc: 0.598 - ETA: 1:10 - loss: 6.3970 - acc: 0.598 - ETA: 1:10 - loss: 6.3969 - acc: 0.598 - ETA: 1:10 - loss: 6.3969 - acc: 0.598 - ETA: 1:10 - loss: 6.3968 - acc: 0.598 - ETA: 1:10 - loss: 6.3971 - acc: 0.598 - ETA: 1:10 - loss: 6.3973 - acc: 0.598 - ETA: 1:10 - loss: 6.3978 - acc: 0.598 - ETA: 1:10 - loss: 6.3982 - acc: 0.598 - ETA: 1:10 - loss: 6.3983 - acc: 0.598 - ETA: 1:10 - loss: 6.3977 - acc: 0.598 - ETA: 1:10 - loss: 6.3977 - acc: 0.598 - ETA: 1:10 - loss: 6.3974 - acc: 0.598 - ETA: 1:09 - loss: 6.3977 - acc: 0.598 - ETA: 1:09 - loss: 6.3972 - acc: 0.598 - ETA: 1:09 - loss: 6.3976 - acc: 0.598 - ETA: 1:09 - loss: 6.3977 - acc: 0.598 - ETA: 1:09 - loss: 6.3972 - acc: 0.598 - ETA: 1:09 - loss: 6.3975 - acc: 0.598 - ETA: 1:09 - loss: 6.3972 - acc: 0.598 - ETA: 1:09 - loss: 6.3976 - acc: 0.598 - ETA: 1:09 - loss: 6.3978 - acc: 0.598 - ETA: 1:09 - loss: 6.3975 - acc: 0.598 - ETA: 1:09 - loss: 6.3976 - acc: 0.598 - ETA: 1:09 - loss: 6.3975 - acc: 0.598 - ETA: 1:09 - loss: 6.3976 - acc: 0.598 - ETA: 1:08 - loss: 6.3975 - acc: 0.598 - ETA: 1:08 - loss: 6.3979 - acc: 0.598 - ETA: 1:08 - loss: 6.3982 - acc: 0.598 - ETA: 1:08 - loss: 6.3980 - acc: 0.598 - ETA: 1:08 - loss: 6.3983 - acc: 0.598 - ETA: 1:08 - loss: 6.3986 - acc: 0.598 - ETA: 1:08 - loss: 6.3988 - acc: 0.598 - ETA: 1:08 - loss: 6.3986 - acc: 0.598 - ETA: 1:08 - loss: 6.3981 - acc: 0.598 - ETA: 1:08 - loss: 6.3986 - acc: 0.598 - ETA: 1:08 - loss: 6.3987 - acc: 0.598 - ETA: 1:07 - loss: 6.3987 - acc: 0.598 - ETA: 1:07 - loss: 6.3985 - acc: 0.598 - ETA: 1:07 - loss: 6.3984 - acc: 0.598 - ETA: 1:07 - loss: 6.3979 - acc: 0.598 - ETA: 1:07 - loss: 6.3979 - acc: 0.598 - ETA: 1:07 - loss: 6.3978 - acc: 0.598 - ETA: 1:07 - loss: 6.3982 - acc: 0.598 - ETA: 1:07 - loss: 6.3984 - acc: 0.598 - ETA: 1:07 - loss: 6.3986 - acc: 0.598 - ETA: 1:07 - loss: 6.3985 - acc: 0.598 - ETA: 1:07 - loss: 6.3982 - acc: 0.598 - ETA: 1:07 - loss: 6.3984 - acc: 0.598 - ETA: 1:07 - loss: 6.3986 - acc: 0.598 - ETA: 1:07 - loss: 6.3987 - acc: 0.598 - ETA: 1:06 - loss: 6.3984 - acc: 0.598 - ETA: 1:06 - loss: 6.3984 - acc: 0.598 - ETA: 1:06 - loss: 6.3985 - acc: 0.598 - ETA: 1:06 - loss: 6.3983 - acc: 0.598 - ETA: 1:06 - loss: 6.3980 - acc: 0.598 - ETA: 1:06 - loss: 6.3979 - acc: 0.598 - ETA: 1:06 - loss: 6.3982 - acc: 0.598 - ETA: 1:06 - loss: 6.3982 - acc: 0.598 - ETA: 1:06 - loss: 6.3984 - acc: 0.598 - ETA: 1:06 - loss: 6.3981 - acc: 0.598 - ETA: 1:06 - loss: 6.3986 - acc: 0.598 - ETA: 1:06 - loss: 6.3985 - acc: 0.598 - ETA: 1:06 - loss: 6.3985 - acc: 0.598 - ETA: 1:06 - loss: 6.3982 - acc: 0.598 - ETA: 1:06 - loss: 6.3982 - acc: 0.598 - ETA: 1:06 - loss: 6.3982 - acc: 0.598 - ETA: 1:06 - loss: 6.3981 - acc: 0.598 - ETA: 1:06 - loss: 6.3980 - acc: 0.598 - ETA: 1:06 - loss: 6.3977 - acc: 0.598 - ETA: 1:06 - loss: 6.3978 - acc: 0.598 - ETA: 1:06 - loss: 6.3979 - acc: 0.598 - ETA: 1:06 - loss: 6.3976 - acc: 0.598 - ETA: 1:06 - loss: 6.3978 - acc: 0.598 - ETA: 1:06 - loss: 6.3978 - acc: 0.598 - ETA: 1:06 - loss: 6.3977 - acc: 0.5987"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627840/969231 [==================>...........] - ETA: 1:06 - loss: 6.3976 - acc: 0.598 - ETA: 1:06 - loss: 6.3977 - acc: 0.598 - ETA: 1:06 - loss: 6.3978 - acc: 0.598 - ETA: 1:06 - loss: 6.3980 - acc: 0.598 - ETA: 1:06 - loss: 6.3981 - acc: 0.598 - ETA: 1:06 - loss: 6.3983 - acc: 0.598 - ETA: 1:06 - loss: 6.3987 - acc: 0.598 - ETA: 1:06 - loss: 6.3986 - acc: 0.598 - ETA: 1:06 - loss: 6.3986 - acc: 0.598 - ETA: 1:06 - loss: 6.3986 - acc: 0.598 - ETA: 1:06 - loss: 6.3985 - acc: 0.598 - ETA: 1:06 - loss: 6.3989 - acc: 0.598 - ETA: 1:06 - loss: 6.3988 - acc: 0.598 - ETA: 1:06 - loss: 6.3988 - acc: 0.598 - ETA: 1:06 - loss: 6.3989 - acc: 0.598 - ETA: 1:06 - loss: 6.3989 - acc: 0.598 - ETA: 1:06 - loss: 6.3989 - acc: 0.598 - ETA: 1:06 - loss: 6.3994 - acc: 0.598 - ETA: 1:05 - loss: 6.3997 - acc: 0.598 - ETA: 1:05 - loss: 6.3996 - acc: 0.598 - ETA: 1:05 - loss: 6.3995 - acc: 0.598 - ETA: 1:05 - loss: 6.3997 - acc: 0.598 - ETA: 1:05 - loss: 6.3996 - acc: 0.598 - ETA: 1:05 - loss: 6.3998 - acc: 0.598 - ETA: 1:05 - loss: 6.4000 - acc: 0.598 - ETA: 1:05 - loss: 6.4000 - acc: 0.598 - ETA: 1:05 - loss: 6.3998 - acc: 0.598 - ETA: 1:05 - loss: 6.3996 - acc: 0.598 - ETA: 1:05 - loss: 6.3994 - acc: 0.598 - ETA: 1:05 - loss: 6.3988 - acc: 0.598 - ETA: 1:05 - loss: 6.3987 - acc: 0.598 - ETA: 1:05 - loss: 6.3987 - acc: 0.598 - ETA: 1:05 - loss: 6.3987 - acc: 0.598 - ETA: 1:05 - loss: 6.3987 - acc: 0.598 - ETA: 1:05 - loss: 6.3989 - acc: 0.598 - ETA: 1:05 - loss: 6.3990 - acc: 0.598 - ETA: 1:05 - loss: 6.3989 - acc: 0.598 - ETA: 1:05 - loss: 6.3993 - acc: 0.598 - ETA: 1:05 - loss: 6.3992 - acc: 0.598 - ETA: 1:05 - loss: 6.3991 - acc: 0.598 - ETA: 1:05 - loss: 6.3989 - acc: 0.598 - ETA: 1:05 - loss: 6.3987 - acc: 0.598 - ETA: 1:05 - loss: 6.3988 - acc: 0.598 - ETA: 1:05 - loss: 6.3990 - acc: 0.598 - ETA: 1:05 - loss: 6.3989 - acc: 0.598 - ETA: 1:05 - loss: 6.3988 - acc: 0.598 - ETA: 1:05 - loss: 6.3985 - acc: 0.598 - ETA: 1:05 - loss: 6.3987 - acc: 0.598 - ETA: 1:04 - loss: 6.3987 - acc: 0.598 - ETA: 1:04 - loss: 6.3985 - acc: 0.598 - ETA: 1:04 - loss: 6.3983 - acc: 0.598 - ETA: 1:04 - loss: 6.3984 - acc: 0.598 - ETA: 1:04 - loss: 6.3982 - acc: 0.598 - ETA: 1:04 - loss: 6.3983 - acc: 0.598 - ETA: 1:04 - loss: 6.3980 - acc: 0.598 - ETA: 1:04 - loss: 6.3974 - acc: 0.598 - ETA: 1:04 - loss: 6.3975 - acc: 0.598 - ETA: 1:04 - loss: 6.3974 - acc: 0.598 - ETA: 1:04 - loss: 6.3975 - acc: 0.598 - ETA: 1:04 - loss: 6.3975 - acc: 0.598 - ETA: 1:04 - loss: 6.3978 - acc: 0.598 - ETA: 1:04 - loss: 6.3981 - acc: 0.598 - ETA: 1:04 - loss: 6.3984 - acc: 0.598 - ETA: 1:04 - loss: 6.3986 - acc: 0.598 - ETA: 1:04 - loss: 6.3988 - acc: 0.598 - ETA: 1:04 - loss: 6.3988 - acc: 0.598 - ETA: 1:04 - loss: 6.3990 - acc: 0.598 - ETA: 1:04 - loss: 6.3992 - acc: 0.598 - ETA: 1:04 - loss: 6.3992 - acc: 0.598 - ETA: 1:04 - loss: 6.3995 - acc: 0.598 - ETA: 1:04 - loss: 6.3996 - acc: 0.598 - ETA: 1:04 - loss: 6.3996 - acc: 0.598 - ETA: 1:04 - loss: 6.3995 - acc: 0.598 - ETA: 1:04 - loss: 6.3997 - acc: 0.598 - ETA: 1:04 - loss: 6.3999 - acc: 0.598 - ETA: 1:04 - loss: 6.3999 - acc: 0.598 - ETA: 1:04 - loss: 6.3994 - acc: 0.598 - ETA: 1:04 - loss: 6.3994 - acc: 0.598 - ETA: 1:04 - loss: 6.3995 - acc: 0.598 - ETA: 1:03 - loss: 6.3995 - acc: 0.598 - ETA: 1:03 - loss: 6.3996 - acc: 0.598 - ETA: 1:03 - loss: 6.4000 - acc: 0.598 - ETA: 1:03 - loss: 6.4004 - acc: 0.598 - ETA: 1:03 - loss: 6.4003 - acc: 0.598 - ETA: 1:03 - loss: 6.4001 - acc: 0.598 - ETA: 1:03 - loss: 6.4003 - acc: 0.598 - ETA: 1:03 - loss: 6.4002 - acc: 0.598 - ETA: 1:03 - loss: 6.4000 - acc: 0.598 - ETA: 1:03 - loss: 6.4001 - acc: 0.598 - ETA: 1:03 - loss: 6.3999 - acc: 0.598 - ETA: 1:03 - loss: 6.4003 - acc: 0.598 - ETA: 1:03 - loss: 6.3999 - acc: 0.598 - ETA: 1:03 - loss: 6.3998 - acc: 0.598 - ETA: 1:03 - loss: 6.3998 - acc: 0.598 - ETA: 1:03 - loss: 6.4003 - acc: 0.598 - ETA: 1:03 - loss: 6.4004 - acc: 0.598 - ETA: 1:03 - loss: 6.4001 - acc: 0.598 - ETA: 1:03 - loss: 6.4000 - acc: 0.598 - ETA: 1:03 - loss: 6.3997 - acc: 0.598 - ETA: 1:03 - loss: 6.3998 - acc: 0.598 - ETA: 1:03 - loss: 6.3998 - acc: 0.598 - ETA: 1:03 - loss: 6.3996 - acc: 0.598 - ETA: 1:02 - loss: 6.3993 - acc: 0.598 - ETA: 1:02 - loss: 6.3994 - acc: 0.598 - ETA: 1:02 - loss: 6.3995 - acc: 0.598 - ETA: 1:02 - loss: 6.3995 - acc: 0.598 - ETA: 1:02 - loss: 6.3994 - acc: 0.598 - ETA: 1:02 - loss: 6.3995 - acc: 0.598 - ETA: 1:02 - loss: 6.3993 - acc: 0.598 - ETA: 1:02 - loss: 6.3994 - acc: 0.598 - ETA: 1:02 - loss: 6.3994 - acc: 0.598 - ETA: 1:02 - loss: 6.3992 - acc: 0.598 - ETA: 1:02 - loss: 6.3993 - acc: 0.598 - ETA: 1:02 - loss: 6.3994 - acc: 0.598 - ETA: 1:02 - loss: 6.3994 - acc: 0.598 - ETA: 1:02 - loss: 6.3995 - acc: 0.598 - ETA: 1:02 - loss: 6.3995 - acc: 0.598 - ETA: 1:02 - loss: 6.3997 - acc: 0.598 - ETA: 1:02 - loss: 6.3996 - acc: 0.598 - ETA: 1:02 - loss: 6.3992 - acc: 0.598 - ETA: 1:02 - loss: 6.3996 - acc: 0.598 - ETA: 1:02 - loss: 6.3993 - acc: 0.598 - ETA: 1:02 - loss: 6.3993 - acc: 0.598 - ETA: 1:02 - loss: 6.3990 - acc: 0.598 - ETA: 1:02 - loss: 6.3993 - acc: 0.598 - ETA: 1:02 - loss: 6.3992 - acc: 0.598 - ETA: 1:02 - loss: 6.3992 - acc: 0.598 - ETA: 1:02 - loss: 6.3993 - acc: 0.598 - ETA: 1:02 - loss: 6.3990 - acc: 0.598 - ETA: 1:02 - loss: 6.3988 - acc: 0.598 - ETA: 1:02 - loss: 6.3989 - acc: 0.598 - ETA: 1:02 - loss: 6.3989 - acc: 0.598 - ETA: 1:02 - loss: 6.3986 - acc: 0.598 - ETA: 1:02 - loss: 6.3986 - acc: 0.598 - ETA: 1:02 - loss: 6.3986 - acc: 0.598 - ETA: 1:02 - loss: 6.3992 - acc: 0.598 - ETA: 1:02 - loss: 6.3994 - acc: 0.598 - ETA: 1:02 - loss: 6.3994 - acc: 0.598 - ETA: 1:02 - loss: 6.3990 - acc: 0.598 - ETA: 1:02 - loss: 6.3990 - acc: 0.598 - ETA: 1:02 - loss: 6.3991 - acc: 0.598 - ETA: 1:02 - loss: 6.3996 - acc: 0.598 - ETA: 1:02 - loss: 6.3996 - acc: 0.598 - ETA: 1:02 - loss: 6.3999 - acc: 0.598 - ETA: 1:02 - loss: 6.4001 - acc: 0.598 - ETA: 1:02 - loss: 6.3999 - acc: 0.598 - ETA: 1:01 - loss: 6.3998 - acc: 0.598 - ETA: 1:01 - loss: 6.3998 - acc: 0.598 - ETA: 1:01 - loss: 6.4001 - acc: 0.598 - ETA: 1:01 - loss: 6.4002 - acc: 0.598 - ETA: 1:01 - loss: 6.4004 - acc: 0.598 - ETA: 1:01 - loss: 6.4004 - acc: 0.598 - ETA: 1:01 - loss: 6.4005 - acc: 0.598 - ETA: 1:01 - loss: 6.4005 - acc: 0.598 - ETA: 1:01 - loss: 6.4007 - acc: 0.598 - ETA: 1:01 - loss: 6.4007 - acc: 0.598 - ETA: 1:01 - loss: 6.4007 - acc: 0.598 - ETA: 1:01 - loss: 6.4008 - acc: 0.598 - ETA: 1:01 - loss: 6.4010 - acc: 0.598 - ETA: 1:01 - loss: 6.4008 - acc: 0.598 - ETA: 1:01 - loss: 6.4008 - acc: 0.598 - ETA: 1:01 - loss: 6.4008 - acc: 0.598 - ETA: 1:01 - loss: 6.4009 - acc: 0.598 - ETA: 1:01 - loss: 6.4008 - acc: 0.598 - ETA: 1:01 - loss: 6.4007 - acc: 0.598 - ETA: 1:01 - loss: 6.4007 - acc: 0.598 - ETA: 1:01 - loss: 6.4010 - acc: 0.598 - ETA: 1:01 - loss: 6.4008 - acc: 0.598 - ETA: 1:01 - loss: 6.4008 - acc: 0.598 - ETA: 1:01 - loss: 6.4006 - acc: 0.598 - ETA: 1:01 - loss: 6.4007 - acc: 0.598 - ETA: 1:01 - loss: 6.4006 - acc: 0.598 - ETA: 1:00 - loss: 6.4007 - acc: 0.598 - ETA: 1:00 - loss: 6.4007 - acc: 0.598 - ETA: 1:00 - loss: 6.4009 - acc: 0.598 - ETA: 1:00 - loss: 6.4007 - acc: 0.598 - ETA: 1:00 - loss: 6.4006 - acc: 0.598 - ETA: 1:00 - loss: 6.4006 - acc: 0.598 - ETA: 1:00 - loss: 6.4009 - acc: 0.598 - ETA: 1:00 - loss: 6.4012 - acc: 0.598 - ETA: 1:00 - loss: 6.4010 - acc: 0.598 - ETA: 1:00 - loss: 6.4010 - acc: 0.598 - ETA: 1:00 - loss: 6.4013 - acc: 0.598 - ETA: 1:00 - loss: 6.4011 - acc: 0.598 - ETA: 1:00 - loss: 6.4007 - acc: 0.598 - ETA: 1:00 - loss: 6.4007 - acc: 0.598 - ETA: 1:00 - loss: 6.4007 - acc: 0.598 - ETA: 1:00 - loss: 6.4009 - acc: 0.598 - ETA: 1:00 - loss: 6.4008 - acc: 0.598 - ETA: 1:00 - loss: 6.4004 - acc: 0.598 - ETA: 1:00 - loss: 6.4002 - acc: 0.598 - ETA: 1:00 - loss: 6.4003 - acc: 0.598 - ETA: 1:00 - loss: 6.4000 - acc: 0.598 - ETA: 1:00 - loss: 6.4000 - acc: 0.598 - ETA: 1:00 - loss: 6.3998 - acc: 0.598 - ETA: 59s - loss: 6.3997 - acc: 0.598 - ETA: 59s - loss: 6.3995 - acc: 0.59 - ETA: 59s - loss: 6.3993 - acc: 0.59 - ETA: 59s - loss: 6.3997 - acc: 0.59 - ETA: 59s - loss: 6.3997 - acc: 0.59 - ETA: 59s - loss: 6.3995 - acc: 0.59 - ETA: 59s - loss: 6.3996 - acc: 0.59 - ETA: 59s - loss: 6.3997 - acc: 0.59 - ETA: 59s - loss: 6.3994 - acc: 0.59 - ETA: 59s - loss: 6.3995 - acc: 0.5986"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "686336/969231 [====================>.........] - ETA: 59s - loss: 6.3994 - acc: 0.59 - ETA: 59s - loss: 6.3993 - acc: 0.59 - ETA: 59s - loss: 6.3994 - acc: 0.59 - ETA: 59s - loss: 6.3995 - acc: 0.59 - ETA: 59s - loss: 6.3995 - acc: 0.59 - ETA: 59s - loss: 6.3993 - acc: 0.59 - ETA: 59s - loss: 6.3994 - acc: 0.59 - ETA: 59s - loss: 6.3997 - acc: 0.59 - ETA: 59s - loss: 6.3998 - acc: 0.59 - ETA: 59s - loss: 6.4000 - acc: 0.59 - ETA: 59s - loss: 6.3999 - acc: 0.59 - ETA: 59s - loss: 6.3996 - acc: 0.59 - ETA: 59s - loss: 6.3997 - acc: 0.59 - ETA: 59s - loss: 6.3998 - acc: 0.59 - ETA: 59s - loss: 6.3998 - acc: 0.59 - ETA: 59s - loss: 6.3994 - acc: 0.59 - ETA: 59s - loss: 6.3992 - acc: 0.59 - ETA: 59s - loss: 6.3991 - acc: 0.59 - ETA: 59s - loss: 6.3992 - acc: 0.59 - ETA: 59s - loss: 6.3992 - acc: 0.59 - ETA: 59s - loss: 6.3992 - acc: 0.59 - ETA: 59s - loss: 6.3991 - acc: 0.59 - ETA: 59s - loss: 6.3993 - acc: 0.59 - ETA: 59s - loss: 6.3991 - acc: 0.59 - ETA: 59s - loss: 6.3987 - acc: 0.59 - ETA: 59s - loss: 6.3984 - acc: 0.59 - ETA: 59s - loss: 6.3983 - acc: 0.59 - ETA: 59s - loss: 6.3982 - acc: 0.59 - ETA: 59s - loss: 6.3983 - acc: 0.59 - ETA: 59s - loss: 6.3981 - acc: 0.59 - ETA: 59s - loss: 6.3980 - acc: 0.59 - ETA: 59s - loss: 6.3980 - acc: 0.59 - ETA: 59s - loss: 6.3979 - acc: 0.59 - ETA: 59s - loss: 6.3978 - acc: 0.59 - ETA: 59s - loss: 6.3977 - acc: 0.59 - ETA: 59s - loss: 6.3973 - acc: 0.59 - ETA: 59s - loss: 6.3970 - acc: 0.59 - ETA: 58s - loss: 6.3970 - acc: 0.59 - ETA: 58s - loss: 6.3970 - acc: 0.59 - ETA: 58s - loss: 6.3970 - acc: 0.59 - ETA: 58s - loss: 6.3973 - acc: 0.59 - ETA: 58s - loss: 6.3975 - acc: 0.59 - ETA: 58s - loss: 6.3973 - acc: 0.59 - ETA: 58s - loss: 6.3971 - acc: 0.59 - ETA: 58s - loss: 6.3970 - acc: 0.59 - ETA: 58s - loss: 6.3971 - acc: 0.59 - ETA: 58s - loss: 6.3970 - acc: 0.59 - ETA: 58s - loss: 6.3973 - acc: 0.59 - ETA: 58s - loss: 6.3974 - acc: 0.59 - ETA: 58s - loss: 6.3974 - acc: 0.59 - ETA: 58s - loss: 6.3971 - acc: 0.59 - ETA: 58s - loss: 6.3972 - acc: 0.59 - ETA: 58s - loss: 6.3972 - acc: 0.59 - ETA: 58s - loss: 6.3975 - acc: 0.59 - ETA: 58s - loss: 6.3975 - acc: 0.59 - ETA: 58s - loss: 6.3976 - acc: 0.59 - ETA: 58s - loss: 6.3977 - acc: 0.59 - ETA: 58s - loss: 6.3981 - acc: 0.59 - ETA: 58s - loss: 6.3985 - acc: 0.59 - ETA: 58s - loss: 6.3980 - acc: 0.59 - ETA: 58s - loss: 6.3980 - acc: 0.59 - ETA: 58s - loss: 6.3977 - acc: 0.59 - ETA: 58s - loss: 6.3977 - acc: 0.59 - ETA: 58s - loss: 6.3978 - acc: 0.59 - ETA: 57s - loss: 6.3978 - acc: 0.59 - ETA: 57s - loss: 6.3979 - acc: 0.59 - ETA: 57s - loss: 6.3975 - acc: 0.59 - ETA: 57s - loss: 6.3975 - acc: 0.59 - ETA: 57s - loss: 6.3973 - acc: 0.59 - ETA: 57s - loss: 6.3970 - acc: 0.59 - ETA: 57s - loss: 6.3966 - acc: 0.59 - ETA: 57s - loss: 6.3968 - acc: 0.59 - ETA: 57s - loss: 6.3970 - acc: 0.59 - ETA: 57s - loss: 6.3970 - acc: 0.59 - ETA: 56s - loss: 6.3972 - acc: 0.59 - ETA: 56s - loss: 6.3970 - acc: 0.59 - ETA: 56s - loss: 6.3973 - acc: 0.59 - ETA: 56s - loss: 6.3971 - acc: 0.59 - ETA: 56s - loss: 6.3973 - acc: 0.59 - ETA: 56s - loss: 6.3973 - acc: 0.59 - ETA: 56s - loss: 6.3974 - acc: 0.59 - ETA: 56s - loss: 6.3977 - acc: 0.59 - ETA: 56s - loss: 6.3977 - acc: 0.59 - ETA: 56s - loss: 6.3977 - acc: 0.59 - ETA: 56s - loss: 6.3975 - acc: 0.59 - ETA: 56s - loss: 6.3977 - acc: 0.59 - ETA: 56s - loss: 6.3976 - acc: 0.59 - ETA: 56s - loss: 6.3978 - acc: 0.59 - ETA: 56s - loss: 6.3980 - acc: 0.59 - ETA: 55s - loss: 6.3980 - acc: 0.59 - ETA: 55s - loss: 6.3978 - acc: 0.59 - ETA: 55s - loss: 6.3979 - acc: 0.59 - ETA: 55s - loss: 6.3979 - acc: 0.59 - ETA: 55s - loss: 6.3979 - acc: 0.59 - ETA: 55s - loss: 6.3979 - acc: 0.59 - ETA: 55s - loss: 6.3978 - acc: 0.59 - ETA: 55s - loss: 6.3979 - acc: 0.59 - ETA: 55s - loss: 6.3980 - acc: 0.59 - ETA: 55s - loss: 6.3980 - acc: 0.59 - ETA: 55s - loss: 6.3978 - acc: 0.59 - ETA: 55s - loss: 6.3975 - acc: 0.59 - ETA: 55s - loss: 6.3976 - acc: 0.59 - ETA: 55s - loss: 6.3975 - acc: 0.59 - ETA: 55s - loss: 6.3972 - acc: 0.59 - ETA: 55s - loss: 6.3974 - acc: 0.59 - ETA: 55s - loss: 6.3975 - acc: 0.59 - ETA: 55s - loss: 6.3976 - acc: 0.59 - ETA: 55s - loss: 6.3975 - acc: 0.59 - ETA: 55s - loss: 6.3975 - acc: 0.59 - ETA: 55s - loss: 6.3975 - acc: 0.59 - ETA: 55s - loss: 6.3979 - acc: 0.59 - ETA: 55s - loss: 6.3977 - acc: 0.59 - ETA: 55s - loss: 6.3977 - acc: 0.59 - ETA: 55s - loss: 6.3977 - acc: 0.59 - ETA: 55s - loss: 6.3978 - acc: 0.59 - ETA: 55s - loss: 6.3978 - acc: 0.59 - ETA: 55s - loss: 6.3978 - acc: 0.59 - ETA: 55s - loss: 6.3979 - acc: 0.59 - ETA: 55s - loss: 6.3978 - acc: 0.59 - ETA: 54s - loss: 6.3973 - acc: 0.59 - ETA: 54s - loss: 6.3972 - acc: 0.59 - ETA: 54s - loss: 6.3971 - acc: 0.59 - ETA: 54s - loss: 6.3974 - acc: 0.59 - ETA: 54s - loss: 6.3975 - acc: 0.59 - ETA: 54s - loss: 6.3974 - acc: 0.59 - ETA: 54s - loss: 6.3973 - acc: 0.59 - ETA: 54s - loss: 6.3971 - acc: 0.59 - ETA: 54s - loss: 6.3972 - acc: 0.59 - ETA: 54s - loss: 6.3970 - acc: 0.59 - ETA: 54s - loss: 6.3970 - acc: 0.59 - ETA: 54s - loss: 6.3969 - acc: 0.59 - ETA: 54s - loss: 6.3965 - acc: 0.59 - ETA: 54s - loss: 6.3963 - acc: 0.59 - ETA: 54s - loss: 6.3963 - acc: 0.59 - ETA: 54s - loss: 6.3961 - acc: 0.59 - ETA: 54s - loss: 6.3962 - acc: 0.59 - ETA: 54s - loss: 6.3962 - acc: 0.59 - ETA: 54s - loss: 6.3959 - acc: 0.59 - ETA: 54s - loss: 6.3960 - acc: 0.59 - ETA: 54s - loss: 6.3960 - acc: 0.59 - ETA: 54s - loss: 6.3958 - acc: 0.59 - ETA: 54s - loss: 6.3960 - acc: 0.59 - ETA: 53s - loss: 6.3965 - acc: 0.59 - ETA: 53s - loss: 6.3967 - acc: 0.59 - ETA: 53s - loss: 6.3965 - acc: 0.59 - ETA: 53s - loss: 6.3968 - acc: 0.59 - ETA: 53s - loss: 6.3967 - acc: 0.59 - ETA: 53s - loss: 6.3969 - acc: 0.59 - ETA: 53s - loss: 6.3970 - acc: 0.59 - ETA: 53s - loss: 6.3971 - acc: 0.59 - ETA: 53s - loss: 6.3971 - acc: 0.59 - ETA: 53s - loss: 6.3973 - acc: 0.59 - ETA: 53s - loss: 6.3975 - acc: 0.59 - ETA: 53s - loss: 6.3975 - acc: 0.59 - ETA: 53s - loss: 6.3973 - acc: 0.59 - ETA: 53s - loss: 6.3978 - acc: 0.59 - ETA: 53s - loss: 6.3980 - acc: 0.59 - ETA: 53s - loss: 6.3978 - acc: 0.59 - ETA: 53s - loss: 6.3979 - acc: 0.59 - ETA: 53s - loss: 6.3977 - acc: 0.59 - ETA: 53s - loss: 6.3975 - acc: 0.59 - ETA: 53s - loss: 6.3975 - acc: 0.59 - ETA: 53s - loss: 6.3975 - acc: 0.59 - ETA: 53s - loss: 6.3975 - acc: 0.59 - ETA: 52s - loss: 6.3978 - acc: 0.59 - ETA: 52s - loss: 6.3977 - acc: 0.59 - ETA: 52s - loss: 6.3975 - acc: 0.59 - ETA: 52s - loss: 6.3978 - acc: 0.59 - ETA: 52s - loss: 6.3979 - acc: 0.59 - ETA: 52s - loss: 6.3978 - acc: 0.59 - ETA: 52s - loss: 6.3978 - acc: 0.59 - ETA: 52s - loss: 6.3980 - acc: 0.59 - ETA: 52s - loss: 6.3983 - acc: 0.59 - ETA: 52s - loss: 6.3983 - acc: 0.59 - ETA: 52s - loss: 6.3979 - acc: 0.59 - ETA: 52s - loss: 6.3979 - acc: 0.59 - ETA: 52s - loss: 6.3975 - acc: 0.59 - ETA: 52s - loss: 6.3974 - acc: 0.59 - ETA: 52s - loss: 6.3971 - acc: 0.59 - ETA: 52s - loss: 6.3970 - acc: 0.59 - ETA: 52s - loss: 6.3968 - acc: 0.59 - ETA: 52s - loss: 6.3968 - acc: 0.59 - ETA: 51s - loss: 6.3972 - acc: 0.59 - ETA: 51s - loss: 6.3971 - acc: 0.59 - ETA: 51s - loss: 6.3974 - acc: 0.59 - ETA: 51s - loss: 6.3976 - acc: 0.59 - ETA: 51s - loss: 6.3974 - acc: 0.59 - ETA: 51s - loss: 6.3973 - acc: 0.59 - ETA: 51s - loss: 6.3972 - acc: 0.59 - ETA: 51s - loss: 6.3972 - acc: 0.59 - ETA: 51s - loss: 6.3972 - acc: 0.59 - ETA: 51s - loss: 6.3974 - acc: 0.59 - ETA: 51s - loss: 6.3971 - acc: 0.59 - ETA: 51s - loss: 6.3972 - acc: 0.59 - ETA: 51s - loss: 6.3971 - acc: 0.59 - ETA: 51s - loss: 6.3973 - acc: 0.59 - ETA: 51s - loss: 6.3974 - acc: 0.59 - ETA: 51s - loss: 6.3974 - acc: 0.59 - ETA: 51s - loss: 6.3975 - acc: 0.59 - ETA: 51s - loss: 6.3974 - acc: 0.59 - ETA: 51s - loss: 6.3973 - acc: 0.59 - ETA: 51s - loss: 6.3974 - acc: 0.59 - ETA: 51s - loss: 6.3973 - acc: 0.59 - ETA: 51s - loss: 6.3979 - acc: 0.59 - ETA: 51s - loss: 6.3979 - acc: 0.59 - ETA: 51s - loss: 6.3982 - acc: 0.59 - ETA: 51s - loss: 6.3983 - acc: 0.59 - ETA: 51s - loss: 6.3979 - acc: 0.59 - ETA: 51s - loss: 6.3981 - acc: 0.59 - ETA: 51s - loss: 6.3983 - acc: 0.59 - ETA: 51s - loss: 6.3983 - acc: 0.59 - ETA: 50s - loss: 6.3984 - acc: 0.59 - ETA: 50s - loss: 6.3984 - acc: 0.59 - ETA: 50s - loss: 6.3984 - acc: 0.59 - ETA: 50s - loss: 6.3984 - acc: 0.5987"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750592/969231 [======================>.......] - ETA: 50s - loss: 6.3988 - acc: 0.59 - ETA: 50s - loss: 6.3986 - acc: 0.59 - ETA: 50s - loss: 6.3988 - acc: 0.59 - ETA: 50s - loss: 6.3991 - acc: 0.59 - ETA: 50s - loss: 6.3992 - acc: 0.59 - ETA: 50s - loss: 6.3992 - acc: 0.59 - ETA: 50s - loss: 6.3992 - acc: 0.59 - ETA: 50s - loss: 6.3994 - acc: 0.59 - ETA: 50s - loss: 6.3992 - acc: 0.59 - ETA: 50s - loss: 6.3999 - acc: 0.59 - ETA: 50s - loss: 6.4002 - acc: 0.59 - ETA: 50s - loss: 6.4002 - acc: 0.59 - ETA: 50s - loss: 6.4004 - acc: 0.59 - ETA: 50s - loss: 6.4005 - acc: 0.59 - ETA: 50s - loss: 6.4005 - acc: 0.59 - ETA: 50s - loss: 6.4005 - acc: 0.59 - ETA: 50s - loss: 6.4002 - acc: 0.59 - ETA: 50s - loss: 6.4002 - acc: 0.59 - ETA: 50s - loss: 6.4008 - acc: 0.59 - ETA: 50s - loss: 6.4009 - acc: 0.59 - ETA: 50s - loss: 6.4009 - acc: 0.59 - ETA: 50s - loss: 6.4011 - acc: 0.59 - ETA: 50s - loss: 6.4011 - acc: 0.59 - ETA: 50s - loss: 6.4011 - acc: 0.59 - ETA: 49s - loss: 6.4011 - acc: 0.59 - ETA: 49s - loss: 6.4011 - acc: 0.59 - ETA: 49s - loss: 6.4014 - acc: 0.59 - ETA: 49s - loss: 6.4017 - acc: 0.59 - ETA: 49s - loss: 6.4018 - acc: 0.59 - ETA: 49s - loss: 6.4021 - acc: 0.59 - ETA: 49s - loss: 6.4022 - acc: 0.59 - ETA: 49s - loss: 6.4022 - acc: 0.59 - ETA: 49s - loss: 6.4024 - acc: 0.59 - ETA: 49s - loss: 6.4026 - acc: 0.59 - ETA: 49s - loss: 6.4025 - acc: 0.59 - ETA: 49s - loss: 6.4024 - acc: 0.59 - ETA: 49s - loss: 6.4023 - acc: 0.59 - ETA: 49s - loss: 6.4022 - acc: 0.59 - ETA: 49s - loss: 6.4026 - acc: 0.59 - ETA: 49s - loss: 6.4025 - acc: 0.59 - ETA: 49s - loss: 6.4024 - acc: 0.59 - ETA: 49s - loss: 6.4025 - acc: 0.59 - ETA: 49s - loss: 6.4024 - acc: 0.59 - ETA: 49s - loss: 6.4024 - acc: 0.59 - ETA: 49s - loss: 6.4023 - acc: 0.59 - ETA: 49s - loss: 6.4024 - acc: 0.59 - ETA: 49s - loss: 6.4021 - acc: 0.59 - ETA: 49s - loss: 6.4022 - acc: 0.59 - ETA: 49s - loss: 6.4023 - acc: 0.59 - ETA: 49s - loss: 6.4024 - acc: 0.59 - ETA: 48s - loss: 6.4020 - acc: 0.59 - ETA: 48s - loss: 6.4018 - acc: 0.59 - ETA: 48s - loss: 6.4018 - acc: 0.59 - ETA: 48s - loss: 6.4015 - acc: 0.59 - ETA: 48s - loss: 6.4013 - acc: 0.59 - ETA: 48s - loss: 6.4012 - acc: 0.59 - ETA: 48s - loss: 6.4011 - acc: 0.59 - ETA: 48s - loss: 6.4009 - acc: 0.59 - ETA: 48s - loss: 6.4010 - acc: 0.59 - ETA: 48s - loss: 6.4010 - acc: 0.59 - ETA: 48s - loss: 6.4010 - acc: 0.59 - ETA: 48s - loss: 6.4011 - acc: 0.59 - ETA: 48s - loss: 6.4013 - acc: 0.59 - ETA: 48s - loss: 6.4014 - acc: 0.59 - ETA: 48s - loss: 6.4013 - acc: 0.59 - ETA: 48s - loss: 6.4014 - acc: 0.59 - ETA: 48s - loss: 6.4015 - acc: 0.59 - ETA: 48s - loss: 6.4013 - acc: 0.59 - ETA: 47s - loss: 6.4011 - acc: 0.59 - ETA: 47s - loss: 6.4010 - acc: 0.59 - ETA: 47s - loss: 6.4007 - acc: 0.59 - ETA: 47s - loss: 6.4006 - acc: 0.59 - ETA: 47s - loss: 6.4007 - acc: 0.59 - ETA: 47s - loss: 6.4008 - acc: 0.59 - ETA: 47s - loss: 6.4005 - acc: 0.59 - ETA: 47s - loss: 6.4006 - acc: 0.59 - ETA: 47s - loss: 6.4008 - acc: 0.59 - ETA: 47s - loss: 6.4007 - acc: 0.59 - ETA: 47s - loss: 6.4006 - acc: 0.59 - ETA: 47s - loss: 6.4005 - acc: 0.59 - ETA: 47s - loss: 6.4007 - acc: 0.59 - ETA: 47s - loss: 6.4006 - acc: 0.59 - ETA: 47s - loss: 6.4006 - acc: 0.59 - ETA: 47s - loss: 6.4008 - acc: 0.59 - ETA: 47s - loss: 6.4007 - acc: 0.59 - ETA: 47s - loss: 6.4005 - acc: 0.59 - ETA: 47s - loss: 6.4005 - acc: 0.59 - ETA: 47s - loss: 6.4005 - acc: 0.59 - ETA: 47s - loss: 6.4008 - acc: 0.59 - ETA: 47s - loss: 6.4007 - acc: 0.59 - ETA: 47s - loss: 6.4006 - acc: 0.59 - ETA: 47s - loss: 6.4008 - acc: 0.59 - ETA: 47s - loss: 6.4009 - acc: 0.59 - ETA: 47s - loss: 6.4009 - acc: 0.59 - ETA: 47s - loss: 6.4008 - acc: 0.59 - ETA: 47s - loss: 6.4007 - acc: 0.59 - ETA: 47s - loss: 6.4010 - acc: 0.59 - ETA: 47s - loss: 6.4012 - acc: 0.59 - ETA: 47s - loss: 6.4009 - acc: 0.59 - ETA: 46s - loss: 6.4011 - acc: 0.59 - ETA: 46s - loss: 6.4010 - acc: 0.59 - ETA: 46s - loss: 6.4006 - acc: 0.59 - ETA: 46s - loss: 6.4008 - acc: 0.59 - ETA: 46s - loss: 6.4008 - acc: 0.59 - ETA: 46s - loss: 6.4008 - acc: 0.59 - ETA: 46s - loss: 6.4005 - acc: 0.59 - ETA: 46s - loss: 6.4004 - acc: 0.59 - ETA: 46s - loss: 6.4003 - acc: 0.59 - ETA: 46s - loss: 6.4004 - acc: 0.59 - ETA: 46s - loss: 6.4004 - acc: 0.59 - ETA: 46s - loss: 6.4003 - acc: 0.59 - ETA: 46s - loss: 6.4005 - acc: 0.59 - ETA: 46s - loss: 6.4005 - acc: 0.59 - ETA: 46s - loss: 6.4007 - acc: 0.59 - ETA: 46s - loss: 6.4007 - acc: 0.59 - ETA: 46s - loss: 6.4008 - acc: 0.59 - ETA: 46s - loss: 6.4009 - acc: 0.59 - ETA: 46s - loss: 6.4010 - acc: 0.59 - ETA: 46s - loss: 6.4009 - acc: 0.59 - ETA: 46s - loss: 6.4008 - acc: 0.59 - ETA: 46s - loss: 6.4007 - acc: 0.59 - ETA: 46s - loss: 6.4007 - acc: 0.59 - ETA: 46s - loss: 6.4008 - acc: 0.59 - ETA: 45s - loss: 6.4010 - acc: 0.59 - ETA: 45s - loss: 6.4009 - acc: 0.59 - ETA: 45s - loss: 6.4010 - acc: 0.59 - ETA: 45s - loss: 6.4010 - acc: 0.59 - ETA: 45s - loss: 6.4008 - acc: 0.59 - ETA: 45s - loss: 6.4009 - acc: 0.59 - ETA: 45s - loss: 6.4011 - acc: 0.59 - ETA: 45s - loss: 6.4010 - acc: 0.59 - ETA: 45s - loss: 6.4007 - acc: 0.59 - ETA: 45s - loss: 6.4009 - acc: 0.59 - ETA: 45s - loss: 6.4010 - acc: 0.59 - ETA: 45s - loss: 6.4008 - acc: 0.59 - ETA: 45s - loss: 6.4006 - acc: 0.59 - ETA: 45s - loss: 6.4007 - acc: 0.59 - ETA: 45s - loss: 6.4004 - acc: 0.59 - ETA: 45s - loss: 6.4003 - acc: 0.59 - ETA: 45s - loss: 6.4005 - acc: 0.59 - ETA: 45s - loss: 6.4006 - acc: 0.59 - ETA: 45s - loss: 6.4005 - acc: 0.59 - ETA: 45s - loss: 6.4009 - acc: 0.59 - ETA: 45s - loss: 6.4011 - acc: 0.59 - ETA: 45s - loss: 6.4010 - acc: 0.59 - ETA: 45s - loss: 6.4008 - acc: 0.59 - ETA: 45s - loss: 6.4008 - acc: 0.59 - ETA: 45s - loss: 6.4007 - acc: 0.59 - ETA: 44s - loss: 6.4006 - acc: 0.59 - ETA: 44s - loss: 6.4007 - acc: 0.59 - ETA: 44s - loss: 6.4009 - acc: 0.59 - ETA: 44s - loss: 6.4013 - acc: 0.59 - ETA: 44s - loss: 6.4011 - acc: 0.59 - ETA: 44s - loss: 6.4009 - acc: 0.59 - ETA: 44s - loss: 6.4005 - acc: 0.59 - ETA: 44s - loss: 6.4007 - acc: 0.59 - ETA: 44s - loss: 6.4005 - acc: 0.59 - ETA: 44s - loss: 6.4005 - acc: 0.59 - ETA: 44s - loss: 6.4004 - acc: 0.59 - ETA: 44s - loss: 6.4005 - acc: 0.59 - ETA: 44s - loss: 6.4008 - acc: 0.59 - ETA: 43s - loss: 6.4012 - acc: 0.59 - ETA: 43s - loss: 6.4009 - acc: 0.59 - ETA: 43s - loss: 6.4011 - acc: 0.59 - ETA: 43s - loss: 6.4012 - acc: 0.59 - ETA: 43s - loss: 6.4011 - acc: 0.59 - ETA: 43s - loss: 6.4008 - acc: 0.59 - ETA: 43s - loss: 6.4004 - acc: 0.59 - ETA: 43s - loss: 6.4002 - acc: 0.59 - ETA: 43s - loss: 6.4002 - acc: 0.59 - ETA: 43s - loss: 6.4006 - acc: 0.59 - ETA: 43s - loss: 6.4006 - acc: 0.59 - ETA: 43s - loss: 6.4004 - acc: 0.59 - ETA: 43s - loss: 6.4001 - acc: 0.59 - ETA: 42s - loss: 6.4002 - acc: 0.59 - ETA: 42s - loss: 6.4007 - acc: 0.59 - ETA: 42s - loss: 6.4005 - acc: 0.59 - ETA: 42s - loss: 6.4004 - acc: 0.59 - ETA: 42s - loss: 6.4003 - acc: 0.59 - ETA: 42s - loss: 6.4005 - acc: 0.59 - ETA: 42s - loss: 6.3998 - acc: 0.59 - ETA: 42s - loss: 6.3997 - acc: 0.59 - ETA: 42s - loss: 6.3997 - acc: 0.59 - ETA: 42s - loss: 6.3999 - acc: 0.59 - ETA: 42s - loss: 6.3998 - acc: 0.59 - ETA: 42s - loss: 6.4002 - acc: 0.59 - ETA: 42s - loss: 6.4001 - acc: 0.59 - ETA: 41s - loss: 6.4002 - acc: 0.59 - ETA: 41s - loss: 6.4002 - acc: 0.59 - ETA: 41s - loss: 6.4003 - acc: 0.59 - ETA: 41s - loss: 6.4000 - acc: 0.59 - ETA: 41s - loss: 6.3999 - acc: 0.59 - ETA: 41s - loss: 6.3999 - acc: 0.59 - ETA: 41s - loss: 6.4000 - acc: 0.59 - ETA: 41s - loss: 6.4000 - acc: 0.59 - ETA: 41s - loss: 6.4001 - acc: 0.59 - ETA: 41s - loss: 6.3999 - acc: 0.59 - ETA: 41s - loss: 6.3999 - acc: 0.59 - ETA: 41s - loss: 6.4000 - acc: 0.59 - ETA: 40s - loss: 6.4002 - acc: 0.59 - ETA: 40s - loss: 6.4000 - acc: 0.59 - ETA: 40s - loss: 6.3998 - acc: 0.59 - ETA: 40s - loss: 6.3998 - acc: 0.59 - ETA: 40s - loss: 6.3998 - acc: 0.59 - ETA: 40s - loss: 6.3997 - acc: 0.59 - ETA: 40s - loss: 6.3997 - acc: 0.59 - ETA: 40s - loss: 6.4001 - acc: 0.59 - ETA: 40s - loss: 6.4003 - acc: 0.59 - ETA: 40s - loss: 6.4003 - acc: 0.59 - ETA: 40s - loss: 6.4004 - acc: 0.59 - ETA: 40s - loss: 6.4006 - acc: 0.59 - ETA: 39s - loss: 6.4004 - acc: 0.59 - ETA: 39s - loss: 6.4003 - acc: 0.59 - ETA: 39s - loss: 6.4007 - acc: 0.59 - ETA: 39s - loss: 6.4004 - acc: 0.5985"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "841856/969231 [=========================>....] - ETA: 39s - loss: 6.4004 - acc: 0.59 - ETA: 39s - loss: 6.4003 - acc: 0.59 - ETA: 39s - loss: 6.4003 - acc: 0.59 - ETA: 39s - loss: 6.4000 - acc: 0.59 - ETA: 39s - loss: 6.4001 - acc: 0.59 - ETA: 39s - loss: 6.4000 - acc: 0.59 - ETA: 39s - loss: 6.4001 - acc: 0.59 - ETA: 39s - loss: 6.3998 - acc: 0.59 - ETA: 39s - loss: 6.3996 - acc: 0.59 - ETA: 39s - loss: 6.3991 - acc: 0.59 - ETA: 39s - loss: 6.3990 - acc: 0.59 - ETA: 38s - loss: 6.3990 - acc: 0.59 - ETA: 38s - loss: 6.3990 - acc: 0.59 - ETA: 38s - loss: 6.3992 - acc: 0.59 - ETA: 38s - loss: 6.3991 - acc: 0.59 - ETA: 38s - loss: 6.3991 - acc: 0.59 - ETA: 38s - loss: 6.3993 - acc: 0.59 - ETA: 38s - loss: 6.3992 - acc: 0.59 - ETA: 38s - loss: 6.3992 - acc: 0.59 - ETA: 38s - loss: 6.3994 - acc: 0.59 - ETA: 38s - loss: 6.3993 - acc: 0.59 - ETA: 38s - loss: 6.3993 - acc: 0.59 - ETA: 38s - loss: 6.3991 - acc: 0.59 - ETA: 38s - loss: 6.3992 - acc: 0.59 - ETA: 38s - loss: 6.3991 - acc: 0.59 - ETA: 38s - loss: 6.3990 - acc: 0.59 - ETA: 38s - loss: 6.3992 - acc: 0.59 - ETA: 38s - loss: 6.3990 - acc: 0.59 - ETA: 38s - loss: 6.3989 - acc: 0.59 - ETA: 37s - loss: 6.3986 - acc: 0.59 - ETA: 37s - loss: 6.3985 - acc: 0.59 - ETA: 37s - loss: 6.3986 - acc: 0.59 - ETA: 37s - loss: 6.3989 - acc: 0.59 - ETA: 37s - loss: 6.3986 - acc: 0.59 - ETA: 37s - loss: 6.3986 - acc: 0.59 - ETA: 37s - loss: 6.3985 - acc: 0.59 - ETA: 37s - loss: 6.3983 - acc: 0.59 - ETA: 37s - loss: 6.3980 - acc: 0.59 - ETA: 37s - loss: 6.3979 - acc: 0.59 - ETA: 37s - loss: 6.3982 - acc: 0.59 - ETA: 37s - loss: 6.3982 - acc: 0.59 - ETA: 37s - loss: 6.3980 - acc: 0.59 - ETA: 37s - loss: 6.3980 - acc: 0.59 - ETA: 37s - loss: 6.3983 - acc: 0.59 - ETA: 36s - loss: 6.3981 - acc: 0.59 - ETA: 36s - loss: 6.3978 - acc: 0.59 - ETA: 36s - loss: 6.3980 - acc: 0.59 - ETA: 36s - loss: 6.3981 - acc: 0.59 - ETA: 36s - loss: 6.3982 - acc: 0.59 - ETA: 36s - loss: 6.3983 - acc: 0.59 - ETA: 36s - loss: 6.3984 - acc: 0.59 - ETA: 36s - loss: 6.3982 - acc: 0.59 - ETA: 36s - loss: 6.3981 - acc: 0.59 - ETA: 36s - loss: 6.3980 - acc: 0.59 - ETA: 35s - loss: 6.3981 - acc: 0.59 - ETA: 35s - loss: 6.3981 - acc: 0.59 - ETA: 35s - loss: 6.3983 - acc: 0.59 - ETA: 35s - loss: 6.3981 - acc: 0.59 - ETA: 35s - loss: 6.3984 - acc: 0.59 - ETA: 35s - loss: 6.3985 - acc: 0.59 - ETA: 35s - loss: 6.3988 - acc: 0.59 - ETA: 35s - loss: 6.3986 - acc: 0.59 - ETA: 35s - loss: 6.3987 - acc: 0.59 - ETA: 35s - loss: 6.3986 - acc: 0.59 - ETA: 35s - loss: 6.3986 - acc: 0.59 - ETA: 35s - loss: 6.3982 - acc: 0.59 - ETA: 35s - loss: 6.3985 - acc: 0.59 - ETA: 34s - loss: 6.3985 - acc: 0.59 - ETA: 34s - loss: 6.3985 - acc: 0.59 - ETA: 34s - loss: 6.3989 - acc: 0.59 - ETA: 34s - loss: 6.3990 - acc: 0.59 - ETA: 34s - loss: 6.3989 - acc: 0.59 - ETA: 34s - loss: 6.3990 - acc: 0.59 - ETA: 34s - loss: 6.3995 - acc: 0.59 - ETA: 34s - loss: 6.3992 - acc: 0.59 - ETA: 34s - loss: 6.3992 - acc: 0.59 - ETA: 34s - loss: 6.3992 - acc: 0.59 - ETA: 34s - loss: 6.3988 - acc: 0.59 - ETA: 34s - loss: 6.3984 - acc: 0.59 - ETA: 34s - loss: 6.3984 - acc: 0.59 - ETA: 34s - loss: 6.3983 - acc: 0.59 - ETA: 34s - loss: 6.3984 - acc: 0.59 - ETA: 33s - loss: 6.3987 - acc: 0.59 - ETA: 33s - loss: 6.3987 - acc: 0.59 - ETA: 33s - loss: 6.3985 - acc: 0.59 - ETA: 33s - loss: 6.3984 - acc: 0.59 - ETA: 33s - loss: 6.3987 - acc: 0.59 - ETA: 33s - loss: 6.3987 - acc: 0.59 - ETA: 33s - loss: 6.3989 - acc: 0.59 - ETA: 33s - loss: 6.3985 - acc: 0.59 - ETA: 33s - loss: 6.3987 - acc: 0.59 - ETA: 32s - loss: 6.3988 - acc: 0.59 - ETA: 32s - loss: 6.3989 - acc: 0.59 - ETA: 32s - loss: 6.3990 - acc: 0.59 - ETA: 32s - loss: 6.3987 - acc: 0.59 - ETA: 32s - loss: 6.3987 - acc: 0.59 - ETA: 32s - loss: 6.3988 - acc: 0.59 - ETA: 32s - loss: 6.3988 - acc: 0.59 - ETA: 32s - loss: 6.3987 - acc: 0.59 - ETA: 32s - loss: 6.3986 - acc: 0.59 - ETA: 31s - loss: 6.3985 - acc: 0.59 - ETA: 31s - loss: 6.3984 - acc: 0.59 - ETA: 31s - loss: 6.3983 - acc: 0.59 - ETA: 31s - loss: 6.3982 - acc: 0.59 - ETA: 31s - loss: 6.3979 - acc: 0.59 - ETA: 31s - loss: 6.3979 - acc: 0.59 - ETA: 31s - loss: 6.3983 - acc: 0.59 - ETA: 31s - loss: 6.3982 - acc: 0.59 - ETA: 31s - loss: 6.3986 - acc: 0.59 - ETA: 31s - loss: 6.3987 - acc: 0.59 - ETA: 31s - loss: 6.3991 - acc: 0.59 - ETA: 30s - loss: 6.3989 - acc: 0.59 - ETA: 30s - loss: 6.3983 - acc: 0.59 - ETA: 30s - loss: 6.3982 - acc: 0.59 - ETA: 30s - loss: 6.3983 - acc: 0.59 - ETA: 30s - loss: 6.3979 - acc: 0.59 - ETA: 30s - loss: 6.3976 - acc: 0.59 - ETA: 30s - loss: 6.3976 - acc: 0.59 - ETA: 30s - loss: 6.3972 - acc: 0.59 - ETA: 30s - loss: 6.3974 - acc: 0.59 - ETA: 30s - loss: 6.3974 - acc: 0.59 - ETA: 30s - loss: 6.3976 - acc: 0.59 - ETA: 30s - loss: 6.3975 - acc: 0.59 - ETA: 29s - loss: 6.3972 - acc: 0.59 - ETA: 29s - loss: 6.3974 - acc: 0.59 - ETA: 29s - loss: 6.3974 - acc: 0.59 - ETA: 29s - loss: 6.3974 - acc: 0.59 - ETA: 29s - loss: 6.3978 - acc: 0.59 - ETA: 29s - loss: 6.3981 - acc: 0.59 - ETA: 29s - loss: 6.3983 - acc: 0.59 - ETA: 29s - loss: 6.3981 - acc: 0.59 - ETA: 29s - loss: 6.3980 - acc: 0.59 - ETA: 29s - loss: 6.3979 - acc: 0.59 - ETA: 29s - loss: 6.3983 - acc: 0.59 - ETA: 29s - loss: 6.3984 - acc: 0.59 - ETA: 29s - loss: 6.3984 - acc: 0.59 - ETA: 28s - loss: 6.3986 - acc: 0.59 - ETA: 28s - loss: 6.3988 - acc: 0.59 - ETA: 28s - loss: 6.3987 - acc: 0.59 - ETA: 28s - loss: 6.3987 - acc: 0.59 - ETA: 28s - loss: 6.3987 - acc: 0.59 - ETA: 28s - loss: 6.3989 - acc: 0.59 - ETA: 28s - loss: 6.3991 - acc: 0.59 - ETA: 28s - loss: 6.3989 - acc: 0.59 - ETA: 28s - loss: 6.3992 - acc: 0.59 - ETA: 28s - loss: 6.3995 - acc: 0.59 - ETA: 28s - loss: 6.3994 - acc: 0.59 - ETA: 27s - loss: 6.3996 - acc: 0.59 - ETA: 27s - loss: 6.3996 - acc: 0.59 - ETA: 27s - loss: 6.3995 - acc: 0.59 - ETA: 27s - loss: 6.3995 - acc: 0.59 - ETA: 27s - loss: 6.3994 - acc: 0.59 - ETA: 27s - loss: 6.3992 - acc: 0.59 - ETA: 27s - loss: 6.3991 - acc: 0.59 - ETA: 27s - loss: 6.3993 - acc: 0.59 - ETA: 27s - loss: 6.3994 - acc: 0.59 - ETA: 27s - loss: 6.3997 - acc: 0.59 - ETA: 27s - loss: 6.3997 - acc: 0.59 - ETA: 27s - loss: 6.3996 - acc: 0.59 - ETA: 27s - loss: 6.3994 - acc: 0.59 - ETA: 26s - loss: 6.3996 - acc: 0.59 - ETA: 26s - loss: 6.3995 - acc: 0.59 - ETA: 26s - loss: 6.3991 - acc: 0.59 - ETA: 26s - loss: 6.3990 - acc: 0.59 - ETA: 26s - loss: 6.3986 - acc: 0.59 - ETA: 26s - loss: 6.3987 - acc: 0.59 - ETA: 26s - loss: 6.3988 - acc: 0.59 - ETA: 26s - loss: 6.3989 - acc: 0.59 - ETA: 26s - loss: 6.3990 - acc: 0.59 - ETA: 26s - loss: 6.3988 - acc: 0.59 - ETA: 26s - loss: 6.3985 - acc: 0.59 - ETA: 26s - loss: 6.3987 - acc: 0.59 - ETA: 25s - loss: 6.3989 - acc: 0.59 - ETA: 25s - loss: 6.3990 - acc: 0.59 - ETA: 25s - loss: 6.3990 - acc: 0.59 - ETA: 25s - loss: 6.3990 - acc: 0.59 - ETA: 25s - loss: 6.3991 - acc: 0.59 - ETA: 25s - loss: 6.3993 - acc: 0.59 - ETA: 25s - loss: 6.3993 - acc: 0.59 - ETA: 25s - loss: 6.3991 - acc: 0.59 - ETA: 25s - loss: 6.3988 - acc: 0.59 - ETA: 25s - loss: 6.3991 - acc: 0.59 - ETA: 25s - loss: 6.3989 - acc: 0.59 - ETA: 24s - loss: 6.3991 - acc: 0.59 - ETA: 24s - loss: 6.3991 - acc: 0.59 - ETA: 24s - loss: 6.3991 - acc: 0.59 - ETA: 24s - loss: 6.3991 - acc: 0.59 - ETA: 24s - loss: 6.3992 - acc: 0.59 - ETA: 24s - loss: 6.3993 - acc: 0.59 - ETA: 24s - loss: 6.3994 - acc: 0.59 - ETA: 24s - loss: 6.3993 - acc: 0.59 - ETA: 24s - loss: 6.3993 - acc: 0.59 - ETA: 24s - loss: 6.3994 - acc: 0.59 - ETA: 24s - loss: 6.3994 - acc: 0.59 - ETA: 24s - loss: 6.3995 - acc: 0.59 - ETA: 24s - loss: 6.3994 - acc: 0.59 - ETA: 23s - loss: 6.3993 - acc: 0.59 - ETA: 23s - loss: 6.3993 - acc: 0.59 - ETA: 23s - loss: 6.3994 - acc: 0.59 - ETA: 23s - loss: 6.3995 - acc: 0.59 - ETA: 23s - loss: 6.3995 - acc: 0.59 - ETA: 23s - loss: 6.3994 - acc: 0.59 - ETA: 23s - loss: 6.3992 - acc: 0.59 - ETA: 23s - loss: 6.3993 - acc: 0.59 - ETA: 23s - loss: 6.3993 - acc: 0.59 - ETA: 23s - loss: 6.3995 - acc: 0.59 - ETA: 23s - loss: 6.3996 - acc: 0.59 - ETA: 23s - loss: 6.3994 - acc: 0.59 - ETA: 23s - loss: 6.3992 - acc: 0.59 - ETA: 22s - loss: 6.3992 - acc: 0.59 - ETA: 22s - loss: 6.3993 - acc: 0.59 - ETA: 22s - loss: 6.3993 - acc: 0.59 - ETA: 22s - loss: 6.3992 - acc: 0.59 - ETA: 22s - loss: 6.3994 - acc: 0.59 - ETA: 22s - loss: 6.3992 - acc: 0.5986"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "931456/969231 [===========================>..] - ETA: 22s - loss: 6.3995 - acc: 0.59 - ETA: 22s - loss: 6.3995 - acc: 0.59 - ETA: 22s - loss: 6.3997 - acc: 0.59 - ETA: 22s - loss: 6.3997 - acc: 0.59 - ETA: 22s - loss: 6.3995 - acc: 0.59 - ETA: 22s - loss: 6.3994 - acc: 0.59 - ETA: 21s - loss: 6.3994 - acc: 0.59 - ETA: 21s - loss: 6.3995 - acc: 0.59 - ETA: 21s - loss: 6.3994 - acc: 0.59 - ETA: 21s - loss: 6.3994 - acc: 0.59 - ETA: 21s - loss: 6.3993 - acc: 0.59 - ETA: 21s - loss: 6.3993 - acc: 0.59 - ETA: 21s - loss: 6.3992 - acc: 0.59 - ETA: 21s - loss: 6.3988 - acc: 0.59 - ETA: 21s - loss: 6.3990 - acc: 0.59 - ETA: 21s - loss: 6.3994 - acc: 0.59 - ETA: 21s - loss: 6.3994 - acc: 0.59 - ETA: 21s - loss: 6.3995 - acc: 0.59 - ETA: 21s - loss: 6.3992 - acc: 0.59 - ETA: 21s - loss: 6.3992 - acc: 0.59 - ETA: 21s - loss: 6.3994 - acc: 0.59 - ETA: 21s - loss: 6.3991 - acc: 0.59 - ETA: 20s - loss: 6.3989 - acc: 0.59 - ETA: 20s - loss: 6.3990 - acc: 0.59 - ETA: 20s - loss: 6.3991 - acc: 0.59 - ETA: 20s - loss: 6.3992 - acc: 0.59 - ETA: 20s - loss: 6.3992 - acc: 0.59 - ETA: 20s - loss: 6.3992 - acc: 0.59 - ETA: 20s - loss: 6.3993 - acc: 0.59 - ETA: 20s - loss: 6.3996 - acc: 0.59 - ETA: 20s - loss: 6.3997 - acc: 0.59 - ETA: 20s - loss: 6.3994 - acc: 0.59 - ETA: 20s - loss: 6.3995 - acc: 0.59 - ETA: 20s - loss: 6.3996 - acc: 0.59 - ETA: 20s - loss: 6.3996 - acc: 0.59 - ETA: 20s - loss: 6.3994 - acc: 0.59 - ETA: 19s - loss: 6.3994 - acc: 0.59 - ETA: 19s - loss: 6.3993 - acc: 0.59 - ETA: 19s - loss: 6.3990 - acc: 0.59 - ETA: 19s - loss: 6.3990 - acc: 0.59 - ETA: 19s - loss: 6.3989 - acc: 0.59 - ETA: 19s - loss: 6.3988 - acc: 0.59 - ETA: 19s - loss: 6.3988 - acc: 0.59 - ETA: 19s - loss: 6.3986 - acc: 0.59 - ETA: 19s - loss: 6.3986 - acc: 0.59 - ETA: 19s - loss: 6.3986 - acc: 0.59 - ETA: 19s - loss: 6.3985 - acc: 0.59 - ETA: 19s - loss: 6.3984 - acc: 0.59 - ETA: 19s - loss: 6.3984 - acc: 0.59 - ETA: 19s - loss: 6.3985 - acc: 0.59 - ETA: 19s - loss: 6.3989 - acc: 0.59 - ETA: 19s - loss: 6.3987 - acc: 0.59 - ETA: 18s - loss: 6.3987 - acc: 0.59 - ETA: 18s - loss: 6.3987 - acc: 0.59 - ETA: 18s - loss: 6.3986 - acc: 0.59 - ETA: 18s - loss: 6.3985 - acc: 0.59 - ETA: 18s - loss: 6.3985 - acc: 0.59 - ETA: 18s - loss: 6.3988 - acc: 0.59 - ETA: 18s - loss: 6.3987 - acc: 0.59 - ETA: 18s - loss: 6.3983 - acc: 0.59 - ETA: 18s - loss: 6.3985 - acc: 0.59 - ETA: 18s - loss: 6.3984 - acc: 0.59 - ETA: 18s - loss: 6.3983 - acc: 0.59 - ETA: 18s - loss: 6.3985 - acc: 0.59 - ETA: 18s - loss: 6.3986 - acc: 0.59 - ETA: 18s - loss: 6.3987 - acc: 0.59 - ETA: 17s - loss: 6.3985 - acc: 0.59 - ETA: 17s - loss: 6.3984 - acc: 0.59 - ETA: 17s - loss: 6.3987 - acc: 0.59 - ETA: 17s - loss: 6.3983 - acc: 0.59 - ETA: 17s - loss: 6.3983 - acc: 0.59 - ETA: 17s - loss: 6.3981 - acc: 0.59 - ETA: 17s - loss: 6.3978 - acc: 0.59 - ETA: 17s - loss: 6.3975 - acc: 0.59 - ETA: 17s - loss: 6.3976 - acc: 0.59 - ETA: 17s - loss: 6.3975 - acc: 0.59 - ETA: 17s - loss: 6.3977 - acc: 0.59 - ETA: 17s - loss: 6.3974 - acc: 0.59 - ETA: 17s - loss: 6.3974 - acc: 0.59 - ETA: 17s - loss: 6.3974 - acc: 0.59 - ETA: 16s - loss: 6.3971 - acc: 0.59 - ETA: 16s - loss: 6.3971 - acc: 0.59 - ETA: 16s - loss: 6.3969 - acc: 0.59 - ETA: 16s - loss: 6.3971 - acc: 0.59 - ETA: 16s - loss: 6.3967 - acc: 0.59 - ETA: 16s - loss: 6.3969 - acc: 0.59 - ETA: 16s - loss: 6.3969 - acc: 0.59 - ETA: 16s - loss: 6.3968 - acc: 0.59 - ETA: 16s - loss: 6.3971 - acc: 0.59 - ETA: 16s - loss: 6.3974 - acc: 0.59 - ETA: 16s - loss: 6.3976 - acc: 0.59 - ETA: 16s - loss: 6.3978 - acc: 0.59 - ETA: 15s - loss: 6.3981 - acc: 0.59 - ETA: 15s - loss: 6.3979 - acc: 0.59 - ETA: 15s - loss: 6.3980 - acc: 0.59 - ETA: 15s - loss: 6.3976 - acc: 0.59 - ETA: 15s - loss: 6.3976 - acc: 0.59 - ETA: 15s - loss: 6.3975 - acc: 0.59 - ETA: 15s - loss: 6.3974 - acc: 0.59 - ETA: 15s - loss: 6.3974 - acc: 0.59 - ETA: 15s - loss: 6.3973 - acc: 0.59 - ETA: 15s - loss: 6.3971 - acc: 0.59 - ETA: 15s - loss: 6.3969 - acc: 0.59 - ETA: 15s - loss: 6.3968 - acc: 0.59 - ETA: 15s - loss: 6.3966 - acc: 0.59 - ETA: 14s - loss: 6.3968 - acc: 0.59 - ETA: 14s - loss: 6.3969 - acc: 0.59 - ETA: 14s - loss: 6.3971 - acc: 0.59 - ETA: 14s - loss: 6.3975 - acc: 0.59 - ETA: 14s - loss: 6.3973 - acc: 0.59 - ETA: 14s - loss: 6.3974 - acc: 0.59 - ETA: 14s - loss: 6.3975 - acc: 0.59 - ETA: 14s - loss: 6.3975 - acc: 0.59 - ETA: 14s - loss: 6.3973 - acc: 0.59 - ETA: 14s - loss: 6.3976 - acc: 0.59 - ETA: 14s - loss: 6.3977 - acc: 0.59 - ETA: 13s - loss: 6.3977 - acc: 0.59 - ETA: 13s - loss: 6.3978 - acc: 0.59 - ETA: 13s - loss: 6.3975 - acc: 0.59 - ETA: 13s - loss: 6.3973 - acc: 0.59 - ETA: 13s - loss: 6.3974 - acc: 0.59 - ETA: 13s - loss: 6.3975 - acc: 0.59 - ETA: 13s - loss: 6.3970 - acc: 0.59 - ETA: 13s - loss: 6.3969 - acc: 0.59 - ETA: 13s - loss: 6.3970 - acc: 0.59 - ETA: 13s - loss: 6.3973 - acc: 0.59 - ETA: 12s - loss: 6.3973 - acc: 0.59 - ETA: 12s - loss: 6.3973 - acc: 0.59 - ETA: 12s - loss: 6.3973 - acc: 0.59 - ETA: 12s - loss: 6.3975 - acc: 0.59 - ETA: 12s - loss: 6.3976 - acc: 0.59 - ETA: 12s - loss: 6.3975 - acc: 0.59 - ETA: 12s - loss: 6.3975 - acc: 0.59 - ETA: 12s - loss: 6.3976 - acc: 0.59 - ETA: 12s - loss: 6.3975 - acc: 0.59 - ETA: 12s - loss: 6.3971 - acc: 0.59 - ETA: 12s - loss: 6.3970 - acc: 0.59 - ETA: 12s - loss: 6.3970 - acc: 0.59 - ETA: 12s - loss: 6.3971 - acc: 0.59 - ETA: 12s - loss: 6.3972 - acc: 0.59 - ETA: 12s - loss: 6.3972 - acc: 0.59 - ETA: 11s - loss: 6.3969 - acc: 0.59 - ETA: 11s - loss: 6.3967 - acc: 0.59 - ETA: 11s - loss: 6.3970 - acc: 0.59 - ETA: 11s - loss: 6.3972 - acc: 0.59 - ETA: 11s - loss: 6.3970 - acc: 0.59 - ETA: 11s - loss: 6.3970 - acc: 0.59 - ETA: 11s - loss: 6.3967 - acc: 0.59 - ETA: 11s - loss: 6.3968 - acc: 0.59 - ETA: 11s - loss: 6.3969 - acc: 0.59 - ETA: 11s - loss: 6.3969 - acc: 0.59 - ETA: 11s - loss: 6.3972 - acc: 0.59 - ETA: 11s - loss: 6.3975 - acc: 0.59 - ETA: 11s - loss: 6.3973 - acc: 0.59 - ETA: 10s - loss: 6.3975 - acc: 0.59 - ETA: 10s - loss: 6.3975 - acc: 0.59 - ETA: 10s - loss: 6.3974 - acc: 0.59 - ETA: 10s - loss: 6.3971 - acc: 0.59 - ETA: 10s - loss: 6.3971 - acc: 0.59 - ETA: 10s - loss: 6.3972 - acc: 0.59 - ETA: 10s - loss: 6.3974 - acc: 0.59 - ETA: 10s - loss: 6.3977 - acc: 0.59 - ETA: 10s - loss: 6.3979 - acc: 0.59 - ETA: 10s - loss: 6.3977 - acc: 0.59 - ETA: 10s - loss: 6.3977 - acc: 0.59 - ETA: 10s - loss: 6.3977 - acc: 0.59 - ETA: 10s - loss: 6.3976 - acc: 0.59 - ETA: 10s - loss: 6.3976 - acc: 0.59 - ETA: 9s - loss: 6.3974 - acc: 0.5987 - ETA: 9s - loss: 6.3976 - acc: 0.598 - ETA: 9s - loss: 6.3974 - acc: 0.598 - ETA: 9s - loss: 6.3976 - acc: 0.598 - ETA: 9s - loss: 6.3978 - acc: 0.598 - ETA: 9s - loss: 6.3976 - acc: 0.598 - ETA: 9s - loss: 6.3973 - acc: 0.598 - ETA: 9s - loss: 6.3974 - acc: 0.598 - ETA: 9s - loss: 6.3972 - acc: 0.598 - ETA: 9s - loss: 6.3971 - acc: 0.598 - ETA: 9s - loss: 6.3971 - acc: 0.598 - ETA: 9s - loss: 6.3973 - acc: 0.598 - ETA: 9s - loss: 6.3972 - acc: 0.598 - ETA: 9s - loss: 6.3973 - acc: 0.598 - ETA: 8s - loss: 6.3972 - acc: 0.598 - ETA: 8s - loss: 6.3975 - acc: 0.598 - ETA: 8s - loss: 6.3978 - acc: 0.598 - ETA: 8s - loss: 6.3982 - acc: 0.598 - ETA: 8s - loss: 6.3983 - acc: 0.598 - ETA: 8s - loss: 6.3986 - acc: 0.598 - ETA: 8s - loss: 6.3982 - acc: 0.598 - ETA: 8s - loss: 6.3984 - acc: 0.598 - ETA: 8s - loss: 6.3988 - acc: 0.598 - ETA: 8s - loss: 6.3989 - acc: 0.598 - ETA: 8s - loss: 6.3990 - acc: 0.598 - ETA: 8s - loss: 6.3993 - acc: 0.598 - ETA: 8s - loss: 6.3991 - acc: 0.598 - ETA: 7s - loss: 6.3991 - acc: 0.598 - ETA: 7s - loss: 6.3988 - acc: 0.598 - ETA: 7s - loss: 6.3987 - acc: 0.598 - ETA: 7s - loss: 6.3987 - acc: 0.598 - ETA: 7s - loss: 6.3985 - acc: 0.598 - ETA: 7s - loss: 6.3987 - acc: 0.598 - ETA: 7s - loss: 6.3985 - acc: 0.598 - ETA: 7s - loss: 6.3984 - acc: 0.598 - ETA: 7s - loss: 6.3984 - acc: 0.598 - ETA: 7s - loss: 6.3986 - acc: 0.598 - ETA: 7s - loss: 6.3986 - acc: 0.598 - ETA: 7s - loss: 6.3986 - acc: 0.598 - ETA: 7s - loss: 6.3984 - acc: 0.598 - ETA: 6s - loss: 6.3984 - acc: 0.598 - ETA: 6s - loss: 6.3985 - acc: 0.598 - ETA: 6s - loss: 6.3985 - acc: 0.598 - ETA: 6s - loss: 6.3982 - acc: 0.598 - ETA: 6s - loss: 6.3982 - acc: 0.598 - ETA: 6s - loss: 6.3981 - acc: 0.598 - ETA: 6s - loss: 6.3983 - acc: 0.5987"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "969231/969231 [==============================] - ETA: 6s - loss: 6.3985 - acc: 0.598 - ETA: 6s - loss: 6.3984 - acc: 0.598 - ETA: 6s - loss: 6.3981 - acc: 0.598 - ETA: 6s - loss: 6.3983 - acc: 0.598 - ETA: 6s - loss: 6.3982 - acc: 0.598 - ETA: 6s - loss: 6.3979 - acc: 0.598 - ETA: 6s - loss: 6.3979 - acc: 0.598 - ETA: 6s - loss: 6.3980 - acc: 0.598 - ETA: 5s - loss: 6.3982 - acc: 0.598 - ETA: 5s - loss: 6.3983 - acc: 0.598 - ETA: 5s - loss: 6.3981 - acc: 0.598 - ETA: 5s - loss: 6.3980 - acc: 0.598 - ETA: 5s - loss: 6.3982 - acc: 0.598 - ETA: 5s - loss: 6.3982 - acc: 0.598 - ETA: 5s - loss: 6.3982 - acc: 0.598 - ETA: 5s - loss: 6.3980 - acc: 0.598 - ETA: 5s - loss: 6.3978 - acc: 0.598 - ETA: 5s - loss: 6.3978 - acc: 0.598 - ETA: 5s - loss: 6.3978 - acc: 0.598 - ETA: 5s - loss: 6.3977 - acc: 0.598 - ETA: 4s - loss: 6.3976 - acc: 0.598 - ETA: 4s - loss: 6.3975 - acc: 0.598 - ETA: 4s - loss: 6.3971 - acc: 0.598 - ETA: 4s - loss: 6.3973 - acc: 0.598 - ETA: 4s - loss: 6.3971 - acc: 0.598 - ETA: 4s - loss: 6.3971 - acc: 0.598 - ETA: 4s - loss: 6.3970 - acc: 0.598 - ETA: 4s - loss: 6.3971 - acc: 0.598 - ETA: 4s - loss: 6.3972 - acc: 0.598 - ETA: 4s - loss: 6.3975 - acc: 0.598 - ETA: 4s - loss: 6.3974 - acc: 0.598 - ETA: 4s - loss: 6.3972 - acc: 0.598 - ETA: 4s - loss: 6.3973 - acc: 0.598 - ETA: 4s - loss: 6.3972 - acc: 0.598 - ETA: 4s - loss: 6.3970 - acc: 0.598 - ETA: 3s - loss: 6.3966 - acc: 0.598 - ETA: 3s - loss: 6.3967 - acc: 0.598 - ETA: 3s - loss: 6.3966 - acc: 0.598 - ETA: 3s - loss: 6.3964 - acc: 0.598 - ETA: 3s - loss: 6.3966 - acc: 0.598 - ETA: 3s - loss: 6.3963 - acc: 0.598 - ETA: 3s - loss: 6.3960 - acc: 0.598 - ETA: 3s - loss: 6.3960 - acc: 0.598 - ETA: 3s - loss: 6.3958 - acc: 0.598 - ETA: 3s - loss: 6.3961 - acc: 0.598 - ETA: 3s - loss: 6.3959 - acc: 0.598 - ETA: 2s - loss: 6.3960 - acc: 0.598 - ETA: 2s - loss: 6.3960 - acc: 0.598 - ETA: 2s - loss: 6.3963 - acc: 0.598 - ETA: 2s - loss: 6.3963 - acc: 0.598 - ETA: 2s - loss: 6.3962 - acc: 0.598 - ETA: 2s - loss: 6.3962 - acc: 0.598 - ETA: 2s - loss: 6.3962 - acc: 0.598 - ETA: 2s - loss: 6.3962 - acc: 0.598 - ETA: 2s - loss: 6.3964 - acc: 0.598 - ETA: 2s - loss: 6.3961 - acc: 0.598 - ETA: 2s - loss: 6.3959 - acc: 0.598 - ETA: 2s - loss: 6.3959 - acc: 0.598 - ETA: 2s - loss: 6.3959 - acc: 0.598 - ETA: 1s - loss: 6.3960 - acc: 0.598 - ETA: 1s - loss: 6.3963 - acc: 0.598 - ETA: 1s - loss: 6.3964 - acc: 0.598 - ETA: 1s - loss: 6.3962 - acc: 0.598 - ETA: 1s - loss: 6.3963 - acc: 0.598 - ETA: 1s - loss: 6.3964 - acc: 0.598 - ETA: 1s - loss: 6.3963 - acc: 0.598 - ETA: 1s - loss: 6.3963 - acc: 0.598 - ETA: 1s - loss: 6.3963 - acc: 0.598 - ETA: 1s - loss: 6.3962 - acc: 0.598 - ETA: 1s - loss: 6.3963 - acc: 0.598 - ETA: 1s - loss: 6.3964 - acc: 0.598 - ETA: 0s - loss: 6.3967 - acc: 0.598 - ETA: 0s - loss: 6.3968 - acc: 0.598 - ETA: 0s - loss: 6.3968 - acc: 0.598 - ETA: 0s - loss: 6.3967 - acc: 0.598 - ETA: 0s - loss: 6.3971 - acc: 0.598 - ETA: 0s - loss: 6.3974 - acc: 0.598 - ETA: 0s - loss: 6.3975 - acc: 0.598 - ETA: 0s - loss: 6.3973 - acc: 0.598 - ETA: 0s - loss: 6.3974 - acc: 0.598 - ETA: 0s - loss: 6.3974 - acc: 0.598 - ETA: 0s - loss: 6.3977 - acc: 0.598 - ETA: 0s - loss: 6.3976 - acc: 0.598 - ETA: 0s - loss: 6.3979 - acc: 0.598 - 181s 187us/step - loss: 6.3979 - acc: 0.5987 - val_loss: 6.3979 - val_acc: 0.5987\n",
      "Test loss: 6.397935726933437\n",
      "Test accuracy: 0.5986839050752915\n"
     ]
    }
   ],
   "source": [
    "# Building the Model\n",
    "model = Sequential()\n",
    "# First convolutional layer, note the specification of shape\n",
    "model.add(Conv1D(32, kernel_size=(3),\n",
    "                 activation='relu',input_shape=(10,1)))\n",
    "model.add(Conv1D(64, (3), activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=(2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.binary_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "X_train = X_train.reshape(X_train.shape[0], 10, 1)\n",
    "#X_train_pca = np.reshape(X_train[0],(10,1))\n",
    "#X_test = np.reshape(X_test, (x_test.shape[0],10, 1))\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=128,\n",
    "          epochs=3,\n",
    "          verbose=1,\n",
    "          validation_data=(X_train, y_train))\n",
    "score = model.evaluate(X_train, y_train, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969231, 10, 1)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(969231,)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
