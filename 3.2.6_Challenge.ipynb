{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "start=datetime.now()\n",
    "from IPython.display import display\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import linear_model\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import neighbors\n",
    "from sklearn import tree,model_selection\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "# A convenience for displaying visualizations.\n",
    "from IPython.display import Image\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "# Display preferences.\n",
    "%matplotlib inline\n",
    "pd.options.display.float_format = '{:.3f}'.format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppress annoying harmless error.\n",
    "warnings.filterwarnings(\n",
    "    action=\"ignore\",\n",
    "    module=\"scipy\",\n",
    "    message=\"^internal gelsd\"\n",
    ")\n",
    "\n",
    "from sklearn import ensemble\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "start=datetime.now()\n",
    "rfc = ensemble.RandomForestRegressor()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are creating dataframe of the the data in .csv format and are renaming the column name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = pd.read_csv('C:/Personal/09142640/Downloads/Car_sales_U.csv')\n",
    "data.columns.values[3]='Year_Resale_Value'\n",
    "data_req=data.loc[:,[\"Sales_in_thousands\",\"Year_Resale_Value\",\"Price_in_thousands\",\"Engine_size\",\"Horsepower\",\"Wheelbase\",\"Width\",\"Length\",\"Curb_weight\",\"Fuel_capacity\",\"Fuel_efficiency\",\"Power_perf_factor\"]]\n",
    "data_na=data_req.fillna(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are taking X and Y variable with X as input variable with the columns except 1 column which is for the output variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year_Resale_Value</th>\n",
       "      <th>Price_in_thousands</th>\n",
       "      <th>Engine_size</th>\n",
       "      <th>Horsepower</th>\n",
       "      <th>Wheelbase</th>\n",
       "      <th>Width</th>\n",
       "      <th>Length</th>\n",
       "      <th>Curb_weight</th>\n",
       "      <th>Fuel_capacity</th>\n",
       "      <th>Fuel_efficiency</th>\n",
       "      <th>Power_perf_factor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>140</td>\n",
       "      <td>101</td>\n",
       "      <td>67</td>\n",
       "      <td>172</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>28</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>19</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "      <td>225</td>\n",
       "      <td>108</td>\n",
       "      <td>70</td>\n",
       "      <td>192</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>25</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>225</td>\n",
       "      <td>106</td>\n",
       "      <td>70</td>\n",
       "      <td>192</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29</td>\n",
       "      <td>42</td>\n",
       "      <td>3</td>\n",
       "      <td>210</td>\n",
       "      <td>114</td>\n",
       "      <td>71</td>\n",
       "      <td>196</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>22</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>150</td>\n",
       "      <td>102</td>\n",
       "      <td>68</td>\n",
       "      <td>178</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>27</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year_Resale_Value  Price_in_thousands  Engine_size  Horsepower  Wheelbase  \\\n",
       "0                 16                  21            1         140        101   \n",
       "1                 19                  28            3         225        108   \n",
       "2                 18                   0            3         225        106   \n",
       "3                 29                  42            3         210        114   \n",
       "4                 22                  23            1         150        102   \n",
       "\n",
       "   Width  Length  Curb_weight  Fuel_capacity  Fuel_efficiency  \\\n",
       "0     67     172            2             13               28   \n",
       "1     70     192            3             17               25   \n",
       "2     70     192            3             17               26   \n",
       "3     71     196            3             18               22   \n",
       "4     68     178            2             16               27   \n",
       "\n",
       "   Power_perf_factor  \n",
       "0                 58  \n",
       "1                 91  \n",
       "2                  0  \n",
       "3                 91  \n",
       "4                 62  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = data_na[['Sales_in_thousands']].astype('int')\n",
    "X = data_na.drop(columns='Sales_in_thousands').astype('int')\n",
    "X.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use Grid searchcv ,Holdout,Cross Validation to validate the accuracy of random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [3, 4, 5], 'max_features': [11]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gridsearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)\n",
    "rfc = ensemble.RandomForestRegressor(max_depth=10,n_estimators= 100)\n",
    "dt_grid={'max_depth':[3,4,5],'max_features': [11]}\n",
    "\n",
    "grid_class=model_selection.GridSearchCV(rfc,dt_grid,cv=6)\n",
    "grid_class.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 3, 'max_features': 11}, {'max_depth': 4, 'max_features': 11}, {'max_depth': 5, 'max_features': 11}]\n",
      "[ 0.00073066 -0.0526419  -0.11281314]\n",
      "[0.56321628 0.6437275  0.71150322]\n",
      "{'max_depth': 3, 'max_features': 11}\n",
      "0.0007306645747829444\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
      "           max_features=11, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Displaying the parameters using Grid searchcv\n",
    "results = grid_class.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(grid_class.best_params_)\n",
    "print(grid_class.best_score_)\n",
    "final_model = grid_class.best_estimator_\n",
    "print(final_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score with 20% Holdout: 0.8409244427642835\n",
      "Testing score with 20% Holdout: 0.05626668571158744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "rfc.fit(X_train, y_train)\n",
    "print('Training score with 20% Holdout: ' + str(rfc.score(X_train, y_train)))\n",
    "print('Testing score with 20% Holdout: ' + str(rfc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After using the holdout  groups, it looks like the training data is having good accuracy but the testing data is overfitting the model .We played around with max_depth=10,n_estimators= 100 and tried to change the value to get good accuracy and reduced overfitting values.Now, we will check the accuracy of the model with cross validation with folds=10.It should be wither 5 or 10, thats one of the better practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data accuracy:  [-0.11434606 -0.02640777 -0.0674444  -0.41735     0.12714916]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Data accuracy:  [ 0.32436271 -0.17912002 -1.45733204  0.44325201 -4.67769448]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print (\"Training Data accuracy: \",cross_val_score(rfc, X_train,y_train, cv=5))\n",
    "print (\"Testing Data accuracy: \",cross_val_score(rfc, X_test,y_test, cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "After doing the cross validation,we are seeing overfitting in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.12961093 0.09507544 0.04504079 0.07148406 0.19286296 0.07604972\n",
      " 0.21695685 0.01246968 0.05176627 0.04328333 0.06539996]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "#Displaying the important feature scores\n",
    "\n",
    "#decision_tree.fit(X_train, y_train)\n",
    "rfc.fit(X_train, y_train)\n",
    "print(rfc.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will try to get the best number of features, here we have observed that maximum percentage is with 8 features so we will take these 8 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of decisions accounted for with 2 features: 0.40981980923079553\n",
      "Percentage of decisions accounted for with 4 features: 0.6345061822317419\n",
      "Percentage of decisions accounted for with 6 features: 0.7820399588227033\n",
      "Percentage of decisions accounted for with 8 features: 0.8992061959299487\n",
      "Percentage of decisions accounted for with 10 features: 0.9875303158974308\n",
      "Percentage of decisions accounted for with 12 features: 1.0\n",
      "Total Features: 11\n"
     ]
    }
   ],
   "source": [
    "# And let's see what percentage of decisions are accounted for with the top X features.\n",
    "importances = rfc.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_indices = indices[:55]\n",
    "for n_idx in range(2, 14, 2):\n",
    "    print('Percentage of decisions accounted for with {} features: {}'.format(n_idx, importances[indices[:n_idx]].sum()))\n",
    "print('Total Features: ' + str(len(indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reduce to 8 features since we could potentially account for 93% of the decisions from the Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Length', 'Wheelbase', 'Year_Resale_Value', 'Price_in_thousands',\n",
       "       'Width', 'Horsepower', 'Power_perf_factor', 'Fuel_capacity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using PCA\n",
    "n_indices = 8\n",
    "X_train.columns[indices[:n_indices]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124, 8) (32, 8)\n"
     ]
    }
   ],
   "source": [
    "X_train_rfc = X_train.loc[:, X_train.columns[indices[:n_indices]]]\n",
    "X_test_rfc = X_test.loc[:, X_train.columns[indices[:n_indices]]]\n",
    "print(X_train_rfc.shape, X_test_rfc.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = PCA(n_components=8)\n",
    "X_pca.fit(X_train)\n",
    "X_train_pca = X_pca.transform(X_train)\n",
    "X_test_pca = X_pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of total variance in the dataset explained by each component from Sklearn PCA.\n",
      " [0.88727673 0.06529464 0.02277412 0.01125091 0.00568839 0.00338902\n",
      " 0.00192852 0.00131014]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'The percentage of total variance in the dataset explained by each',\n",
    "    'component from Sklearn PCA.\\n',\n",
    "    X_pca.explained_variance_ratio_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using PCA, we can see 8 features are closely correlated to the output variable so we will keep them\n",
    "Now we will use these models after doing PCA-\n",
    "\n",
    "1.GridsearchCV\n",
    "\n",
    "2.R-squared\n",
    "\n",
    "3.Mean Square Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 10, 'max_features': 8}]\n",
      "[-0.19501099]\n",
      "[0.86140985]\n",
      "{'max_depth': 10, 'max_features': 8}\n",
      "-0.19501099291853002\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
      "           max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Using Grid search  for finding the best set of parameters with random Forest model\n",
    "dt_grid_pca={'max_depth':[10],'max_features': [8]}\n",
    "grid_DT_pca=model_selection.GridSearchCV(rfc,dt_grid_pca,cv=6)\n",
    "grid_DT_pca.fit(X_train, y_train)\n",
    "\n",
    "#grid_class_pca=model_selection.GridSearchCV(random_f_pca,dt_grid_pca,refit=True,return_train_score=True)\n",
    "#grid_class_pca.fit(X_train_pca, y_train_pca)\n",
    "#Displaying the parameters using Grid search\n",
    "results_pca = grid_DT_pca.cv_results_\n",
    "print(results_pca.get('params'))\n",
    "print(results_pca.get('mean_test_score'))\n",
    "print(results_pca.get('mean_train_score'))\n",
    "print(grid_DT_pca.best_params_)\n",
    "print(grid_DT_pca.best_score_)\n",
    "final_model_pca = grid_DT_pca.best_estimator_\n",
    "print(final_model_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared : 0.8583785303053476\n"
     ]
    }
   ],
   "source": [
    "# Calculating model accuracy using R square\n",
    "print(\"R-squared :\" ,grid_DT_pca.score(X_train,y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the R-squared got 85.8% accuracy.Now we will determine mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  699.2672803347574\n"
     ]
    }
   ],
   "source": [
    "#Validating model accuracy using mean square error\n",
    "\n",
    "y_pred=grid_DT_pca.predict(X_train)\n",
    "print(\"Mean Squared Error: \",metrics.mean_squared_error(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the mean squared error is medium,not so hight not so low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have completed feature selection using PCA where we used grid searchcv , R-squared and mean squared error to check the accuracy.Now we are going to use selectkbest to get the optimum features for  the feature selection and will use the same methods to validate the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Length', 'Wheelbase', 'Year_Resale_Value', 'Price_in_thousands',\n",
       "       'Width', 'Horsepower', 'Power_perf_factor', 'Fuel_capacity'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_indices = 8\n",
    "X_train.columns[indices[:n_indices]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length 8.438299882694018\n",
      "Wheelbase 9.442760665349974\n",
      "Year_Resale_Value 0.032121195318380376\n",
      "Price_in_thousands 3.8193782923248536\n",
      "Width 20.339651897458115\n",
      "Horsepower 3.531395140114711\n",
      "Power_perf_factor 10.998690940404886\n",
      "Fuel_capacity 0.001409436087695959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#selectkbest to get the scores of the best parameters\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=1)\n",
    "names = X_train.columns[indices[:n_indices]]\n",
    "skb_test = SelectKBest(score_func=f_regression,k=n_indices)\n",
    "X_train_kbest = skb_test.fit_transform(X_train, y_train)\n",
    "for n in range(0, len(names)):\n",
    " print(names[n], skb_test.scores_[n])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using selectkbest , we have got 8 best features. Now we will use these methods  to validate the accuracy of the model\n",
    "\n",
    "\n",
    "1.GridsearchCV\n",
    "\n",
    "2.R-squared\n",
    "\n",
    "3.Mean Square Error\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#Gridsearchcv\n",
    "n_indices = 8\n",
    "X_train.columns[indices[:n_indices]]\n",
    "skb = SelectKBest(k=n_indices)\n",
    "skb.fit(X_train, y_train)\n",
    "X_train_skb = skb.transform(X_train)\n",
    "X_test_skb = skb.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually its a good practice to assign max depth as highest as possible.Here we have chose it as 50.Max_features is 11.Now,we will gridsearchcv to get the best set of parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 10, 'max_features': 8}]\n",
      "[-0.19501099]\n",
      "[0.86140985]\n",
      "{'max_depth': 3, 'max_features': 11}\n",
      "0.0012226642847281794\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
      "           max_features=8, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Using Grid search  for finding the best set of parameters with random Forest model\n",
    "\n",
    "dt_grid_skb={'max_depth':[10],'max_features': [11]}\n",
    "grid_DT_skb=model_selection.GridSearchCV(rfc,dt_grid,cv=6)\n",
    "grid_DT_skb.fit(X_train, y_train)\n",
    "\n",
    "#grid_class_pca=model_selection.GridSearchCV(random_f_pca,dt_grid_pca,refit=True,return_train_score=True)\n",
    "#grid_class_pca.fit(X_train_pca, y_train_pca)\n",
    "#Displaying the parameters using Grid search\n",
    "results_skb = grid_DT_pca.cv_results_\n",
    "print(results_skb.get('params'))\n",
    "print(results_skb.get('mean_test_score'))\n",
    "print(results_skb.get('mean_train_score'))\n",
    "print(grid_DT_skb.best_params_)\n",
    "print(grid_DT_skb.best_score_)\n",
    "final_model_pca = grid_DT_pca.best_estimator_\n",
    "print(final_model_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared : 0.5451488180352453\n"
     ]
    }
   ],
   "source": [
    "# Calculate R-squared to get the accuracy\n",
    "print(\"R-squared :\" ,grid_DT_skb.score(X_train,y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The R-squared  accuracy is little low.so looks like PCA is better to get the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  2396.367220549899\n"
     ]
    }
   ],
   "source": [
    "#Validating model accuracy using mean square error\n",
    "\n",
    "y_pred_skb=grid_DT_skb.predict(X_train)\n",
    "print(\"Mean Squared Error: \",metrics.mean_squared_error(y_train,y_pred_skb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The mean squared error here for Seleckbest feature selection came to be on the higher side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:03:46.306687\n"
     ]
    }
   ],
   "source": [
    "#Total time took to run the entire model\n",
    "print(datetime.now()-start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for this model is 86% which is good.But there is overfitting in the variables.We played with the paramters to decrease the overfitting ,it gets reduced a little but never goes away.We used feature selections such as PCA/Selectkbest which provided us more information about the paramters but didn't do that well in accuracy of the mode.Total time to run this model took 4 minutes,so it is not that slow, lets compare it with the Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use Grid searchcv ,Holdout,Cross Validation to validate the accuracy of Decision Tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:458: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  estimator.fit(X_train, y_train, **fit_params)\n",
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:740: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self.best_estimator_.fit(X, y, **fit_params)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise',\n",
       "       estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=10,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=1, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [50], 'max_features': [11]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gridsearchCV to get  the best parameters of the model\n",
    "decision_tree = tree.DecisionTreeRegressor(max_depth=50)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.20)\n",
    "dt_grid={'max_depth':[50],'max_features': [11]}\n",
    "grid_class_dt=model_selection.GridSearchCV(rfc,dt_grid,cv=6)\n",
    "grid_class_dt.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 50, 'max_features': 11}]\n",
      "[-0.09585207]\n",
      "[0.85998853]\n",
      "{'max_depth': 3, 'max_features': 11}\n",
      "0.0007306645747829444\n",
      "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=3,\n",
      "           max_features=11, max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "           verbose=0, warm_start=False)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Displaying the parameters using Grid searchcv\n",
    "results = grid_class_dt.cv_results_\n",
    "print(results.get('params'))\n",
    "print(results.get('mean_test_score'))\n",
    "print(results.get('mean_train_score'))\n",
    "print(grid_class.best_params_)\n",
    "print(grid_class.best_score_)\n",
    "final_model = grid_class.best_estimator_\n",
    "print(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score with 20% Holdout: 0.9983320100163819\n",
      "Testing score with 20% Holdout: -1.8280346912491514\n"
     ]
    }
   ],
   "source": [
    "#Holdout Groups to get the accuracy of the model\n",
    "decision_tree.fit(X_train, y_train)\n",
    "print('Training score with 20% Holdout: ' + str(decision_tree.score(X_train, y_train)))\n",
    "print('Testing score with 20% Holdout: ' + str(decision_tree.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like decision tree accuracy is very high which is 99.9% for the training data.But it looks like we have overfitting for the testing data.If there is any overfitting there is no option to remove it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data accuracy:  [-3.27662965 -0.08601479 -1.08286987 -0.50237446 -0.44275607]\n",
      "Testing Data accuracy:  [-0.57312993 -0.35709988 -4.32987185  0.71389126 -0.48725284]\n"
     ]
    }
   ],
   "source": [
    "#Cross Validation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "print (\"Training Data accuracy: \",cross_val_score(decision_tree, X_train,y_train, cv=5))\n",
    "print (\"Testing Data accuracy: \",cross_val_score(decision_tree, X_test,y_test, cv=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After doing the cross validation,we are seeing overfitting in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.02434791 0.15421578 0.01313339 0.01983086 0.37803859 0.06393907\n",
      " 0.09461163 0.01422038 0.07455922 0.10859569 0.05450748]\n"
     ]
    }
   ],
   "source": [
    "#Displaying the important feature scores\n",
    "print(decision_tree.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will try to get the best number of features as mentioned below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of decisions accounted for with 2 features: 0.5322543663161408\n",
      "Percentage of decisions accounted for with 4 features: 0.7354616840385361\n",
      "Percentage of decisions accounted for with 6 features: 0.8739599764462221\n",
      "Percentage of decisions accounted for with 8 features: 0.9528153654094783\n",
      "Percentage of decisions accounted for with 10 features: 0.9868666063376076\n",
      "Percentage of decisions accounted for with 12 features: 1.0000000000000002\n",
      "Total Features: 11\n"
     ]
    }
   ],
   "source": [
    "# And let's see what percentage of decisions are accounted for with the top X features.\n",
    "importances = decision_tree.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "top_indices = indices[:55]\n",
    "for n_idx in range(2, 14, 2):\n",
    "    print('Percentage of decisions accounted for with {} features: {}'.format(n_idx, importances[indices[:n_idx]].sum()))\n",
    "print('Total Features: ' + str(len(indices)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As noticed above. we have observed that  out of all the features 8 features are the most important ones with  97% of the Decision tree,so we will ignore the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will use PCA for the 8 features to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Wheelbase', 'Price_in_thousands', 'Fuel_efficiency', 'Length',\n",
       "       'Fuel_capacity', 'Width', 'Power_perf_factor', 'Year_Resale_Value'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using PCA\n",
    "n_indices = 8\n",
    "X_train.columns[indices[:n_indices]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = PCA(n_components=8)\n",
    "X_pca.fit(X_train)\n",
    "X_train_pca = X_pca.transform(X_train)\n",
    "X_test_pca = X_pca.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The percentage of total variance in the dataset explained by each component from Sklearn PCA.\n",
      " [0.89263658 0.06091915 0.02342764 0.01054047 0.00516519 0.00300382\n",
      " 0.00236456 0.00100843]\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    'The percentage of total variance in the dataset explained by each',\n",
    "    'component from Sklearn PCA.\\n',\n",
    "    X_pca.explained_variance_ratio_\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above shows that variance explained by 8 variables in the model.It looks like the first variable explains the most in the model and followed by rest of the variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By using PCA, we can see 8 features are closely correlated to the output variable so we will keep them Now we will use these models after doing PCA-\n",
    "\n",
    "1.GridsearchCV\n",
    "\n",
    "2.R-squared\n",
    "\n",
    "3.Mean Square Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 10, 'max_features': 8}]\n",
      "[-0.19501099]\n",
      "[0.86140985]\n",
      "{'max_depth': 10, 'max_features': 8}\n",
      "-0.9096220106387761\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=10, max_features=8,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "#Using Grid search  for finding the best set of parameters with random Forest model\n",
    "dt_grid_pca={'max_depth':[10],'max_features': [8]}\n",
    "grid_dt_pca=model_selection.GridSearchCV(decision_tree,dt_grid_pca,cv=6)\n",
    "grid_dt_pca.fit(X_train, y_train)\n",
    "\n",
    "#grid_class_pca=model_selection.GridSearchCV(random_f_pca,dt_grid_pca,refit=True,return_train_score=True)\n",
    "#grid_class_pca.fit(X_train_pca, y_train_pca)\n",
    "#Displaying the parameters using Grid search\n",
    "results_pca_dt = grid_dt_pca.cv_results_\n",
    "print(results_pca.get('params'))\n",
    "print(results_pca.get('mean_test_score'))\n",
    "print(results_pca.get('mean_train_score'))\n",
    "print(grid_dt_pca.best_params_)\n",
    "print(grid_dt_pca.best_score_)\n",
    "final_model_pca = grid_dt_pca.best_estimator_\n",
    "print(final_model_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared : 0.8791756547134039\n"
     ]
    }
   ],
   "source": [
    "# Calculating model accuracy using R square\n",
    "print(\"R-squared :\" ,grid_dt_pca.score(X_train,y_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the R-squared got 87.9% accuracy which is good.Now we will determine mean square error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  662.7409824046921\n"
     ]
    }
   ],
   "source": [
    "#Validating model accuracy using mean square error\n",
    "\n",
    "y_pred=grid_dt_pca.predict(X_train)\n",
    "print(\"Mean Squared Error: \",metrics.mean_squared_error(y_train,y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the mean squared error is very low."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have completed feature selection using PCA where we used grid searchcv , R-squared and mean squared error to check the accuracy.Now we are going to use selectkbest to get the optimum features for the feature selection and will use the same methods to validate the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Length', 'Year_Resale_Value', 'Horsepower', 'Price_in_thousands',\n",
       "       'Width', 'Wheelbase', 'Power_perf_factor', 'Engine_size'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_indices = 8\n",
    "X_train.columns[indices[:n_indices]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wheelbase 9.811881430592454\n",
      "Price_in_thousands 9.704322194063911\n",
      "Fuel_efficiency 0.2236537612958624\n",
      "Length 3.7185452745498724\n",
      "Fuel_capacity 21.18935199538139\n",
      "Width 4.608615055041465\n",
      "Power_perf_factor 10.534657365839875\n",
      "Year_Resale_Value 0.25822026672355836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "#selectkbest to get the scores of the best parameters\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, Y, random_state=1)\n",
    "names = X_train.columns[indices[:n_indices]]\n",
    "skb_test_dt = SelectKBest(score_func=f_regression,k=n_indices)\n",
    "X_train_kbest = skb_test_dt.fit_transform(X_train, y_train)\n",
    "for n in range(0, len(names)):\n",
    " print(names[n], skb_test_dt.scores_[n])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using selectkbest , we have got 8 best features. Now we will use these methods to validate the accuracy of the model\n",
    "\n",
    "1.GridsearchCV\n",
    "\n",
    "2.R-squared\n",
    "\n",
    "3.Mean Square Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gridsearchcv\n",
    "n_indices = 8\n",
    "X_train.columns[indices[:n_indices]]\n",
    "skb_dt = SelectKBest(k=n_indices)\n",
    "skb_dt.fit(X_train, y_train)\n",
    "X_train_skb = skb_dt.transform(X_train)\n",
    "X_test_skb = skb_dt.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usually its a good practice to assign max depth as highest as possible.Here we have chose it as 50.Max_features is 11.Now,we will gridsearchcv to get the best set of parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'max_depth': 10, 'max_features': 8}]\n",
      "[-0.03784745]\n",
      "[0.85985436]\n",
      "{'max_depth': 50, 'max_features': 11}\n",
      "-0.8352723644127859\n",
      "DecisionTreeRegressor(criterion='mse', max_depth=50, max_features=11,\n",
      "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
      "           min_impurity_split=None, min_samples_leaf=1,\n",
      "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "           presort=False, random_state=None, splitter='best')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\09142640\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    }
   ],
   "source": [
    "dt_grid_skb={'max_depth':[50],'max_features': [11]}\n",
    "grid_dt_skb=model_selection.GridSearchCV(decision_tree,dt_grid,cv=6)\n",
    "grid_dt_skb.fit(X_train, y_train)\n",
    "\n",
    "#grid_class_pca=model_selection.GridSearchCV(random_f_pca,dt_grid_pca,refit=True,return_train_score=True)\n",
    "#grid_class_pca.fit(X_train_pca, y_train_pca)\n",
    "#Displaying the parameters using Grid search\n",
    "results_skb_dt = grid_dt_skb.cv_results_\n",
    "print(results_skb.get('params'))\n",
    "print(results_skb.get('mean_test_score'))\n",
    "print(results_skb.get('mean_train_score'))\n",
    "print(grid_dt_skb.best_params_)\n",
    "print(grid_dt_skb.best_score_)\n",
    "final_model_skb = grid_dt_skb.best_estimator_\n",
    "print(final_model_skb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared : 0.8744979048156781\n"
     ]
    }
   ],
   "source": [
    "# Calculate R-squared to get the accuracy\n",
    "print(\"R-squared :\" ,grid_dt_skb.score(X_train,y_train))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like R-squared is very accurate with accuracy of 87.44%.Now lets go for mean squared error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error:  688.3991935483871\n"
     ]
    }
   ],
   "source": [
    "y_pred_skb=grid_dt_skb.predict(X_train)\n",
    "print(\"Mean Squared Error: \",metrics.mean_squared_error(y_train,y_pred_skb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above,mean squared error is very low as compared to PCA, which means the accuracy is very high if coompared to PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:08:56.415570\n"
     ]
    }
   ],
   "source": [
    "#Total time took to run the entire model\n",
    "print(datetime.now()-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy for this model is 87.4% which is good.Selectkbest provides good accuracy for Decision Tree.But there is overfitting in the variables.We played with the paramters to decrease the overfitting ,it gets reduced a little but never goes away.We used feature selections such as PCA/Selectkbest which provided us more information about the paramters .Total time to run this model took 4 minutes,so it is not that slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model Decision Tree is able to perform  better than Random Forest. The dataset (test and training ) has some overfitting which can be reduced but not eliminated completely. Decision tree was the top scorer, with 0.87 on training data  with R-squrared.Random Forest has the score of 0.858 on training data.Decision tree took more time than Random Forest to run the model where Decision tree took 8 minutes and Random Forest took 3 minutes respectively.Using PCA and SelectKbest, the feature selection was performed and featured were reduced to 8.Since, the score was on the higher side, so we assume that all the 8 features were able to explicitly explain most of the variance in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
